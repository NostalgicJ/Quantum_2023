{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 00m 01s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |16                |rnn_units\n",
      "adam              |sgd               |optimizer\n",
      "0.00029273        |0.00016459        |learning_rate\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Yeojung\\AppData\\Local\\Temp\\__autograph_generated_filek6jy5btg.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (32, 35) and (32, 35, 35) are incompatible\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Yeojung\\AppData\\Local\\Temp\\__autograph_generated_filek6jy5btg.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 35) and (32, 35, 35) are incompatible\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m max_epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[39m# Train the tuner\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m tuner\u001b[39m.\u001b[39;49msearch([theta_train, phi_train], sequence_train, \n\u001b[0;32m     79\u001b[0m              validation_data\u001b[39m=\u001b[39;49m([theta_val, phi_val], sequence_val),\n\u001b[0;32m     80\u001b[0m              epochs\u001b[39m=\u001b[39;49mmax_epochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[0;32m     82\u001b[0m \u001b[39m# 최적의 하이퍼파라미터를 가진 모델 가져오기\u001b[39;00m\n\u001b[0;32m     83\u001b[0m best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_models(num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:335\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_trial_end\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[0;32m    330\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \n\u001b[0;32m    332\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mend_trial(trial)\n\u001b[0;32m    336\u001b[0m     \u001b[39m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display\u001b[39m.\u001b[39mon_trial_end(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:107\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    106\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[1;32m--> 107\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[0;32m    109\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:434\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry(trial):\n\u001b[0;32m    433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_order\u001b[39m.\u001b[39mappend(trial\u001b[39m.\u001b[39mtrial_id)\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_consecutive_failures()\n\u001b[0;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:386\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m     consecutive_failures \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m consecutive_failures \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    387\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of consecutive failures excceeded the limit \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    388\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m+\u001b[39m trial\u001b[39m.\u001b[39mmessage\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Yeojung\\AppData\\Local\\Temp\\__autograph_generated_filek6jy5btg.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 35) and (32, 35, 35) are incompatible\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Concatenate, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('NVspinData_None_-1_230807.csv')\n",
    "\n",
    "# 전체 데이터셋에서 시퀀스 중에서 최대 길이 구하기\n",
    "all_sequences = df['combination'].apply(eval).tolist()\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 데이터셋 분리\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 준비\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "# 모델 생성 함수\n",
    "def build_rnn_model(hp):\n",
    "    # Inputs\n",
    "    theta_input = Input(shape=(1,), name='theta_input')\n",
    "    phi_input = Input(shape=(1,), name='phi_input')\n",
    "    \n",
    "    merged = Concatenate()([theta_input, phi_input])\n",
    "    \n",
    "    repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "    \n",
    "    # SimpleRNN Layer\n",
    "    rnn_units = hp.Int('rnn_units', min_value=16, max_value=128, step=16)\n",
    "    rnn_layer = SimpleRNN(units=rnn_units, return_sequences=True)(repeated_vector)\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Dense(max_seq_length, activation='softmax')(rnn_layer)\n",
    "\n",
    "    model = Model(inputs=[theta_input, phi_input], outputs=output_layer)\n",
    "\n",
    "    # Optimizer choice\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3))\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_rnn_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='keras_tuner_bayesian_rnn'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "max_epochs = 30\n",
    "# Train the tuner\n",
    "tuner.search([theta_train, phi_train], sequence_train, \n",
    "             validation_data=([theta_val, phi_val], sequence_val),\n",
    "             epochs=max_epochs, batch_size=32)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 가진 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 검증\n",
    "val_predictions = best_model.predict([theta_val, phi_val])\n",
    "# 임의로 테스트 샘플 5개 확인\n",
    "indices = np.random.choice(len(theta_test), 5, replace=False)\n",
    "for i in indices:\n",
    "    print(f\"Theta: {theta_test[i]}, Phi: {phi_test[i]}\")\n",
    "    print(\"Actual Sequence:\", sequence_test[i])\n",
    "    print(\"Predicted Sequence:\", np.argmax(val_predictions[i], axis=-1))\n",
    "    print(\"----\")\n",
    "\n",
    "# 훈련 과정 그래프로 확인\n",
    "history = best_model.fit([theta_train, phi_train], np.array(sequence_train),\n",
    "                         validation_data=([theta_val, phi_val], np.array(sequence_val)),\n",
    "                         epochs=10, batch_size=32)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
