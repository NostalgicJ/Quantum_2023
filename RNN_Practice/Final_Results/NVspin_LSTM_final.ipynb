{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../../Data/using/dt_2.6/ByAstar_dt_2.6_modified.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "87/87 [==============================] - 13s 129ms/step - loss: 1.0038 - accuracy: 0.5677 - val_loss: 0.9053 - val_accuracy: 0.5792\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.8820 - accuracy: 0.5883 - val_loss: 0.8832 - val_accuracy: 0.5873\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 0.8602 - accuracy: 0.5917 - val_loss: 0.8838 - val_accuracy: 0.5814\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.8348 - accuracy: 0.6100 - val_loss: 0.8038 - val_accuracy: 0.6669\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.7054 - accuracy: 0.7175 - val_loss: 0.5455 - val_accuracy: 0.7912\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.4465 - accuracy: 0.8339 - val_loss: 0.3702 - val_accuracy: 0.8691\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.3736 - accuracy: 0.8614 - val_loss: 0.4186 - val_accuracy: 0.8351\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.3687 - accuracy: 0.8594 - val_loss: 0.4284 - val_accuracy: 0.8195\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.3505 - accuracy: 0.8679 - val_loss: 0.3324 - val_accuracy: 0.8819\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.3331 - accuracy: 0.8771 - val_loss: 0.3398 - val_accuracy: 0.8735\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.3322 - accuracy: 0.8746 - val_loss: 0.3124 - val_accuracy: 0.8917\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.3113 - accuracy: 0.8865 - val_loss: 0.3722 - val_accuracy: 0.8728\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.3214 - accuracy: 0.8784 - val_loss: 0.3268 - val_accuracy: 0.8754\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.3025 - accuracy: 0.8889 - val_loss: 0.3139 - val_accuracy: 0.8809\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.3117 - accuracy: 0.8828 - val_loss: 0.2932 - val_accuracy: 0.8916\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.2955 - accuracy: 0.8874 - val_loss: 0.3096 - val_accuracy: 0.8816\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.3008 - accuracy: 0.8846 - val_loss: 0.3477 - val_accuracy: 0.8634\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2908 - accuracy: 0.8883 - val_loss: 0.2909 - val_accuracy: 0.8883\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.2942 - accuracy: 0.8861 - val_loss: 0.3445 - val_accuracy: 0.8653\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2874 - accuracy: 0.8900 - val_loss: 0.2742 - val_accuracy: 0.8932\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2814 - accuracy: 0.8910 - val_loss: 0.3789 - val_accuracy: 0.8453\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2894 - accuracy: 0.8873 - val_loss: 0.3911 - val_accuracy: 0.8483\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.2953 - accuracy: 0.8860 - val_loss: 0.2679 - val_accuracy: 0.8999\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2865 - accuracy: 0.8884 - val_loss: 0.2793 - val_accuracy: 0.8873\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2777 - accuracy: 0.8929 - val_loss: 0.2891 - val_accuracy: 0.8853\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2730 - accuracy: 0.8928 - val_loss: 0.2913 - val_accuracy: 0.8834\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2740 - accuracy: 0.8924 - val_loss: 0.2624 - val_accuracy: 0.8971\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2741 - accuracy: 0.8915 - val_loss: 0.2716 - val_accuracy: 0.8945\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2641 - accuracy: 0.8976 - val_loss: 0.2636 - val_accuracy: 0.8976\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.2653 - accuracy: 0.8959 - val_loss: 0.2613 - val_accuracy: 0.8976\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.2616 - accuracy: 0.8977 - val_loss: 0.2901 - val_accuracy: 0.8865\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2687 - accuracy: 0.8940 - val_loss: 0.3526 - val_accuracy: 0.8577\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2825 - accuracy: 0.8874 - val_loss: 0.2778 - val_accuracy: 0.8942\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.2651 - accuracy: 0.8957 - val_loss: 0.2897 - val_accuracy: 0.8827\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2620 - accuracy: 0.8964 - val_loss: 0.3032 - val_accuracy: 0.8862\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.2621 - accuracy: 0.8975 - val_loss: 0.2760 - val_accuracy: 0.8940\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2624 - accuracy: 0.8962 - val_loss: 0.3182 - val_accuracy: 0.8731\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2612 - accuracy: 0.8969 - val_loss: 0.3407 - val_accuracy: 0.8625\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.2672 - accuracy: 0.8937 - val_loss: 0.2520 - val_accuracy: 0.8998\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2589 - accuracy: 0.8976 - val_loss: 0.2642 - val_accuracy: 0.8974\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2572 - accuracy: 0.8988 - val_loss: 0.2660 - val_accuracy: 0.8932\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2720 - accuracy: 0.8908 - val_loss: 0.2572 - val_accuracy: 0.9007\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2539 - accuracy: 0.9002 - val_loss: 0.2785 - val_accuracy: 0.8882\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2581 - accuracy: 0.8980 - val_loss: 0.2538 - val_accuracy: 0.8971\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2489 - accuracy: 0.9013 - val_loss: 0.2521 - val_accuracy: 0.8997\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 14s 167ms/step - loss: 0.2545 - accuracy: 0.8993 - val_loss: 0.2864 - val_accuracy: 0.8838\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2707 - accuracy: 0.8927 - val_loss: 0.2540 - val_accuracy: 0.8990\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2544 - accuracy: 0.8989 - val_loss: 0.2511 - val_accuracy: 0.9008\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.2614 - accuracy: 0.8966 - val_loss: 0.2648 - val_accuracy: 0.8941\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2534 - accuracy: 0.8992 - val_loss: 0.2890 - val_accuracy: 0.8832\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2549 - accuracy: 0.8998 - val_loss: 0.2511 - val_accuracy: 0.9014\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2485 - accuracy: 0.9012 - val_loss: 0.2562 - val_accuracy: 0.8996\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2507 - accuracy: 0.9009 - val_loss: 0.2515 - val_accuracy: 0.8996\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2489 - accuracy: 0.9012 - val_loss: 0.2585 - val_accuracy: 0.8951\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2476 - accuracy: 0.9018 - val_loss: 0.2377 - val_accuracy: 0.9037\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2447 - accuracy: 0.9025 - val_loss: 0.2487 - val_accuracy: 0.9013\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2426 - accuracy: 0.9024 - val_loss: 0.2656 - val_accuracy: 0.8948\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2393 - accuracy: 0.9040 - val_loss: 0.2342 - val_accuracy: 0.9057\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2545 - accuracy: 0.8984 - val_loss: 0.2597 - val_accuracy: 0.8976\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2459 - accuracy: 0.9016 - val_loss: 0.2719 - val_accuracy: 0.8912\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2427 - accuracy: 0.9029 - val_loss: 0.2441 - val_accuracy: 0.9010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2439 - accuracy: 0.9027 - val_loss: 0.2302 - val_accuracy: 0.9080\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2393 - accuracy: 0.9045 - val_loss: 0.2486 - val_accuracy: 0.8985\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2425 - accuracy: 0.9033 - val_loss: 0.2713 - val_accuracy: 0.8898\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2391 - accuracy: 0.9038 - val_loss: 0.2453 - val_accuracy: 0.8986\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2411 - accuracy: 0.9023 - val_loss: 0.2688 - val_accuracy: 0.8937\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2391 - accuracy: 0.9047 - val_loss: 0.2779 - val_accuracy: 0.8919\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2407 - accuracy: 0.9037 - val_loss: 0.2352 - val_accuracy: 0.9042\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2390 - accuracy: 0.9029 - val_loss: 0.2525 - val_accuracy: 0.8955\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2394 - accuracy: 0.9029 - val_loss: 0.2624 - val_accuracy: 0.8932\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2373 - accuracy: 0.9033 - val_loss: 0.2283 - val_accuracy: 0.9069\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2324 - accuracy: 0.9060 - val_loss: 0.2407 - val_accuracy: 0.9028\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2294 - accuracy: 0.9077 - val_loss: 0.2486 - val_accuracy: 0.9015\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2382 - accuracy: 0.9031 - val_loss: 0.2375 - val_accuracy: 0.9035\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2346 - accuracy: 0.9048 - val_loss: 0.2274 - val_accuracy: 0.9072\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2320 - accuracy: 0.9058 - val_loss: 0.2486 - val_accuracy: 0.8988\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2337 - accuracy: 0.9044 - val_loss: 0.2396 - val_accuracy: 0.9029\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2351 - accuracy: 0.9047 - val_loss: 0.2300 - val_accuracy: 0.9070\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2275 - accuracy: 0.9074 - val_loss: 0.2353 - val_accuracy: 0.9032\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2286 - accuracy: 0.9066 - val_loss: 0.2398 - val_accuracy: 0.9008\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2260 - accuracy: 0.9079 - val_loss: 0.2348 - val_accuracy: 0.9060\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2309 - accuracy: 0.9061 - val_loss: 0.2311 - val_accuracy: 0.9062\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2301 - accuracy: 0.9064 - val_loss: 0.2315 - val_accuracy: 0.9069\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2232 - accuracy: 0.9096 - val_loss: 0.2297 - val_accuracy: 0.9058\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2337 - accuracy: 0.9048 - val_loss: 0.2244 - val_accuracy: 0.9079\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2249 - accuracy: 0.9083 - val_loss: 0.2506 - val_accuracy: 0.8976\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2320 - accuracy: 0.9043 - val_loss: 0.2208 - val_accuracy: 0.9095\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2347 - accuracy: 0.9041 - val_loss: 0.2314 - val_accuracy: 0.9044\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2239 - accuracy: 0.9076 - val_loss: 0.2415 - val_accuracy: 0.8986\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2347 - accuracy: 0.9042 - val_loss: 0.2423 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2295 - accuracy: 0.9063 - val_loss: 0.2478 - val_accuracy: 0.8969\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2261 - accuracy: 0.9078 - val_loss: 0.2261 - val_accuracy: 0.9068\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2242 - accuracy: 0.9077 - val_loss: 0.2226 - val_accuracy: 0.9074\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2172 - accuracy: 0.9098 - val_loss: 0.2430 - val_accuracy: 0.8983\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2352 - accuracy: 0.9038 - val_loss: 0.2437 - val_accuracy: 0.9004\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2249 - accuracy: 0.9071 - val_loss: 0.2395 - val_accuracy: 0.9020\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2211 - accuracy: 0.9084 - val_loss: 0.2169 - val_accuracy: 0.9092\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2200 - accuracy: 0.9096 - val_loss: 0.3020 - val_accuracy: 0.8852\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 0.2301 - val_accuracy: 0.9032\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2207 - accuracy: 0.9082 - val_loss: 0.2205 - val_accuracy: 0.9092\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2204 - accuracy: 0.9087 - val_loss: 0.2220 - val_accuracy: 0.9090\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2192 - accuracy: 0.9101 - val_loss: 0.2193 - val_accuracy: 0.9086\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.2191 - accuracy: 0.9098 - val_loss: 0.2209 - val_accuracy: 0.9080\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.2139 - accuracy: 0.9113 - val_loss: 0.2186 - val_accuracy: 0.9079\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2121 - accuracy: 0.9114 - val_loss: 0.2232 - val_accuracy: 0.9078\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2182 - accuracy: 0.9102 - val_loss: 0.2277 - val_accuracy: 0.9068\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2129 - accuracy: 0.9120 - val_loss: 0.2240 - val_accuracy: 0.9054\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2221 - accuracy: 0.9079 - val_loss: 0.2128 - val_accuracy: 0.9117\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2135 - accuracy: 0.9116 - val_loss: 0.2140 - val_accuracy: 0.9120\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2162 - accuracy: 0.9097 - val_loss: 0.2278 - val_accuracy: 0.9048\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2199 - accuracy: 0.9084 - val_loss: 0.2213 - val_accuracy: 0.9080\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2207 - accuracy: 0.9083 - val_loss: 0.2233 - val_accuracy: 0.9073\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2100 - accuracy: 0.9132 - val_loss: 0.2290 - val_accuracy: 0.9044\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2171 - accuracy: 0.9095 - val_loss: 0.2127 - val_accuracy: 0.9114\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2176 - accuracy: 0.9104 - val_loss: 0.2615 - val_accuracy: 0.8920\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.2212 - accuracy: 0.9079 - val_loss: 0.2113 - val_accuracy: 0.9127\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.2132 - accuracy: 0.9108 - val_loss: 0.2091 - val_accuracy: 0.9139\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2116 - accuracy: 0.9113 - val_loss: 0.2090 - val_accuracy: 0.9125\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2148 - accuracy: 0.9102 - val_loss: 0.2192 - val_accuracy: 0.9091\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2156 - accuracy: 0.9099 - val_loss: 0.2125 - val_accuracy: 0.9107\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2085 - accuracy: 0.9127 - val_loss: 0.2300 - val_accuracy: 0.9056\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2102 - accuracy: 0.9122 - val_loss: 0.2080 - val_accuracy: 0.9143\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2159 - accuracy: 0.9108 - val_loss: 0.2177 - val_accuracy: 0.9090\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2150 - accuracy: 0.9103 - val_loss: 0.2177 - val_accuracy: 0.9078\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2045 - accuracy: 0.9146 - val_loss: 0.2010 - val_accuracy: 0.9165\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.2049 - accuracy: 0.9145 - val_loss: 0.2147 - val_accuracy: 0.9107\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2118 - accuracy: 0.9119 - val_loss: 0.2069 - val_accuracy: 0.9142\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2020 - accuracy: 0.9146 - val_loss: 0.2059 - val_accuracy: 0.9138\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2174 - accuracy: 0.9083 - val_loss: 0.2214 - val_accuracy: 0.9074\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.2095 - accuracy: 0.9124 - val_loss: 0.2226 - val_accuracy: 0.9081\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2113 - accuracy: 0.9108 - val_loss: 0.2363 - val_accuracy: 0.9014\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2202 - accuracy: 0.9083 - val_loss: 0.2089 - val_accuracy: 0.9120\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2056 - accuracy: 0.9132 - val_loss: 0.2307 - val_accuracy: 0.9037\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2068 - accuracy: 0.9135 - val_loss: 0.2104 - val_accuracy: 0.9124\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2007 - accuracy: 0.9159 - val_loss: 0.2139 - val_accuracy: 0.9092\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2136 - accuracy: 0.9106 - val_loss: 0.2012 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.2101 - accuracy: 0.9119 - val_loss: 0.2063 - val_accuracy: 0.9141\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.2007 - accuracy: 0.9161 - val_loss: 0.2017 - val_accuracy: 0.9138\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.2019 - accuracy: 0.9151 - val_loss: 0.2307 - val_accuracy: 0.9081\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.2088 - accuracy: 0.9119 - val_loss: 0.2177 - val_accuracy: 0.9081\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.2050 - accuracy: 0.9140 - val_loss: 0.2115 - val_accuracy: 0.9139\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2010 - accuracy: 0.9159 - val_loss: 0.2097 - val_accuracy: 0.9117\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1995 - accuracy: 0.9159 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2004 - accuracy: 0.9156 - val_loss: 0.2064 - val_accuracy: 0.9127\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.2040 - accuracy: 0.9135 - val_loss: 0.2229 - val_accuracy: 0.9061\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2048 - accuracy: 0.9136 - val_loss: 0.2143 - val_accuracy: 0.9094\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1970 - accuracy: 0.9164 - val_loss: 0.2081 - val_accuracy: 0.9117\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.2075 - accuracy: 0.9128 - val_loss: 0.2334 - val_accuracy: 0.9049\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2014 - accuracy: 0.9149 - val_loss: 0.2134 - val_accuracy: 0.9105\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2079 - accuracy: 0.9118 - val_loss: 0.2271 - val_accuracy: 0.9042\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.2028 - accuracy: 0.9145 - val_loss: 0.2127 - val_accuracy: 0.9102\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 0.1976 - accuracy: 0.9172 - val_loss: 0.2035 - val_accuracy: 0.9134\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2008 - accuracy: 0.9154 - val_loss: 0.2022 - val_accuracy: 0.9156\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1977 - accuracy: 0.9162 - val_loss: 0.1996 - val_accuracy: 0.9161\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1979 - accuracy: 0.9160 - val_loss: 0.2099 - val_accuracy: 0.9105\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 0.2144 - accuracy: 0.9106 - val_loss: 0.2086 - val_accuracy: 0.9112\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1944 - accuracy: 0.9180 - val_loss: 0.1968 - val_accuracy: 0.9161\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.2046 - accuracy: 0.9139 - val_loss: 0.2297 - val_accuracy: 0.9043\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1953 - accuracy: 0.9180 - val_loss: 0.2030 - val_accuracy: 0.9137\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1945 - accuracy: 0.9170 - val_loss: 0.2249 - val_accuracy: 0.9048\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.2017 - accuracy: 0.9159 - val_loss: 0.2026 - val_accuracy: 0.9142\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1925 - accuracy: 0.9184 - val_loss: 0.2233 - val_accuracy: 0.9060\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1961 - accuracy: 0.9166 - val_loss: 0.2215 - val_accuracy: 0.9066\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1992 - accuracy: 0.9157 - val_loss: 0.1999 - val_accuracy: 0.9146\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.2018 - accuracy: 0.9141 - val_loss: 0.2354 - val_accuracy: 0.9006\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1933 - accuracy: 0.9178 - val_loss: 0.2033 - val_accuracy: 0.9144\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1899 - accuracy: 0.9190 - val_loss: 0.2088 - val_accuracy: 0.9118\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1960 - accuracy: 0.9172 - val_loss: 0.2221 - val_accuracy: 0.9072\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1990 - accuracy: 0.9163 - val_loss: 0.2074 - val_accuracy: 0.9119\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1936 - accuracy: 0.9177 - val_loss: 0.2192 - val_accuracy: 0.9083\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1928 - accuracy: 0.9182 - val_loss: 0.2140 - val_accuracy: 0.9087\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1935 - accuracy: 0.9177 - val_loss: 0.2078 - val_accuracy: 0.9129\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1948 - accuracy: 0.9167 - val_loss: 0.2221 - val_accuracy: 0.9102\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.2062 - accuracy: 0.9132 - val_loss: 0.1982 - val_accuracy: 0.9168\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1927 - accuracy: 0.9183 - val_loss: 0.2030 - val_accuracy: 0.9125\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1989 - accuracy: 0.9152 - val_loss: 0.1976 - val_accuracy: 0.9155\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1931 - accuracy: 0.9175 - val_loss: 0.1993 - val_accuracy: 0.9139\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1944 - accuracy: 0.9161 - val_loss: 0.2052 - val_accuracy: 0.9143\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1913 - accuracy: 0.9182 - val_loss: 0.1929 - val_accuracy: 0.9176\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1869 - accuracy: 0.9195 - val_loss: 0.2107 - val_accuracy: 0.9129\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1987 - accuracy: 0.9165 - val_loss: 0.2171 - val_accuracy: 0.9077\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1909 - accuracy: 0.9175 - val_loss: 0.2028 - val_accuracy: 0.9125\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.2013 - accuracy: 0.9145 - val_loss: 0.2114 - val_accuracy: 0.9111\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.2026 - accuracy: 0.9142 - val_loss: 0.1963 - val_accuracy: 0.9166\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1887 - accuracy: 0.9188 - val_loss: 0.2001 - val_accuracy: 0.9161\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1911 - accuracy: 0.9185 - val_loss: 0.1923 - val_accuracy: 0.9184\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1943 - accuracy: 0.9173 - val_loss: 0.2025 - val_accuracy: 0.9154\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1875 - accuracy: 0.9193 - val_loss: 0.1997 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1839 - accuracy: 0.9203 - val_loss: 0.1959 - val_accuracy: 0.9155\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1946 - accuracy: 0.9177 - val_loss: 0.2072 - val_accuracy: 0.9108\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1873 - accuracy: 0.9198 - val_loss: 0.1975 - val_accuracy: 0.9145\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1823 - accuracy: 0.9217 - val_loss: 0.1890 - val_accuracy: 0.9193\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1867 - accuracy: 0.9210 - val_loss: 0.2109 - val_accuracy: 0.9119\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1952 - accuracy: 0.9172 - val_loss: 0.1894 - val_accuracy: 0.9186\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1847 - accuracy: 0.9215 - val_loss: 0.1981 - val_accuracy: 0.9149\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1857 - accuracy: 0.9201 - val_loss: 0.2129 - val_accuracy: 0.9105\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1897 - accuracy: 0.9185 - val_loss: 0.1982 - val_accuracy: 0.9159\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1891 - accuracy: 0.9194 - val_loss: 0.1921 - val_accuracy: 0.9178\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.1938 - val_accuracy: 0.9166\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1876 - accuracy: 0.9194 - val_loss: 0.2023 - val_accuracy: 0.9125\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1880 - accuracy: 0.9196 - val_loss: 0.2164 - val_accuracy: 0.9117\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2060 - accuracy: 0.9128 - val_loss: 0.2003 - val_accuracy: 0.9134\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1814 - accuracy: 0.9216 - val_loss: 0.1920 - val_accuracy: 0.9170\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1883 - accuracy: 0.9190 - val_loss: 0.2004 - val_accuracy: 0.9133\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1861 - accuracy: 0.9205 - val_loss: 0.1887 - val_accuracy: 0.9184\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1841 - accuracy: 0.9207 - val_loss: 0.2153 - val_accuracy: 0.9084\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1844 - accuracy: 0.9206 - val_loss: 0.2046 - val_accuracy: 0.9111\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1824 - accuracy: 0.9216 - val_loss: 0.2308 - val_accuracy: 0.9034\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1902 - accuracy: 0.9183 - val_loss: 0.2322 - val_accuracy: 0.9076\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.2046 - accuracy: 0.9129 - val_loss: 0.2224 - val_accuracy: 0.9074\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.2048 - accuracy: 0.9137 - val_loss: 0.1951 - val_accuracy: 0.9163\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1840 - accuracy: 0.9202 - val_loss: 0.2075 - val_accuracy: 0.9101\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1815 - accuracy: 0.9219 - val_loss: 0.1966 - val_accuracy: 0.9152\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1867 - accuracy: 0.9192 - val_loss: 0.2049 - val_accuracy: 0.9117\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1838 - accuracy: 0.9205 - val_loss: 0.2145 - val_accuracy: 0.9092\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1876 - accuracy: 0.9183 - val_loss: 0.2114 - val_accuracy: 0.9089\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1866 - accuracy: 0.9201 - val_loss: 0.1990 - val_accuracy: 0.9157\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1797 - accuracy: 0.9226 - val_loss: 0.1924 - val_accuracy: 0.9186\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1816 - accuracy: 0.9222 - val_loss: 0.1862 - val_accuracy: 0.9195\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1768 - accuracy: 0.9237 - val_loss: 0.1938 - val_accuracy: 0.9162\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1929 - accuracy: 0.9173 - val_loss: 0.1923 - val_accuracy: 0.9166\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1888 - accuracy: 0.9192 - val_loss: 0.2002 - val_accuracy: 0.9129\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1811 - accuracy: 0.9211 - val_loss: 0.1898 - val_accuracy: 0.9191\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1833 - accuracy: 0.9208 - val_loss: 0.2131 - val_accuracy: 0.9098\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1904 - accuracy: 0.9177 - val_loss: 0.2107 - val_accuracy: 0.9084\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1788 - accuracy: 0.9222 - val_loss: 0.2030 - val_accuracy: 0.9141\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1797 - accuracy: 0.9220 - val_loss: 0.1852 - val_accuracy: 0.9212\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1789 - accuracy: 0.9227 - val_loss: 0.2435 - val_accuracy: 0.9082\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1897 - accuracy: 0.9190 - val_loss: 0.1921 - val_accuracy: 0.9177\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1822 - accuracy: 0.9209 - val_loss: 0.1939 - val_accuracy: 0.9164\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1852 - accuracy: 0.9213 - val_loss: 0.2004 - val_accuracy: 0.9141\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1793 - accuracy: 0.9226 - val_loss: 0.1886 - val_accuracy: 0.9181\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1786 - accuracy: 0.9221 - val_loss: 0.1921 - val_accuracy: 0.9175\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1775 - accuracy: 0.9231 - val_loss: 0.2114 - val_accuracy: 0.9112\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1794 - accuracy: 0.9223 - val_loss: 0.1978 - val_accuracy: 0.9148\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1825 - accuracy: 0.9202 - val_loss: 0.1867 - val_accuracy: 0.9199\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1795 - accuracy: 0.9226 - val_loss: 0.2011 - val_accuracy: 0.9125\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1779 - accuracy: 0.9233 - val_loss: 0.1996 - val_accuracy: 0.9150\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1873 - accuracy: 0.9194 - val_loss: 0.1980 - val_accuracy: 0.9162\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1799 - accuracy: 0.9211 - val_loss: 0.2111 - val_accuracy: 0.9096\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1888 - accuracy: 0.9190 - val_loss: 0.2003 - val_accuracy: 0.9130\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1809 - accuracy: 0.9218 - val_loss: 0.1855 - val_accuracy: 0.9201\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1749 - accuracy: 0.9246 - val_loss: 0.1891 - val_accuracy: 0.9185\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1754 - accuracy: 0.9234 - val_loss: 0.1855 - val_accuracy: 0.9192\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1841 - accuracy: 0.9203 - val_loss: 0.1919 - val_accuracy: 0.9175\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1805 - accuracy: 0.9211 - val_loss: 0.1978 - val_accuracy: 0.9155\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1803 - accuracy: 0.9209 - val_loss: 0.2121 - val_accuracy: 0.9131\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1822 - accuracy: 0.9212 - val_loss: 0.1964 - val_accuracy: 0.9147\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1834 - accuracy: 0.9215 - val_loss: 0.2504 - val_accuracy: 0.8984\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1833 - accuracy: 0.9210 - val_loss: 0.1888 - val_accuracy: 0.9191\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1821 - accuracy: 0.9213 - val_loss: 0.1888 - val_accuracy: 0.9179\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1763 - accuracy: 0.9228 - val_loss: 0.1903 - val_accuracy: 0.9175\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1833 - accuracy: 0.9203 - val_loss: 0.1877 - val_accuracy: 0.9187\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1840 - accuracy: 0.9199 - val_loss: 0.1837 - val_accuracy: 0.9200\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1792 - accuracy: 0.9219 - val_loss: 0.1815 - val_accuracy: 0.9226\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1734 - accuracy: 0.9243 - val_loss: 0.1878 - val_accuracy: 0.9200\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1764 - accuracy: 0.9230 - val_loss: 0.2009 - val_accuracy: 0.9145\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1777 - accuracy: 0.9230 - val_loss: 0.2108 - val_accuracy: 0.9137\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1843 - accuracy: 0.9207 - val_loss: 0.2244 - val_accuracy: 0.9074\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1761 - accuracy: 0.9236 - val_loss: 0.1823 - val_accuracy: 0.9215\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1745 - accuracy: 0.9244 - val_loss: 0.1872 - val_accuracy: 0.9208\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1771 - accuracy: 0.9234 - val_loss: 0.1865 - val_accuracy: 0.9206\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1741 - accuracy: 0.9241 - val_loss: 0.2075 - val_accuracy: 0.9112\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1703 - accuracy: 0.9256 - val_loss: 0.2119 - val_accuracy: 0.9114\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1855 - accuracy: 0.9201 - val_loss: 0.1854 - val_accuracy: 0.9203\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1715 - accuracy: 0.9253 - val_loss: 0.1816 - val_accuracy: 0.9218\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1746 - accuracy: 0.9244 - val_loss: 0.1944 - val_accuracy: 0.9164\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1782 - accuracy: 0.9219 - val_loss: 0.1869 - val_accuracy: 0.9192\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1840 - accuracy: 0.9203 - val_loss: 0.1855 - val_accuracy: 0.9212\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1731 - accuracy: 0.9241 - val_loss: 0.1835 - val_accuracy: 0.9219\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1742 - accuracy: 0.9247 - val_loss: 0.2133 - val_accuracy: 0.9100\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1812 - accuracy: 0.9218 - val_loss: 0.1861 - val_accuracy: 0.9192\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1701 - accuracy: 0.9258 - val_loss: 0.1892 - val_accuracy: 0.9175\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1709 - accuracy: 0.9251 - val_loss: 0.1823 - val_accuracy: 0.9216\n",
      "Epoch 275/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1726 - accuracy: 0.9245 - val_loss: 0.1847 - val_accuracy: 0.9193\n",
      "Epoch 276/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1740 - accuracy: 0.9246 - val_loss: 0.2031 - val_accuracy: 0.9108\n",
      "Epoch 277/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1766 - accuracy: 0.9235 - val_loss: 0.2372 - val_accuracy: 0.9035\n",
      "Epoch 278/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1754 - accuracy: 0.9240 - val_loss: 0.2108 - val_accuracy: 0.9115\n",
      "Epoch 279/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1747 - accuracy: 0.9243 - val_loss: 0.1852 - val_accuracy: 0.9202\n",
      "Epoch 280/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1696 - accuracy: 0.9254 - val_loss: 0.1805 - val_accuracy: 0.9214\n",
      "Epoch 281/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1710 - accuracy: 0.9253 - val_loss: 0.1847 - val_accuracy: 0.9203\n",
      "Epoch 282/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1741 - accuracy: 0.9241 - val_loss: 0.2485 - val_accuracy: 0.9019\n",
      "Epoch 283/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1770 - accuracy: 0.9233 - val_loss: 0.1907 - val_accuracy: 0.9185\n",
      "Epoch 284/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1712 - accuracy: 0.9251 - val_loss: 0.1852 - val_accuracy: 0.9206\n",
      "Epoch 285/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1709 - accuracy: 0.9249 - val_loss: 0.1787 - val_accuracy: 0.9210\n",
      "Epoch 286/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1717 - accuracy: 0.9245 - val_loss: 0.2077 - val_accuracy: 0.9116\n",
      "Epoch 287/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1713 - accuracy: 0.9248 - val_loss: 0.1839 - val_accuracy: 0.9213\n",
      "Epoch 288/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1681 - accuracy: 0.9267 - val_loss: 0.1894 - val_accuracy: 0.9181\n",
      "Epoch 289/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1676 - accuracy: 0.9266 - val_loss: 0.1940 - val_accuracy: 0.9167\n",
      "Epoch 290/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1795 - accuracy: 0.9235 - val_loss: 0.2013 - val_accuracy: 0.9146\n",
      "Epoch 291/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1693 - accuracy: 0.9263 - val_loss: 0.1855 - val_accuracy: 0.9201\n",
      "Epoch 292/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1711 - accuracy: 0.9263 - val_loss: 0.1983 - val_accuracy: 0.9172\n",
      "Epoch 293/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1766 - accuracy: 0.9229 - val_loss: 0.1982 - val_accuracy: 0.9150\n",
      "Epoch 294/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1671 - accuracy: 0.9265 - val_loss: 0.1762 - val_accuracy: 0.9225\n",
      "Epoch 295/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1679 - accuracy: 0.9268 - val_loss: 0.1996 - val_accuracy: 0.9160\n",
      "Epoch 296/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1667 - accuracy: 0.9268 - val_loss: 0.1813 - val_accuracy: 0.9208\n",
      "Epoch 297/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1670 - accuracy: 0.9258 - val_loss: 0.1933 - val_accuracy: 0.9169\n",
      "Epoch 298/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1772 - accuracy: 0.9228 - val_loss: 0.1984 - val_accuracy: 0.9138\n",
      "Epoch 299/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1726 - accuracy: 0.9242 - val_loss: 0.1857 - val_accuracy: 0.9184\n",
      "Epoch 300/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1710 - accuracy: 0.9256 - val_loss: 0.1992 - val_accuracy: 0.9156\n",
      "Epoch 301/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1669 - accuracy: 0.9270 - val_loss: 0.1880 - val_accuracy: 0.9183\n",
      "Epoch 302/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1668 - accuracy: 0.9271 - val_loss: 0.1889 - val_accuracy: 0.9175\n",
      "Epoch 303/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1670 - accuracy: 0.9267 - val_loss: 0.1858 - val_accuracy: 0.9183\n",
      "Epoch 304/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1717 - accuracy: 0.9249 - val_loss: 0.1911 - val_accuracy: 0.9174\n",
      "Epoch 305/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1712 - accuracy: 0.9251 - val_loss: 0.1913 - val_accuracy: 0.9167\n",
      "Epoch 306/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1662 - accuracy: 0.9273 - val_loss: 0.1810 - val_accuracy: 0.9214\n",
      "Epoch 307/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1746 - accuracy: 0.9248 - val_loss: 0.1837 - val_accuracy: 0.9211\n",
      "Epoch 308/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1739 - accuracy: 0.9243 - val_loss: 0.1945 - val_accuracy: 0.9153\n",
      "Epoch 309/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1709 - accuracy: 0.9256 - val_loss: 0.1919 - val_accuracy: 0.9144\n",
      "Epoch 310/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1667 - accuracy: 0.9262 - val_loss: 0.1757 - val_accuracy: 0.9237\n",
      "Epoch 311/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1651 - accuracy: 0.9278 - val_loss: 0.1853 - val_accuracy: 0.9191\n",
      "Epoch 312/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1663 - accuracy: 0.9268 - val_loss: 0.1849 - val_accuracy: 0.9187\n",
      "Epoch 313/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1602 - accuracy: 0.9297 - val_loss: 0.1774 - val_accuracy: 0.9236\n",
      "Epoch 314/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1627 - accuracy: 0.9288 - val_loss: 0.1977 - val_accuracy: 0.9147\n",
      "Epoch 315/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1666 - accuracy: 0.9267 - val_loss: 0.1879 - val_accuracy: 0.9180\n",
      "Epoch 316/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1759 - accuracy: 0.9234 - val_loss: 0.1852 - val_accuracy: 0.9194\n",
      "Epoch 317/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1646 - accuracy: 0.9278 - val_loss: 0.1849 - val_accuracy: 0.9195\n",
      "Epoch 318/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1672 - accuracy: 0.9272 - val_loss: 0.1828 - val_accuracy: 0.9192\n",
      "Epoch 319/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1638 - accuracy: 0.9286 - val_loss: 0.1879 - val_accuracy: 0.9180\n",
      "Epoch 320/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1682 - accuracy: 0.9256 - val_loss: 0.1869 - val_accuracy: 0.9189\n",
      "Epoch 321/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1670 - accuracy: 0.9266 - val_loss: 0.2050 - val_accuracy: 0.9139\n",
      "Epoch 322/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.1650 - accuracy: 0.9280 - val_loss: 0.1829 - val_accuracy: 0.9220\n",
      "Epoch 323/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1697 - accuracy: 0.9261 - val_loss: 0.1887 - val_accuracy: 0.9199\n",
      "Epoch 324/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1711 - accuracy: 0.9252 - val_loss: 0.1802 - val_accuracy: 0.9239\n",
      "Epoch 325/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1792 - accuracy: 0.9230 - val_loss: 0.1898 - val_accuracy: 0.9185\n",
      "Epoch 326/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1791 - accuracy: 0.9229 - val_loss: 0.1899 - val_accuracy: 0.9174\n",
      "Epoch 327/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1646 - accuracy: 0.9270 - val_loss: 0.1839 - val_accuracy: 0.9230\n",
      "Epoch 328/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1651 - accuracy: 0.9287 - val_loss: 0.1790 - val_accuracy: 0.9223\n",
      "Epoch 329/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1715 - accuracy: 0.9252 - val_loss: 0.1825 - val_accuracy: 0.9203\n",
      "Epoch 330/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.1647 - accuracy: 0.9276 - val_loss: 0.1826 - val_accuracy: 0.9209\n",
      "Epoch 331/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1581 - accuracy: 0.9305 - val_loss: 0.1764 - val_accuracy: 0.9238\n",
      "Epoch 332/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1656 - accuracy: 0.9278 - val_loss: 0.1820 - val_accuracy: 0.9194\n",
      "Epoch 333/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1640 - accuracy: 0.9294 - val_loss: 0.1812 - val_accuracy: 0.9223\n",
      "Epoch 334/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1601 - accuracy: 0.9294 - val_loss: 0.2007 - val_accuracy: 0.9156\n",
      "Epoch 335/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1626 - accuracy: 0.9293 - val_loss: 0.1891 - val_accuracy: 0.9201\n",
      "Epoch 336/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1637 - accuracy: 0.9278 - val_loss: 0.1804 - val_accuracy: 0.9208\n",
      "Epoch 337/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1658 - accuracy: 0.9282 - val_loss: 0.1994 - val_accuracy: 0.9161\n",
      "Epoch 338/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1672 - accuracy: 0.9271 - val_loss: 0.1898 - val_accuracy: 0.9163\n",
      "Epoch 339/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1630 - accuracy: 0.9283 - val_loss: 0.1801 - val_accuracy: 0.9215\n",
      "Epoch 340/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1618 - accuracy: 0.9286 - val_loss: 0.1846 - val_accuracy: 0.9183\n",
      "Epoch 341/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1659 - accuracy: 0.9268 - val_loss: 0.2104 - val_accuracy: 0.9132\n",
      "Epoch 342/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1650 - accuracy: 0.9276 - val_loss: 0.1761 - val_accuracy: 0.9217\n",
      "Epoch 343/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1624 - accuracy: 0.9288 - val_loss: 0.1803 - val_accuracy: 0.9209\n",
      "Epoch 344/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1570 - accuracy: 0.9308 - val_loss: 0.1855 - val_accuracy: 0.9189\n",
      "Epoch 345/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1693 - accuracy: 0.9261 - val_loss: 0.1825 - val_accuracy: 0.9215\n",
      "Epoch 346/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1584 - accuracy: 0.9299 - val_loss: 0.1769 - val_accuracy: 0.9231\n",
      "Epoch 347/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1708 - accuracy: 0.9251 - val_loss: 0.1787 - val_accuracy: 0.9225\n",
      "Epoch 348/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1623 - accuracy: 0.9283 - val_loss: 0.2085 - val_accuracy: 0.9111\n",
      "Epoch 349/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1640 - accuracy: 0.9275 - val_loss: 0.1937 - val_accuracy: 0.9150\n",
      "Epoch 350/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1670 - accuracy: 0.9261 - val_loss: 0.2125 - val_accuracy: 0.9093\n",
      "Epoch 351/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1628 - accuracy: 0.9281 - val_loss: 0.1837 - val_accuracy: 0.9211\n",
      "Epoch 352/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1635 - accuracy: 0.9283 - val_loss: 0.1765 - val_accuracy: 0.9223\n",
      "Epoch 353/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1555 - accuracy: 0.9312 - val_loss: 0.1763 - val_accuracy: 0.9231\n",
      "Epoch 354/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1617 - accuracy: 0.9288 - val_loss: 0.1786 - val_accuracy: 0.9229\n",
      "Epoch 355/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1598 - accuracy: 0.9300 - val_loss: 0.2315 - val_accuracy: 0.9081\n",
      "Epoch 356/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1655 - accuracy: 0.9270 - val_loss: 0.1996 - val_accuracy: 0.9150\n",
      "Epoch 357/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1563 - accuracy: 0.9307 - val_loss: 0.1921 - val_accuracy: 0.9171\n",
      "Epoch 358/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1624 - accuracy: 0.9284 - val_loss: 0.1744 - val_accuracy: 0.9236\n",
      "Epoch 359/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1619 - accuracy: 0.9286 - val_loss: 0.1929 - val_accuracy: 0.9157\n",
      "Epoch 360/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1588 - accuracy: 0.9297 - val_loss: 0.1892 - val_accuracy: 0.9180\n",
      "Epoch 361/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1588 - accuracy: 0.9297 - val_loss: 0.1779 - val_accuracy: 0.9235\n",
      "Epoch 362/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1585 - accuracy: 0.9297 - val_loss: 0.1730 - val_accuracy: 0.9254\n",
      "Epoch 363/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1619 - accuracy: 0.9290 - val_loss: 0.1777 - val_accuracy: 0.9231\n",
      "Epoch 364/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1599 - accuracy: 0.9293 - val_loss: 0.1882 - val_accuracy: 0.9194\n",
      "Epoch 365/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1593 - accuracy: 0.9293 - val_loss: 0.1760 - val_accuracy: 0.9226\n",
      "Epoch 366/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1538 - accuracy: 0.9322 - val_loss: 0.1840 - val_accuracy: 0.9198\n",
      "Epoch 367/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1602 - accuracy: 0.9298 - val_loss: 0.1789 - val_accuracy: 0.9216\n",
      "Epoch 368/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1722 - accuracy: 0.9242 - val_loss: 0.2072 - val_accuracy: 0.9109\n",
      "Epoch 369/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1652 - accuracy: 0.9272 - val_loss: 0.2189 - val_accuracy: 0.9135\n",
      "Epoch 370/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1715 - accuracy: 0.9246 - val_loss: 0.1755 - val_accuracy: 0.9235\n",
      "Epoch 371/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1556 - accuracy: 0.9311 - val_loss: 0.1788 - val_accuracy: 0.9230\n",
      "Epoch 372/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1580 - accuracy: 0.9298 - val_loss: 0.1964 - val_accuracy: 0.9153\n",
      "Epoch 373/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1639 - accuracy: 0.9282 - val_loss: 0.1880 - val_accuracy: 0.9191\n",
      "Epoch 374/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1648 - accuracy: 0.9281 - val_loss: 0.1806 - val_accuracy: 0.9208\n",
      "Epoch 375/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1664 - accuracy: 0.9274 - val_loss: 0.1814 - val_accuracy: 0.9223\n",
      "Epoch 376/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1590 - accuracy: 0.9297 - val_loss: 0.1770 - val_accuracy: 0.9238\n",
      "Epoch 377/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1603 - accuracy: 0.9294 - val_loss: 0.1919 - val_accuracy: 0.9198\n",
      "Epoch 378/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1563 - accuracy: 0.9310 - val_loss: 0.1766 - val_accuracy: 0.9225\n",
      "Epoch 379/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1575 - accuracy: 0.9303 - val_loss: 0.1915 - val_accuracy: 0.9209\n",
      "Epoch 380/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1561 - accuracy: 0.9309 - val_loss: 0.1966 - val_accuracy: 0.9159\n",
      "Epoch 381/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1573 - accuracy: 0.9307 - val_loss: 0.1817 - val_accuracy: 0.9199\n",
      "Epoch 382/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1577 - accuracy: 0.9300 - val_loss: 0.1816 - val_accuracy: 0.9207\n",
      "Epoch 383/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1666 - accuracy: 0.9264 - val_loss: 0.1968 - val_accuracy: 0.9170\n",
      "Epoch 384/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1576 - accuracy: 0.9311 - val_loss: 0.1748 - val_accuracy: 0.9244\n",
      "Epoch 385/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1596 - accuracy: 0.9300 - val_loss: 0.1744 - val_accuracy: 0.9248\n",
      "Epoch 386/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1540 - accuracy: 0.9319 - val_loss: 0.1785 - val_accuracy: 0.9217\n",
      "Epoch 387/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1538 - accuracy: 0.9324 - val_loss: 0.1712 - val_accuracy: 0.9267\n",
      "Epoch 388/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1619 - accuracy: 0.9279 - val_loss: 0.1909 - val_accuracy: 0.9201\n",
      "Epoch 389/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1624 - accuracy: 0.9283 - val_loss: 0.1781 - val_accuracy: 0.9225\n",
      "Epoch 390/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1518 - accuracy: 0.9323 - val_loss: 0.1848 - val_accuracy: 0.9204\n",
      "Epoch 391/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1636 - accuracy: 0.9274 - val_loss: 0.1981 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1601 - accuracy: 0.9290 - val_loss: 0.1804 - val_accuracy: 0.9219\n",
      "Epoch 393/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1536 - accuracy: 0.9319 - val_loss: 0.1749 - val_accuracy: 0.9256\n",
      "Epoch 394/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1581 - accuracy: 0.9301 - val_loss: 0.1827 - val_accuracy: 0.9218\n",
      "Epoch 395/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1609 - accuracy: 0.9291 - val_loss: 0.1759 - val_accuracy: 0.9249\n",
      "Epoch 396/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1576 - accuracy: 0.9298 - val_loss: 0.1843 - val_accuracy: 0.9206\n",
      "Epoch 397/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1551 - accuracy: 0.9310 - val_loss: 0.1820 - val_accuracy: 0.9219\n",
      "Epoch 398/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1565 - accuracy: 0.9302 - val_loss: 0.1875 - val_accuracy: 0.9164\n",
      "Epoch 399/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1643 - accuracy: 0.9282 - val_loss: 0.1866 - val_accuracy: 0.9194\n",
      "Epoch 400/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1553 - accuracy: 0.9313 - val_loss: 0.1985 - val_accuracy: 0.9192\n",
      "Epoch 401/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1610 - accuracy: 0.9287 - val_loss: 0.1735 - val_accuracy: 0.9247\n",
      "Epoch 402/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1539 - accuracy: 0.9323 - val_loss: 0.1765 - val_accuracy: 0.9244\n",
      "Epoch 403/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1564 - accuracy: 0.9307 - val_loss: 0.1784 - val_accuracy: 0.9235\n",
      "Epoch 404/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1518 - accuracy: 0.9326 - val_loss: 0.1736 - val_accuracy: 0.9237\n",
      "Epoch 405/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1536 - accuracy: 0.9313 - val_loss: 0.1924 - val_accuracy: 0.9161\n",
      "Epoch 406/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1645 - accuracy: 0.9272 - val_loss: 0.1765 - val_accuracy: 0.9224\n",
      "Epoch 407/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1509 - accuracy: 0.9330 - val_loss: 0.1852 - val_accuracy: 0.9206\n",
      "Epoch 408/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1555 - accuracy: 0.9313 - val_loss: 0.1814 - val_accuracy: 0.9223\n",
      "Epoch 409/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1526 - accuracy: 0.9326 - val_loss: 0.1796 - val_accuracy: 0.9223\n",
      "Epoch 410/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1583 - accuracy: 0.9299 - val_loss: 0.1803 - val_accuracy: 0.9212\n",
      "Epoch 411/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1516 - accuracy: 0.9327 - val_loss: 0.1711 - val_accuracy: 0.9259\n",
      "Epoch 412/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1597 - accuracy: 0.9303 - val_loss: 0.1736 - val_accuracy: 0.9246\n",
      "Epoch 413/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1495 - accuracy: 0.9332 - val_loss: 0.1802 - val_accuracy: 0.9233\n",
      "Epoch 414/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1583 - accuracy: 0.9294 - val_loss: 0.1843 - val_accuracy: 0.9199\n",
      "Epoch 415/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1586 - accuracy: 0.9305 - val_loss: 0.1862 - val_accuracy: 0.9182\n",
      "Epoch 416/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1537 - accuracy: 0.9315 - val_loss: 0.1949 - val_accuracy: 0.9179\n",
      "Epoch 417/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1537 - accuracy: 0.9313 - val_loss: 0.1726 - val_accuracy: 0.9252\n",
      "Epoch 418/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1532 - accuracy: 0.9323 - val_loss: 0.1760 - val_accuracy: 0.9230\n",
      "Epoch 419/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1596 - accuracy: 0.9297 - val_loss: 0.1927 - val_accuracy: 0.9179\n",
      "Epoch 420/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1574 - accuracy: 0.9298 - val_loss: 0.1719 - val_accuracy: 0.9257\n",
      "Epoch 421/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1478 - accuracy: 0.9341 - val_loss: 0.1858 - val_accuracy: 0.9213\n",
      "Epoch 422/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1498 - accuracy: 0.9335 - val_loss: 0.1792 - val_accuracy: 0.9243\n",
      "Epoch 423/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1525 - accuracy: 0.9323 - val_loss: 0.1752 - val_accuracy: 0.9245\n",
      "Epoch 424/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1564 - accuracy: 0.9303 - val_loss: 0.1928 - val_accuracy: 0.9200\n",
      "Epoch 425/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1512 - accuracy: 0.9325 - val_loss: 0.1751 - val_accuracy: 0.9234\n",
      "Epoch 426/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1551 - accuracy: 0.9308 - val_loss: 0.1898 - val_accuracy: 0.9186\n",
      "Epoch 427/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1610 - accuracy: 0.9290 - val_loss: 0.1797 - val_accuracy: 0.9215\n",
      "Epoch 428/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1614 - accuracy: 0.9288 - val_loss: 0.1831 - val_accuracy: 0.9234\n",
      "Epoch 429/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1492 - accuracy: 0.9342 - val_loss: 0.1920 - val_accuracy: 0.9195\n",
      "Epoch 430/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1544 - accuracy: 0.9316 - val_loss: 0.1881 - val_accuracy: 0.9216\n",
      "Epoch 431/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1519 - accuracy: 0.9323 - val_loss: 0.1771 - val_accuracy: 0.9242\n",
      "Epoch 432/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1489 - accuracy: 0.9332 - val_loss: 0.1807 - val_accuracy: 0.9208\n",
      "Epoch 433/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1487 - accuracy: 0.9335 - val_loss: 0.1785 - val_accuracy: 0.9203\n",
      "Epoch 434/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1540 - accuracy: 0.9311 - val_loss: 0.1785 - val_accuracy: 0.9217\n",
      "Epoch 435/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1490 - accuracy: 0.9331 - val_loss: 0.1823 - val_accuracy: 0.9205\n",
      "Epoch 436/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1521 - accuracy: 0.9324 - val_loss: 0.1752 - val_accuracy: 0.9259\n",
      "Epoch 437/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1466 - accuracy: 0.9342 - val_loss: 0.1748 - val_accuracy: 0.9238\n",
      "Epoch 438/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1535 - accuracy: 0.9319 - val_loss: 0.1810 - val_accuracy: 0.9209\n",
      "Epoch 439/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1529 - accuracy: 0.9323 - val_loss: 0.1785 - val_accuracy: 0.9222\n",
      "Epoch 440/1000\n",
      "87/87 [==============================] - 14s 157ms/step - loss: 0.1527 - accuracy: 0.9317 - val_loss: 0.1879 - val_accuracy: 0.9180\n",
      "Epoch 441/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1456 - accuracy: 0.9349 - val_loss: 0.1743 - val_accuracy: 0.9233\n",
      "Epoch 442/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1558 - accuracy: 0.9307 - val_loss: 0.1932 - val_accuracy: 0.9183\n",
      "Epoch 443/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1554 - accuracy: 0.9315 - val_loss: 0.1784 - val_accuracy: 0.9217\n",
      "Epoch 444/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1531 - accuracy: 0.9321 - val_loss: 0.1916 - val_accuracy: 0.9164\n",
      "Epoch 445/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1511 - accuracy: 0.9319 - val_loss: 0.2107 - val_accuracy: 0.9115\n",
      "Epoch 446/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1477 - accuracy: 0.9334 - val_loss: 0.1761 - val_accuracy: 0.9252\n",
      "Epoch 447/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1508 - accuracy: 0.9324 - val_loss: 0.1943 - val_accuracy: 0.9188\n",
      "Epoch 448/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1539 - accuracy: 0.9311 - val_loss: 0.1947 - val_accuracy: 0.9161\n",
      "Epoch 449/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1598 - accuracy: 0.9286 - val_loss: 0.1808 - val_accuracy: 0.9203\n",
      "Epoch 450/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1477 - accuracy: 0.9338 - val_loss: 0.1874 - val_accuracy: 0.9204\n",
      "Epoch 451/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1483 - accuracy: 0.9333 - val_loss: 0.1791 - val_accuracy: 0.9225\n",
      "Epoch 452/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1506 - accuracy: 0.9326 - val_loss: 0.1779 - val_accuracy: 0.9228\n",
      "Epoch 453/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1492 - accuracy: 0.9330 - val_loss: 0.1765 - val_accuracy: 0.9231\n",
      "Epoch 454/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1489 - accuracy: 0.9334 - val_loss: 0.1914 - val_accuracy: 0.9184\n",
      "Epoch 455/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1524 - accuracy: 0.9324 - val_loss: 0.1791 - val_accuracy: 0.9238\n",
      "Epoch 456/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1517 - accuracy: 0.9321 - val_loss: 0.1955 - val_accuracy: 0.9175\n",
      "Epoch 457/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1495 - accuracy: 0.9328 - val_loss: 0.1917 - val_accuracy: 0.9179\n",
      "Epoch 458/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1516 - accuracy: 0.9326 - val_loss: 0.1879 - val_accuracy: 0.9204\n",
      "Epoch 459/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1516 - accuracy: 0.9324 - val_loss: 0.1832 - val_accuracy: 0.9214\n",
      "Epoch 460/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1453 - accuracy: 0.9346 - val_loss: 0.1807 - val_accuracy: 0.9204\n",
      "Epoch 461/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1529 - accuracy: 0.9317 - val_loss: 0.1791 - val_accuracy: 0.9214\n",
      "Epoch 462/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1439 - accuracy: 0.9348 - val_loss: 0.1694 - val_accuracy: 0.9263\n",
      "Epoch 463/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1460 - accuracy: 0.9349 - val_loss: 0.2243 - val_accuracy: 0.9075\n",
      "Epoch 464/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1601 - accuracy: 0.9291 - val_loss: 0.1745 - val_accuracy: 0.9247\n",
      "Epoch 465/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1536 - accuracy: 0.9317 - val_loss: 0.1746 - val_accuracy: 0.9252\n",
      "Epoch 466/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1429 - accuracy: 0.9348 - val_loss: 0.1842 - val_accuracy: 0.9206\n",
      "Epoch 467/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1519 - accuracy: 0.9322 - val_loss: 0.1727 - val_accuracy: 0.9247\n",
      "Epoch 468/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1434 - accuracy: 0.9360 - val_loss: 0.1763 - val_accuracy: 0.9242\n",
      "Epoch 469/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1511 - accuracy: 0.9332 - val_loss: 0.1886 - val_accuracy: 0.9202\n",
      "Epoch 470/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1430 - accuracy: 0.9360 - val_loss: 0.1794 - val_accuracy: 0.9247\n",
      "Epoch 471/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1460 - accuracy: 0.9345 - val_loss: 0.1837 - val_accuracy: 0.9199\n",
      "Epoch 472/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1733 - accuracy: 0.9261 - val_loss: 0.1868 - val_accuracy: 0.9191\n",
      "Epoch 473/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1481 - accuracy: 0.9338 - val_loss: 0.1925 - val_accuracy: 0.9176\n",
      "Epoch 474/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1522 - accuracy: 0.9318 - val_loss: 0.1760 - val_accuracy: 0.9245\n",
      "Epoch 475/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1430 - accuracy: 0.9354 - val_loss: 0.1790 - val_accuracy: 0.9223\n",
      "Epoch 476/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1451 - accuracy: 0.9350 - val_loss: 0.1782 - val_accuracy: 0.9222\n",
      "Epoch 477/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1555 - accuracy: 0.9306 - val_loss: 0.1842 - val_accuracy: 0.9204\n",
      "Epoch 478/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1615 - accuracy: 0.9281 - val_loss: 0.1821 - val_accuracy: 0.9230\n",
      "Epoch 479/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1495 - accuracy: 0.9328 - val_loss: 0.1733 - val_accuracy: 0.9251\n",
      "Epoch 480/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1453 - accuracy: 0.9353 - val_loss: 0.2024 - val_accuracy: 0.9156\n",
      "Epoch 481/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1556 - accuracy: 0.9317 - val_loss: 0.1784 - val_accuracy: 0.9216\n",
      "Epoch 482/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1461 - accuracy: 0.9344 - val_loss: 0.1734 - val_accuracy: 0.9257\n",
      "Epoch 483/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1513 - accuracy: 0.9317 - val_loss: 0.1882 - val_accuracy: 0.9189\n",
      "Epoch 484/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1446 - accuracy: 0.9352 - val_loss: 0.1717 - val_accuracy: 0.9246\n",
      "Epoch 485/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1449 - accuracy: 0.9351 - val_loss: 0.1805 - val_accuracy: 0.9224\n",
      "Epoch 486/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1477 - accuracy: 0.9339 - val_loss: 0.1819 - val_accuracy: 0.9228\n",
      "Epoch 487/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1533 - accuracy: 0.9319 - val_loss: 0.1724 - val_accuracy: 0.9239\n",
      "Epoch 488/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1428 - accuracy: 0.9357 - val_loss: 0.1786 - val_accuracy: 0.9235\n",
      "Epoch 489/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1490 - accuracy: 0.9339 - val_loss: 0.1898 - val_accuracy: 0.9213\n",
      "Epoch 490/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1439 - accuracy: 0.9347 - val_loss: 0.1765 - val_accuracy: 0.9233\n",
      "Epoch 491/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1481 - accuracy: 0.9337 - val_loss: 0.1915 - val_accuracy: 0.9175\n",
      "Epoch 492/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1462 - accuracy: 0.9344 - val_loss: 0.1929 - val_accuracy: 0.9190\n",
      "Epoch 493/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1658 - accuracy: 0.9271 - val_loss: 0.1873 - val_accuracy: 0.9193\n",
      "Epoch 494/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1457 - accuracy: 0.9344 - val_loss: 0.1880 - val_accuracy: 0.9188\n",
      "Epoch 495/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1419 - accuracy: 0.9359 - val_loss: 0.1778 - val_accuracy: 0.9242\n",
      "Epoch 496/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1535 - accuracy: 0.9327 - val_loss: 0.1723 - val_accuracy: 0.9241\n",
      "Epoch 497/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1412 - accuracy: 0.9364 - val_loss: 0.1942 - val_accuracy: 0.9187\n",
      "Epoch 498/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1514 - accuracy: 0.9326 - val_loss: 0.1711 - val_accuracy: 0.9243\n",
      "Epoch 499/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1413 - accuracy: 0.9367 - val_loss: 0.1823 - val_accuracy: 0.9215\n",
      "Epoch 500/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1413 - accuracy: 0.9367 - val_loss: 0.1771 - val_accuracy: 0.9233\n",
      "Epoch 501/1000\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1449 - accuracy: 0.9351 - val_loss: 0.1734 - val_accuracy: 0.9246\n",
      "Epoch 502/1000\n",
      "87/87 [==============================] - 15s 178ms/step - loss: 0.1453 - accuracy: 0.9348 - val_loss: 0.1816 - val_accuracy: 0.9211\n",
      "Epoch 503/1000\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.1559 - accuracy: 0.9302 - val_loss: 0.1778 - val_accuracy: 0.9226\n",
      "Epoch 504/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1506 - accuracy: 0.9330 - val_loss: 0.2144 - val_accuracy: 0.9117\n",
      "Epoch 505/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1481 - accuracy: 0.9332 - val_loss: 0.1779 - val_accuracy: 0.9226\n",
      "Epoch 506/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1452 - accuracy: 0.9338 - val_loss: 0.1912 - val_accuracy: 0.9212\n",
      "Epoch 507/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1438 - accuracy: 0.9352 - val_loss: 0.1782 - val_accuracy: 0.9231\n",
      "Epoch 508/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1475 - accuracy: 0.9340 - val_loss: 0.1741 - val_accuracy: 0.9242\n",
      "Epoch 509/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1408 - accuracy: 0.9371 - val_loss: 0.1744 - val_accuracy: 0.9228\n",
      "Epoch 510/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1470 - accuracy: 0.9340 - val_loss: 0.1860 - val_accuracy: 0.9200\n",
      "Epoch 511/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1530 - accuracy: 0.9320 - val_loss: 0.1805 - val_accuracy: 0.9220\n",
      "Epoch 512/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1405 - accuracy: 0.9364 - val_loss: 0.1728 - val_accuracy: 0.9240\n",
      "Epoch 513/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1452 - accuracy: 0.9346 - val_loss: 0.1792 - val_accuracy: 0.9230\n",
      "Epoch 514/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1423 - accuracy: 0.9360 - val_loss: 0.1800 - val_accuracy: 0.9209\n",
      "Epoch 515/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1502 - accuracy: 0.9333 - val_loss: 0.1801 - val_accuracy: 0.9228\n",
      "Epoch 516/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1386 - accuracy: 0.9375 - val_loss: 0.1766 - val_accuracy: 0.9234\n",
      "Epoch 517/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1416 - accuracy: 0.9357 - val_loss: 0.1786 - val_accuracy: 0.9219\n",
      "Epoch 518/1000\n",
      "87/87 [==============================] - 13s 143ms/step - loss: 0.1451 - accuracy: 0.9352 - val_loss: 0.1726 - val_accuracy: 0.9252\n",
      "Epoch 519/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1453 - accuracy: 0.9344 - val_loss: 0.1791 - val_accuracy: 0.9231\n",
      "Epoch 520/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1479 - accuracy: 0.9345 - val_loss: 0.1842 - val_accuracy: 0.9190\n",
      "Epoch 521/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1432 - accuracy: 0.9351 - val_loss: 0.1819 - val_accuracy: 0.9205\n",
      "Epoch 522/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1463 - accuracy: 0.9350 - val_loss: 0.1978 - val_accuracy: 0.9142\n",
      "Epoch 523/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1470 - accuracy: 0.9337 - val_loss: 0.1746 - val_accuracy: 0.9237\n",
      "Epoch 524/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1365 - accuracy: 0.9382 - val_loss: 0.1721 - val_accuracy: 0.9257\n",
      "Epoch 525/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1467 - accuracy: 0.9339 - val_loss: 0.1962 - val_accuracy: 0.9164\n",
      "Epoch 526/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1413 - accuracy: 0.9361 - val_loss: 0.1818 - val_accuracy: 0.9208\n",
      "Epoch 527/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1370 - accuracy: 0.9377 - val_loss: 0.1731 - val_accuracy: 0.9258\n",
      "Epoch 528/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1513 - accuracy: 0.9331 - val_loss: 0.1870 - val_accuracy: 0.9190\n",
      "Epoch 529/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1431 - accuracy: 0.9358 - val_loss: 0.1756 - val_accuracy: 0.9231\n",
      "Epoch 530/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1414 - accuracy: 0.9360 - val_loss: 0.1748 - val_accuracy: 0.9249\n",
      "Epoch 531/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1444 - accuracy: 0.9347 - val_loss: 0.1743 - val_accuracy: 0.9248\n",
      "Epoch 532/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1506 - accuracy: 0.9330 - val_loss: 0.1753 - val_accuracy: 0.9237\n",
      "Epoch 533/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1479 - accuracy: 0.9332 - val_loss: 0.1750 - val_accuracy: 0.9236\n",
      "Epoch 534/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1439 - accuracy: 0.9349 - val_loss: 0.1733 - val_accuracy: 0.9254\n",
      "Epoch 535/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1409 - accuracy: 0.9362 - val_loss: 0.1753 - val_accuracy: 0.9244\n",
      "Epoch 536/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1363 - accuracy: 0.9382 - val_loss: 0.1712 - val_accuracy: 0.9258\n",
      "Epoch 537/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1399 - accuracy: 0.9364 - val_loss: 0.1885 - val_accuracy: 0.9213\n",
      "Epoch 538/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1405 - accuracy: 0.9363 - val_loss: 0.1772 - val_accuracy: 0.9232\n",
      "Epoch 539/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1561 - accuracy: 0.9302 - val_loss: 0.1871 - val_accuracy: 0.9196\n",
      "Epoch 540/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1386 - accuracy: 0.9368 - val_loss: 0.1757 - val_accuracy: 0.9224\n",
      "Epoch 541/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1471 - accuracy: 0.9338 - val_loss: 0.1732 - val_accuracy: 0.9251\n",
      "Epoch 542/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1392 - accuracy: 0.9363 - val_loss: 0.1789 - val_accuracy: 0.9212\n",
      "Epoch 543/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1404 - accuracy: 0.9365 - val_loss: 0.1798 - val_accuracy: 0.9234\n",
      "Epoch 544/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1455 - accuracy: 0.9342 - val_loss: 0.1803 - val_accuracy: 0.9221\n",
      "Epoch 545/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1392 - accuracy: 0.9375 - val_loss: 0.1828 - val_accuracy: 0.9231\n",
      "Epoch 546/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1420 - accuracy: 0.9366 - val_loss: 0.1930 - val_accuracy: 0.9196\n",
      "Epoch 547/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1426 - accuracy: 0.9361 - val_loss: 0.1738 - val_accuracy: 0.9248\n",
      "Epoch 548/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1474 - accuracy: 0.9338 - val_loss: 0.2024 - val_accuracy: 0.9160\n",
      "Epoch 549/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1443 - accuracy: 0.9344 - val_loss: 0.2020 - val_accuracy: 0.9154\n",
      "Epoch 550/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1369 - accuracy: 0.9377 - val_loss: 0.1830 - val_accuracy: 0.9239\n",
      "Epoch 551/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1410 - accuracy: 0.9367 - val_loss: 0.1825 - val_accuracy: 0.9226\n",
      "Epoch 552/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.1446 - accuracy: 0.9345 - val_loss: 0.1784 - val_accuracy: 0.9240\n",
      "Epoch 553/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1380 - accuracy: 0.9375 - val_loss: 0.1738 - val_accuracy: 0.9249\n",
      "Epoch 554/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1424 - accuracy: 0.9355 - val_loss: 0.1726 - val_accuracy: 0.9264\n",
      "Epoch 555/1000\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.1322 - accuracy: 0.9399 - val_loss: 0.1752 - val_accuracy: 0.9245\n",
      "Epoch 556/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.1434 - accuracy: 0.9352 - val_loss: 0.1843 - val_accuracy: 0.9216\n",
      "Epoch 557/1000\n",
      "87/87 [==============================] - 14s 158ms/step - loss: 0.1420 - accuracy: 0.9359 - val_loss: 0.1782 - val_accuracy: 0.9236\n",
      "Epoch 558/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1404 - accuracy: 0.9361 - val_loss: 0.1797 - val_accuracy: 0.9231\n",
      "Epoch 559/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1355 - accuracy: 0.9385 - val_loss: 0.1801 - val_accuracy: 0.9252\n",
      "Epoch 560/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1438 - accuracy: 0.9353 - val_loss: 0.1768 - val_accuracy: 0.9243\n",
      "Epoch 561/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1360 - accuracy: 0.9386 - val_loss: 0.1747 - val_accuracy: 0.9248\n",
      "Epoch 562/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1483 - accuracy: 0.9328 - val_loss: 0.1738 - val_accuracy: 0.9247\n",
      "Epoch 563/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1411 - accuracy: 0.9362 - val_loss: 0.1805 - val_accuracy: 0.9224\n",
      "Epoch 564/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1423 - accuracy: 0.9358 - val_loss: 0.1986 - val_accuracy: 0.9190\n",
      "Epoch 565/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1449 - accuracy: 0.9340 - val_loss: 0.1828 - val_accuracy: 0.9223\n",
      "Epoch 566/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1386 - accuracy: 0.9370 - val_loss: 0.1837 - val_accuracy: 0.9227\n",
      "Epoch 567/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1413 - accuracy: 0.9365 - val_loss: 0.1789 - val_accuracy: 0.9246\n",
      "Epoch 568/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1547 - accuracy: 0.9309 - val_loss: 0.1854 - val_accuracy: 0.9217\n",
      "Epoch 569/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1358 - accuracy: 0.9387 - val_loss: 0.1788 - val_accuracy: 0.9242\n",
      "Epoch 570/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1386 - accuracy: 0.9372 - val_loss: 0.1827 - val_accuracy: 0.9212\n",
      "Epoch 571/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1352 - accuracy: 0.9383 - val_loss: 0.1720 - val_accuracy: 0.9252\n",
      "Epoch 572/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1319 - accuracy: 0.9398 - val_loss: 0.1894 - val_accuracy: 0.9219\n",
      "Epoch 573/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1453 - accuracy: 0.9345 - val_loss: 0.1805 - val_accuracy: 0.9227\n",
      "Epoch 574/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1420 - accuracy: 0.9357 - val_loss: 0.1799 - val_accuracy: 0.9222\n",
      "Epoch 575/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1360 - accuracy: 0.9383 - val_loss: 0.1764 - val_accuracy: 0.9243\n",
      "Epoch 576/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1346 - accuracy: 0.9389 - val_loss: 0.1799 - val_accuracy: 0.9225\n",
      "Epoch 577/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1360 - accuracy: 0.9377 - val_loss: 0.1730 - val_accuracy: 0.9267\n",
      "Epoch 578/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1368 - accuracy: 0.9375 - val_loss: 0.1932 - val_accuracy: 0.9183\n",
      "Epoch 579/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1446 - accuracy: 0.9344 - val_loss: 0.1953 - val_accuracy: 0.9190\n",
      "Epoch 580/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1397 - accuracy: 0.9367 - val_loss: 0.1859 - val_accuracy: 0.9246\n",
      "Epoch 581/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1417 - accuracy: 0.9350 - val_loss: 0.1755 - val_accuracy: 0.9249\n",
      "Epoch 582/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1285 - accuracy: 0.9410 - val_loss: 0.1784 - val_accuracy: 0.9233\n",
      "Epoch 583/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1428 - accuracy: 0.9352 - val_loss: 0.1729 - val_accuracy: 0.9267\n",
      "Epoch 584/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1375 - accuracy: 0.9378 - val_loss: 0.1865 - val_accuracy: 0.9204\n",
      "Epoch 585/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1349 - accuracy: 0.9386 - val_loss: 0.2387 - val_accuracy: 0.9064\n",
      "Epoch 586/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1388 - accuracy: 0.9373 - val_loss: 0.1779 - val_accuracy: 0.9238\n",
      "Epoch 587/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1360 - accuracy: 0.9381 - val_loss: 0.1893 - val_accuracy: 0.9194\n",
      "Epoch 588/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1386 - accuracy: 0.9371 - val_loss: 0.1919 - val_accuracy: 0.9197\n",
      "Epoch 589/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1391 - accuracy: 0.9368 - val_loss: 0.2106 - val_accuracy: 0.9136\n",
      "Epoch 590/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1528 - accuracy: 0.9315 - val_loss: 0.1813 - val_accuracy: 0.9213\n",
      "Epoch 591/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1358 - accuracy: 0.9383 - val_loss: 0.1801 - val_accuracy: 0.9241\n",
      "Epoch 592/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1331 - accuracy: 0.9396 - val_loss: 0.1777 - val_accuracy: 0.9238\n",
      "Epoch 593/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1299 - accuracy: 0.9403 - val_loss: 0.1790 - val_accuracy: 0.9233\n",
      "Epoch 594/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1338 - accuracy: 0.9394 - val_loss: 0.1788 - val_accuracy: 0.9234\n",
      "Epoch 595/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1357 - accuracy: 0.9386 - val_loss: 0.2068 - val_accuracy: 0.9136\n",
      "Epoch 596/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1482 - accuracy: 0.9335 - val_loss: 0.1887 - val_accuracy: 0.9213\n",
      "Epoch 597/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1415 - accuracy: 0.9362 - val_loss: 0.1718 - val_accuracy: 0.9259\n",
      "Epoch 598/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1360 - accuracy: 0.9378 - val_loss: 0.1721 - val_accuracy: 0.9248\n",
      "Epoch 599/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1297 - accuracy: 0.9401 - val_loss: 0.1835 - val_accuracy: 0.9210\n",
      "Epoch 600/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1322 - accuracy: 0.9399 - val_loss: 0.1838 - val_accuracy: 0.9213\n",
      "Epoch 601/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1470 - accuracy: 0.9336 - val_loss: 0.1908 - val_accuracy: 0.9184\n",
      "Epoch 602/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1339 - accuracy: 0.9385 - val_loss: 0.1745 - val_accuracy: 0.9260\n",
      "Epoch 603/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.1285 - accuracy: 0.9408 - val_loss: 0.1764 - val_accuracy: 0.9256\n",
      "Epoch 604/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1336 - accuracy: 0.9390 - val_loss: 0.1846 - val_accuracy: 0.9224\n",
      "Epoch 605/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1580 - accuracy: 0.9307 - val_loss: 0.1858 - val_accuracy: 0.9202\n",
      "Epoch 606/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1317 - accuracy: 0.9397 - val_loss: 0.1780 - val_accuracy: 0.9240\n",
      "Epoch 607/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1467 - accuracy: 0.9339 - val_loss: 0.1856 - val_accuracy: 0.9190\n",
      "Epoch 608/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1414 - accuracy: 0.9358 - val_loss: 0.1739 - val_accuracy: 0.9253\n",
      "Epoch 609/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1294 - accuracy: 0.9413 - val_loss: 0.1799 - val_accuracy: 0.9247\n",
      "Epoch 610/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1297 - accuracy: 0.9409 - val_loss: 0.1763 - val_accuracy: 0.9241\n",
      "Epoch 611/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1298 - accuracy: 0.9405 - val_loss: 0.1862 - val_accuracy: 0.9234\n",
      "Epoch 612/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1491 - accuracy: 0.9340 - val_loss: 0.1821 - val_accuracy: 0.9224\n",
      "Epoch 613/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1442 - accuracy: 0.9348 - val_loss: 0.1737 - val_accuracy: 0.9270\n",
      "Epoch 614/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1282 - accuracy: 0.9412 - val_loss: 0.1881 - val_accuracy: 0.9210\n",
      "Epoch 615/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1379 - accuracy: 0.9375 - val_loss: 0.1814 - val_accuracy: 0.9220\n",
      "Epoch 616/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1329 - accuracy: 0.9392 - val_loss: 0.1847 - val_accuracy: 0.9235\n",
      "Epoch 617/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1317 - accuracy: 0.9394 - val_loss: 0.1770 - val_accuracy: 0.9263\n",
      "Epoch 618/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1325 - accuracy: 0.9397 - val_loss: 0.1900 - val_accuracy: 0.9216\n",
      "Epoch 619/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1344 - accuracy: 0.9389 - val_loss: 0.1880 - val_accuracy: 0.9203\n",
      "Epoch 620/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1358 - accuracy: 0.9384 - val_loss: 0.1791 - val_accuracy: 0.9219\n",
      "Epoch 621/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1336 - accuracy: 0.9385 - val_loss: 0.1794 - val_accuracy: 0.9233\n",
      "Epoch 622/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1308 - accuracy: 0.9405 - val_loss: 0.1798 - val_accuracy: 0.9241\n",
      "Epoch 623/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1293 - accuracy: 0.9403 - val_loss: 0.1845 - val_accuracy: 0.9231\n",
      "Epoch 624/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1440 - accuracy: 0.9354 - val_loss: 0.1788 - val_accuracy: 0.9228\n",
      "Epoch 625/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1310 - accuracy: 0.9401 - val_loss: 0.1947 - val_accuracy: 0.9187\n",
      "Epoch 626/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1363 - accuracy: 0.9381 - val_loss: 0.1780 - val_accuracy: 0.9229\n",
      "Epoch 627/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1360 - accuracy: 0.9374 - val_loss: 0.1835 - val_accuracy: 0.9226\n",
      "Epoch 628/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1378 - accuracy: 0.9375 - val_loss: 0.1848 - val_accuracy: 0.9205\n",
      "Epoch 629/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1393 - accuracy: 0.9375 - val_loss: 0.1910 - val_accuracy: 0.9208\n",
      "Epoch 630/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1384 - accuracy: 0.9373 - val_loss: 0.1816 - val_accuracy: 0.9225\n",
      "Epoch 631/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1312 - accuracy: 0.9398 - val_loss: 0.1762 - val_accuracy: 0.9245\n",
      "Epoch 632/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1295 - accuracy: 0.9407 - val_loss: 0.1820 - val_accuracy: 0.9227\n",
      "Epoch 633/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1289 - accuracy: 0.9404 - val_loss: 0.1772 - val_accuracy: 0.9237\n",
      "Epoch 634/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1263 - accuracy: 0.9420 - val_loss: 0.1755 - val_accuracy: 0.9262\n",
      "Epoch 635/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1369 - accuracy: 0.9380 - val_loss: 0.1982 - val_accuracy: 0.9178\n",
      "Epoch 636/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1388 - accuracy: 0.9372 - val_loss: 0.1833 - val_accuracy: 0.9233\n",
      "Epoch 637/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1272 - accuracy: 0.9418 - val_loss: 0.1916 - val_accuracy: 0.9239\n",
      "Epoch 638/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1249 - accuracy: 0.9426 - val_loss: 0.1774 - val_accuracy: 0.9263\n",
      "Epoch 639/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1359 - accuracy: 0.9377 - val_loss: 0.1978 - val_accuracy: 0.9172\n",
      "Epoch 640/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1395 - accuracy: 0.9369 - val_loss: 0.1832 - val_accuracy: 0.9237\n",
      "Epoch 641/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1320 - accuracy: 0.9396 - val_loss: 0.1829 - val_accuracy: 0.9232\n",
      "Epoch 642/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1251 - accuracy: 0.9425 - val_loss: 0.1855 - val_accuracy: 0.9268\n",
      "Epoch 643/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1346 - accuracy: 0.9386 - val_loss: 0.1755 - val_accuracy: 0.9256\n",
      "Epoch 644/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1342 - accuracy: 0.9385 - val_loss: 0.1893 - val_accuracy: 0.9242\n",
      "Epoch 645/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1307 - accuracy: 0.9402 - val_loss: 0.1818 - val_accuracy: 0.9252\n",
      "Epoch 646/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1327 - accuracy: 0.9391 - val_loss: 0.1998 - val_accuracy: 0.9176\n",
      "Epoch 647/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1316 - accuracy: 0.9395 - val_loss: 0.1810 - val_accuracy: 0.9240\n",
      "Epoch 648/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1303 - accuracy: 0.9404 - val_loss: 0.1886 - val_accuracy: 0.9200\n",
      "Epoch 649/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1400 - accuracy: 0.9369 - val_loss: 0.1884 - val_accuracy: 0.9215\n",
      "Epoch 650/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1358 - accuracy: 0.9379 - val_loss: 0.1784 - val_accuracy: 0.9246\n",
      "Epoch 651/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1328 - accuracy: 0.9392 - val_loss: 0.1897 - val_accuracy: 0.9199\n",
      "Epoch 652/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1471 - accuracy: 0.9343 - val_loss: 0.1964 - val_accuracy: 0.9187\n",
      "Epoch 653/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1328 - accuracy: 0.9391 - val_loss: 0.1785 - val_accuracy: 0.9249\n",
      "Epoch 654/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1310 - accuracy: 0.9406 - val_loss: 0.1794 - val_accuracy: 0.9234\n",
      "Epoch 655/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1409 - accuracy: 0.9364 - val_loss: 0.1752 - val_accuracy: 0.9252\n",
      "Epoch 656/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1295 - accuracy: 0.9404 - val_loss: 0.1786 - val_accuracy: 0.9239\n",
      "Epoch 657/1000\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.1287 - accuracy: 0.9406 - val_loss: 0.1869 - val_accuracy: 0.9221\n",
      "Epoch 658/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1286 - accuracy: 0.9402 - val_loss: 0.1985 - val_accuracy: 0.9225\n",
      "Epoch 659/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1280 - accuracy: 0.9417 - val_loss: 0.1763 - val_accuracy: 0.9249\n",
      "Epoch 660/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1267 - accuracy: 0.9418 - val_loss: 0.1950 - val_accuracy: 0.9199\n",
      "Epoch 661/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1405 - accuracy: 0.9361 - val_loss: 0.1866 - val_accuracy: 0.9219\n",
      "Epoch 662/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1337 - accuracy: 0.9392 - val_loss: 0.1792 - val_accuracy: 0.9237\n",
      "Epoch 663/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1332 - accuracy: 0.9394 - val_loss: 0.1829 - val_accuracy: 0.9236\n",
      "Epoch 664/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1399 - accuracy: 0.9366 - val_loss: 0.1863 - val_accuracy: 0.9239\n",
      "Epoch 665/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1430 - accuracy: 0.9351 - val_loss: 0.1839 - val_accuracy: 0.9239\n",
      "Epoch 666/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1275 - accuracy: 0.9419 - val_loss: 0.1847 - val_accuracy: 0.9218\n",
      "Epoch 667/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1297 - accuracy: 0.9410 - val_loss: 0.1826 - val_accuracy: 0.9234\n",
      "Epoch 668/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1266 - accuracy: 0.9415 - val_loss: 0.1768 - val_accuracy: 0.9256\n",
      "Epoch 669/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1284 - accuracy: 0.9408 - val_loss: 0.1809 - val_accuracy: 0.9234\n",
      "Epoch 670/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1260 - accuracy: 0.9421 - val_loss: 0.2088 - val_accuracy: 0.9144\n",
      "Epoch 671/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.1302 - accuracy: 0.9405 - val_loss: 0.1814 - val_accuracy: 0.9246\n",
      "Epoch 672/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1298 - accuracy: 0.9412 - val_loss: 0.1810 - val_accuracy: 0.9227\n",
      "Epoch 673/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1284 - accuracy: 0.9415 - val_loss: 0.1796 - val_accuracy: 0.9228\n",
      "Epoch 674/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1269 - accuracy: 0.9419 - val_loss: 0.1816 - val_accuracy: 0.9244\n",
      "Epoch 675/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1296 - accuracy: 0.9405 - val_loss: 0.1882 - val_accuracy: 0.9212\n",
      "Epoch 676/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1335 - accuracy: 0.9391 - val_loss: 0.1885 - val_accuracy: 0.9228\n",
      "Epoch 677/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1314 - accuracy: 0.9407 - val_loss: 0.1784 - val_accuracy: 0.9264\n",
      "Epoch 678/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1356 - accuracy: 0.9382 - val_loss: 0.1979 - val_accuracy: 0.9193\n",
      "Epoch 679/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1344 - accuracy: 0.9394 - val_loss: 0.1885 - val_accuracy: 0.9215\n",
      "Epoch 680/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1367 - accuracy: 0.9381 - val_loss: 0.1869 - val_accuracy: 0.9217\n",
      "Epoch 681/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1253 - accuracy: 0.9423 - val_loss: 0.1857 - val_accuracy: 0.9225\n",
      "Epoch 682/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1281 - accuracy: 0.9420 - val_loss: 0.1791 - val_accuracy: 0.9246\n",
      "Epoch 683/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1301 - accuracy: 0.9402 - val_loss: 0.1810 - val_accuracy: 0.9224\n",
      "Epoch 684/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1247 - accuracy: 0.9427 - val_loss: 0.1996 - val_accuracy: 0.9177\n",
      "Epoch 685/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1321 - accuracy: 0.9394 - val_loss: 0.1852 - val_accuracy: 0.9242\n",
      "Epoch 686/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1396 - accuracy: 0.9368 - val_loss: 0.1802 - val_accuracy: 0.9248\n",
      "Epoch 687/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1264 - accuracy: 0.9418 - val_loss: 0.1842 - val_accuracy: 0.9249\n",
      "Epoch 688/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1259 - accuracy: 0.9425 - val_loss: 0.1807 - val_accuracy: 0.9248\n",
      "Epoch 689/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1289 - accuracy: 0.9407 - val_loss: 0.1786 - val_accuracy: 0.9259\n",
      "Epoch 690/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1249 - accuracy: 0.9421 - val_loss: 0.1841 - val_accuracy: 0.9235\n",
      "Epoch 691/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1234 - accuracy: 0.9431 - val_loss: 0.1815 - val_accuracy: 0.9242\n",
      "Epoch 692/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1403 - accuracy: 0.9367 - val_loss: 0.1832 - val_accuracy: 0.9249\n",
      "Epoch 693/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1239 - accuracy: 0.9427 - val_loss: 0.2040 - val_accuracy: 0.9221\n",
      "Epoch 694/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1357 - accuracy: 0.9376 - val_loss: 0.1789 - val_accuracy: 0.9251\n",
      "Epoch 695/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1184 - accuracy: 0.9452 - val_loss: 0.1806 - val_accuracy: 0.9243\n",
      "Epoch 696/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1253 - accuracy: 0.9425 - val_loss: 0.2024 - val_accuracy: 0.9168\n",
      "Epoch 697/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1293 - accuracy: 0.9407 - val_loss: 0.1876 - val_accuracy: 0.9203\n",
      "Epoch 698/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1546 - accuracy: 0.9314 - val_loss: 0.1787 - val_accuracy: 0.9250\n",
      "Epoch 699/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1221 - accuracy: 0.9435 - val_loss: 0.1833 - val_accuracy: 0.9255\n",
      "Epoch 700/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1251 - accuracy: 0.9424 - val_loss: 0.1894 - val_accuracy: 0.9226\n",
      "Epoch 701/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1361 - accuracy: 0.9376 - val_loss: 0.1813 - val_accuracy: 0.9250\n",
      "Epoch 702/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1290 - accuracy: 0.9409 - val_loss: 0.1855 - val_accuracy: 0.9256\n",
      "Epoch 703/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1247 - accuracy: 0.9423 - val_loss: 0.1803 - val_accuracy: 0.9253\n",
      "Epoch 704/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1265 - accuracy: 0.9419 - val_loss: 0.1822 - val_accuracy: 0.9265\n",
      "Epoch 705/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1254 - accuracy: 0.9422 - val_loss: 0.1883 - val_accuracy: 0.9244\n",
      "Epoch 706/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1311 - accuracy: 0.9401 - val_loss: 0.1814 - val_accuracy: 0.9255\n",
      "Epoch 707/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1280 - accuracy: 0.9410 - val_loss: 0.1822 - val_accuracy: 0.9230\n",
      "Epoch 708/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1258 - accuracy: 0.9423 - val_loss: 0.1916 - val_accuracy: 0.9241\n",
      "Epoch 709/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1401 - accuracy: 0.9359 - val_loss: 0.1857 - val_accuracy: 0.9226\n",
      "Epoch 710/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1293 - accuracy: 0.9406 - val_loss: 0.1872 - val_accuracy: 0.9234\n",
      "Epoch 711/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1249 - accuracy: 0.9420 - val_loss: 0.1786 - val_accuracy: 0.9258\n",
      "Epoch 712/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1253 - accuracy: 0.9428 - val_loss: 0.1791 - val_accuracy: 0.9254\n",
      "Epoch 713/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1286 - accuracy: 0.9411 - val_loss: 0.1895 - val_accuracy: 0.9198\n",
      "Epoch 714/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1274 - accuracy: 0.9412 - val_loss: 0.1789 - val_accuracy: 0.9254\n",
      "Epoch 715/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1211 - accuracy: 0.9444 - val_loss: 0.1874 - val_accuracy: 0.9231\n",
      "Epoch 716/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1274 - accuracy: 0.9421 - val_loss: 0.1835 - val_accuracy: 0.9249\n",
      "Epoch 717/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1309 - accuracy: 0.9396 - val_loss: 0.1833 - val_accuracy: 0.9255\n",
      "Epoch 718/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1212 - accuracy: 0.9441 - val_loss: 0.1896 - val_accuracy: 0.9227\n",
      "Epoch 719/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1241 - accuracy: 0.9418 - val_loss: 0.1849 - val_accuracy: 0.9247\n",
      "Epoch 720/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1378 - accuracy: 0.9380 - val_loss: 0.2323 - val_accuracy: 0.9102\n",
      "Epoch 721/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1281 - accuracy: 0.9410 - val_loss: 0.1848 - val_accuracy: 0.9223\n",
      "Epoch 722/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1223 - accuracy: 0.9431 - val_loss: 0.1803 - val_accuracy: 0.9272\n",
      "Epoch 723/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1228 - accuracy: 0.9430 - val_loss: 0.1917 - val_accuracy: 0.9187\n",
      "Epoch 724/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1271 - accuracy: 0.9419 - val_loss: 0.1862 - val_accuracy: 0.9216\n",
      "Epoch 725/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1304 - accuracy: 0.9406 - val_loss: 0.1836 - val_accuracy: 0.9260\n",
      "Epoch 726/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1284 - accuracy: 0.9411 - val_loss: 0.1871 - val_accuracy: 0.9244\n",
      "Epoch 727/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1304 - accuracy: 0.9399 - val_loss: 0.1786 - val_accuracy: 0.9275\n",
      "Epoch 728/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1223 - accuracy: 0.9436 - val_loss: 0.2006 - val_accuracy: 0.9178\n",
      "Epoch 729/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1348 - accuracy: 0.9377 - val_loss: 0.1878 - val_accuracy: 0.9222\n",
      "Epoch 730/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1296 - accuracy: 0.9404 - val_loss: 0.1812 - val_accuracy: 0.9252\n",
      "Epoch 731/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1274 - accuracy: 0.9414 - val_loss: 0.1813 - val_accuracy: 0.9261\n",
      "Epoch 732/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1222 - accuracy: 0.9432 - val_loss: 0.1855 - val_accuracy: 0.9239\n",
      "Epoch 733/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1253 - accuracy: 0.9423 - val_loss: 0.1827 - val_accuracy: 0.9260\n",
      "Epoch 734/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1269 - accuracy: 0.9418 - val_loss: 0.1882 - val_accuracy: 0.9237\n",
      "Epoch 735/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1334 - accuracy: 0.9396 - val_loss: 0.1951 - val_accuracy: 0.9197\n",
      "Epoch 736/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1249 - accuracy: 0.9417 - val_loss: 0.1828 - val_accuracy: 0.9265\n",
      "Epoch 737/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1251 - accuracy: 0.9422 - val_loss: 0.1837 - val_accuracy: 0.9252\n",
      "Epoch 738/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1227 - accuracy: 0.9440 - val_loss: 0.1927 - val_accuracy: 0.9201\n",
      "Epoch 739/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1202 - accuracy: 0.9446 - val_loss: 0.1915 - val_accuracy: 0.9205\n",
      "Epoch 740/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1349 - accuracy: 0.9395 - val_loss: 0.2119 - val_accuracy: 0.9133\n",
      "Epoch 741/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1315 - accuracy: 0.9389 - val_loss: 0.1839 - val_accuracy: 0.9245\n",
      "Epoch 742/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1241 - accuracy: 0.9427 - val_loss: 0.1861 - val_accuracy: 0.9245\n",
      "Epoch 743/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1252 - accuracy: 0.9424 - val_loss: 0.1850 - val_accuracy: 0.9226\n",
      "Epoch 744/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1213 - accuracy: 0.9443 - val_loss: 0.1797 - val_accuracy: 0.9244\n",
      "Epoch 745/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1222 - accuracy: 0.9434 - val_loss: 0.1950 - val_accuracy: 0.9183\n",
      "Epoch 746/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.1222 - accuracy: 0.9433 - val_loss: 0.1945 - val_accuracy: 0.9200\n",
      "Epoch 747/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1313 - accuracy: 0.9396 - val_loss: 0.1968 - val_accuracy: 0.9203\n",
      "Epoch 748/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1262 - accuracy: 0.9420 - val_loss: 0.1866 - val_accuracy: 0.9246\n",
      "Epoch 749/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1223 - accuracy: 0.9434 - val_loss: 0.1839 - val_accuracy: 0.9255\n",
      "Epoch 750/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1194 - accuracy: 0.9445 - val_loss: 0.1892 - val_accuracy: 0.9227\n",
      "Epoch 751/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1287 - accuracy: 0.9416 - val_loss: 0.1860 - val_accuracy: 0.9239\n",
      "Epoch 752/1000\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.1215 - accuracy: 0.9436 - val_loss: 0.1832 - val_accuracy: 0.9243\n",
      "Epoch 753/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.1297 - accuracy: 0.9407 - val_loss: 0.1859 - val_accuracy: 0.9249\n",
      "Epoch 754/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1222 - accuracy: 0.9434 - val_loss: 0.1857 - val_accuracy: 0.9224\n",
      "Epoch 755/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1208 - accuracy: 0.9443 - val_loss: 0.1835 - val_accuracy: 0.9226\n",
      "Epoch 756/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1212 - accuracy: 0.9436 - val_loss: 0.1860 - val_accuracy: 0.9227\n",
      "Epoch 757/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1174 - accuracy: 0.9459 - val_loss: 0.1828 - val_accuracy: 0.9276\n",
      "Epoch 758/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1146 - accuracy: 0.9464 - val_loss: 0.1922 - val_accuracy: 0.9224\n",
      "Epoch 759/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1227 - accuracy: 0.9432 - val_loss: 0.1855 - val_accuracy: 0.9246\n",
      "Epoch 760/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1195 - accuracy: 0.9449 - val_loss: 0.1954 - val_accuracy: 0.9218\n",
      "Epoch 761/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1371 - accuracy: 0.9374 - val_loss: 0.1936 - val_accuracy: 0.9183\n",
      "Epoch 762/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1178 - accuracy: 0.9453 - val_loss: 0.1849 - val_accuracy: 0.9264\n",
      "Epoch 763/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 0.1274 - accuracy: 0.9412 - val_loss: 0.1952 - val_accuracy: 0.9197\n",
      "Epoch 764/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1305 - accuracy: 0.9402 - val_loss: 0.2028 - val_accuracy: 0.9203\n",
      "Epoch 765/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1240 - accuracy: 0.9429 - val_loss: 0.1945 - val_accuracy: 0.9240\n",
      "Epoch 766/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1273 - accuracy: 0.9412 - val_loss: 0.1854 - val_accuracy: 0.9245\n",
      "Epoch 767/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1147 - accuracy: 0.9466 - val_loss: 0.2002 - val_accuracy: 0.9207\n",
      "Epoch 768/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1228 - accuracy: 0.9432 - val_loss: 0.1892 - val_accuracy: 0.9234\n",
      "Epoch 769/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1280 - accuracy: 0.9415 - val_loss: 0.1824 - val_accuracy: 0.9234\n",
      "Epoch 770/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1202 - accuracy: 0.9442 - val_loss: 0.1992 - val_accuracy: 0.9218\n",
      "Epoch 771/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1242 - accuracy: 0.9423 - val_loss: 0.1945 - val_accuracy: 0.9210\n",
      "Epoch 772/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1364 - accuracy: 0.9380 - val_loss: 0.1858 - val_accuracy: 0.9249\n",
      "Epoch 773/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1250 - accuracy: 0.9429 - val_loss: 0.1909 - val_accuracy: 0.9211\n",
      "Epoch 774/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1192 - accuracy: 0.9448 - val_loss: 0.1837 - val_accuracy: 0.9244\n",
      "Epoch 775/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1149 - accuracy: 0.9467 - val_loss: 0.1890 - val_accuracy: 0.9218\n",
      "Epoch 776/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1248 - accuracy: 0.9425 - val_loss: 0.1941 - val_accuracy: 0.9214\n",
      "Epoch 777/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1201 - accuracy: 0.9444 - val_loss: 0.1915 - val_accuracy: 0.9254\n",
      "Epoch 778/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1219 - accuracy: 0.9434 - val_loss: 0.2130 - val_accuracy: 0.9155\n",
      "Epoch 779/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1283 - accuracy: 0.9410 - val_loss: 0.1903 - val_accuracy: 0.9227\n",
      "Epoch 780/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1159 - accuracy: 0.9464 - val_loss: 0.1866 - val_accuracy: 0.9249\n",
      "Epoch 781/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1278 - accuracy: 0.9410 - val_loss: 0.1881 - val_accuracy: 0.9235\n",
      "Epoch 782/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1259 - accuracy: 0.9426 - val_loss: 0.1996 - val_accuracy: 0.9197\n",
      "Epoch 783/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1255 - accuracy: 0.9413 - val_loss: 0.1802 - val_accuracy: 0.9265\n",
      "Epoch 784/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1194 - accuracy: 0.9449 - val_loss: 0.2059 - val_accuracy: 0.9177\n",
      "Epoch 785/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1194 - accuracy: 0.9447 - val_loss: 0.2007 - val_accuracy: 0.9236\n",
      "Epoch 786/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1203 - accuracy: 0.9446 - val_loss: 0.1873 - val_accuracy: 0.9218\n",
      "Epoch 787/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1187 - accuracy: 0.9447 - val_loss: 0.1887 - val_accuracy: 0.9262\n",
      "Epoch 788/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1167 - accuracy: 0.9466 - val_loss: 0.1855 - val_accuracy: 0.9260\n",
      "Epoch 789/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1161 - accuracy: 0.9458 - val_loss: 0.1862 - val_accuracy: 0.9239\n",
      "Epoch 790/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1373 - accuracy: 0.9388 - val_loss: 0.2131 - val_accuracy: 0.9146\n",
      "Epoch 791/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1343 - accuracy: 0.9386 - val_loss: 0.1874 - val_accuracy: 0.9239\n",
      "Epoch 792/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1192 - accuracy: 0.9447 - val_loss: 0.1811 - val_accuracy: 0.9258\n",
      "Epoch 793/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1200 - accuracy: 0.9442 - val_loss: 0.1836 - val_accuracy: 0.9225\n",
      "Epoch 794/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1157 - accuracy: 0.9463 - val_loss: 0.1964 - val_accuracy: 0.9198\n",
      "Epoch 795/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1207 - accuracy: 0.9443 - val_loss: 0.1848 - val_accuracy: 0.9249\n",
      "Epoch 796/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1221 - accuracy: 0.9436 - val_loss: 0.1925 - val_accuracy: 0.9235\n",
      "Epoch 797/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1352 - accuracy: 0.9382 - val_loss: 0.2000 - val_accuracy: 0.9169\n",
      "Epoch 798/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1251 - accuracy: 0.9420 - val_loss: 0.1882 - val_accuracy: 0.9217\n",
      "Epoch 799/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1132 - accuracy: 0.9473 - val_loss: 0.1829 - val_accuracy: 0.9269\n",
      "Epoch 800/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1120 - accuracy: 0.9480 - val_loss: 0.1932 - val_accuracy: 0.9215\n",
      "Epoch 801/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1236 - accuracy: 0.9433 - val_loss: 0.1927 - val_accuracy: 0.9232\n",
      "Epoch 802/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1318 - accuracy: 0.9389 - val_loss: 0.2025 - val_accuracy: 0.9220\n",
      "Epoch 803/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1267 - accuracy: 0.9421 - val_loss: 0.1886 - val_accuracy: 0.9228\n",
      "Epoch 804/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1261 - accuracy: 0.9413 - val_loss: 0.1874 - val_accuracy: 0.9237\n",
      "Epoch 805/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1147 - accuracy: 0.9469 - val_loss: 0.1820 - val_accuracy: 0.9265\n",
      "Epoch 806/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1166 - accuracy: 0.9463 - val_loss: 0.1942 - val_accuracy: 0.9192\n",
      "Epoch 807/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1288 - accuracy: 0.9408 - val_loss: 0.1938 - val_accuracy: 0.9213\n",
      "Epoch 808/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1290 - accuracy: 0.9417 - val_loss: 0.1862 - val_accuracy: 0.9241\n",
      "Epoch 809/1000\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.1195 - accuracy: 0.9446 - val_loss: 0.1940 - val_accuracy: 0.9238\n",
      "Epoch 810/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1189 - accuracy: 0.9449 - val_loss: 0.1973 - val_accuracy: 0.9192\n",
      "Epoch 811/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1197 - accuracy: 0.9449 - val_loss: 0.1932 - val_accuracy: 0.9235\n",
      "Epoch 812/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1164 - accuracy: 0.9463 - val_loss: 0.1861 - val_accuracy: 0.9258\n",
      "Epoch 813/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1329 - accuracy: 0.9407 - val_loss: 0.1971 - val_accuracy: 0.9206\n",
      "Epoch 814/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1187 - accuracy: 0.9449 - val_loss: 0.1824 - val_accuracy: 0.9248\n",
      "Epoch 815/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1108 - accuracy: 0.9484 - val_loss: 0.1849 - val_accuracy: 0.9257\n",
      "Epoch 816/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1252 - accuracy: 0.9423 - val_loss: 0.1897 - val_accuracy: 0.9231\n",
      "Epoch 817/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1184 - accuracy: 0.9448 - val_loss: 0.1890 - val_accuracy: 0.9236\n",
      "Epoch 818/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1142 - accuracy: 0.9474 - val_loss: 0.1935 - val_accuracy: 0.9222\n",
      "Epoch 819/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1299 - accuracy: 0.9416 - val_loss: 0.1813 - val_accuracy: 0.9253\n",
      "Epoch 820/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1192 - accuracy: 0.9453 - val_loss: 0.2048 - val_accuracy: 0.9190\n",
      "Epoch 821/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1175 - accuracy: 0.9451 - val_loss: 0.1849 - val_accuracy: 0.9244\n",
      "Epoch 822/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1131 - accuracy: 0.9471 - val_loss: 0.1940 - val_accuracy: 0.9208\n",
      "Epoch 823/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1292 - accuracy: 0.9404 - val_loss: 0.1927 - val_accuracy: 0.9237\n",
      "Epoch 824/1000\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1232 - accuracy: 0.9432 - val_loss: 0.1972 - val_accuracy: 0.9189\n",
      "Epoch 825/1000\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.1221 - accuracy: 0.9435 - val_loss: 0.1871 - val_accuracy: 0.9233\n",
      "Epoch 826/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1200 - accuracy: 0.9444 - val_loss: 0.1886 - val_accuracy: 0.9230\n",
      "Epoch 827/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1221 - accuracy: 0.9437 - val_loss: 0.1900 - val_accuracy: 0.9245\n",
      "Epoch 828/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1189 - accuracy: 0.9451 - val_loss: 0.1947 - val_accuracy: 0.9240\n",
      "Epoch 829/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1286 - accuracy: 0.9415 - val_loss: 0.1882 - val_accuracy: 0.9226\n",
      "Epoch 830/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1150 - accuracy: 0.9463 - val_loss: 0.1897 - val_accuracy: 0.9236\n",
      "Epoch 831/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1248 - accuracy: 0.9422 - val_loss: 0.1865 - val_accuracy: 0.9246\n",
      "Epoch 832/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1241 - accuracy: 0.9427 - val_loss: 0.1951 - val_accuracy: 0.9223\n",
      "Epoch 833/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1248 - accuracy: 0.9425 - val_loss: 0.1849 - val_accuracy: 0.9260\n",
      "Epoch 834/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1105 - accuracy: 0.9484 - val_loss: 0.1938 - val_accuracy: 0.9216\n",
      "Epoch 835/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1324 - accuracy: 0.9396 - val_loss: 0.1909 - val_accuracy: 0.9228\n",
      "Epoch 836/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1126 - accuracy: 0.9476 - val_loss: 0.1874 - val_accuracy: 0.9247\n",
      "Epoch 837/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1119 - accuracy: 0.9483 - val_loss: 0.2011 - val_accuracy: 0.9221\n",
      "Epoch 838/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1298 - accuracy: 0.9410 - val_loss: 0.1948 - val_accuracy: 0.9228\n",
      "Epoch 839/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1161 - accuracy: 0.9461 - val_loss: 0.1902 - val_accuracy: 0.9240\n",
      "Epoch 840/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1264 - accuracy: 0.9432 - val_loss: 0.2110 - val_accuracy: 0.9194\n",
      "Epoch 841/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1189 - accuracy: 0.9451 - val_loss: 0.1897 - val_accuracy: 0.9236\n",
      "Epoch 842/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1192 - accuracy: 0.9444 - val_loss: 0.1836 - val_accuracy: 0.9275\n",
      "Epoch 843/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1096 - accuracy: 0.9488 - val_loss: 0.1936 - val_accuracy: 0.9267\n",
      "Epoch 844/1000\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.1158 - accuracy: 0.9465 - val_loss: 0.1843 - val_accuracy: 0.9284\n",
      "Epoch 845/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1179 - accuracy: 0.9451 - val_loss: 0.1900 - val_accuracy: 0.9214\n",
      "Epoch 846/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1283 - accuracy: 0.9417 - val_loss: 0.2005 - val_accuracy: 0.9222\n",
      "Epoch 847/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1160 - accuracy: 0.9458 - val_loss: 0.1914 - val_accuracy: 0.9249\n",
      "Epoch 848/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1104 - accuracy: 0.9489 - val_loss: 0.1858 - val_accuracy: 0.9256\n",
      "Epoch 849/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1106 - accuracy: 0.9488 - val_loss: 0.1979 - val_accuracy: 0.9231\n",
      "Epoch 850/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1160 - accuracy: 0.9462 - val_loss: 0.2077 - val_accuracy: 0.9174\n",
      "Epoch 851/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1275 - accuracy: 0.9414 - val_loss: 0.2151 - val_accuracy: 0.9168\n",
      "Epoch 852/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1277 - accuracy: 0.9418 - val_loss: 0.2076 - val_accuracy: 0.9205\n",
      "Epoch 853/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1360 - accuracy: 0.9383 - val_loss: 0.1912 - val_accuracy: 0.9239\n",
      "Epoch 854/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1168 - accuracy: 0.9457 - val_loss: 0.1924 - val_accuracy: 0.9209\n",
      "Epoch 855/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1146 - accuracy: 0.9468 - val_loss: 0.1927 - val_accuracy: 0.9226\n",
      "Epoch 856/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1192 - accuracy: 0.9452 - val_loss: 0.2022 - val_accuracy: 0.9195\n",
      "Epoch 857/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1262 - accuracy: 0.9421 - val_loss: 0.1830 - val_accuracy: 0.9259\n",
      "Epoch 858/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1086 - accuracy: 0.9498 - val_loss: 0.1837 - val_accuracy: 0.9280\n",
      "Epoch 859/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1182 - accuracy: 0.9459 - val_loss: 0.1898 - val_accuracy: 0.9240\n",
      "Epoch 860/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1175 - accuracy: 0.9452 - val_loss: 0.2043 - val_accuracy: 0.9197\n",
      "Epoch 861/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1281 - accuracy: 0.9414 - val_loss: 0.1917 - val_accuracy: 0.9234\n",
      "Epoch 862/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1130 - accuracy: 0.9473 - val_loss: 0.1913 - val_accuracy: 0.9217\n",
      "Epoch 863/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1194 - accuracy: 0.9466 - val_loss: 0.2073 - val_accuracy: 0.9184\n",
      "Epoch 864/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1187 - accuracy: 0.9455 - val_loss: 0.2004 - val_accuracy: 0.9221\n",
      "Epoch 865/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1177 - accuracy: 0.9453 - val_loss: 0.1893 - val_accuracy: 0.9256\n",
      "Epoch 866/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1107 - accuracy: 0.9482 - val_loss: 0.2000 - val_accuracy: 0.9213\n",
      "Epoch 867/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1278 - accuracy: 0.9417 - val_loss: 0.2253 - val_accuracy: 0.9150\n",
      "Epoch 868/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1257 - accuracy: 0.9422 - val_loss: 0.2044 - val_accuracy: 0.9216\n",
      "Epoch 869/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1172 - accuracy: 0.9450 - val_loss: 0.1886 - val_accuracy: 0.9259\n",
      "Epoch 870/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1161 - accuracy: 0.9457 - val_loss: 0.1940 - val_accuracy: 0.9240\n",
      "Epoch 871/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1138 - accuracy: 0.9471 - val_loss: 0.1951 - val_accuracy: 0.9212\n",
      "Epoch 872/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1161 - accuracy: 0.9459 - val_loss: 0.1828 - val_accuracy: 0.9257\n",
      "Epoch 873/1000\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 0.1127 - accuracy: 0.9479 - val_loss: 0.1949 - val_accuracy: 0.9227\n",
      "Epoch 874/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1199 - accuracy: 0.9442 - val_loss: 0.1898 - val_accuracy: 0.9275\n",
      "Epoch 875/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1121 - accuracy: 0.9477 - val_loss: 0.1884 - val_accuracy: 0.9245\n",
      "Epoch 876/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1325 - accuracy: 0.9401 - val_loss: 0.1896 - val_accuracy: 0.9235\n",
      "Epoch 877/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1129 - accuracy: 0.9481 - val_loss: 0.1931 - val_accuracy: 0.9216\n",
      "Epoch 878/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1192 - accuracy: 0.9451 - val_loss: 0.1868 - val_accuracy: 0.9267\n",
      "Epoch 879/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1111 - accuracy: 0.9486 - val_loss: 0.2042 - val_accuracy: 0.9195\n",
      "Epoch 880/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1400 - accuracy: 0.9368 - val_loss: 0.2069 - val_accuracy: 0.9169\n",
      "Epoch 881/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.1173 - accuracy: 0.9452 - val_loss: 0.1937 - val_accuracy: 0.9240\n",
      "Epoch 882/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1068 - accuracy: 0.9506 - val_loss: 0.1987 - val_accuracy: 0.9209\n",
      "Epoch 883/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1147 - accuracy: 0.9466 - val_loss: 0.1863 - val_accuracy: 0.9255\n",
      "Epoch 884/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1112 - accuracy: 0.9479 - val_loss: 0.1919 - val_accuracy: 0.9230\n",
      "Epoch 885/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.1139 - accuracy: 0.9476 - val_loss: 0.1957 - val_accuracy: 0.9234\n",
      "Epoch 886/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1091 - accuracy: 0.9491 - val_loss: 0.2016 - val_accuracy: 0.9203\n",
      "Epoch 887/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.1254 - accuracy: 0.9427 - val_loss: 0.1901 - val_accuracy: 0.9243\n",
      "Epoch 888/1000\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.1076 - accuracy: 0.9498 - val_loss: 0.1987 - val_accuracy: 0.9250\n",
      "Epoch 889/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.1135 - accuracy: 0.9469 - val_loss: 0.2102 - val_accuracy: 0.9225\n",
      "Epoch 890/1000\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.1152 - accuracy: 0.9466 - val_loss: 0.1919 - val_accuracy: 0.9249\n",
      "Epoch 891/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.1170 - accuracy: 0.9458 - val_loss: 0.1942 - val_accuracy: 0.9236\n",
      "Epoch 892/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1109 - accuracy: 0.9488 - val_loss: 0.1933 - val_accuracy: 0.9223\n",
      "Epoch 893/1000\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.1147 - accuracy: 0.9466 - val_loss: 0.1985 - val_accuracy: 0.9251\n",
      "Epoch 894/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1183 - accuracy: 0.9451 - val_loss: 0.2027 - val_accuracy: 0.9237\n",
      "Epoch 895/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1126 - accuracy: 0.9477 - val_loss: 0.2079 - val_accuracy: 0.9181\n",
      "Epoch 896/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1242 - accuracy: 0.9428 - val_loss: 0.1985 - val_accuracy: 0.9199\n",
      "Epoch 897/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1213 - accuracy: 0.9439 - val_loss: 0.1904 - val_accuracy: 0.9223\n",
      "Epoch 898/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1104 - accuracy: 0.9485 - val_loss: 0.1882 - val_accuracy: 0.9258\n",
      "Epoch 899/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1112 - accuracy: 0.9486 - val_loss: 0.1969 - val_accuracy: 0.9253\n",
      "Epoch 900/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1124 - accuracy: 0.9480 - val_loss: 0.1904 - val_accuracy: 0.9243\n",
      "Epoch 901/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1084 - accuracy: 0.9493 - val_loss: 0.1988 - val_accuracy: 0.9208\n",
      "Epoch 902/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1226 - accuracy: 0.9436 - val_loss: 0.1890 - val_accuracy: 0.9241\n",
      "Epoch 903/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1098 - accuracy: 0.9489 - val_loss: 0.1912 - val_accuracy: 0.9244\n",
      "Epoch 904/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1092 - accuracy: 0.9488 - val_loss: 0.1930 - val_accuracy: 0.9232\n",
      "Epoch 905/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1157 - accuracy: 0.9463 - val_loss: 0.2081 - val_accuracy: 0.9209\n",
      "Epoch 906/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1171 - accuracy: 0.9458 - val_loss: 0.1915 - val_accuracy: 0.9249\n",
      "Epoch 907/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1111 - accuracy: 0.9483 - val_loss: 0.2054 - val_accuracy: 0.9194\n",
      "Epoch 908/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1103 - accuracy: 0.9482 - val_loss: 0.1909 - val_accuracy: 0.9257\n",
      "Epoch 909/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1174 - accuracy: 0.9462 - val_loss: 0.1966 - val_accuracy: 0.9199\n",
      "Epoch 910/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1146 - accuracy: 0.9465 - val_loss: 0.2041 - val_accuracy: 0.9237\n",
      "Epoch 911/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1119 - accuracy: 0.9480 - val_loss: 0.2016 - val_accuracy: 0.9238\n",
      "Epoch 912/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1148 - accuracy: 0.9470 - val_loss: 0.2035 - val_accuracy: 0.9186\n",
      "Epoch 913/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1300 - accuracy: 0.9404 - val_loss: 0.1899 - val_accuracy: 0.9244\n",
      "Epoch 914/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1154 - accuracy: 0.9466 - val_loss: 0.2007 - val_accuracy: 0.9216\n",
      "Epoch 915/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1066 - accuracy: 0.9504 - val_loss: 0.1883 - val_accuracy: 0.9262\n",
      "Epoch 916/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1045 - accuracy: 0.9512 - val_loss: 0.2098 - val_accuracy: 0.9219\n",
      "Epoch 917/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1143 - accuracy: 0.9472 - val_loss: 0.1934 - val_accuracy: 0.9235\n",
      "Epoch 918/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1048 - accuracy: 0.9513 - val_loss: 0.2033 - val_accuracy: 0.9246\n",
      "Epoch 919/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1189 - accuracy: 0.9451 - val_loss: 0.1935 - val_accuracy: 0.9233\n",
      "Epoch 920/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1091 - accuracy: 0.9493 - val_loss: 0.1931 - val_accuracy: 0.9234\n",
      "Epoch 921/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1124 - accuracy: 0.9481 - val_loss: 0.1941 - val_accuracy: 0.9222\n",
      "Epoch 922/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1123 - accuracy: 0.9475 - val_loss: 0.1957 - val_accuracy: 0.9243\n",
      "Epoch 923/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1101 - accuracy: 0.9482 - val_loss: 0.1885 - val_accuracy: 0.9273\n",
      "Epoch 924/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1075 - accuracy: 0.9504 - val_loss: 0.2024 - val_accuracy: 0.9222\n",
      "Epoch 925/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1112 - accuracy: 0.9484 - val_loss: 0.1980 - val_accuracy: 0.9238\n",
      "Epoch 926/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1052 - accuracy: 0.9507 - val_loss: 0.2118 - val_accuracy: 0.9197\n",
      "Epoch 927/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1277 - accuracy: 0.9421 - val_loss: 0.1988 - val_accuracy: 0.9207\n",
      "Epoch 928/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1104 - accuracy: 0.9488 - val_loss: 0.1993 - val_accuracy: 0.9221\n",
      "Epoch 929/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1202 - accuracy: 0.9442 - val_loss: 0.1995 - val_accuracy: 0.9207\n",
      "Epoch 930/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1112 - accuracy: 0.9483 - val_loss: 0.2033 - val_accuracy: 0.9217\n",
      "Epoch 931/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1250 - accuracy: 0.9430 - val_loss: 0.1952 - val_accuracy: 0.9220\n",
      "Epoch 932/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1101 - accuracy: 0.9486 - val_loss: 0.1900 - val_accuracy: 0.9257\n",
      "Epoch 933/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1007 - accuracy: 0.9528 - val_loss: 0.1919 - val_accuracy: 0.9247\n",
      "Epoch 934/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1111 - accuracy: 0.9488 - val_loss: 0.2013 - val_accuracy: 0.9227\n",
      "Epoch 935/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1269 - accuracy: 0.9418 - val_loss: 0.2109 - val_accuracy: 0.9174\n",
      "Epoch 936/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1100 - accuracy: 0.9490 - val_loss: 0.1963 - val_accuracy: 0.9252\n",
      "Epoch 937/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1087 - accuracy: 0.9496 - val_loss: 0.1885 - val_accuracy: 0.9252\n",
      "Epoch 938/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1066 - accuracy: 0.9501 - val_loss: 0.1950 - val_accuracy: 0.9247\n",
      "Epoch 939/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1152 - accuracy: 0.9464 - val_loss: 0.1985 - val_accuracy: 0.9239\n",
      "Epoch 940/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1139 - accuracy: 0.9470 - val_loss: 0.1936 - val_accuracy: 0.9228\n",
      "Epoch 941/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1082 - accuracy: 0.9493 - val_loss: 0.1919 - val_accuracy: 0.9249\n",
      "Epoch 942/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1079 - accuracy: 0.9492 - val_loss: 0.1949 - val_accuracy: 0.9259\n",
      "Epoch 943/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1095 - accuracy: 0.9494 - val_loss: 0.2011 - val_accuracy: 0.9227\n",
      "Epoch 944/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1268 - accuracy: 0.9423 - val_loss: 0.2012 - val_accuracy: 0.9211\n",
      "Epoch 945/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1313 - accuracy: 0.9403 - val_loss: 0.1949 - val_accuracy: 0.9249\n",
      "Epoch 946/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1102 - accuracy: 0.9489 - val_loss: 0.1946 - val_accuracy: 0.9235\n",
      "Epoch 947/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1069 - accuracy: 0.9494 - val_loss: 0.1941 - val_accuracy: 0.9224\n",
      "Epoch 948/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1026 - accuracy: 0.9526 - val_loss: 0.2050 - val_accuracy: 0.9246\n",
      "Epoch 949/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1059 - accuracy: 0.9507 - val_loss: 0.2009 - val_accuracy: 0.9211\n",
      "Epoch 950/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1163 - accuracy: 0.9465 - val_loss: 0.2029 - val_accuracy: 0.9209\n",
      "Epoch 951/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1132 - accuracy: 0.9477 - val_loss: 0.1993 - val_accuracy: 0.9222\n",
      "Epoch 952/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1215 - accuracy: 0.9442 - val_loss: 0.1929 - val_accuracy: 0.9245\n",
      "Epoch 953/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1119 - accuracy: 0.9473 - val_loss: 0.1947 - val_accuracy: 0.9244\n",
      "Epoch 954/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1116 - accuracy: 0.9479 - val_loss: 0.2160 - val_accuracy: 0.9195\n",
      "Epoch 955/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1195 - accuracy: 0.9451 - val_loss: 0.1915 - val_accuracy: 0.9234\n",
      "Epoch 956/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1048 - accuracy: 0.9517 - val_loss: 0.1932 - val_accuracy: 0.9236\n",
      "Epoch 957/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1070 - accuracy: 0.9500 - val_loss: 0.1930 - val_accuracy: 0.9270\n",
      "Epoch 958/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1104 - accuracy: 0.9487 - val_loss: 0.1958 - val_accuracy: 0.9232\n",
      "Epoch 959/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1163 - accuracy: 0.9469 - val_loss: 0.1937 - val_accuracy: 0.9246\n",
      "Epoch 960/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1172 - accuracy: 0.9455 - val_loss: 0.1936 - val_accuracy: 0.9238\n",
      "Epoch 961/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1066 - accuracy: 0.9497 - val_loss: 0.1937 - val_accuracy: 0.9247\n",
      "Epoch 962/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1063 - accuracy: 0.9504 - val_loss: 0.1934 - val_accuracy: 0.9266\n",
      "Epoch 963/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1020 - accuracy: 0.9527 - val_loss: 0.1982 - val_accuracy: 0.9252\n",
      "Epoch 964/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1051 - accuracy: 0.9510 - val_loss: 0.1973 - val_accuracy: 0.9225\n",
      "Epoch 965/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1299 - accuracy: 0.9414 - val_loss: 0.2006 - val_accuracy: 0.9216\n",
      "Epoch 966/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1112 - accuracy: 0.9493 - val_loss: 0.1954 - val_accuracy: 0.9224\n",
      "Epoch 967/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1141 - accuracy: 0.9469 - val_loss: 0.1958 - val_accuracy: 0.9268\n",
      "Epoch 968/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1069 - accuracy: 0.9502 - val_loss: 0.2037 - val_accuracy: 0.9229\n",
      "Epoch 969/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1171 - accuracy: 0.9463 - val_loss: 0.2043 - val_accuracy: 0.9219\n",
      "Epoch 970/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1163 - accuracy: 0.9458 - val_loss: 0.1956 - val_accuracy: 0.9240\n",
      "Epoch 971/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1032 - accuracy: 0.9515 - val_loss: 0.1993 - val_accuracy: 0.9234\n",
      "Epoch 972/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.1120 - accuracy: 0.9492 - val_loss: 0.1986 - val_accuracy: 0.9232\n",
      "Epoch 973/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1148 - accuracy: 0.9467 - val_loss: 0.1998 - val_accuracy: 0.9237\n",
      "Epoch 974/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1071 - accuracy: 0.9502 - val_loss: 0.1963 - val_accuracy: 0.9229\n",
      "Epoch 975/1000\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.1131 - accuracy: 0.9481 - val_loss: 0.1934 - val_accuracy: 0.9241\n",
      "Epoch 976/1000\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 0.1082 - accuracy: 0.9492 - val_loss: 0.1959 - val_accuracy: 0.9251\n",
      "Epoch 977/1000\n",
      "87/87 [==============================] - 14s 161ms/step - loss: 0.1050 - accuracy: 0.9514 - val_loss: 0.2010 - val_accuracy: 0.9259\n",
      "Epoch 978/1000\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 0.1203 - accuracy: 0.9445 - val_loss: 0.2034 - val_accuracy: 0.9251\n",
      "Epoch 979/1000\n",
      "87/87 [==============================] - 14s 157ms/step - loss: 0.1150 - accuracy: 0.9465 - val_loss: 0.1955 - val_accuracy: 0.9266\n",
      "Epoch 980/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.1073 - accuracy: 0.9501 - val_loss: 0.2042 - val_accuracy: 0.9241\n",
      "Epoch 981/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.1027 - accuracy: 0.9516 - val_loss: 0.1982 - val_accuracy: 0.9271\n",
      "Epoch 982/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.1161 - accuracy: 0.9473 - val_loss: 0.2087 - val_accuracy: 0.9202\n",
      "Epoch 983/1000\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1129 - accuracy: 0.9479 - val_loss: 0.2363 - val_accuracy: 0.9186\n",
      "Epoch 984/1000\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.1226 - accuracy: 0.9440 - val_loss: 0.2078 - val_accuracy: 0.9224\n",
      "Epoch 985/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1159 - accuracy: 0.9465 - val_loss: 0.2059 - val_accuracy: 0.9225\n",
      "Epoch 986/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1118 - accuracy: 0.9477 - val_loss: 0.1997 - val_accuracy: 0.9214\n",
      "Epoch 987/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.1135 - accuracy: 0.9476 - val_loss: 0.1911 - val_accuracy: 0.9274\n",
      "Epoch 988/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0970 - accuracy: 0.9552 - val_loss: 0.1985 - val_accuracy: 0.9255\n",
      "Epoch 989/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1047 - accuracy: 0.9509 - val_loss: 0.2003 - val_accuracy: 0.9231\n",
      "Epoch 990/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1094 - accuracy: 0.9490 - val_loss: 0.1944 - val_accuracy: 0.9253\n",
      "Epoch 991/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1069 - accuracy: 0.9499 - val_loss: 0.2021 - val_accuracy: 0.9242\n",
      "Epoch 992/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.1055 - accuracy: 0.9512 - val_loss: 0.2304 - val_accuracy: 0.9178\n",
      "Epoch 993/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.1341 - accuracy: 0.9402 - val_loss: 0.1946 - val_accuracy: 0.9240\n",
      "Epoch 994/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1000 - accuracy: 0.9535 - val_loss: 0.1982 - val_accuracy: 0.9248\n",
      "Epoch 995/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1085 - accuracy: 0.9497 - val_loss: 0.2027 - val_accuracy: 0.9226\n",
      "Epoch 996/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1091 - accuracy: 0.9491 - val_loss: 0.1950 - val_accuracy: 0.9240\n",
      "Epoch 997/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.1012 - accuracy: 0.9533 - val_loss: 0.2041 - val_accuracy: 0.9249\n",
      "Epoch 998/1000\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 0.1181 - accuracy: 0.9461 - val_loss: 0.2108 - val_accuracy: 0.9188\n",
      "Epoch 999/1000\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1078 - accuracy: 0.9494 - val_loss: 0.2002 - val_accuracy: 0.9231\n",
      "Epoch 1000/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.1014 - accuracy: 0.9528 - val_loss: 0.1984 - val_accuracy: 0.9247\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.1850 - accuracy: 0.9276\n",
      "Test Loss: 0.1850\n",
      "Test Accuracy: 0.9276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 SimpleRNN 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = LSTM(256, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAByTUlEQVR4nO3dd1zU9eMH8Ncd4wCZylRRzIV7a7gH7tyWOzXTSu3ryDIzZ7kqzfq5yhwNV5qauRW1HCgu3OLeAqKy993n98eHW3DH/MCH8Xo+HjzkPuve9wHvXrynQhAEAURERETFhFLuAhARERFJieGGiIiIihWGGyIiIipWGG6IiIioWGG4ISIiomKF4YaIiIiKFYYbIiIiKlYYboiIiKhYYbghIiKiYoXhhogKPYVCgdmzZ+f4vAcPHkChUGD9+vWZHnfs2DEoFAocO3YsV+UjosKF4YaIsmX9+vVQKBRQKBQ4ceJEhv2CIMDb2xsKhQJvvfWWDCUkIhIx3BBRjtjY2GDjxo0Ztv/777948uQJVCqVDKUiItJjuCGiHOnWrRu2bt2K1NRUo+0bN25Eo0aN4OnpKVPJiIhEDDdElCODBg3Cy5cvcejQId225ORkbNu2DYMHDzZ5TlxcHD755BN4e3tDpVKhevXq+O677yAIgtFxSUlJmDRpEtzc3ODg4ICePXviyZMnJq/59OlTvPfee/Dw8IBKpUKtWrWwdu1a6V4ogK1bt6JRo0awtbWFq6srhg4diqdPnxodExoaipEjR6J8+fJQqVTw8vJCr1698ODBA90x586dQ+fOneHq6gpbW1tUqlQJ7733nqRlJSI9S7kLQERFi4+PD/z8/LBp0yZ07doVALBv3z5ERUVh4MCB+PHHH42OFwQBPXv2xNGjRzFq1CjUr18fBw4cwKeffoqnT5/i+++/1x37/vvv448//sDgwYPRvHlzHDlyBN27d89QhrCwMLz55ptQKBQYP3483NzcsG/fPowaNQrR0dGYOHFinl/n+vXrMXLkSDRp0gQLFixAWFgYfvjhB5w8eRIXL16Es7MzAKBfv364du0aPv74Y/j4+CA8PByHDh3Co0ePdI87deoENzc3fP7553B2dsaDBw+wffv2PJeRiMwQiIiyYd26dQIA4ezZs8KyZcsEBwcHIT4+XhAEQXj77beFdu3aCYIgCBUrVhS6d++uO2/nzp0CAOHrr782ul7//v0FhUIh3LlzRxAEQQgODhYACGPHjjU6bvDgwQIAYdasWbpto0aNEry8vISIiAijYwcOHCg4OTnpynX//n0BgLBu3bpMX9vRo0cFAMLRo0cFQRCE5ORkwd3dXahdu7aQkJCgO2737t0CAGHmzJmCIAjC69evBQDCt99+a/baO3bs0N03IioYbJYiohx75513kJCQgN27dyMmJga7d+822yS1d+9eWFhY4H//+5/R9k8++QSCIGDfvn264wBkOC59LYwgCPjrr7/Qo0cPCIKAiIgI3Vfnzp0RFRWFCxcu5On1nTt3DuHh4Rg7dixsbGx027t37w5fX1/s2bMHAGBrawtra2scO3YMr1+/NnktbQ3P7t27kZKSkqdyEVH2MNwQUY65ubnB398fGzduxPbt26FWq9G/f3+Txz58+BBly5aFg4OD0fYaNWro9mv/VSqVqFy5stFx1atXN3r84sULREZG4ueff4abm5vR18iRIwEA4eHheXp92jKlf24A8PX11e1XqVRYtGgR9u3bBw8PD7Ru3RrffPMNQkNDdce3adMG/fr1w5w5c+Dq6opevXph3bp1SEpKylMZicg89rkholwZPHgwRo8ejdDQUHTt2lVXQ5HfNBoNAGDo0KEYPny4yWPq1q1bIGUBxJqlHj16YOfOnThw4ABmzJiBBQsW4MiRI2jQoAEUCgW2bduG06dP459//sGBAwfw3nvvYfHixTh9+jTs7e0LrKxEJQVrbogoV/r06QOlUonTp0+bbZICgIoVK+LZs2eIiYkx2n7z5k3dfu2/Go0Gd+/eNTouJCTE6LF2JJVarYa/v7/JL3d39zy9Nm2Z0j+3dpt2v1blypXxySef4ODBg7h69SqSk5OxePFio2PefPNNzJs3D+fOncOGDRtw7do1bN68OU/lJCLTGG6IKFfs7e2xcuVKzJ49Gz169DB7XLdu3aBWq7Fs2TKj7d9//z0UCoVuxJX23/SjrZYuXWr02MLCAv369cNff/2Fq1evZni+Fy9e5OblGGncuDHc3d2xatUqo+ajffv24caNG7oRXPHx8UhMTDQ6t3LlynBwcNCd9/r16wxD3uvXrw8AbJoiyidsliKiXDPXLGSoR48eaNeuHaZPn44HDx6gXr16OHjwIP7++29MnDhR18emfv36GDRoEFasWIGoqCg0b94cAQEBuHPnToZrLly4EEePHkWzZs0wevRo1KxZE69evcKFCxdw+PBhvHr1Kk+vy8rKCosWLcLIkSPRpk0bDBo0SDcU3MfHB5MmTQIA3Lp1Cx06dMA777yDmjVrwtLSEjt27EBYWBgGDhwIAPj111+xYsUK9OnTB5UrV0ZMTAxWr14NR0dHdOvWLU/lJCLTGG6IKF8plUrs2rULM2fOxJYtW7Bu3Tr4+Pjg22+/xSeffGJ07Nq1a+Hm5oYNGzZg586daN++Pfbs2QNvb2+j4zw8PBAUFIS5c+di+/btWLFiBcqUKYNatWph0aJFkpR7xIgRsLOzw8KFCzF16lSUKlUKffr0waJFi3T9i7y9vTFo0CAEBATg999/h6WlJXx9ffHnn3+iX79+AMQOxUFBQdi8eTPCwsLg5OSEpk2bYsOGDahUqZIkZSUiYwohfX0pERERURHGPjdERERUrDDcEBERUbHCcENERETFCsMNERERFSsMN0RERFSsMNwQERFRsVLi5rnRaDR49uwZHBwcoFAo5C4OERERZYMgCIiJiUHZsmWhVGZeN1Piws2zZ88yTAhGRERERcPjx49Rvnz5TI8pceHGwcEBgHhzHB0dZS4NERERZUd0dDS8vb11n+OZKXHhRtsU5ejoyHBDRERUxGSnSwk7FBMREVGxwnBDRERExQrDDRERERUrJa7PDRERFR9qtRopKSlyF4MkYm1tneUw7+xguCEioiJHEASEhoYiMjJS7qKQhJRKJSpVqgRra+s8XYfhhoiIihxtsHF3d4ednR0nZS0GtJPsPn/+HBUqVMjTz5ThhoiIihS1Wq0LNmXKlJG7OCQhNzc3PHv2DKmpqbCyssr1ddihmIiIihRtHxs7OzuZS0JS0zZHqdXqPF2H4YaIiIokNkUVP1L9TBluiIiIqFhhuCEiIirCfHx8sHTpUrmLUajIGm7+++8/9OjRA2XLloVCocDOnTuzPOfYsWNo2LAhVCoVqlSpgvXr1+d7OYmIiPJKoVBk+jV79uxcXffs2bMYM2aMtIUt4mQNN3FxcahXrx6WL1+erePv37+P7t27o127dggODsbEiRPx/vvv48CBA/lc0qwlparxNDIBz6MS5C4KEREVQs+fP9d9LV26FI6OjkbbpkyZojtWEASkpqZm67pubm7sXJ2OrOGma9eu+Prrr9GnT59sHb9q1SpUqlQJixcvRo0aNTB+/Hj0798f33//fT6XNGtXn0ahxcIjGPjzabmLQkREhZCnp6fuy8nJCQqFQvf45s2bcHBwwL59+9CoUSOoVCqcOHECd+/eRa9eveDh4QF7e3s0adIEhw8fNrpu+mYphUKBX375BX369IGdnR2qVq2KXbt2FfCrlVeR6nMTGBgIf39/o22dO3dGYGCg2XOSkpIQHR1t9JUftD281RohX65PRETmCYKA+ORUWb4EQbr3/c8//xwLFy7EjRs3ULduXcTGxqJbt24ICAjAxYsX0aVLF/To0QOPHj3K9Dpz5szBO++8g8uXL6Nbt24YMmQIXr16JVk5C7siNYlfaGgoPDw8jLZ5eHggOjoaCQkJsLW1zXDOggULMGfOnHwvm0VauJHwd5yIiLIpIUWNmjPl6aJwfW5n2FlL83E6d+5cdOzYUfe4dOnSqFevnu7xV199hR07dmDXrl0YP3682euMGDECgwYNAgDMnz8fP/74I4KCgtClSxdJylnYFamam9yYNm0aoqKidF+PHz/Ol+exULLmhoiI8qZx48ZGj2NjYzFlyhTUqFEDzs7OsLe3x40bN7Ksualbt67u+1KlSsHR0RHh4eH5UubCqEjV3Hh6eiIsLMxoW1hYGBwdHU3W2gCASqWCSqXK97Jp5x1Ss+qGiKjA2VpZ4PrczrI9t1RKlSpl9HjKlCk4dOgQvvvuO1SpUgW2trbo378/kpOTM71O+qULFAoFNBqNZOUs7IpUuPHz88PevXuNth06dAh+fn4ylUhPW3MjZdsrERFlj0KhkKxpqDA5efIkRowYoRt4ExsbiwcPHshbqCJA1map2NhYBAcHIzg4GIA41Ds4OFhX3TZt2jS8++67uuM//PBD3Lt3D5999hlu3ryJFStW4M8//8SkSZPkKL4RJTsUExGRxKpWrYrt27cjODgYly5dwuDBg0tUDUxuyRpuzp07hwYNGqBBgwYAgMmTJ6NBgwaYOXMmAHFOAMN2xUqVKmHPnj04dOgQ6tWrh8WLF+OXX35B587yVEUa0oYbZhsiIpLKkiVL4OLigubNm6NHjx7o3LkzGjZsKHexCj2FUMLaUaKjo+Hk5ISoqCg4OjpKdt17L2LRfvG/cFBZ4soc+cMWEVFxlZiYiPv376NSpUqwsbGRuzgkocx+tjn5/C72o6UKirbPjaZkZUUiIqJCh+FGIro+Nww3REREsmK4kYhSW3PDfl5ERESyYriRiIWCzVJERESFAcONRJScxI+IiKhQYLiRiFKpX1uqhA1AIyIiKlQYbiSi7VAMcK4bIiIiOTHcSMTCKNww3RAREcmF4UYiSoM7ySUYiIiI5MNwIxHDZilW3BARUX5o27YtJk6cqHvs4+ODpUuXZnqOQqHAzp078/zcUl2nIDDcSEQ7QzHAEVNERJRRjx490KVLF5P7jh8/DoVCgcuXL+fommfPnsWYMWOkKJ7O7NmzUb9+/Qzbnz9/jq5du0r6XPmF4UYiBhU3bJYiIqIMRo0ahUOHDuHJkycZ9q1btw6NGzdG3bp1c3RNNzc32NnZSVXETHl6ekKlUhXIc+UVw41ELIyapRhuiIjI2FtvvQU3NzesX7/eaHtsbCy2bt2K3r17Y9CgQShXrhzs7OxQp04dbNq0KdNrpm+Wun37Nlq3bg0bGxvUrFkThw4dynDO1KlTUa1aNdjZ2eGNN97AjBkzkJKSAgBYv3495syZg0uXLkGhUEChUOjKm75Z6sqVK2jfvj1sbW1RpkwZjBkzBrGxsbr9I0aMQO/evfHdd9/By8sLZcqUwbhx43TPlZ8s8/0ZSgjDPjesuSEiKmCCAKTEy/PcVnbG1fdmWFpa4t1338X69esxffp0KNLO2bp1K9RqNYYOHYqtW7di6tSpcHR0xJ49ezBs2DBUrlwZTZs2zfL6Go0Gffv2hYeHB86cOYOoqCij/jlaDg4OWL9+PcqWLYsrV65g9OjRcHBwwGeffYYBAwbg6tWr2L9/Pw4fPgwAcHJyynCNuLg4dO7cGX5+fjh79izCw8Px/vvvY/z48Ubh7ejRo/Dy8sLRo0dx584dDBgwAPXr18fo0aOzfD15wXAjEaWS89wQEckmJR6YX1ae5/7iGWBdKluHvvfee/j222/x77//om3btgDEJql+/fqhYsWKmDJliu7Yjz/+GAcOHMCff/6ZrXBz+PBh3Lx5EwcOHEDZsuK9mD9/foZ+Ml9++aXuex8fH0yZMgWbN2/GZ599BltbW9jb28PS0hKenp5mn2vjxo1ITEzEb7/9hlKlxNe+bNky9OjRA4sWLYKHhwcAwMXFBcuWLYOFhQV8fX3RvXt3BAQE5Hu4YbOUhLSdijnPDRERmeLr64vmzZtj7dq1AIA7d+7g+PHjGDVqFNRqNb766ivUqVMHpUuXhr29PQ4cOIBHjx5l69o3btyAt7e3LtgAgJ+fX4bjtmzZghYtWsDT0xP29vb48ssvs/0chs9Vr149XbABgBYtWkCj0SAkJES3rVatWrCwsNA99vLyQnh4eI6eKzdYcyMhpQJQg+GGiKjAWdmJNShyPXcOjBo1Ch9//DGWL1+OdevWoXLlymjTpg0WLVqEH374AUuXLkWdOnVQqlQpTJw4EcnJyZIVNTAwEEOGDMGcOXPQuXNnODk5YfPmzVi8eLFkz2HIysrK6LFCoYBGo8mX5zLEcCMhsd+NwD43REQFTaHIdtOQ3N555x1MmDABGzduxG+//YaPPvoICoUCJ0+eRK9evTB06FAAYh+aW7duoWbNmtm6bo0aNfD48WM8f/4cXl5eAIDTp08bHXPq1ClUrFgR06dP1217+PCh0THW1tZQq9VZPtf69esRFxenq705efIklEolqlevnq3y5ic2S0lI26mYFTdERGSOvb09BgwYgGnTpuH58+cYMWIEAKBq1ao4dOgQTp06hRs3buCDDz5AWFhYtq/r7++PatWqYfjw4bh06RKOHz9uFGK0z/Ho0SNs3rwZd+/exY8//ogdO3YYHePj44P79+8jODgYERERSEpKyvBcQ4YMgY2NDYYPH46rV6/i6NGj+PjjjzFs2DBdfxs5MdxISNvnhjU3RESUmVGjRuH169fo3Lmzro/Ml19+iYYNG6Jz585o27YtPD090bt372xfU6lUYseOHUhISEDTpk3x/vvvY968eUbH9OzZE5MmTcL48eNRv359nDp1CjNmzDA6pl+/fujSpQvatWsHNzc3k8PR7ezscODAAbx69QpNmjRB//790aFDByxbtiznNyMfKIQSNilLdHQ0nJycEBUVBUdHR0mvXWf2AcQkpiLgkzao7GYv6bWJiEiUmJiI+/fvo1KlSrCxsZG7OCShzH62Ofn8Zs2NhLQ1NyUsLxIRERUqDDcS0s5SrM7/juBERERkBsONhLSzTXIoOBERkXwYbiRkkXY32aGYiIhIPgw3EuJQcCKigsP+jcWPVD9ThhsJacONmv/hiIjyjXbW2/h4mRbKpHyjnY3ZcMmG3OAMxVKJuIPPUlfiuaUKGqG53KUhIiq2LCws4OzsrFujyM7OTtfnkYoujUaDFy9ewM7ODpaWeYsnDDdSSXiNXqkH8UjphnD2uSEiylfaFasLYhFGKjhKpRIVKlTIc1hluJGKygEAYK9IwHOGGyKifKVQKODl5QV3d3ekpKTIXRySiLW1NZTKvPeYYbiRSlq4cUACNAw3REQFwsLCIs/9M6j4YYdiqdiIU0FbKdRAaqLMhSEiIiq5GG6kYlUKGohthIrkGJkLQ0REVHIx3EhFqUSCwhYAww0REZGcGG4kFK+wAwAok2NlLgkREVHJxXAjoWSFCgBQ+ukxeQtCRERUgjHcSKiUJg4AUPb+VplLQkREVHIx3EjohF07AECStYvMJSEiIiq5GG4kdMe+CQBwnhsiIiIZMdxIyNraGgAgaFJlLgkREVHJxXAjIeu0lWoZboiIiOTDcCMhVVrNDRhuiIiIZMNwIyF9uNHIWxAiIqISjOFGQiqVGG4UAmtuiIiI5MJwIyFbbbjRqGUuCRERUcnFcCMhlUqcoZg1N0RERPJhuJGQTVrNjVJgzQ0REZFcGG4kZJdWc8NwQ0REJB+GGwnZ2qSFGzDcEBERyYXhRkJ2aeHGgjU3REREsmG4kZCtjQ0AwAIapKo51w0REZEcGG4kZGcjdii2UqgRl8QRU0RERHJguJGQyspa931cYrKMJSEiIiq5GG6kpLTQfRuXmChjQYiIiEouhhspKS1137LmhoiISB4MN1IyCDeCOkXGghAREZVcDDdSMgg3GjWHgxMREcmB4UZKCv3tZM0NERGRPBhupKRQIBVip2JBw6HgREREcmC4kZg6LdyAzVJERESyYLiRmFpXc8NmKSIiIjkw3EhMk9bvRqNmsxQREZEcGG4kpmuWYp8bIiIiWcgebpYvXw4fHx/Y2NigWbNmCAoKyvT4pUuXonr16rC1tYW3tzcmTZqExEI0G7Baoe1zw3BDREQkB1nDzZYtWzB58mTMmjULFy5cQL169dC5c2eEh4ebPH7jxo34/PPPMWvWLNy4cQNr1qzBli1b8MUXXxRwyc0T0m6phjU3REREspA13CxZsgSjR4/GyJEjUbNmTaxatQp2dnZYu3atyeNPnTqFFi1aYPDgwfDx8UGnTp0waNCgLGt7CpK2WUrBcENERCQL2cJNcnIyzp8/D39/f31hlEr4+/sjMDDQ5DnNmzfH+fPndWHm3r172Lt3L7p162b2eZKSkhAdHW30lZ80ac1SnKGYiIhIHpZZH5I/IiIioFar4eHhYbTdw8MDN2/eNHnO4MGDERERgZYtW0IQBKSmpuLDDz/MtFlqwYIFmDNnjqRlzw5BEAr8OYmIiKgQdCjOiWPHjmH+/PlYsWIFLly4gO3bt2PPnj346quvzJ4zbdo0REVF6b4eP36cv4VUKAAAgqDJ3+chIiIik2SruXF1dYWFhQXCwsKMtoeFhcHT09PkOTNmzMCwYcPw/vvvAwDq1KmDuLg4jBkzBtOnT4dSmTGrqVQqqFQq6V+AGQIYboiIiOQkW82NtbU1GjVqhICAAN02jUaDgIAA+Pn5mTwnPj4+Q4CxsEibEbjQNAOJ4UbDbENERCQL2WpuAGDy5MkYPnw4GjdujKZNm2Lp0qWIi4vDyJEjAQDvvvsuypUrhwULFgAAevTogSVLlqBBgwZo1qwZ7ty5gxkzZqBHjx66kCM3fc0NOxQTERHJQdZwM2DAALx48QIzZ85EaGgo6tevj/379+s6GT969MiopubLL7+EQqHAl19+iadPn8LNzQ09evTAvHnz5HoJGen63BSWmiQiIqKSRSGUsE/h6OhoODk5ISoqCo6OjpJf/9m8uiib8hCHm66Bf7f+kl+fiIioJMrJ53eRGi1VFLBDMRERkbwYbqSW1iyFklUhRkREVGgw3EhM0I2WYodiIiIiOTDcSI0diomIiGTFcCM5hhsiIiI5MdxIjh2KiYiI5MRwIzVtsxSzDRERkSwYbiQmKMRbyhmKiYiI5MFwIzkOBSciIpITw43U0rKNRsNwQ0REJAeGG8mxQzEREZGcGG4kp22WYrghIiKSA8ONxPQditksRUREJAeGG8mlNUuB4YaIiEgODDdS081zw2YpIiIiOTDcSI1rSxEREcmK4UZyrLkhIiKSE8ON1FhzQ0REJCuGG8mxQzEREZGcGG6kpuA8N0RERHJiuJEc57khIiKSE8ON1DgUnIiISFYMN1JTcFVwIiIiOTHcSE4MNxqGGyIiIlkw3EiNNTdERESyYriRmIKjpYiIiGTFcCMx3argnOeGiIhIFgw3ElNoJ/FjzQ0REZEsGG6kpm2W0rDmhoiISA4MN5JLCzdsliIiIpIFw43U2KGYiIhIVgw3EtN2KCYiIiJ58JNYcpznhoiISE4MN1LTNkuBzVJERERyYLjJL6y4ISIikgXDjcQUaX1uFKy5ISIikgXDjcQEhXYSP1bdEBERyYHhRnLsUExERCQnhhuppdXcKLI4jIiIiPIHw43kOFqKiIhITgw3UtPW3LBZioiISBYMN5ITb6nAmhsiIiJZMNxITVdzI3M5iIiISiiGG8lxtBQREZGcGG6kplt+geGGiIhIDgw3UtMNBWefGyIiIjkw3EiOt5SIiEhO/CSWmrZZSmDNDRERkRwYbvILu9wQERHJguFGYgr2uSEiIpIVw43UOFqKiIhIVgw3UlOk3VLOc0NERCQLhhvJcT1wIiIiOTHcSE23/AL73BAREcmB4UZq7HNDREQkK4YbiSmgHS3FcENERCQHhhuJCdoOxQw3REREsmC4kZqCq4ITERHJieFGYtpmKVbcEBERyYPhRmqcoZiIiEhWDDdSU7BDMRERkZwYbqTGGYqJiIhkxXAjMV2fG9bcEBERyUL2cLN8+XL4+PjAxsYGzZo1Q1BQUKbHR0ZGYty4cfDy8oJKpUK1atWwd+/eAipt1gQ2SxEREcnKUs4n37JlCyZPnoxVq1ahWbNmWLp0KTp37oyQkBC4u7tnOD45ORkdO3aEu7s7tm3bhnLlyuHhw4dwdnYu+MKboeBQcCIiIlnJGm6WLFmC0aNHY+TIkQCAVatWYc+ePVi7di0+//zzDMevXbsWr169wqlTp2BlZQUA8PHxKcgiZwObpYiIiOQkW7NUcnIyzp8/D39/f31hlEr4+/sjMDDQ5Dm7du2Cn58fxo0bBw8PD9SuXRvz58+HWq0uqGJnLa1DMZuliIiI5CFbzU1ERATUajU8PDyMtnt4eODmzZsmz7l37x6OHDmCIUOGYO/evbhz5w7Gjh2LlJQUzJo1y+Q5SUlJSEpK0j2Ojo6W7kWYwGYpIiIiecneoTgnNBoN3N3d8fPPP6NRo0YYMGAApk+fjlWrVpk9Z8GCBXByctJ9eXt7528h2aGYiIhIVrKFG1dXV1hYWCAsLMxoe1hYGDw9PU2e4+XlhWrVqsHCwkK3rUaNGggNDUVycrLJc6ZNm4aoqCjd1+PHj6V7EaYo2OeGiIhITrKFG2trazRq1AgBAQG6bRqNBgEBAfDz8zN5TosWLXDnzh1oNPqlDW7dugUvLy9YW1ubPEelUsHR0dHoKz9p57lhzQ0REZE8ZG2Wmjx5MlavXo1ff/0VN27cwEcffYS4uDjd6Kl3330X06ZN0x3/0Ucf4dWrV5gwYQJu3bqFPXv2YP78+Rg3bpxcLyEjzlBMREQkK1mHgg8YMAAvXrzAzJkzERoaivr162P//v26TsaPHj2CUqnPX97e3jhw4AAmTZqEunXroly5cpgwYQKmTp0q10vISNcsRURERHKQNdwAwPjx4zF+/HiT+44dO5Zhm5+fH06fPp3Ppco97WgppcBVwYmIiOSQq2apx48f48mTJ7rHQUFBmDhxIn7++WfJClZ0aW8pm6WIiIjkkKtwM3jwYBw9ehQAEBoaio4dOyIoKAjTp0/H3LlzJS1gUaNgsxQREZGschVurl69iqZNmwIA/vzzT9SuXRunTp3Chg0bsH79einLV+Rw4UwiIiJ55SrcpKSkQKVSAQAOHz6Mnj17AgB8fX3x/Plz6UpXBHGGYiIiInnlKtzUqlULq1atwvHjx3Ho0CF06dIFAPDs2TOUKVNG0gIWOVxbioiISFa5CjeLFi3CTz/9hLZt22LQoEGoV68eAHFhS21zVUml0DVLcbQUERGRHHI1FLxt27aIiIhAdHQ0XFxcdNvHjBkDOzs7yQpXNLFDMRERkZxyVXOTkJCApKQkXbB5+PAhli5dipCQELi7u0tawCJHyWYpIiIiOeUq3PTq1Qu//fYbACAyMhLNmjXD4sWL0bt3b6xcuVLSAhY1urWlOIkfERGRLHIVbi5cuIBWrVoBALZt2wYPDw88fPgQv/32G3788UdJC1jkcJ4bIiIiWeUq3MTHx8PBwQEAcPDgQfTt2xdKpRJvvvkmHj58KGkBixr9JH5sliIiIpJDrsJNlSpVsHPnTjx+/BgHDhxAp06dAADh4eFwdHSUtIBFDyfxIyIiklOuws3MmTMxZcoU+Pj4oGnTpvDz8wMg1uI0aNBA0gIWOdoOxZzEj4iISBa5Ggrev39/tGzZEs+fP9fNcQMAHTp0QJ8+fSQrXFGkYM0NERGRrHIVbgDA09MTnp6eutXBy5cvX+In8AMAhdIi7TuGGyIiIjnkqllKo9Fg7ty5cHJyQsWKFVGxYkU4Ozvjq6++gkZTwodAp3UoVjLcEBERySJXNTfTp0/HmjVrsHDhQrRo0QIAcOLECcyePRuJiYmYN2+epIUsUjhaioiISFa5Cje//vorfvnlF91q4ABQt25dlCtXDmPHji3h4UasDFOyQzEREZEsctUs9erVK/j6+mbY7uvri1evXuW5UEWZQrf8QglvniMiIpJJrsJNvXr1sGzZsgzbly1bhrp16+a5UEWZQsG1pYiIiOSUq2apb775Bt27d8fhw4d1c9wEBgbi8ePH2Lt3r6QFLHrSmqVYc0NERCSLXNXctGnTBrdu3UKfPn0QGRmJyMhI9O3bF9euXcPvv/8udRmLFG2zFBEREckj1/PclC1bNkPH4UuXLmHNmjX4+eef81ywIks3FJw1N0RERHJgNYPEFApxEj8uv0BERCQPhhupKbV9bhhuiIiI5MBwIzHd2lIKAQJrb4iIiApcjvrc9O3bN9P9kZGReSlL8aDUDwUXBIMJi4mIiKhA5CjcODk5Zbn/3XffzVOBijrtPDdKaNgwRUREJIMchZt169blVzmKDe2q4EoI0AgCLMCqGyIiooLEPjdSM1gVnF1uiIiICh7DjcQUaeFGAQECG6aIiIgKHMON1BTGHYqJiIioYDHcSEzf54YzFBMREcmB4UZiCoNJ/DSsuiEiIipwDDcS003iB7BZioiISAYMNxJT6Cbx4zw3REREcmC4kZpC3yzF5ReIiIgKHsON1AzDjcxFISIiKokYbiSmNFxbigOmiIiIChzDjdQ4iR8REZGsGG4kplDo57lhlxsiIqKCx3AjMQX73BAREcmK4UZihpP4cbQUERFRwWO4kZhunhuFAA2zDRERUYFjuJEcOxQTERHJieFGagZ9bphtiIiICh7DjdR04YbLLxAREcmB4UZqCu0kflw4k4iISA4MN1LTTeKngYbphoiIqMAx3EiN89wQERHJiuFGagbhRsOx4ERERAWO4UZqCv3CmWyWIiIiKngMN1IzqLlJUTPcEBERFTSGm3yigAA1m6WIiIgKHMON1AzmuUnVaGQuDBERUcnDcCM1g2Yp1twQEREVPIYbqaWFG1tFMsoe+0TmwhAREZU8DDdSU+hvqeudbUBqkoyFISIiKnkYbqSWNkOxjkYtTzmIiIhKKIYbqSnS3VJNqjzlICIiKqEYbqSWPtwIrLkhIiIqSAw3UstQc8Ph4ERERAWJ4UZy6frcsOaGiIioQBWKcLN8+XL4+PjAxsYGzZo1Q1BQULbO27x5MxQKBXr37p2/BcyJDB2K2eeGiIioIMkebrZs2YLJkydj1qxZuHDhAurVq4fOnTsjPDw80/MePHiAKVOmoFWrVgVU0mzK0CzFmhsiIqKCJHu4WbJkCUaPHo2RI0eiZs2aWLVqFezs7LB27Vqz56jVagwZMgRz5szBG2+8UYClzQZ2KCYiIpKVrOEmOTkZ58+fh7+/v26bUqmEv78/AgMDzZ43d+5cuLu7Y9SoUQVRzJxhzQ0REZGsLOV88oiICKjVanh4eBht9/DwwM2bN02ec+LECaxZswbBwcHZeo6kpCQkJelnCY6Ojs51ebOFk/gRERHJSvZmqZyIiYnBsGHDsHr1ari6umbrnAULFsDJyUn35e3tnb+FZLMUERGRrGStuXF1dYWFhQXCwsKMtoeFhcHT0zPD8Xfv3sWDBw/Qo0cP3TZN2jwylpaWCAkJQeXKlY3OmTZtGiZPnqx7HB0dnb8BJzvNUqnJgKV1/pWBiIioBJO15sba2hqNGjVCQECAbptGo0FAQAD8/PwyHO/r64srV64gODhY99WzZ0+0a9cOwcHBJkOLSqWCo6Oj0Ve+yqrm5uCXwKKKQLjpZjciIiLKG1lrbgBg8uTJGD58OBo3boymTZti6dKliIuLw8iRIwEA7777LsqVK4cFCxbAxsYGtWvXNjrf2dkZADJsl01Wa0ud+j/x35NLgT6rCqRIREREJYns4WbAgAF48eIFZs6cidDQUNSvXx/79+/XdTJ+9OgRlMqi1DUofYdiM8sv2JXJ/6IQERGVQLKHGwAYP348xo8fb3LfsWPHMj13/fr10hcoL9KPljJsllIb1OKUciuY8hAREZUwRalKpGjIbPmFuBf67+1KF0x5iIiIShiGm/xmOFrKMNwQERFRvmC4yW/qFP33GsPvOf8NERFRfmC4yW8b+gH/TBC/N+xcLJjpaExERER5wnBTEM6vF/817FzMcENERJQvGG7yQYL/AtM7NAw3RERE+Y3hJh/YtPgI5zTVM+4wrLlhnxsiIqJ8wXCTDxQKBRRKi4w7WHNDRESU7xhu8onSwkS4Mepzw5obIiKi/MBwk0+UJmtuOFqKiIgovzHc5BOlpZXxBo3GdJ+b1CRg8xAgaHXBFY6IiKgYY7jJJ0qLdMt2qZPT9bkRxH+DNwI3dwN7pxRc4YiIiIqxQrFwZnFkkb7Pzca3gfv/6R9ra3ESowquUERERCUAa27yiUX6mhvDYAMY9LkRCqQ8REREJQXDTT6xtMyiUkzbRCUYhJuUBCBkH5Acl38FIyIiKuYYbvKJjSIl8wN0nYsNws2eKcCmgcDf4/OtXERERMUdw00+8Qr7N/MDTA0FD/5D/PfadukLREREVEIw3MjFVLMUERER5RnDTT7RWNllfoAu1DDcEBERSYnhJp8oR+zJ/ABtnxtT2cbCWvLyEBERlRQMN/mlXMPM92c2FNzKVvLiEBERlRQMN3LRZLJwplWpgisHERFRMcNwIxdtzY2pDsWsuSEiIso1hhu5mJrnRiurzshERERkFsONXDKrubFkh2IiIqLcYriRi0YbbkxM5qfkeqZERES5xXCTj55U6m9+pzbUaEws08BwQ0RElGsMN/mo3LDV+CBlkumd2j43alPhxiL/CkVERFTMMdzkI4VSiarVa5veqau5STWxr4BmLdaYaBIjIiIq4hhu8pmlrbPpHZpMam5M9cOR2uMgYFFF4Nza/H8uIiKiAsRwk8+Gtq1jekdmfW5M1eZIbdt7QFI0sNtMsxkREVERxXCTz1zLuJrcHhWfJH6jNhFkMpu9WDKKAngOIiKigsdwk9/MdA4+fy9M7PMiV80NERFRMcVwUwAEuzIZtrW3CIawtA6QGG3ihHQ1N1FPgbiX0haKFTdERFRMMdwUAMX/LuJ6tY8ybo9+AkTcyniCtlkq4TXw/BLwfU3g2zekLpXE1yMiIiocGG4Kgo0TagxaYHpfvIkaGW24+a4a8FNrg+0cuk1ERJQVhpsColCYqSlJMtEspe1zo0423q5OkrJA0l2LiIioEGG4KYwENfDoTMbtqYmmjzfVbydLDDdERFQ8MdwURq8fAGs7ZdyeYiLc3DoALPQGji/O2XOw5oaIiIophpuixFTNzV+jxX8D5ubwYgw3RERUPDHcFKQqHc3u6pU0FyFOLTI/PzWtz82dAGBVS7G2JilKwgISEREVfQw3BWnAH0D17iZ3hQqlsdvtg8zP19bc/NEXCL2Si9oaA2yWIiKiYorhpiBZ2QDVu5jclQAVwuOymJk4NRG4c9jMtUvlsDAMN0REVDwx3BS0ugOBVlMybI6HCoEPsmhiSk0E/uhnel9KnFibIyVT614REREVcgw3Bc3SGugwA6jezWhzKiyhyerHkdWQ71Utsz/RX1bNUodmAYsqAi/vZu96REREhQTDjVy6LwZqi7UwJy2aYFBTbzjY2mR+zp/Dsr6uublwMsgi3JxcCiTHAv8uyub1iIiICgdLuQtQYjmWBfqvBfr+ghZKJVoAQEd3IIfT1WSQmghY20lQQCIioqKJNTdyUxr8CBQWeb9eSrzp7YJg/JijpYiIqJhiuClMLK113x5SN8zdNZ6cFVcST47Tb9v7KbC0jrjKuA7DjZG4l8AKP+DE97k7/+VdQJ0ibZmIiChX2CxVmNg4AQM2AJY2uHbPCwf/W4+OyvNo7fAcNvHPsneNrSPEf31aASN2i98H/Sz++0c/IPIx8PY6yYte5J36AQi/DhyeDbSclLNzr+0Q73vVzsCQP/OjdERElAMMN4VNjbcAAB/6qLE4dSTc606H0ssR4/84iWUP3sr+dR4cz7jt6Xnx3996A5rs1jIUgxqemDAg9DJQxd98c1xKQu6vH7hc/Pf2gdxfg4iIJMNmqULKxsoC07vXRH1vZ1hbKrFseMucXyR9Pxut9MFGo875tYuSZY2BDf2BK1vlLgkRERUAhpuiwkyNw3/qOubPmeMMhOzP+tqaYj5ZX1La/EC3MqlZMRcEs6JRo1jUblH+enkXOPI1EP9K7pIQlQgMN8XdpgFZH5PTcBNxB9g5LvcT/D06I/b9KXCZBZhchJuza4CFFYAnQbkuEZUQP7cD/vsW2PWx3CUhyrug1cDRBXKXIlMMN0VJ9yUZNtUv75D366Yf5ZPVLMe/9waC/wA2DTK9P2Sf+FeqqeuEXgXWdgKW1s5VUU2KCcte01pmtTO5qbnZM1mc6JAoK0lpS6s8CpS3HAVJnQJE3Ja7FCQ1QQD2TgH+XViof74MN0VJk1HiaCoDjpYaoNPXebtu+mBg2CdHoQCeXgCeBeu3RaXVukSEiEOor+0AjhsEr00Dxb9Sb+7Wb3txC0hNEoeqS+nyn8ASX2D3RGmvW9SEXgF+qAdc2SZ3SShTJagJc8tQsb8bfyeLF8PBF9o/7h4GApe2yFMeMxhuipoabwFfPNc/Lt8YaJ63qu7ExDhxbpzzvwJXtwM/t9XvTI4FVrcDfm4DpCZnPHnPZHEYdMAc4NFp4323D4r/huwDljcBfu8LKCT+lds+GhA0wIXfsnFwLvvVFAXbxwCvHwB/jZK7JJSZkjR55q20/n7a0YRUPBhOFKut8V7XBdgxRvwcKSQYbooiaztg7Bmg7TTxCwDqvG10SJRgh05J2VsX6sH928BPrYF//gdsGynO96IVF6H/Pikm48mPDfqbvH5gvO/i70DsC7FvCgA8PAHEhun357YTryHDWZ3zdD0T5yZGizVWUpQzv+VlKHthkZoMhN8sGvc710pQuCFRchyw/4uMf/wVVYYTxKZfy/D1w4ItSyYYbooqd1+g7eeAyl583HMZ8N4B4N2/gTZTsa39v7gleGN9aqcsL+V8YYX5nYazGidFZ/zgUSfpv49/BWwdabz/5R3j2pqj8/TfX/1LPOfiBiApl31XbJ313xsGMVNy2udGW2N172iuilaglMVgyqrNg4AVzYr3kP2SVHOjVRJfs6ET3wOnlwNrO8tdEmkYhpvkeONuDUoJlhCSSDF4RyQAgJUNUOFN8fs32mIUgEF+b+DTDQ4Y8fCg7rBwwRnuikijUz2fHTZ/3Rc39d8nxRj3owGMf9EvbRInyzOUEm++KcqwCeVRINBrmflymKM2GOkV/RSwd8vk4GzWCGg04ppfL++Ij2/sBiq3z3nZClJm4eb1A8CqVBb3phC4k/Z7eHolUPcdecuSb0r4B31JFH5D7hJIy7BZKiXO+LEU6yNKhDU3xZidtSW+H9YS4QP2ABYqoP0M/FTrD3yQPDF3F/ypFRKu7TXeZlgtGf004znxL7OX5i+nLVtw9S/gzE+ZH/vqPvDsoljbYjhaKU8jlwyCT/pJDm2c8nDdAmIu3MS+EDsaf1elYMuTJ8W4Waqk12KURIWoNsOk+FdiE3x2pa+5STZcrLnw/N9luCnmrC2VcK/REpj2GGg9BW3q++KApqlu//WqHyJBsIZayN6bru3VjeZ3xr/MsEkT+wJ3XsSZODgdKxsgJRHY9h6w7zPTbbfqVDHQ/Fhf7PR8bAEgGFSJhl4BDs0ybkpLNtH5zRTDfeoUcWSXlo2j8bExYVkPly9o5t5ApR6dVhQIgtiJ9U4mNZKyYbjJFymJGbelJhnX7OanByeB1R2AJ+cy7itEtRkZpCQA31QCFlXM/nuaYbhJiRO/tNL3wZERw01JYakCALSu5oY1wxvj+dv/AL1XouaQRfCz2ICqSb/ny9PeuncfIeHZCDeWtsALg+pbw34XqcniTMuLqwFbh+u3/5uuw/T+z4GTS4FNg8XHwRuB+WUNDhDEWYpvHxb/I986CMSGi99f+FV/mCYFiHuhfxwXAfwzQZzT4f5xsRzbRmT9mvKLYefhy1uBVa2AqCemj00wmBG3oN7ozUlJKJgOhw9OAAe+EBeKLWw0qUBMqNylKDyeBQN7pohTSuTW9V3AfC+x755WahLwfS3gp1Z5LmIGqcni+4DhH0B/9AOengO2DMt4vGGzfFad5fO6FM6T88CB6frBHykJ4jZzwUU7maqgMW5eyozhccnx6cJOojgooBDMxF0ows3y5cvh4+MDGxsbNGvWDEFB5md8Xb16NVq1agUXFxe4uLjA398/0+Mpow41POBVqzVQXwwBc3rWggZKHFQ3QqjggkHJ0yV7Lt87q9HdIhs/HysbIOya/vGRr/STC+7/XJxpOf4lcP3vrK/16JT4b+ByGFWTJsUAG98BNvQTw8zGt4E1HTMueKlONR7VFbgMOL8e2PU/4OQP4jZz5UiMyrp8ebH3U2Cep9iOn/Aa2P6+2M8p3kxnasM3GcPO33JY3QH4oS7w/HLmx+V1tFTko7ydn5/iwoHF1QtPPwxBEH+3s/qZ5Jef2wBnVwMHpuX+Gn8OEz+c/x6r3xZ+Q/wDJfx6xklK8+rQTODXt8T/i1qpaX9wxDzLeLxhrWpmAeLJOWCBt/i+pU7NGPgi7hj/f06OB9Z2FecU0/qlvfh+pZ09eMcH4jbDP94MGTbBZ7dZ3yjMpGuWen5JHBSwul32rpWPZA83W7ZsweTJkzFr1ixcuHAB9erVQ+fOnREeHm7y+GPHjmHQoEE4evQoAgMD4e3tjU6dOuHpUxP9PShbetUvh90ft0STqfvgOfMOWnbsi4bJq6G2tCuwMsRpLI0nCgTE/8h7PwXOrcn5BdWpgHMF420Jkfrvg1aL/75+YFxLA4j/4aNM/D5FhGQ9T8/CCrmfzEoQ0rVfmxD0s/jvf98B27Ixp41hzU2qzOEmPC28Xt8pazEKhSvbxLB8LHvTNeSb63+LtZL5UcORE6FXpbnOy7tivz1DydmoOTaUVQ3nmZXiv9rAYK5WJDVJnGLjssH7gWHflvCbwG+9xQnwAODvcWITz4EvgIDZwLeVgcdpzcqv7gPLGolNSNr3iMubxT/kjpiYxPXZBfFf7R9hpuYaUqcaT++R3ftkeM7rh8bNUlfTJmx8/UD2KR1kDzdLlizB6NGjMXLkSNSsWROrVq2CnZ0d1q5da/L4DRs2YOzYsahfvz58fX3xyy+/QKPRICAgoIBLXrzULucEF3sVYGGJce2q4NScfrAYcxTo+i2O18v4Bjw/ZRAC1A3MXm9lao8cPX+pqDviX3AGhBc39B/mORUXnrGKNzFS/73hh37649TJpv/6L1M1ex1Cd4zJdjGN/DMBWOidvTW7FErgrpnfecM3W8OaJLWJSRjlYKHK4gAzb4opiTmfz0eqN9jYcGnDYcQt8cPx2Hx5+2/lZNK1ixvEtbFiX2R9bE5lp9Nt3EtxIEFm1nQU++1d/EO/zfBDW6MBop9nPE/r6nZgQTlxhGR2pa81TY4X/1D72j3j/U0yCDcrmonTTOyZLD42DD6X/wQgAPePiY/v/6vfN98LWOyrH4QBiLU6hr/rzy4CN/7RP7YuZVyOfVOBr8ro5yADMs5j9uQc8FMb/QAPQQBOLAUOGtTsX/3LuI+j4R+KMjdNyRpukpOTcf78efj7++u2KZVK+Pv7IzAwe2uwxMfHIyUlBaVLl86vYpZINlYW4lw6zcagVZ8PEeunr4L9OmUIUpt9jEuayibPbZO0BCtSe2X9JC0n41y7DWZ3K37LxjXMiXqasbnJcJLBGIM3uMh0/UDUqfolJgwpLZHtDqHb3hPfLExNfGjOhV/FPhmB6YbE3z8OXPg9+/NJpBoEAMOaIDk7+xl+gFtaZ36sqUCi0QBL6wDfVjU9U7Y5Urzm55fED5OldaV7wzYMyUk5GKmSXYlRWdcCZkWjMQ50f48VZwL/roo4XD+nbh8W+0OZkp15mn7pIA4kOL7Y/LxY2kENhn8oJceKP7fIx8C+T8XlWsx1Nt82Uvyd2TLE9P70tUIv72a8F/O9xOY2Uwxrj7Viw8XZ4Q2btLTN4q/ui/8K6QJwzHPjdcqWNdLXRgNpr2Go/rE23Jz8UZxR/swq8fEVg4Bk2Cx1J0C838+DxaV1op6I5xyeZVwOdZJ4TVOizfQDLCCyhpuIiAio1Wp4eHgYbffw8EBoaPY63U2dOhVly5Y1CkiGkpKSEB0dbfRFOWdfVV9tvbtUP0zsVA2Bmpq6bb+n+uOuxgvH1bXxUPBADOywKTXzdte+N9ti9828/zwiBMeMG/dPzf4F0jeHaVJMd9DVpGZ/KO/Vv4AF5cWvOaWB2U7A4dkZjwu/KY60MJS+6evXt4Bd44G5BgE+sxEYhh9qRiMZTIQCw23n1unLIgjAkXlifwwpGL5xWtrk/PyUOLE2LjnGdPA0e56Zmp4HJ7I/Y+yLEHFUXmxoxr4ygiDOPntiafbLBBj/jA1rFHPjwu9A8Cax1uHFLfHnv7CC2KHW0OOzYs1LZpNdRj8Dzv4iXuP3XmKgNBUk9n+eeZnSB9S4l2Jft/XdTTf7aMONuf4xGjXwOu2DPmCuWLuSnWZZQPzd+79G4mK9Z39Ju8ZX4r8xoeLox1gT3SBM1d5ue8/48f81Ak5kXNDYLG2NseH/u/gIcXZ4U17eFTtc756U9bX3fWp+38OT4v06NENcC9AUbQ3XwRnAH33122NDxd8lcz/z58Gmt9/71/T2AlKkJ/FbuHAhNm/ejGPHjsHGxvQb5oIFCzBnzpwCLlkx9EYbYNAWCG7VcdLZBxZKBRZMHIN/TpdHsqUDqvo2wfjdN3HjeRS0tRvzUofgDeVzNFOKEwEuSemPC0JVfGixC1+kvo9HT2LxFGrMzsVnnSElTFTrPz2f/QuEXjF+rE4x7lCsFf00Y/VudmiHq5/4HvCfLV4/6glQupJYNQ0AH1/QH5+dJSUyq7mJeqSfsM8w6CxvAky6Ls7q/Iu/2NnS2gEYe0r8q1a7+OjsKHGx1P++ER83GpHxOV7dEz8UKvqZL4chw+axx2fEa1rZiv0NQi8DTbNoyjMMKeZGlCRGAyoHMYRqmWpKSogUP2QBoFxj4J1fAafy5p/bsFkjfYfxFyHi7LOAuMab4c9FnSIuQVKxZcZrGtboJbwGXHzMP7+h1CTxZ1O+MWBhJZ67a7zxMWPSPlQSXomd9Le9B7SYAOz8SNx+4x/gs/tiUDcM6xoNsOFtIOyq+Lru/yduf3AcqNIxe+XTXcswwCiMmy7iI8T/X4bNQ0oL4K/RYk1C71VA/UH6fa8fiv930ru6Deg4N+uyrDYxAaeVrfj8K5vrA8fIfcbHLK0DDN4KuFUTQ62dq4mL57DZ89hC8ffUx8TvhCmPT4tfUtD2hzFn+xigw0zglJmamPQqthSX1DHn1I9A09HivZaBrOHG1dUVFhYWCAsz/iAJCwuDp6dnpud+9913WLhwIQ4fPoy6deuaPW7atGmYPHmy7nF0dDS8vb3zVvCSqnoXKABo376reDigSq8But37JrghLDoRw9cGYWATbyiVCnx2YiH6Ra1Hb+VJbFB3wEs44YSmju6cMJTGyORP8Z7FPrSyEDsVhmjKo7oy+1WaZzQ10NUireOde03jtbGyI32bucZMuIl6nLNaA1PUqeIQ9v++BXoYvIkY1iIYfkCa6+SXWbj5czjw0Slxfp70ozMOzwKs7fX3KDlGbFMvXUl/jCAYv87wG+IHTPUu+m0/pvW3qjcIaD9DbK6o3A5wrihWoTuV0x+r0YhvnFrXdoj9l9pPFz+YX95JFy4MPjCu/iVe066MfpthLVDYdbE5r3IHcfRb41GAW3X9/lQTNTeG/QKenhP7Hww00zyqUQN7p+gfp69lMawZS4gEShmUc//nYk2BqXBjWAbDD/6s7PtMrE1rOUkMyqaaPQ2DxeYhYo2HNthon+/yn0C9AcbnpcSLwQYwbuJQp2TddJYUK4attCknjEJlzHPjUBgTmrHZ5lEggLRmluPf6cNNSoI48sbEHFq6Y3PjUaDYPGVo+wcZj9v4dsZtefE8WOyTl2W/szxo+oH4s0jfvJ2VxEh9/5+s1OwtBjRz4abpGKDZh7IFG0DmcGNtbY1GjRohICAAvXv3BgBd5+Dx48ebPe+bb77BvHnzcODAATRu3DjT51CpVFCp8vEXiYx4ONpg/8TWusfv+vlg/UkftP7HfOA4qmmAo5oGeGAhDk3/JOVD7FZ9CUBscnJVZP7GOj1lFB4Knjhi3RZ/digHbBqYrbIKZRtB8cxEDc+hWfk3F8lXBh9+hlXRhv1+Hp4UR0M1GmG+E7DCAnAoa3roadRjYNMgYOSejOHI1LpNj4OM3whTEowDxIq0ZT3eOwhUaJZxyY1Lm8Tv/12oL9vU+/qZne//qx+erxWyT3xt2iUuru3U7xMgBqxHgfpmgI8M+hdoy/boDLA2be00bR+Cc2uM/5rfPw0YnG70WvrZWNM3PwiCvkbjylbjsJC+5sawySbhlRgoH5wAvJvpm0BMfQAYNg09uygO3W3+MVCzZ8Zjw2+Knccbj9I3E574Xpz7qfO8jMcbNhNom3LSu5IWbgz7chgFYYOAmRxnOtw8OQ+UbyTWDv7YACjlBgzeLPZtczEIy9FPgc2DDcqXRSfmhEjx/pRyFZuPzAUbADhneuBJrkQV4BQC+TktQ5P3xfcFc+HGuaL4O129q9iUaTi4Qqv+UKBsfaBMFfH/woOTYk1u0w+Aco3E5VEM30tcfADHcuL/+Vp9gboSh8JckL1ZavLkyRg+fDgaN26Mpk2bYunSpYiLi8PIkeICjO+++y7KlSuHBQvEcfuLFi3CzJkzsXHjRvj4+Oj65tjb28Pe3l6210HmjWhRCSNaVEJEbBK2nH0MtUbAkkO3YKFUYH6f2qjkao8Tt1+gzdElqKAIx1XhDfRJmoO3LE5jTWpXnLLRh4C/1c2xT90U/7PcgZpKMRC8giMWpg4CUoGZQUpko6IaALDjsS36aitALG3F2oOXt8Vq+IJmOFTz+SXxK/qZWK1riiYl82HpD08AK1sCYVfMH6P1JN08RImRxnNnaD09J4ab9Ku/pyeoxQ6btdMm0dtloj9B2BXjsoWkaxL4o5/xaDDDD95fewDjz+uDTXqGs9Xe2i/WIlga/IGT/sMy9LLYAd2pnBhqV7USX8PoIxlrAdN3CDWsyYl/KdY0HVsgvnYrO/PzmhjW3ASk/cb+OUxsEgTE2pKHp8RrPb8s1hA9TvdzenED+PebjNfe84np5zT06p7Yydaw2XKzmU608RGmp+f/pb1Ya3ckrf9KXLjYlGNKrMEfC1ktRBsfIY56Gnta3+RXFFTwE4NqXjuxV+0MdPtGXDbFnFJu+t8hC2ug9af6RYlLuQKOZcX3h/QdkRsOB7ovFmt2AKDRSDHo3tgN1OghhhZ1MuBRB7AwiAc+rYA6b4tNdLpydhRrVMs2AIam62hdCMgebgYMGIAXL15g5syZCA0NRf369bF//35dJ+NHjx5BqdS/ia9cuRLJycno37+/0XVmzZqF2bNnF2TRKYdc7VUY164KNBoB7g4qNKjgguqeDgCAppVK40ZoDA5dD4OFUgGld1N89bAqAGBDagcMsQzA3JRhWKvuCgA4ktwAf1rPwW2NcV+J366lYG5aH56LmiqwQTJqKMW/yLarW6Kvhf6vaBfoq/QFTQpSar8D639N/CVcEExNoPX4jPkFJLPT0Tc7wcaUaztMB5gDX4hVzdlZ0uHZRfED/tW97P1FnGzQvBJ2BUjfKqitmdHKbIbo9B8u88sCXRbqg6Kp8PpzW+DT2+LzxKV1Ll3bRfzr1lBilBiEHpwA6vQ3blIyXPX56l+ArYv5cGOuRm52Wm1X6TfEe2fI1PxA6edoyq5X98Q5UwylD7laZ38x3zyqDTY5Ya5Dq6FX98Sh1Nnl5J33JuPssnYw/n3Vaj0FeKM9MNdFv216qNiJW+WY9XxdnRcA1ToDZdJGoQ7bIYZ8QQN41Aa6fgN4NxWDpiZV7MycHAO8u0vsg3Vth9gMZOsi1rYM2yH+3J5fEpue3w8AXNOtMedZW/zKqu+S0sI42ADi80y6LoarQkghCDLPtFPAoqOj4eTkhKioKDg6mhhlQ7KJTUrFsiN30K9hOVT1cMCY387h4HXjT7laZR0x9M2KmLbd/Af3GIt/0MHiIt5PngJPxSscUn2GaMEOdZN+ASDgj/K7sPe5PR4K7thgLdYIfpL8If7StEZVxRMcUn2Wny+zaBu8VZyh1XCpDFMqtQbca4lvijlt+88zBUx29JwdJfahMRx1ln7/oVniEh5atfoC17brH9uVAUq5i6+/8wIxpKQfHqultEzXsZbyzftpQ5ezQ+UEJKXVkL3RznxNUvsZQKU2YrPNxrQ/Miq1AXotF0deGXKqAIwNBFT2+oCqchTX9NMKvQKsSut/NS4IOPV/QL2BQOAKwNkb6GpiQsfEKPE65kZpJsWKzwnop1tQZlKjW8Tl5POb4YYKraj4FMzcdRV/B4v9Sma8VRMDm4idwWvNOpDZqUaqKJ7gheCMKGRstnRCLAQA0SgF7YfiLdW7sFao8VDjjorKcEQrHACNGo4K8a/wy5pKqK54ApUiBajWRWz6MPC0+gjsUHTA+JsG68xMfQDYOItNKqZqDmycxb4uci+RUJw5lBXDhrZmJr3ZUWLfF23fIUDs+JnZz8SuTOZ9Qkoyq1LGHa5NqdZVbDLU1ko1GS3WDBoNL1YAH58X+w95vwn8NUr8P9f8Y7E/Up3+Ykg4PFs/quqLZ8C9Y/q+Ph2/Ai5tFpsbG40QO3s7eAGf3BSvsaKZcegZtgOobDDKKv6VOAKzcnsxsN8+LF67cnug/1pxegNtqNg6QmxmfXu9cc1fahLwfW2xX9b4c1whPhcYbjLBcFP0PH4Vj1SNgEqu+mHY607eh4VSgb4Ny+Phyzi42Fnj5//uoXnlMhjzew6GgRsoZW2BuGQ1KijCMMLiAFal9kAV5VPc0njDEqkYZHkUv6R2Qwzs4KN4jjHNyyFOYY+Rtz7CQ/sGqPxsFwCgduIvSIElQmxGAACuOLTCiUY/4KO2lcUq4sNzMswufH/0TVTyKIPUG3tg+deIXJVfci4+WfevkYq9p3G/DDl8elccqptupmzJFZZAVL07ELLH9D6nCjnrYNv6U3FJCW0HZqUlMPOluHxK8CYx5Gj7f1TvBnT6Why1Z+8ufsgvrCj2Xxp/DnCtqr+utjnMcAqGlEQxaHg31fcdAcQJ736sL15/0CZxZOKeSWKTTrMPxH5M2mkWgjcAFZvrm4BCr4p9ri5tEUegtclkzpisaDRijZ6ViTkukuPEe2PYB4yyjeEmEww3xd+nWy9h6/knePON0viye00s2HcDld3s0ba6Gz7bdgURsUkoXcoaZZ1tcPWp2FGya21PLB1YH9W/3J/F1c1732IPRr5ZDi1O1gcg4IGN2EGzXdJi3Be8cGV2J5SytsS4jRew8o7+r8LlqT3xbepA3PyqC55FJqD34r2wRwK2OP0I76S00UQzX4u1DufWGE+mVb2b2AlWu5ZMZmycjEf7dPvOeJizFGr0AG7u1c/tY079oUBw2hT5HxwXp8sP+inDYalWDrBMyWKWZwcv4xmn84uFtfm+Mh1micOnTY1eM9TwXbG2YsvQrO9Reh3nip3Mz6wC6g4U1xbKzLSnwM4PgZt7MnYsfec3wLOOOMpJYSHWjMS/EofV27uLZXweDDQYJo7eC94AtP8SCN4ohoV7R4F2X4q1ENqAEbJP7J+jUAL+cwCPmuIHvUIh9qE5vlgcwm4YXrRiX4g/Qy/z03pkS2K0GJqKcdNMScZwkwmGm+JPoxFw8HoYGvu4wNXe+C8ktUZAqkYDlaUFBEHAOz8F4ubzGPw0rBGaV3HF8dsvcCzkBdacMDOENge6KU/DVRGF39RiR9MJHapiZ/BTPHwZjy7KIEx2PwdVtwVos/YRAAX+/bQtQkJjDGqeBPz95h3Ua9Ze/6afkijOk/NGW4SERiHOsyka2kWIIx6qdBRnMzZwr+Y4zA22wwSbffB5bw1cHByAO4cA1+riMgiGE5wN+UucRRYQJzQ7NMu4k2nXb8R5VsxRWACf3tGPTjo0U5zETqvNVPEv11p9gLINxSHk7r7i0NITSzP0XdnuOBS/v6iK6ZVuobHmijiqKT2nCsCYo+Iig4aqdBQ7Y283M9osu8o30XegNhwZVK4x0Gi42FlUYQF8EiJOIDjPw/y1XHyACWnDoNWp4og2wyVGlJZi80n6FbIHbxV//g7p5v56cEKc+j/6qXieew2xRmjnR+K9rpbWwVmjATb0F4NZ5Xbia6qUNl3D0/OAbWnjeY6ICimGm0ww3FB6giBAka79e82J+yhTyhr+NT1Q26B/j6ejDUKj9aNxGld0wbmHOZiEzYCbgwqL+tXBe+vPAQDeblQeR0PCERFrXDtwb343KJUKJKaoYW2hhFKpwBc7rmDjGbHZ4PrczrCzThv4GP1MrH4/Og+o0hE+G/Uruw99swK+7p1uqG7EbWBZ2lxRn93Xj7TQ7ru6Xaxh8O0ufnhrJ+8bsUecUTbmmdgv5cu0jt/p+xEkxYgf2s8viyM6zE0+ePlPfRCpPxSIfoJa14chDrZwtbfGuQl1xGHP4df1a+o4lgc++E+cOG//NOD0CnG7V31xUj7HcmLfjNgwcZLBHj+II0oenADeWgr81lMcbVTnHXEG3+eXxPWTAKDzfHGCQL+xgNJKfM4GQ8WFXE/+APRbA/i0AG4dEDsp+3YTz1v+pjhvzsTL4kKolduLQ2UPfinWZng30b/mmFBxvSp1MjBiN1C6shhgru8UJ6N8/VCsaSsEc4YQFQYMN5lguKGcuvciFrN2XUN7X3eMaO6DO+Gx+Oyvy+hSyxNdanui2w/H0aCCC958ozS+O3hL8ucf0/oNvN2oPAb/cgYvYpIwqmWlDDVL/4xviVSNBgnJajSvop8m3udzfZ+K8i62qOpujxEtKqFNNTesO3kf/1x6hl87Ag7KtL/qDRiGvrikVJRSWYpNHA6eYm0LIK4ZZGElNk/kRUIksKSGGEze22dU9jKlrHF+hsH0/xG3xX4raUHs98AHKO9ih3alHorNH+ln3jUnOU6c38iwCSPqqRhkavfLXYfP1GRxKHp270dMmBgeHcvm/LmIShiGm0ww3JDUUtQaWCoVUCgUuB0Wg+8OhqCJT2mcuvsSR26Gw8pCAQ9HGzx5bWYRR4lteL8ZmlYqjfgkNerNPZhhfw0vR+yb0EoXHiZ0qIo21d2waN9NdKvjheHNffDPpWf4YscV/N+gBrCxssDg1afxSafqGNeuSobrSSY5XuzXkjZ5mLZ8pUtZ48KMjiZr2K4+jcJb/yfOXfRgYff8KxsRyY7hJhMMN1SQEpLVSNVoYK+yxMu4ZDjYWOLKkyhUci2FRl8fznC8m4MK8/vUwZazj3D4hpkhy9lkY6VEYoqJRUUBnPy8PVosPGJyXxMfF5x9oG9q044iA4ArszvhZmgMGld0QapGwNWnUahX3hlKpQIL993EjotP8HXvOuhY03zfkzvhsUhO1aBmWeP/f4Ig4O/gZ/D1coCvp6Mu3DjbWaFddXdceRqFf8a3hK21vmnr4LVQXR8lbfMdERVPOfn8ln2GYqLiTPwgFj+MtZ2bG/uIk8jN6VkLs3Zdg6VSgZtfdcGr+GS4O4jDRzvW9DDqVwMA/+tQFQeuhiIkLIvRQ2nMBRsAZoMNAKNgA0AXbACgzmx9TVB5F1s8eZ2A91pUwqSOVbHq37sAgO0XnpgNN0mpavgvEVetvjqnM+xV+reg0/deYeKWYADGtTBxSanYcfEpAODcw1doVdVNt8/wL7OYpFQ42RoMDc4DU7VE+e36s2j8cvweJnWsBu/SdlmfQERmcbwckUwGNa2A6d1q4OiUtrC0UOqCjdaAxvrV6xf2rYNJ/lVxYFJr+NfQB4eJ/lXRKZNakvykbWZbe/K+UejZdzUUCclqhKd1vE5Ra/D+r+cwYl0QTt3Rz+/yPNK4me7uC/0SFLFJ+pl9U9T6CDNsTRBuPNevc5SUqg9w0QkpAIAjN8PQ/cfjuBOevRCYXkhoDJrMC8D6k9kfMafRCNh67rHRa8ipPitOYvvFp/h408VcX6MgRMYn459Lz5CYksOh7EQFiM1SRIXYnfBYuNmr4GSnr5F4EZOEubuvo3VVV/RvVB7nHr7G26sCYWtlgVIqS3zduxbqlHfGwJ8D8fiVGCCsLZTwcrbBwUmt8daPJ3A7PBa+ng64GZq7ACCF9SOb4NqzaFhZKPA6PgUrj93V7RvZwgfrTj4we+7IFj7499YL9G9UHt/sD9Ft3/qhH95eJY6mqlDaDv9+2hYz/r6K5FQNFvWra7I25llkAtwdVLC0EP/WG/BTIM7cF1dKzm4/nr/OP8EnWy9lec7L2CRM234Fg5pWQDtf47WTtM1wKkslQr7uaur0QqH38pMIfhyJUS0rYcZbNeUuDpUg7HOTCYYbKo7uR8TB09HGqD/KjefRmLQlGFO7+KK6pwMcba10zUCpag0slArcfRGHiVsu6iYzBIDx7aqgmqcDXO2tMXj1GbPPqVAAhf3dw7BvUeOKLuhZvyze9fPR7T/74BXeXhUIp7R7M69PbSw+eAtXnoqTHWYVblLVGggApv51GdsvPM3ynClbL2Hb+Se645JTNbC2FEOVYbi5PLsTDl4LQ4sqrihdqnAtTGh2FBtRPmOfG6ISxnBpCq0aXo7YP7G1yeO1tRRV3O2x++NWCAmNweazjzC+XRWUMZj48OZXXbD4YAj2XwtFcqoGYdH6dZZuzO2COrMP6JqN6pV3wqUnUShMDPsWnXv4Gucevkbg3ZfYdzUUraq64vjtCABAVEIKohJSMGLdWdT00r9p3g6LgYeTDab9dQVv1fVC1zpeun2CIKDnspOITUpFDS+HbJXnQYR+raVfjt/DN/tDsGJIQ5y+p2+uS0rVYO2JB1i0/yZ8PR3M/gyzIyo+Bd8evIk+DcqjUUWXrE/IAXbepsKMNTdElG2CIODPc49Rp5wzapZ1xPKjd7D4YAi+H1AfveqXw+agRzhxJwLPIhNw4VFkhvMtlAqoNfq3nO51vKBUKvDPpSyWLShA6ctoqGe9shjT+g0oFQpEJ6Zg4M+nMxzTupobUlI1+PndRpjzz3X0qFcWb75RGipLC/RafhKXHkfmqDz3F3TTNacdvRmOVI2Q6Wg0Q9N3XMGGtE7p6WuUIuOT4WRrleOO09qaGw9HFc584Z+jc4nygjU3RJQvFAoFBjSpoHs8tm1lDH2zom6U0sCmFTCwqbg/MUWN1f/dg5WlEpuDHuGHgQ3gXdoOjjaWeBGbBE9HGygUYpA4eScCr+LMrNuUxtXeOsPszfnBXLABgF2XnmFXFkHsv1svAABD1wTh0uNIXTPUd2/Xg1pjfgSbOS9ikuDuaIOkVDVGrheXgrg4oyNcstFcdd2g83VIaAyqezrgWWQCjoaEY/qOq1jYt47u55WV13HJRqPRLNKFohS1BlYWHKOSExqNwBqwfMKaGyIqFLZfeIIUtQazd11HQtpInJ+HNcKKY3fhX8Md49uLCy5efxaN2+Ex+GzbZZQuZY0vu9fEuI3GC4fun9gKzyITdEtbFGUb32+G5lVc8TwqAX4LxGa28e2q4FZYDD7r4guVpRJbzz2GjbUFzt5/hf8b3BD2KkssO3I7w4zZhh2uATEwnvvSdL8ZQRAwZetlCIKAkS0qoceyE+jToJxuWH55F1ucmCquTbbmxH0s2n8Tf4wSJ5AExJD4LDKBw9rNOHU3AmN+O4/ZPWuhf6PychenSGCH4kww3BAVD4Zz0Vx89Bq/Bz5EfLIaXet4olf9cgCAHRef4J9Lz5GQrEZgWr+WCR2qorqnA8Zu0Aei8i62+GV4Y3RZerzgX0g2/DO+JXZcfIq16YanN6tUWjeyS2t2j5oY0aKS0dIb5o5vXNEF2z5qrnscGZ+MGX9fQ1RCCr7o5qu7H6aeBwC2feiHxj6ldc9VobQd/vtMXMZj6rbL2HLuMX4e1gidaomLfiYkq406vQuCgIQUtX5tNBMSU9QY8FMgGlUsjZk9xNFZqWoN5vxzHU0qlUbPehmXrkhVa/D2T4GwV1ni15FNEZOUirikVJR1tjX7PHn1+FU89l8NxeBmFcSlSrJQf+5BRMaL0xdwdu3sYbMUERV7hn1FGlRwQYMKGTvM9mlQHn0aiH8V3wqLQdD9VxjctILR4qcqSyU2vN8MFcuUQvPKZXDq7ksMblYBno426FTLA0kpGsQmpWLIL6ZHjtUp54ThzX0wJW0oeH7oseyEye2mAsfsf65jy7knJo9PURs3i6kN/rZ98joeLRcd1T22NmhiemmmybD/qkCjD+b4ZP38RFvOPQYALD54C51qeeKX4/cwf+8NrBnRBKlqAQ8i4pCs1mDJoVtYP7KJ0eSMhvZfDcWlJ1G49CRKF272Xg3F76cf4vfTD02Gm+dRibiY1ufrxJ0ITNwSjFdxyTg73R9uDiqjY1/EJOHCo9fwr+EBi0yaiJJS1QiPTjJbE9Vj2QlExqfgZVwyPu/qa/Y6APDwZRzik4rPPEEhoTGYtv0yJnWsZvbnWNAYboioRKjm4YBqHuKoprLOtjg4qTWcbK1QSmWpGyL/46AGuPE8Gi2ruGboaHvuS3+ce/AaH/4hLvcwoLE34lPU+KKbL7ycbFHJtRT6rTylO97dQYURLXyM5uEZ2MQbKWoBf10wHT6kYjjRoaF7BqO1AODio0g8eR2Py0+isCnokdG+wzfCdN9HxCbBnGVHbuu+106q+Mfph7ptMYkp+Pm/u5i/9yYAYOS6sxmuMWxNEAI+aYM5/1zHlE7VUM3DAWHRiahYppTRZIHbzj9Bv4blEBalD6dqjZAhlEQnpui+v/Dota4/17Ttl3ErLBZrhjdG1bTfhXd+CsT9iDh81asWOtXyRIpag7JOthn6wgxZfQbnHr7Gon510Ldh+Qz9i7S1MEH3XyIzlx5Hotfyk5kek5WkVDWuPIlCfW9n3cjH7FBrBEz96zIqlLbD/zpUNXvc/Yg42FpZwNPJxuwxhj764zzuRcRh2JqgQlMLxXBDRCWSNugYcrVXmf3L09Vehfa+7mhRpQxql3XCtG41jPY3quiC30c1xbgNFzC/bx10r+OF2KRUXbjZMbY5GlRwwdWnUbpw079ReV2H48xol7rQGvZmRQQ/jtTNx5Nd2g9gQ4a1NTk5T8uwX09MYiraf3fMKEQ9i0rUBZvMfLbtMs4/fK3rkA0Auz9uabTExpStl/AgIs6oeS4iNgl/nn2MgJvhmNmjJhpWcEFsor4G6U64ftZo7Xptb/3fCZR1toWXkw3up5V116VnmPH3NQCAo40lOtTwwNi2lfHVnhuY0KEqzj0UlyWZ+tcVBN59iaUDG+DAtVD8d+sFJnespnuO0qXEmqE/Tj+EUqHAgCbe2HL2MVpWcUWFMna6Pkt5MXvXdWwKeoSP21fBJ52q67YLgoBdl56hVlknVHG3hyAICItO0oWUA9dCdb9v5sLN67hktPvuGIDsN5cZ1oQWFgw3RETZZG2pxIb33zS7v1VVN1ye3Vn32HDtrDdc7QEAtcs5YZJ/NSSr1RjTujJexCQhMj4Zl55EYWzbyrC3scS6kw/wIkasLelZryx+GFgfgXdf4uNNF9HO1x3Tu9fA9efR6LviFEypV94JLaq4okml0mhd1Q3fHgjRrf0FiP1yZv9z3eS5H7evgv87cif7NyWd9LVD2XX+4esM2/44/RDVPY1D6LKjxmWbv/cG/g4WR7D1XXEKK4c0NKpVCTExC3dSqgb3I+J0wQYwXlMtOlFcz+zsg1d48jrBKHABwM7gZ+haxwsfpC3aajiVweEbYWi56IgujDrYWOKLHVcAALe+7gpTI++TUtX44fBttPd11609F5OYApWlhW6SR0PaWrb/O3LHKNwE3AjHhM3BAIBv+tXFybsR+Dv4GVYMaYhudbxwxmg+JTVUlhZI7+Gr+CyPSU9TCLvuMtwQEeUThUKBoOkdkJSiMVpCY4K//q/mX99rCkEQcP15NKp7OMDSQomxbasgMUWNk3ci0Lyy2ETWvIqr0YzADSu44MdBDfA/E2tRzexRy2jSvs+7+uJdv4pYfvQOTt6JQNc6XkhK1WDBPrFGxc7aAj5lSuHj9lXgYGOF/0Puw42UklI1+OV45mt8aYON1ry9NzDF4AP/dnju1/syrC1LTxtsADEMmTsvyKBf1KUnkVAgY7pZd/IBVhy7ixXH7uLBwu54GpmAdt8dQ4vKZbCwX11sPPMIg5tVgIdj5s1El55E6r7/7K/Luu/n772BbnW8EJmgr4GLTUxFqpWAFLUGznb6aQUMSxeVkAJ3h4zhJjw6EX+cfojBzSrC08kGmcyeIBuGGyKifJR+QVRTFAoFapV1MtpmY2WBDjUyn6yvZ72y6FrbE/dexGHP5Wdo5FMaT18nmJyNuKyzLeb1qaN7/EGbyvigTWWExyTC0cYKNlbih5ggCFg6oD6eRibAUqlAp1qeGP3bOaPmHa2WVVzh5WSDYX4VERGbhEPXw7Ap6HGG41ztVZn22zEnN004T14n6FaXLwz2XQ3VfX8/Ig7rTmUMa+n7SJ259xLJqRocDXkB/yX/IiYxFSfvRBiNbNNKTFEjOiEF7o42ZjtEK9Oqi2IMQlhMYip6LT+JJ68TsKhfHfSqXw42Vha6aRgAIDohFe5pFWfJqRrM/Psq/CqXwY6LT3Es5AX+ux2BneNaoDAOuma4ISIqwqwslKju6YDqntWzPtiE9OFLoVCgd4NyRtsOTGyNiNgkNJsfAABoVdUVQ9+siM5pQ7y12vt64FVcMg5cC4OrvTU+bFMZ8clqDGpaASfuvIDK0gJ3wmPRrFJpONpaoesPx1HexRZdanni4PUwONhY4toz052hiyrDULfi6B2T67EZjmL7v4DbWHzIuB8TIC4f8sPh2xlC4oCfAnHpSRSOf9YOlmbCjbYpLDJeP+rt0pNIXQ3T1L+u4NKTKHimC0jfH76Foc0qwq9yGQTcCMPms4+x+aw+vAanzbZt+Jr6rTyFFpXLYHKn3P0+SoXz3BARUba8t/4snkclYue45tnqi5GV22ExsLW2QHkXcXi1RiNg9fF7qFDaDq2ruaHWrANmz/19VFMMWxOUYbudtQXik/M+zLpRRRfcDovJ0ORUWE3t4gu1RpNh4katVlVdce7Ba6OamexqW90Ndco5meyLdWNuF9SefSDDzN75MWoqJ5/fnCubiIiyZc3wxtj7v5aSBBsAqOrhoAs2gLgY5wdtKqNrHS+UUlmiU9oaWiNb+CDgkza6ET7+NdzRqqobXNMWef2yew1Uci2FneNa4PrcLvi8qy+qezhg6YD68HKyMZoB2Ctt5JCNlRI35nbB0DdNLz+R2ezNpthYKTPMoVOQFu2/iZ/+vWd2//HbEbkKNgBwLOSF2U7mdeccMNmh2HDOIzmw5oaIiAqlxBQ19l8NRceaHiilskRSqhrHb0Wg2Rul4WBjhYjYJLyOS9bNWWOOIAhouegonkYm4MvuNVDZ3R51yzmhTFo40s6w7GJnhZEtKmFT0COsH9kU1T0d8DwqAT/9ew/rTz3QXe+TjtWMmo4AsaZnxZCGuqY7QBwtF5skfsj3bVAO2yUYBl5UHJ7cGlXcM/+55BSXX8gEww0RUckTnZiCk7cj0M7XXdd5WmvDmYc4cC0MK4Y0NBq+rxWTmIK3VwXC08kGQ5tVRO1yTnhzQQBc7a3Rtro7Dt8Iw8K+ddClthe+3HkFf5wWh2rfm98NG4Ie4Z9Lz7B6WGM42loiNDoR91/E4XZ4LGbtumayrB+2qYyONd3Rb2Vghn0ONpaY0KEqfjl+P8/zyzjYWKJueSecvJP5xIOmjGzhg3UnH5jdv35kE7St7p6H0mXEcJMJhhsiIsqrey9i4WRrpav90YqMT8b3h26hX6PyqFveOdNrzP3nOtaevI+e9cri4PVQONtaY++EVihtsOL7mhP3ce1ZFNpWd0f3Ol4AAAulAr2WncClJ/pJHP/XoSp+DBBnix7SrAI2nDGecRoQJ4Ps4OuOXwPFGaTrlnfCrB61jGbWzq4VQxoarc+W3vRuNTC69Rs5vm5muLYUERFRPnrDzd7kdmc7a8zpVTtb15jatTq61vFEfW9nWFk0MFoMVmtUy0omz53ftw66/yiuOTa6VSVM7lgN5ZxtsP7UQ3zYprJRuPl9VFNUdXcQ56TRCLpwU8PTEdU9HeDlZIMq7vboXb8cPklbI21ur1rYefEpLqSt0TW5YzWsPn5PN3rLzjrzflfXnuVs9mypseaGiIioCIqKT4G1pdJopXWtt1edwtkHr9Gqqit+H9XMaN+vpx7gn0vPsGJoQ7g7iIFHGwR6LjuBhGQ19vyvFZJTNfj+8C30bVhOVwv1y/F7uPwkCkveqYcq0/cBAMo52+JppPGEh9U87HFwUhtJXy+bpTLBcENERMVdWHQitpx9jIFNvbM1kaSWIAjQCMh0hXQtbUfsdtXdUKG0HcKik9Chhjvik9Wo7+2Met7OuS2+SWyWIiIiKsE8HG0yXfnbHIVCAYuscw0AselqzYn7mNOzNiqUscv6hALEmhsiIiIq9DiJHxEREZVYDDdERERUrDDcEBERUbHCcENERETFCsMNERERFSsMN0RERFSsMNwQERFRscJwQ0RERMUKww0REREVKww3REREVKww3BAREVGxwnBDRERExQrDDRERERUrDDdERERUrFjKXYCCJggCAHHpdCIiIioatJ/b2s/xzJS4cBMTEwMA8Pb2lrkkRERElFMxMTFwcnLK9BiFkJ0IVIxoNBo8e/YMDg4OUCgUkl47Ojoa3t7eePz4MRwdHSW9NunxPhcM3ueCw3tdMHifC0Z+3WdBEBATE4OyZctCqcy8V02Jq7lRKpUoX758vj6Ho6Mj/+MUAN7ngsH7XHB4rwsG73PByI/7nFWNjRY7FBMREVGxwnBDRERExQrDjYRUKhVmzZoFlUold1GKNd7ngsH7XHB4rwsG73PBKAz3ucR1KCYiIqLijTU3REREVKww3BAREVGxwnBDRERExQrDDRERERUrDDcSWb58OXx8fGBjY4NmzZohKChI7iIVKQsWLECTJk3g4OAAd3d39O7dGyEhIUbHJCYmYty4cShTpgzs7e3Rr18/hIWFGR3z6NEjdO/eHXZ2dnB3d8enn36K1NTUgnwpRcrChQuhUCgwceJE3TbeZ2k8ffoUQ4cORZkyZWBra4s6derg3Llzuv2CIGDmzJnw8vKCra0t/P39cfv2baNrvHr1CkOGDIGjoyOcnZ0xatQoxMbGFvRLKdTUajVmzJiBSpUqwdbWFpUrV8ZXX31ltP4Q73XO/ffff+jRowfKli0LhUKBnTt3Gu2X6p5evnwZrVq1go2NDby9vfHNN99I8wIEyrPNmzcL1tbWwtq1a4Vr164Jo0ePFpydnYWwsDC5i1ZkdO7cWVi3bp1w9epVITg4WOjWrZtQoUIFITY2VnfMhx9+KHh7ewsBAQHCuXPnhDfffFNo3ry5bn9qaqpQu3Ztwd/fX7h48aKwd+9ewdXVVZg2bZocL6nQCwoKEnx8fIS6desKEyZM0G3nfc67V69eCRUrVhRGjBghnDlzRrh3755w4MAB4c6dO7pjFi5cKDg5OQk7d+4ULl26JPTs2VOoVKmSkJCQoDumS5cuQr169YTTp08Lx48fF6pUqSIMGjRIjpdUaM2bN08oU6aMsHv3buH+/fvC1q1bBXt7e+GHH37QHcN7nXN79+4Vpk+fLmzfvl0AIOzYscNovxT3NCoqSvDw8BCGDBkiXL16Vdi0aZNga2sr/PTTT3kuP8ONBJo2bSqMGzdO91itVgtly5YVFixYIGOpirbw8HABgPDvv/8KgiAIkZGRgpWVlbB161bdMTdu3BAACIGBgYIgiP8ZlUqlEBoaqjtm5cqVgqOjo5CUlFSwL6CQi4mJEapWrSocOnRIaNOmjS7c8D5LY+rUqULLli3N7tdoNIKnp6fw7bff6rZFRkYKKpVK2LRpkyAIgnD9+nUBgHD27FndMfv27RMUCoXw9OnT/Ct8EdO9e3fhvffeM9rWt29fYciQIYIg8F5LIX24keqerlixQnBxcTF635g6dapQvXr1PJeZzVJ5lJycjPPnz8Pf31+3TalUwt/fH4GBgTKWrGiLiooCAJQuXRoAcP78eaSkpBjdZ19fX1SoUEF3nwMDA1GnTh14eHjojuncuTOio6Nx7dq1Aix94Tdu3Dh0797d6H4CvM9S2bVrFxo3boy3334b7u7uaNCgAVavXq3bf//+fYSGhhrdZycnJzRr1szoPjs7O6Nx48a6Y/z9/aFUKnHmzJmCezGFXPPmzREQEIBbt24BAC5duoQTJ06ga9euAHiv84NU9zQwMBCtW7eGtbW17pjOnTsjJCQEr1+/zlMZS9zCmVKLiIiAWq02eqMHAA8PD9y8eVOmUhVtGo0GEydORIsWLVC7dm0AQGhoKKytreHs7Gx0rIeHB0JDQ3XHmPo5aPeRaPPmzbhw4QLOnj2bYR/vszTu3buHlStXYvLkyfjiiy9w9uxZ/O9//4O1tTWGDx+uu0+m7qPhfXZ3dzfab2lpidKlS/M+G/j8888RHR0NX19fWFhYQK1WY968eRgyZAgA8F7nA6nuaWhoKCpVqpThGtp9Li4uuS4jww0VOuPGjcPVq1dx4sQJuYtS7Dx+/BgTJkzAoUOHYGNjI3dxii2NRoPGjRtj/vz5AIAGDRrg6tWrWLVqFYYPHy5z6YqXP//8Exs2bMDGjRtRq1YtBAcHY+LEiShbtizvdQnGZqk8cnV1hYWFRYbRJGFhYfD09JSpVEXX+PHjsXv3bhw9ehTly5fXbff09ERycjIiIyONjje8z56eniZ/Dtp9JDY7hYeHo2HDhrC0tISlpSX+/fdf/Pjjj7C0tISHhwfvswS8vLxQs2ZNo201atTAo0ePAOjvU2bvG56enggPDzfan5qailevXvE+G/j000/x+eefY+DAgahTpw6GDRuGSZMmYcGCBQB4r/ODVPc0P99LGG7yyNraGo0aNUJAQIBum0ajQUBAAPz8/GQsWdEiCALGjx+PHTt24MiRIxmqKhs1agQrKyuj+xwSEoJHjx7p7rOfnx+uXLli9B/q0KFDcHR0zPBBU1J16NABV65cQXBwsO6rcePGGDJkiO573ue8a9GiRYapDG7duoWKFSsCACpVqgRPT0+j+xwdHY0zZ84Y3efIyEicP39ed8yRI0eg0WjQrFmzAngVRUN8fDyUSuOPMgsLC2g0GgC81/lBqnvq5+eH//77DykpKbpjDh06hOrVq+epSQoAh4JLYfPmzYJKpRLWr18vXL9+XRgzZozg7OxsNJqEMvfRRx8JTk5OwrFjx4Tnz5/rvuLj43XHfPjhh0KFChWEI0eOCOfOnRP8/PwEPz8/3X7tEOVOnToJwcHBwv79+wU3NzcOUc6C4WgpQeB9lkJQUJBgaWkpzJs3T7h9+7awYcMGwc7OTvjjjz90xyxcuFBwdnYW/v77b+Hy5ctCr169TA6lbdCggXDmzBnhxIkTQtWqVUv08GRThg8fLpQrV043FHz79u2Cq6ur8Nlnn+mO4b3OuZiYGOHixYvCxYsXBQDCkiVLhIsXLwoPHz4UBEGaexoZGSl4eHgIw4YNE65evSps3rxZsLOz41DwwuT//u//hAoVKgjW1tZC06ZNhdOnT8tdpCIFgMmvdevW6Y5JSEgQxo4dK7i4uAh2dnZCnz59hOfPnxtd58GDB0LXrl0FW1tbwdXVVfjkk0+ElJSUAn41RUv6cMP7LI1//vlHqF27tqBSqQRfX1/h559/Ntqv0WiEGTNmCB4eHoJKpRI6dOgghISEGB3z8uVLYdCgQYK9vb3g6OgojBw5UoiJiSnIl1HoRUdHCxMmTBAqVKgg2NjYCG+88YYwffp0o+HFvNc5d/ToUZPvycOHDxcEQbp7eunSJaFly5aCSqUSypUrJyxcuFCS8isEwWAaRyIiIqIijn1uiIiIqFhhuCEiIqJiheGGiIiIihWGGyIiIipWGG6IiIioWGG4ISIiomKF4YaIiIiKFYYbIirxFAoFdu7cKXcxiEgiDDdEJKsRI0ZAoVBk+OrSpYvcRSOiIspS7gIQEXXp0gXr1q0z2qZSqWQqDREVday5ISLZqVQqeHp6Gn1pVwVWKBRYuXIlunbtCltbW7zxxhvYtm2b0flXrlxB+/btYWtrizJlymDMmDGIjY01Ombt2rWoVasWVCoVvLy8MH78eKP9ERER6NOnD+zs7FC1alXs2rUrf180EeUbhhsiKvRmzJiBfv364dKlSxgyZAgGDhyIGzduAADi4uLQuXNnuLi44OzZs9i6dSsOHz5sFF5WrlyJcePGYcyYMbhy5Qp27dqFKlWqGD3HnDlz8M477+Dy5cvo1q0bhgwZglevXhXo6yQiiUiy/CYRUS4NHz5csLCwEEqVKmX0NW/ePEEQxBXjP/zwQ6NzmjVrJnz00UeCIAjCzz//LLi4uAixsbG6/Xv27BGUSqUQGhoqCIIglC1bVpg+fbrZMgAQvvzyS93j2NhYAYCwb98+yV4nERUc9rkhItm1a9cOK1euNNpWunRp3fd+fn5G+/z8/BAcHAwAuHHjBurVq4dSpUrp9rdo0QIajQYhISFQKBR49uwZOnTokGkZ6tatq/u+VKlScHR0RHh4eG5fEhHJiOGGiGRXqlSpDM1EUrG1tc3WcVZWVkaPFQoFNBpNfhSJiPIZ+9wQUaF3+vTpDI9r1KgBAKhRowYuXbqEuLg43f6TJ09CqVSievXqcHBwgI+PDwICAgq0zEQkH9bcEJHskpKSEBoaarTN0tISrq6uAICtW7eicePGaNmyJTZs2ICgoCCsWbMGADBkyBDMmjULw4cPx+zZs/HixQt8/PHHGDZsGDw8PAAAs2fPxocffgh3d3d07doVMTExOHnyJD7++OOCfaFEVCAYbohIdvv374eXl5fRturVq+PmzZsAxJFMmzdvxtixY+Hl5YVNmzahZs2aAAA7OzscOHAAEyZMQJMmTWBnZ4d+/fphyZIlumsNHz4ciYmJ+P777zFlyhS4urqif//+BfcCiahAKQRBEOQuBBGROQqFAjt27EDv3r3lLgoRFRHsc0NERETFCsMNERERFSvsc0NEhRpbzokop1hzQ0RERMUKww0REREVKww3REREVKww3BAREVGxwnBDRERExQrDDRERERUrDDdERERUrDDcEBERUbHCcENERETFyv8DE/JN8Xg+r5QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\functional.py:639: UserWarning: Input dict contained keys ['sequence_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 4s 29ms/step - loss: 0.1850 - accuracy: 0.9276\n",
      "Test Accuracy: 92.76\n",
      "Test Loss: 18.50\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, theta, phi, sequence):\n",
    "    loss, acc = model.evaluate({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, theta_test, phi_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_LSTM_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 385ms/step\n",
      "Results saved to LSTM_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_LSTM'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'LSTM_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to LSTM_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Sample 1:\n",
      "Theta    : [0.72880193]\n",
      "Phi      : [4.43912341]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 2]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [1.75820963]\n",
      "Phi      : [4.88073317]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 2]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [2.25250676]\n",
      "Phi      : [0.45764375]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 1 4 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 1 4 3]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [0.82738663]\n",
      "Phi      : [0.58355655]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 0 4]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 0 4]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [2.68394531]\n",
      "Phi      : [5.00302144]\n",
      "Actual   : [0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 1 1 1 3 2]\n",
      "Predicted: [0 0 0 0 0 0 0 2 2 2 4 4 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [3.09095732]\n",
      "Phi      : [5.485549]\n",
      "Actual   : [0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 3 2]\n",
      "Predicted: [0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 3 2]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [0.0178058]\n",
      "Phi      : [2.30560444]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [0.36725968]\n",
      "Phi      : [4.02525261]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [1.4475716]\n",
      "Phi      : [4.43360245]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 2 3 3 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 3 3 1 2]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [0.04243573]\n",
      "Phi      : [1.96666639]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
