{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../../Data/using/dt_2.6/ByAstar_dt_2.6_modified.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "87/87 [==============================] - 9s 88ms/step - loss: 1.1282 - accuracy: 0.5338 - val_loss: 0.9161 - val_accuracy: 0.5756\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.8879 - accuracy: 0.5788 - val_loss: 0.9171 - val_accuracy: 0.5740\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.8664 - accuracy: 0.5822 - val_loss: 0.8625 - val_accuracy: 0.5836\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.8582 - accuracy: 0.5852 - val_loss: 0.8608 - val_accuracy: 0.5849\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.8477 - accuracy: 0.5909 - val_loss: 0.8370 - val_accuracy: 0.5980\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.7785 - accuracy: 0.6509 - val_loss: 0.6582 - val_accuracy: 0.7358\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.4494 - accuracy: 0.8334 - val_loss: 0.4147 - val_accuracy: 0.8463\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.3856 - accuracy: 0.8594 - val_loss: 0.3777 - val_accuracy: 0.8580\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.3558 - accuracy: 0.8694 - val_loss: 0.4149 - val_accuracy: 0.8441\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.3607 - accuracy: 0.8659 - val_loss: 0.3189 - val_accuracy: 0.8858\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.3194 - accuracy: 0.8832 - val_loss: 0.3127 - val_accuracy: 0.8874\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.3219 - accuracy: 0.8801 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.3031 - accuracy: 0.8866 - val_loss: 0.3018 - val_accuracy: 0.8857\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.3077 - accuracy: 0.8832 - val_loss: 0.3034 - val_accuracy: 0.8838\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.3123 - accuracy: 0.8827 - val_loss: 0.2877 - val_accuracy: 0.8916\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.2952 - accuracy: 0.8885 - val_loss: 0.3285 - val_accuracy: 0.8720\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.2968 - accuracy: 0.8867 - val_loss: 0.2719 - val_accuracy: 0.8979\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2862 - accuracy: 0.8913 - val_loss: 0.2926 - val_accuracy: 0.8922\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2933 - accuracy: 0.8871 - val_loss: 0.2803 - val_accuracy: 0.8920\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.2885 - accuracy: 0.8896 - val_loss: 0.2870 - val_accuracy: 0.8915\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.2780 - accuracy: 0.8928 - val_loss: 0.2847 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.2808 - accuracy: 0.8919 - val_loss: 0.2868 - val_accuracy: 0.8899\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.2805 - accuracy: 0.8917 - val_loss: 0.2813 - val_accuracy: 0.8905\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2701 - accuracy: 0.8953 - val_loss: 0.2945 - val_accuracy: 0.8864\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2728 - accuracy: 0.8936 - val_loss: 0.2757 - val_accuracy: 0.8976\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2690 - accuracy: 0.8961 - val_loss: 0.2628 - val_accuracy: 0.8960\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2744 - accuracy: 0.8923 - val_loss: 0.2805 - val_accuracy: 0.8920\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2682 - accuracy: 0.8956 - val_loss: 0.2573 - val_accuracy: 0.8978\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2666 - accuracy: 0.8953 - val_loss: 0.2676 - val_accuracy: 0.8958\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.2777 - accuracy: 0.8910 - val_loss: 0.2573 - val_accuracy: 0.9016\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2612 - accuracy: 0.8981 - val_loss: 0.2673 - val_accuracy: 0.8929\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2611 - accuracy: 0.8981 - val_loss: 0.2529 - val_accuracy: 0.9015\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2571 - accuracy: 0.8994 - val_loss: 0.2615 - val_accuracy: 0.8950\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.2609 - accuracy: 0.8966 - val_loss: 0.2593 - val_accuracy: 0.8952\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.2694 - accuracy: 0.8946 - val_loss: 0.2650 - val_accuracy: 0.8965\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2536 - accuracy: 0.8999 - val_loss: 0.2645 - val_accuracy: 0.8980\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.2633 - accuracy: 0.8960 - val_loss: 0.2487 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2598 - accuracy: 0.8968 - val_loss: 0.2554 - val_accuracy: 0.8986\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2524 - accuracy: 0.9002 - val_loss: 0.2662 - val_accuracy: 0.8935\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.2586 - accuracy: 0.8984 - val_loss: 0.2468 - val_accuracy: 0.9023\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 0.2471 - accuracy: 0.9019 - val_loss: 0.2550 - val_accuracy: 0.9021\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.2505 - accuracy: 0.9002 - val_loss: 0.2716 - val_accuracy: 0.8962\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2419 - accuracy: 0.9032 - val_loss: 0.2406 - val_accuracy: 0.9032\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.2518 - accuracy: 0.9001 - val_loss: 0.2529 - val_accuracy: 0.8989\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.2513 - accuracy: 0.8992 - val_loss: 0.2366 - val_accuracy: 0.9072\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.2444 - accuracy: 0.9020 - val_loss: 0.2474 - val_accuracy: 0.8986\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.2399 - accuracy: 0.9037 - val_loss: 0.2391 - val_accuracy: 0.9056\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.2416 - accuracy: 0.9026 - val_loss: 0.2396 - val_accuracy: 0.9046\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 0.2411 - accuracy: 0.9023 - val_loss: 0.2371 - val_accuracy: 0.9024\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.2378 - accuracy: 0.9037 - val_loss: 0.2489 - val_accuracy: 0.9024\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 0.2423 - accuracy: 0.9027 - val_loss: 0.2540 - val_accuracy: 0.8980\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.2452 - accuracy: 0.9012 - val_loss: 0.2782 - val_accuracy: 0.8898\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.2496 - accuracy: 0.8997 - val_loss: 0.2755 - val_accuracy: 0.8942\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.2471 - accuracy: 0.9002 - val_loss: 0.2326 - val_accuracy: 0.9067\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.2377 - accuracy: 0.9045 - val_loss: 0.2574 - val_accuracy: 0.9002\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2358 - accuracy: 0.9044 - val_loss: 0.2322 - val_accuracy: 0.9038\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2321 - accuracy: 0.9053 - val_loss: 0.2433 - val_accuracy: 0.9000\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.2400 - accuracy: 0.9014 - val_loss: 0.2333 - val_accuracy: 0.9019\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.2331 - accuracy: 0.9049 - val_loss: 0.2366 - val_accuracy: 0.9046\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2323 - accuracy: 0.9044 - val_loss: 0.2278 - val_accuracy: 0.9042\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2320 - accuracy: 0.9054 - val_loss: 0.2449 - val_accuracy: 0.8973\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2299 - accuracy: 0.9057 - val_loss: 0.2365 - val_accuracy: 0.9011\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2316 - accuracy: 0.9045 - val_loss: 0.2444 - val_accuracy: 0.9000\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 0.2294 - val_accuracy: 0.9061\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2333 - accuracy: 0.9042 - val_loss: 0.2459 - val_accuracy: 0.8986\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.2247 - accuracy: 0.9068 - val_loss: 0.2275 - val_accuracy: 0.9065\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.2379 - accuracy: 0.9019 - val_loss: 0.2330 - val_accuracy: 0.9041\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2267 - accuracy: 0.9067 - val_loss: 0.2345 - val_accuracy: 0.9022\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2255 - accuracy: 0.9073 - val_loss: 0.2339 - val_accuracy: 0.9046\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2301 - accuracy: 0.9047 - val_loss: 0.2362 - val_accuracy: 0.9045\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2240 - accuracy: 0.9072 - val_loss: 0.2581 - val_accuracy: 0.8988\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2282 - accuracy: 0.9055 - val_loss: 0.2663 - val_accuracy: 0.8953\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.2232 - accuracy: 0.9076 - val_loss: 0.2505 - val_accuracy: 0.8975\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2228 - accuracy: 0.9071 - val_loss: 0.2399 - val_accuracy: 0.9053\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2227 - accuracy: 0.9070 - val_loss: 0.2158 - val_accuracy: 0.9074\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2210 - accuracy: 0.9072 - val_loss: 0.2291 - val_accuracy: 0.9047\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2199 - accuracy: 0.9084 - val_loss: 0.2492 - val_accuracy: 0.8984\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2262 - accuracy: 0.9064 - val_loss: 0.2174 - val_accuracy: 0.9092\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2150 - accuracy: 0.9106 - val_loss: 0.2516 - val_accuracy: 0.8979\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2195 - accuracy: 0.9085 - val_loss: 0.2401 - val_accuracy: 0.9060\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2260 - accuracy: 0.9050 - val_loss: 0.2088 - val_accuracy: 0.9125\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2151 - accuracy: 0.9101 - val_loss: 0.2236 - val_accuracy: 0.9065\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.2164 - accuracy: 0.9088 - val_loss: 0.2264 - val_accuracy: 0.9045\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.2148 - accuracy: 0.9101 - val_loss: 0.2136 - val_accuracy: 0.9114\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2167 - accuracy: 0.9091 - val_loss: 0.2181 - val_accuracy: 0.9099\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2149 - accuracy: 0.9102 - val_loss: 0.2190 - val_accuracy: 0.9073\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.2099 - accuracy: 0.9121 - val_loss: 0.2201 - val_accuracy: 0.9082\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.2129 - accuracy: 0.9107 - val_loss: 0.2165 - val_accuracy: 0.9104\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2284 - accuracy: 0.9049 - val_loss: 0.2294 - val_accuracy: 0.9012\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.2136 - accuracy: 0.9098 - val_loss: 0.2153 - val_accuracy: 0.9100\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2120 - accuracy: 0.9103 - val_loss: 0.2365 - val_accuracy: 0.9018\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.2123 - accuracy: 0.9107 - val_loss: 0.2233 - val_accuracy: 0.9055\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.2124 - accuracy: 0.9107 - val_loss: 0.2210 - val_accuracy: 0.9113\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2134 - accuracy: 0.9101 - val_loss: 0.2123 - val_accuracy: 0.9098\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2092 - accuracy: 0.9116 - val_loss: 0.2158 - val_accuracy: 0.9112\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2119 - accuracy: 0.9097 - val_loss: 0.2072 - val_accuracy: 0.9116\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.2046 - accuracy: 0.9126 - val_loss: 0.2090 - val_accuracy: 0.9112\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2090 - accuracy: 0.9118 - val_loss: 0.2235 - val_accuracy: 0.9091\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2174 - accuracy: 0.9082 - val_loss: 0.2066 - val_accuracy: 0.9114\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2087 - accuracy: 0.9123 - val_loss: 0.2348 - val_accuracy: 0.9029\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2214 - accuracy: 0.9066 - val_loss: 0.2256 - val_accuracy: 0.9007\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2102 - accuracy: 0.9112 - val_loss: 0.2104 - val_accuracy: 0.9092\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2028 - accuracy: 0.9140 - val_loss: 0.2202 - val_accuracy: 0.9078\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2107 - accuracy: 0.9120 - val_loss: 0.2192 - val_accuracy: 0.9072\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2082 - accuracy: 0.9113 - val_loss: 0.2047 - val_accuracy: 0.9136\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2049 - accuracy: 0.9128 - val_loss: 0.2240 - val_accuracy: 0.9075\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2045 - accuracy: 0.9137 - val_loss: 0.2160 - val_accuracy: 0.9106\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2066 - accuracy: 0.9130 - val_loss: 0.2157 - val_accuracy: 0.9079\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2071 - accuracy: 0.9126 - val_loss: 0.2016 - val_accuracy: 0.9151\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.2084 - accuracy: 0.9109 - val_loss: 0.2112 - val_accuracy: 0.9099\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.2034 - accuracy: 0.9132 - val_loss: 0.2109 - val_accuracy: 0.9111\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.2040 - accuracy: 0.9125 - val_loss: 0.2375 - val_accuracy: 0.9043\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.2013 - accuracy: 0.9138 - val_loss: 0.2210 - val_accuracy: 0.9065\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2092 - accuracy: 0.9103 - val_loss: 0.2233 - val_accuracy: 0.9088\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.2044 - accuracy: 0.9129 - val_loss: 0.2099 - val_accuracy: 0.9126\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2017 - accuracy: 0.9143 - val_loss: 0.2166 - val_accuracy: 0.9102\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.2025 - accuracy: 0.9139 - val_loss: 0.2291 - val_accuracy: 0.9012\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.2091 - accuracy: 0.9114 - val_loss: 0.2042 - val_accuracy: 0.9128\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1997 - accuracy: 0.9149 - val_loss: 0.2185 - val_accuracy: 0.9100\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.2032 - accuracy: 0.9132 - val_loss: 0.2004 - val_accuracy: 0.9130\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1959 - accuracy: 0.9154 - val_loss: 0.2443 - val_accuracy: 0.9026\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.2125 - accuracy: 0.9096 - val_loss: 0.2464 - val_accuracy: 0.8941\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2013 - accuracy: 0.9134 - val_loss: 0.1997 - val_accuracy: 0.9147\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1979 - accuracy: 0.9156 - val_loss: 0.2085 - val_accuracy: 0.9124\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1967 - accuracy: 0.9154 - val_loss: 0.2169 - val_accuracy: 0.9086\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.2006 - accuracy: 0.9142 - val_loss: 0.2013 - val_accuracy: 0.9148\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.1962 - accuracy: 0.9160 - val_loss: 0.2063 - val_accuracy: 0.9119\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.2010 - accuracy: 0.9142 - val_loss: 0.2118 - val_accuracy: 0.9100\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1989 - accuracy: 0.9149 - val_loss: 0.2005 - val_accuracy: 0.9136\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1987 - accuracy: 0.9146 - val_loss: 0.1991 - val_accuracy: 0.9140\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.2000 - accuracy: 0.9146 - val_loss: 0.2125 - val_accuracy: 0.9111\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1936 - accuracy: 0.9173 - val_loss: 0.1964 - val_accuracy: 0.9170\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1974 - accuracy: 0.9158 - val_loss: 0.2039 - val_accuracy: 0.9150\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.2011 - accuracy: 0.9144 - val_loss: 0.2134 - val_accuracy: 0.9078\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1978 - accuracy: 0.9153 - val_loss: 0.2214 - val_accuracy: 0.9115\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1952 - accuracy: 0.9157 - val_loss: 0.2340 - val_accuracy: 0.9053\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1984 - accuracy: 0.9152 - val_loss: 0.2743 - val_accuracy: 0.8939\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.2062 - accuracy: 0.9122 - val_loss: 0.2039 - val_accuracy: 0.9112\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 0.1941 - accuracy: 0.9163 - val_loss: 0.2152 - val_accuracy: 0.9088\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.1919 - accuracy: 0.9175 - val_loss: 0.2026 - val_accuracy: 0.9120\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.1949 - accuracy: 0.9160 - val_loss: 0.2011 - val_accuracy: 0.9129\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1951 - accuracy: 0.9158 - val_loss: 0.2187 - val_accuracy: 0.9096\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.2009 - accuracy: 0.9138 - val_loss: 0.2334 - val_accuracy: 0.9046\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 0.1924 - accuracy: 0.9167 - val_loss: 0.2006 - val_accuracy: 0.9161\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1912 - accuracy: 0.9181 - val_loss: 0.2009 - val_accuracy: 0.9155\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1878 - accuracy: 0.9195 - val_loss: 0.1895 - val_accuracy: 0.9186\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.1951 - accuracy: 0.9159 - val_loss: 0.2120 - val_accuracy: 0.9109\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.1928 - accuracy: 0.9164 - val_loss: 0.2198 - val_accuracy: 0.9115\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1960 - accuracy: 0.9160 - val_loss: 0.1978 - val_accuracy: 0.9148\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1893 - accuracy: 0.9185 - val_loss: 0.1906 - val_accuracy: 0.9183\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1890 - accuracy: 0.9180 - val_loss: 0.2011 - val_accuracy: 0.9151\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1928 - accuracy: 0.9171 - val_loss: 0.1868 - val_accuracy: 0.9190\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.1881 - accuracy: 0.9193 - val_loss: 0.2023 - val_accuracy: 0.9136\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1910 - accuracy: 0.9176 - val_loss: 0.2134 - val_accuracy: 0.9126\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1955 - accuracy: 0.9153 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1901 - accuracy: 0.9176 - val_loss: 0.2074 - val_accuracy: 0.9131\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1862 - accuracy: 0.9190 - val_loss: 0.1962 - val_accuracy: 0.9162\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1878 - accuracy: 0.9186 - val_loss: 0.1942 - val_accuracy: 0.9170\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.1889 - accuracy: 0.9192 - val_loss: 0.1880 - val_accuracy: 0.9192\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.1934 - accuracy: 0.9173 - val_loss: 0.1915 - val_accuracy: 0.9173\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1885 - accuracy: 0.9179 - val_loss: 0.1961 - val_accuracy: 0.9161\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1891 - accuracy: 0.9184 - val_loss: 0.1953 - val_accuracy: 0.9180\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1908 - accuracy: 0.9171 - val_loss: 0.2082 - val_accuracy: 0.9092\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.1940 - accuracy: 0.9164 - val_loss: 0.2285 - val_accuracy: 0.9018\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.1840 - accuracy: 0.9209 - val_loss: 0.2008 - val_accuracy: 0.9128\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 0.1925 - accuracy: 0.9176 - val_loss: 0.1901 - val_accuracy: 0.9202\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1812 - accuracy: 0.9217 - val_loss: 0.1908 - val_accuracy: 0.9168\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1888 - accuracy: 0.9180 - val_loss: 0.2126 - val_accuracy: 0.9135\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.1887 - accuracy: 0.9180 - val_loss: 0.1867 - val_accuracy: 0.9183\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.1833 - accuracy: 0.9205 - val_loss: 0.2078 - val_accuracy: 0.9133\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.1840 - accuracy: 0.9200 - val_loss: 0.2038 - val_accuracy: 0.9108\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.1923 - accuracy: 0.9167 - val_loss: 0.2092 - val_accuracy: 0.9146\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 0.1867 - accuracy: 0.9187 - val_loss: 0.2103 - val_accuracy: 0.9089\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.1900 - accuracy: 0.9182 - val_loss: 0.2012 - val_accuracy: 0.9152\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.1845 - accuracy: 0.9195 - val_loss: 0.2061 - val_accuracy: 0.9138\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1854 - accuracy: 0.9199 - val_loss: 0.2068 - val_accuracy: 0.9125\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1932 - accuracy: 0.9168 - val_loss: 0.1882 - val_accuracy: 0.9181\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1885 - accuracy: 0.9193 - val_loss: 0.1879 - val_accuracy: 0.9203\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1810 - accuracy: 0.9214 - val_loss: 0.1959 - val_accuracy: 0.9144\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1876 - accuracy: 0.9196 - val_loss: 0.1910 - val_accuracy: 0.9173\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1803 - accuracy: 0.9210 - val_loss: 0.1914 - val_accuracy: 0.9217\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1830 - accuracy: 0.9218 - val_loss: 0.1900 - val_accuracy: 0.9189\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.1881 - accuracy: 0.9189 - val_loss: 0.1930 - val_accuracy: 0.9185\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1787 - accuracy: 0.9221 - val_loss: 0.1993 - val_accuracy: 0.9143\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1862 - accuracy: 0.9189 - val_loss: 0.2141 - val_accuracy: 0.9082\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1858 - accuracy: 0.9199 - val_loss: 0.1921 - val_accuracy: 0.9176\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1797 - accuracy: 0.9217 - val_loss: 0.1910 - val_accuracy: 0.9177\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1846 - accuracy: 0.9197 - val_loss: 0.1915 - val_accuracy: 0.9178\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1842 - accuracy: 0.9200 - val_loss: 0.2008 - val_accuracy: 0.9131\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1841 - accuracy: 0.9198 - val_loss: 0.1950 - val_accuracy: 0.9193\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1822 - accuracy: 0.9208 - val_loss: 0.2535 - val_accuracy: 0.9029\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1865 - accuracy: 0.9193 - val_loss: 0.2089 - val_accuracy: 0.9151\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1815 - accuracy: 0.9213 - val_loss: 0.1931 - val_accuracy: 0.9162\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1827 - accuracy: 0.9200 - val_loss: 0.1955 - val_accuracy: 0.9167\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1784 - accuracy: 0.9227 - val_loss: 0.1936 - val_accuracy: 0.9171\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1798 - accuracy: 0.9210 - val_loss: 0.2051 - val_accuracy: 0.9168\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1838 - accuracy: 0.9199 - val_loss: 0.2118 - val_accuracy: 0.9107\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1945 - accuracy: 0.9162 - val_loss: 0.1961 - val_accuracy: 0.9207\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1795 - accuracy: 0.9221 - val_loss: 0.1967 - val_accuracy: 0.9204\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1849 - accuracy: 0.9199 - val_loss: 0.2258 - val_accuracy: 0.9083\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1876 - accuracy: 0.9178 - val_loss: 0.2137 - val_accuracy: 0.9097\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1809 - accuracy: 0.9220 - val_loss: 0.2062 - val_accuracy: 0.9130\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1770 - accuracy: 0.9230 - val_loss: 0.1920 - val_accuracy: 0.9179\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1782 - accuracy: 0.9219 - val_loss: 0.1852 - val_accuracy: 0.9208\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1843 - accuracy: 0.9210 - val_loss: 0.2048 - val_accuracy: 0.9120\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1801 - accuracy: 0.9214 - val_loss: 0.1858 - val_accuracy: 0.9227\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1735 - accuracy: 0.9237 - val_loss: 0.1863 - val_accuracy: 0.9188\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.1732 - accuracy: 0.9237 - val_loss: 0.1954 - val_accuracy: 0.9166\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1815 - accuracy: 0.9208 - val_loss: 0.1963 - val_accuracy: 0.9168\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 0.1798 - accuracy: 0.9213 - val_loss: 0.1999 - val_accuracy: 0.9124\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.1745 - accuracy: 0.9237 - val_loss: 0.2236 - val_accuracy: 0.9117\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 0.1832 - accuracy: 0.9201 - val_loss: 0.1898 - val_accuracy: 0.9204\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.1735 - accuracy: 0.9243 - val_loss: 0.1856 - val_accuracy: 0.9187\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 0.1745 - accuracy: 0.9238 - val_loss: 0.2086 - val_accuracy: 0.9124\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 0.1773 - accuracy: 0.9223 - val_loss: 0.1863 - val_accuracy: 0.9187\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1750 - accuracy: 0.9239 - val_loss: 0.2660 - val_accuracy: 0.8963\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 0.1847 - accuracy: 0.9187 - val_loss: 0.1954 - val_accuracy: 0.9198\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.1802 - accuracy: 0.9212 - val_loss: 0.2220 - val_accuracy: 0.9106\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 0.1752 - accuracy: 0.9237 - val_loss: 0.1924 - val_accuracy: 0.9167\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1834 - accuracy: 0.9205 - val_loss: 0.1912 - val_accuracy: 0.9208\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1767 - accuracy: 0.9220 - val_loss: 0.2015 - val_accuracy: 0.9124\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1814 - accuracy: 0.9206 - val_loss: 0.1901 - val_accuracy: 0.9198\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1844 - accuracy: 0.9197 - val_loss: 0.2190 - val_accuracy: 0.9077\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1837 - accuracy: 0.9194 - val_loss: 0.2022 - val_accuracy: 0.9151\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1727 - accuracy: 0.9240 - val_loss: 0.2118 - val_accuracy: 0.9137\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 0.1776 - accuracy: 0.9230 - val_loss: 0.2253 - val_accuracy: 0.9057\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.1749 - accuracy: 0.9230 - val_loss: 0.2018 - val_accuracy: 0.9178\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 0.1767 - accuracy: 0.9228 - val_loss: 0.2043 - val_accuracy: 0.9197\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.1710 - accuracy: 0.9247 - val_loss: 0.1878 - val_accuracy: 0.9188\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.1758 - accuracy: 0.9225 - val_loss: 0.2118 - val_accuracy: 0.9119\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 0.1759 - accuracy: 0.9233 - val_loss: 0.2099 - val_accuracy: 0.9103\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 0.1728 - accuracy: 0.9244 - val_loss: 0.2204 - val_accuracy: 0.9135\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 0.1727 - accuracy: 0.9245 - val_loss: 0.1947 - val_accuracy: 0.9179\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1719 - accuracy: 0.9244 - val_loss: 0.1808 - val_accuracy: 0.9223\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 0.1714 - accuracy: 0.9247 - val_loss: 0.2040 - val_accuracy: 0.9166\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 0.1967 - accuracy: 0.9162 - val_loss: 0.1976 - val_accuracy: 0.9183\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.1677 - accuracy: 0.9259 - val_loss: 0.1785 - val_accuracy: 0.9249\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.1714 - accuracy: 0.9243 - val_loss: 0.1980 - val_accuracy: 0.9197\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.1706 - accuracy: 0.9250 - val_loss: 0.2160 - val_accuracy: 0.9146\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1748 - accuracy: 0.9227 - val_loss: 0.1948 - val_accuracy: 0.9191\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.1694 - accuracy: 0.9252 - val_loss: 0.1842 - val_accuracy: 0.9207\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1682 - accuracy: 0.9259 - val_loss: 0.1904 - val_accuracy: 0.9212\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1747 - accuracy: 0.9231 - val_loss: 0.1993 - val_accuracy: 0.9145\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1832 - accuracy: 0.9204 - val_loss: 0.2017 - val_accuracy: 0.9117\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1710 - accuracy: 0.9240 - val_loss: 0.1942 - val_accuracy: 0.9169\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1719 - accuracy: 0.9246 - val_loss: 0.1925 - val_accuracy: 0.9198\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1699 - accuracy: 0.9248 - val_loss: 0.1835 - val_accuracy: 0.9197\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1716 - accuracy: 0.9232 - val_loss: 0.2003 - val_accuracy: 0.9182\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1733 - accuracy: 0.9241 - val_loss: 0.1892 - val_accuracy: 0.9210\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1684 - accuracy: 0.9254 - val_loss: 0.1887 - val_accuracy: 0.9187\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1784 - accuracy: 0.9221 - val_loss: 0.1826 - val_accuracy: 0.9225\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1714 - accuracy: 0.9253 - val_loss: 0.1938 - val_accuracy: 0.9187\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1673 - accuracy: 0.9260 - val_loss: 0.1806 - val_accuracy: 0.9215\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1752 - accuracy: 0.9227 - val_loss: 0.1946 - val_accuracy: 0.9177\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1717 - accuracy: 0.9244 - val_loss: 0.1801 - val_accuracy: 0.9246\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1774 - accuracy: 0.9226 - val_loss: 0.2028 - val_accuracy: 0.9163\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1759 - accuracy: 0.9229 - val_loss: 0.1788 - val_accuracy: 0.9247\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1691 - accuracy: 0.9253 - val_loss: 0.1904 - val_accuracy: 0.9186\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1662 - accuracy: 0.9256 - val_loss: 0.1824 - val_accuracy: 0.9224\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1684 - accuracy: 0.9255 - val_loss: 0.1806 - val_accuracy: 0.9231\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1674 - accuracy: 0.9257 - val_loss: 0.2010 - val_accuracy: 0.9132\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1650 - accuracy: 0.9260 - val_loss: 0.2002 - val_accuracy: 0.9196\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1675 - accuracy: 0.9258 - val_loss: 0.1850 - val_accuracy: 0.9232\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1645 - accuracy: 0.9275 - val_loss: 0.1916 - val_accuracy: 0.9190\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1694 - accuracy: 0.9252 - val_loss: 0.2185 - val_accuracy: 0.9086\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1655 - accuracy: 0.9263 - val_loss: 0.1886 - val_accuracy: 0.9197\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1773 - accuracy: 0.9216 - val_loss: 0.1966 - val_accuracy: 0.9178\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1654 - accuracy: 0.9261 - val_loss: 0.2158 - val_accuracy: 0.9146\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1680 - accuracy: 0.9256 - val_loss: 0.1851 - val_accuracy: 0.9216\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1691 - accuracy: 0.9252 - val_loss: 0.1927 - val_accuracy: 0.9202\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1730 - accuracy: 0.9240 - val_loss: 0.2349 - val_accuracy: 0.9083\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1741 - accuracy: 0.9225 - val_loss: 0.1817 - val_accuracy: 0.9213\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1672 - accuracy: 0.9257 - val_loss: 0.1823 - val_accuracy: 0.9211\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1601 - accuracy: 0.9287 - val_loss: 0.1825 - val_accuracy: 0.9249\n",
      "Epoch 275/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1743 - accuracy: 0.9247 - val_loss: 0.1856 - val_accuracy: 0.9224\n",
      "Epoch 276/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1632 - accuracy: 0.9273 - val_loss: 0.1808 - val_accuracy: 0.9212\n",
      "Epoch 277/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1624 - accuracy: 0.9275 - val_loss: 0.1954 - val_accuracy: 0.9165\n",
      "Epoch 278/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1773 - accuracy: 0.9224 - val_loss: 0.1864 - val_accuracy: 0.9205\n",
      "Epoch 279/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1685 - accuracy: 0.9253 - val_loss: 0.1950 - val_accuracy: 0.9153\n",
      "Epoch 280/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1721 - accuracy: 0.9243 - val_loss: 0.1872 - val_accuracy: 0.9187\n",
      "Epoch 281/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1645 - accuracy: 0.9271 - val_loss: 0.1876 - val_accuracy: 0.9186\n",
      "Epoch 282/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1625 - accuracy: 0.9279 - val_loss: 0.1849 - val_accuracy: 0.9229\n",
      "Epoch 283/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1657 - accuracy: 0.9265 - val_loss: 0.1900 - val_accuracy: 0.9179\n",
      "Epoch 284/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1756 - accuracy: 0.9230 - val_loss: 0.2007 - val_accuracy: 0.9163\n",
      "Epoch 285/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1703 - accuracy: 0.9252 - val_loss: 0.2323 - val_accuracy: 0.9039\n",
      "Epoch 286/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1640 - accuracy: 0.9268 - val_loss: 0.1968 - val_accuracy: 0.9180\n",
      "Epoch 287/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1634 - accuracy: 0.9277 - val_loss: 0.1943 - val_accuracy: 0.9166\n",
      "Epoch 288/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1703 - accuracy: 0.9250 - val_loss: 0.1836 - val_accuracy: 0.9231\n",
      "Epoch 289/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1683 - accuracy: 0.9251 - val_loss: 0.2242 - val_accuracy: 0.9117\n",
      "Epoch 290/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1670 - accuracy: 0.9259 - val_loss: 0.1967 - val_accuracy: 0.9202\n",
      "Epoch 291/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1665 - accuracy: 0.9266 - val_loss: 0.1822 - val_accuracy: 0.9214\n",
      "Epoch 292/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1599 - accuracy: 0.9290 - val_loss: 0.2024 - val_accuracy: 0.9137\n",
      "Epoch 293/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1574 - accuracy: 0.9297 - val_loss: 0.1843 - val_accuracy: 0.9214\n",
      "Epoch 294/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1589 - accuracy: 0.9290 - val_loss: 0.1849 - val_accuracy: 0.9197\n",
      "Epoch 295/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1651 - accuracy: 0.9263 - val_loss: 0.1852 - val_accuracy: 0.9202\n",
      "Epoch 296/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1648 - accuracy: 0.9260 - val_loss: 0.1817 - val_accuracy: 0.9205\n",
      "Epoch 297/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1658 - accuracy: 0.9265 - val_loss: 0.1880 - val_accuracy: 0.9198\n",
      "Epoch 298/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1635 - accuracy: 0.9267 - val_loss: 0.1946 - val_accuracy: 0.9226\n",
      "Epoch 299/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1612 - accuracy: 0.9278 - val_loss: 0.1861 - val_accuracy: 0.9184\n",
      "Epoch 300/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1570 - accuracy: 0.9301 - val_loss: 0.1822 - val_accuracy: 0.9230\n",
      "Epoch 301/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1618 - accuracy: 0.9282 - val_loss: 0.1914 - val_accuracy: 0.9190\n",
      "Epoch 302/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1583 - accuracy: 0.9293 - val_loss: 0.1849 - val_accuracy: 0.9216\n",
      "Epoch 303/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1614 - accuracy: 0.9277 - val_loss: 0.1857 - val_accuracy: 0.9187\n",
      "Epoch 304/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1603 - accuracy: 0.9284 - val_loss: 0.1815 - val_accuracy: 0.9242\n",
      "Epoch 305/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1615 - accuracy: 0.9277 - val_loss: 0.1843 - val_accuracy: 0.9227\n",
      "Epoch 306/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1637 - accuracy: 0.9266 - val_loss: 0.1798 - val_accuracy: 0.9231\n",
      "Epoch 307/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1645 - accuracy: 0.9270 - val_loss: 0.1843 - val_accuracy: 0.9215\n",
      "Epoch 308/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1659 - accuracy: 0.9266 - val_loss: 0.1920 - val_accuracy: 0.9180\n",
      "Epoch 309/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1551 - accuracy: 0.9306 - val_loss: 0.1802 - val_accuracy: 0.9232\n",
      "Epoch 310/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1566 - accuracy: 0.9290 - val_loss: 0.1920 - val_accuracy: 0.9188\n",
      "Epoch 311/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1662 - accuracy: 0.9261 - val_loss: 0.1850 - val_accuracy: 0.9219\n",
      "Epoch 312/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1629 - accuracy: 0.9268 - val_loss: 0.1923 - val_accuracy: 0.9189\n",
      "Epoch 313/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1624 - accuracy: 0.9275 - val_loss: 0.2042 - val_accuracy: 0.9184\n",
      "Epoch 314/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1614 - accuracy: 0.9281 - val_loss: 0.1877 - val_accuracy: 0.9208\n",
      "Epoch 315/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1612 - accuracy: 0.9274 - val_loss: 0.1904 - val_accuracy: 0.9169\n",
      "Epoch 316/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1582 - accuracy: 0.9291 - val_loss: 0.1966 - val_accuracy: 0.9185\n",
      "Epoch 317/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1636 - accuracy: 0.9269 - val_loss: 0.1800 - val_accuracy: 0.9225\n",
      "Epoch 318/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1554 - accuracy: 0.9303 - val_loss: 0.1781 - val_accuracy: 0.9240\n",
      "Epoch 319/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1598 - accuracy: 0.9283 - val_loss: 0.1794 - val_accuracy: 0.9246\n",
      "Epoch 320/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1656 - accuracy: 0.9263 - val_loss: 0.1931 - val_accuracy: 0.9192\n",
      "Epoch 321/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1682 - accuracy: 0.9248 - val_loss: 0.1911 - val_accuracy: 0.9215\n",
      "Epoch 322/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1581 - accuracy: 0.9290 - val_loss: 0.1768 - val_accuracy: 0.9241\n",
      "Epoch 323/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1584 - accuracy: 0.9285 - val_loss: 0.1838 - val_accuracy: 0.9241\n",
      "Epoch 324/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1612 - accuracy: 0.9288 - val_loss: 0.1939 - val_accuracy: 0.9183\n",
      "Epoch 325/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1602 - accuracy: 0.9281 - val_loss: 0.1783 - val_accuracy: 0.9226\n",
      "Epoch 326/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1687 - accuracy: 0.9263 - val_loss: 0.2014 - val_accuracy: 0.9163\n",
      "Epoch 327/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1596 - accuracy: 0.9280 - val_loss: 0.1827 - val_accuracy: 0.9210\n",
      "Epoch 328/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1531 - accuracy: 0.9313 - val_loss: 0.1878 - val_accuracy: 0.9200\n",
      "Epoch 329/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1584 - accuracy: 0.9289 - val_loss: 0.1821 - val_accuracy: 0.9231\n",
      "Epoch 330/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1614 - accuracy: 0.9277 - val_loss: 0.1781 - val_accuracy: 0.9256\n",
      "Epoch 331/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1615 - accuracy: 0.9273 - val_loss: 0.2007 - val_accuracy: 0.9184\n",
      "Epoch 332/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1615 - accuracy: 0.9277 - val_loss: 0.1839 - val_accuracy: 0.9222\n",
      "Epoch 333/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1586 - accuracy: 0.9292 - val_loss: 0.1925 - val_accuracy: 0.9218\n",
      "Epoch 334/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1597 - accuracy: 0.9285 - val_loss: 0.1842 - val_accuracy: 0.9259\n",
      "Epoch 335/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1597 - accuracy: 0.9289 - val_loss: 0.1990 - val_accuracy: 0.9208\n",
      "Epoch 336/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1766 - accuracy: 0.9223 - val_loss: 0.1889 - val_accuracy: 0.9228\n",
      "Epoch 337/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1683 - accuracy: 0.9253 - val_loss: 0.1782 - val_accuracy: 0.9225\n",
      "Epoch 338/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1567 - accuracy: 0.9295 - val_loss: 0.1795 - val_accuracy: 0.9243\n",
      "Epoch 339/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1534 - accuracy: 0.9307 - val_loss: 0.1925 - val_accuracy: 0.9176\n",
      "Epoch 340/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1564 - accuracy: 0.9300 - val_loss: 0.1947 - val_accuracy: 0.9186\n",
      "Epoch 341/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1555 - accuracy: 0.9298 - val_loss: 0.1707 - val_accuracy: 0.9279\n",
      "Epoch 342/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1539 - accuracy: 0.9302 - val_loss: 0.1788 - val_accuracy: 0.9245\n",
      "Epoch 343/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1598 - accuracy: 0.9295 - val_loss: 0.1915 - val_accuracy: 0.9178\n",
      "Epoch 344/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1549 - accuracy: 0.9305 - val_loss: 0.1853 - val_accuracy: 0.9253\n",
      "Epoch 345/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1546 - accuracy: 0.9304 - val_loss: 0.1811 - val_accuracy: 0.9217\n",
      "Epoch 346/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1531 - accuracy: 0.9309 - val_loss: 0.1936 - val_accuracy: 0.9193\n",
      "Epoch 347/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1635 - accuracy: 0.9271 - val_loss: 0.1854 - val_accuracy: 0.9220\n",
      "Epoch 348/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1686 - accuracy: 0.9252 - val_loss: 0.2132 - val_accuracy: 0.9144\n",
      "Epoch 349/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1621 - accuracy: 0.9276 - val_loss: 0.1948 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1602 - accuracy: 0.9284 - val_loss: 0.1792 - val_accuracy: 0.9255\n",
      "Epoch 351/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1518 - accuracy: 0.9314 - val_loss: 0.1984 - val_accuracy: 0.9181\n",
      "Epoch 352/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1561 - accuracy: 0.9299 - val_loss: 0.1783 - val_accuracy: 0.9233\n",
      "Epoch 353/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1620 - accuracy: 0.9274 - val_loss: 0.1849 - val_accuracy: 0.9239\n",
      "Epoch 354/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1532 - accuracy: 0.9304 - val_loss: 0.1795 - val_accuracy: 0.9256\n",
      "Epoch 355/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1577 - accuracy: 0.9298 - val_loss: 0.1897 - val_accuracy: 0.9192\n",
      "Epoch 356/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1551 - accuracy: 0.9294 - val_loss: 0.1967 - val_accuracy: 0.9211\n",
      "Epoch 357/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1560 - accuracy: 0.9302 - val_loss: 0.1859 - val_accuracy: 0.9230\n",
      "Epoch 358/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1510 - accuracy: 0.9318 - val_loss: 0.1802 - val_accuracy: 0.9229\n",
      "Epoch 359/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1549 - accuracy: 0.9305 - val_loss: 0.1866 - val_accuracy: 0.9208\n",
      "Epoch 360/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1531 - accuracy: 0.9310 - val_loss: 0.1773 - val_accuracy: 0.9253\n",
      "Epoch 361/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1592 - accuracy: 0.9286 - val_loss: 0.1968 - val_accuracy: 0.9219\n",
      "Epoch 362/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1562 - accuracy: 0.9301 - val_loss: 0.1966 - val_accuracy: 0.9198\n",
      "Epoch 363/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1704 - accuracy: 0.9242 - val_loss: 0.1888 - val_accuracy: 0.9200\n",
      "Epoch 364/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1486 - accuracy: 0.9335 - val_loss: 0.1842 - val_accuracy: 0.9210\n",
      "Epoch 365/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.1492 - accuracy: 0.9321 - val_loss: 0.2076 - val_accuracy: 0.9143\n",
      "Epoch 366/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1580 - accuracy: 0.9289 - val_loss: 0.1927 - val_accuracy: 0.9174\n",
      "Epoch 367/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1511 - accuracy: 0.9317 - val_loss: 0.1860 - val_accuracy: 0.9224\n",
      "Epoch 368/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1472 - accuracy: 0.9334 - val_loss: 0.1896 - val_accuracy: 0.9230\n",
      "Epoch 369/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1575 - accuracy: 0.9289 - val_loss: 0.1759 - val_accuracy: 0.9258\n",
      "Epoch 370/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1603 - accuracy: 0.9278 - val_loss: 0.1918 - val_accuracy: 0.9185\n",
      "Epoch 371/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1565 - accuracy: 0.9295 - val_loss: 0.1790 - val_accuracy: 0.9267\n",
      "Epoch 372/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1513 - accuracy: 0.9314 - val_loss: 0.1926 - val_accuracy: 0.9197\n",
      "Epoch 373/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.1698 - accuracy: 0.9256 - val_loss: 0.1778 - val_accuracy: 0.9226\n",
      "Epoch 374/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1615 - accuracy: 0.9269 - val_loss: 0.1803 - val_accuracy: 0.9223\n",
      "Epoch 375/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1532 - accuracy: 0.9308 - val_loss: 0.1765 - val_accuracy: 0.9247\n",
      "Epoch 376/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1544 - accuracy: 0.9305 - val_loss: 0.1778 - val_accuracy: 0.9260\n",
      "Epoch 377/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.1556 - accuracy: 0.9296 - val_loss: 0.1873 - val_accuracy: 0.9226\n",
      "Epoch 378/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.1578 - accuracy: 0.9287 - val_loss: 0.1831 - val_accuracy: 0.9215\n",
      "Epoch 379/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1586 - accuracy: 0.9287 - val_loss: 0.1841 - val_accuracy: 0.9235\n",
      "Epoch 380/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1491 - accuracy: 0.9323 - val_loss: 0.1771 - val_accuracy: 0.9250\n",
      "Epoch 381/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1577 - accuracy: 0.9289 - val_loss: 0.1845 - val_accuracy: 0.9214\n",
      "Epoch 382/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1580 - accuracy: 0.9296 - val_loss: 0.1797 - val_accuracy: 0.9227\n",
      "Epoch 383/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1589 - accuracy: 0.9278 - val_loss: 0.1758 - val_accuracy: 0.9275\n",
      "Epoch 384/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1569 - accuracy: 0.9302 - val_loss: 0.2081 - val_accuracy: 0.9128\n",
      "Epoch 385/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.1505 - accuracy: 0.9310 - val_loss: 0.1845 - val_accuracy: 0.9207\n",
      "Epoch 386/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1553 - accuracy: 0.9297 - val_loss: 0.1792 - val_accuracy: 0.9247\n",
      "Epoch 387/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1499 - accuracy: 0.9318 - val_loss: 0.1720 - val_accuracy: 0.9269\n",
      "Epoch 388/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.1522 - accuracy: 0.9307 - val_loss: 0.2133 - val_accuracy: 0.9172\n",
      "Epoch 389/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1562 - accuracy: 0.9293 - val_loss: 0.1811 - val_accuracy: 0.9212\n",
      "Epoch 390/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1629 - accuracy: 0.9268 - val_loss: 0.1762 - val_accuracy: 0.9255\n",
      "Epoch 391/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1541 - accuracy: 0.9301 - val_loss: 0.1757 - val_accuracy: 0.9246\n",
      "Epoch 392/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1485 - accuracy: 0.9317 - val_loss: 0.1842 - val_accuracy: 0.9208\n",
      "Epoch 393/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1597 - accuracy: 0.9282 - val_loss: 0.1838 - val_accuracy: 0.9238\n",
      "Epoch 394/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1456 - accuracy: 0.9333 - val_loss: 0.1754 - val_accuracy: 0.9249\n",
      "Epoch 395/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1502 - accuracy: 0.9325 - val_loss: 0.1819 - val_accuracy: 0.9222\n",
      "Epoch 396/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1506 - accuracy: 0.9317 - val_loss: 0.1703 - val_accuracy: 0.9279\n",
      "Epoch 397/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1434 - accuracy: 0.9347 - val_loss: 0.1752 - val_accuracy: 0.9253\n",
      "Epoch 398/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1482 - accuracy: 0.9326 - val_loss: 0.1881 - val_accuracy: 0.9247\n",
      "Epoch 399/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1471 - accuracy: 0.9333 - val_loss: 0.1767 - val_accuracy: 0.9251\n",
      "Epoch 400/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1457 - accuracy: 0.9332 - val_loss: 0.1955 - val_accuracy: 0.9176\n",
      "Epoch 401/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1586 - accuracy: 0.9282 - val_loss: 0.1789 - val_accuracy: 0.9240\n",
      "Epoch 402/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1538 - accuracy: 0.9317 - val_loss: 0.1902 - val_accuracy: 0.9210\n",
      "Epoch 403/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1554 - accuracy: 0.9298 - val_loss: 0.2158 - val_accuracy: 0.9111\n",
      "Epoch 404/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1489 - accuracy: 0.9325 - val_loss: 0.1793 - val_accuracy: 0.9250\n",
      "Epoch 405/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1498 - accuracy: 0.9321 - val_loss: 0.1761 - val_accuracy: 0.9246\n",
      "Epoch 406/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1505 - accuracy: 0.9317 - val_loss: 0.1916 - val_accuracy: 0.9224\n",
      "Epoch 407/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1487 - accuracy: 0.9321 - val_loss: 0.1751 - val_accuracy: 0.9278\n",
      "Epoch 408/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1493 - accuracy: 0.9318 - val_loss: 0.1773 - val_accuracy: 0.9273\n",
      "Epoch 409/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1450 - accuracy: 0.9332 - val_loss: 0.1849 - val_accuracy: 0.9218\n",
      "Epoch 410/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1465 - accuracy: 0.9327 - val_loss: 0.1813 - val_accuracy: 0.9233\n",
      "Epoch 411/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1569 - accuracy: 0.9294 - val_loss: 0.1760 - val_accuracy: 0.9249\n",
      "Epoch 412/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1547 - accuracy: 0.9303 - val_loss: 0.2097 - val_accuracy: 0.9157\n",
      "Epoch 413/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1530 - accuracy: 0.9312 - val_loss: 0.1807 - val_accuracy: 0.9250\n",
      "Epoch 414/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1428 - accuracy: 0.9349 - val_loss: 0.1855 - val_accuracy: 0.9252\n",
      "Epoch 415/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1527 - accuracy: 0.9301 - val_loss: 0.1809 - val_accuracy: 0.9237\n",
      "Epoch 416/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1556 - accuracy: 0.9302 - val_loss: 0.1759 - val_accuracy: 0.9268\n",
      "Epoch 417/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1456 - accuracy: 0.9341 - val_loss: 0.1778 - val_accuracy: 0.9241\n",
      "Epoch 418/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1541 - accuracy: 0.9301 - val_loss: 0.1835 - val_accuracy: 0.9224\n",
      "Epoch 419/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1450 - accuracy: 0.9332 - val_loss: 0.1730 - val_accuracy: 0.9289\n",
      "Epoch 420/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1559 - accuracy: 0.9288 - val_loss: 0.1843 - val_accuracy: 0.9234\n",
      "Epoch 421/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1458 - accuracy: 0.9343 - val_loss: 0.1839 - val_accuracy: 0.9219\n",
      "Epoch 422/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1518 - accuracy: 0.9309 - val_loss: 0.1761 - val_accuracy: 0.9229\n",
      "Epoch 423/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1517 - accuracy: 0.9310 - val_loss: 0.1837 - val_accuracy: 0.9240\n",
      "Epoch 424/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1434 - accuracy: 0.9345 - val_loss: 0.1721 - val_accuracy: 0.9269\n",
      "Epoch 425/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1466 - accuracy: 0.9339 - val_loss: 0.1809 - val_accuracy: 0.9241\n",
      "Epoch 426/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1521 - accuracy: 0.9307 - val_loss: 0.2214 - val_accuracy: 0.9133\n",
      "Epoch 427/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1619 - accuracy: 0.9272 - val_loss: 0.1776 - val_accuracy: 0.9249\n",
      "Epoch 428/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1495 - accuracy: 0.9322 - val_loss: 0.1791 - val_accuracy: 0.9258\n",
      "Epoch 429/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1487 - accuracy: 0.9322 - val_loss: 0.1782 - val_accuracy: 0.9239\n",
      "Epoch 430/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1504 - accuracy: 0.9311 - val_loss: 0.1838 - val_accuracy: 0.9247\n",
      "Epoch 431/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1445 - accuracy: 0.9343 - val_loss: 0.1955 - val_accuracy: 0.9222\n",
      "Epoch 432/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1513 - accuracy: 0.9315 - val_loss: 0.1777 - val_accuracy: 0.9238\n",
      "Epoch 433/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 0.1486 - accuracy: 0.9324 - val_loss: 0.1790 - val_accuracy: 0.9263\n",
      "Epoch 434/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1508 - accuracy: 0.9312 - val_loss: 0.1791 - val_accuracy: 0.9235\n",
      "Epoch 435/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1535 - accuracy: 0.9306 - val_loss: 0.1791 - val_accuracy: 0.9205\n",
      "Epoch 436/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1408 - accuracy: 0.9361 - val_loss: 0.1900 - val_accuracy: 0.9218\n",
      "Epoch 437/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1450 - accuracy: 0.9336 - val_loss: 0.1781 - val_accuracy: 0.9255\n",
      "Epoch 438/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1453 - accuracy: 0.9337 - val_loss: 0.1808 - val_accuracy: 0.9245\n",
      "Epoch 439/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1433 - accuracy: 0.9340 - val_loss: 0.1720 - val_accuracy: 0.9276\n",
      "Epoch 440/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1465 - accuracy: 0.9327 - val_loss: 0.1976 - val_accuracy: 0.9207\n",
      "Epoch 441/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1519 - accuracy: 0.9315 - val_loss: 0.1900 - val_accuracy: 0.9198\n",
      "Epoch 442/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1473 - accuracy: 0.9323 - val_loss: 0.1927 - val_accuracy: 0.9181\n",
      "Epoch 443/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1499 - accuracy: 0.9312 - val_loss: 0.1773 - val_accuracy: 0.9243\n",
      "Epoch 444/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1560 - accuracy: 0.9295 - val_loss: 0.1881 - val_accuracy: 0.9234\n",
      "Epoch 445/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1516 - accuracy: 0.9314 - val_loss: 0.1768 - val_accuracy: 0.9244\n",
      "Epoch 446/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1433 - accuracy: 0.9347 - val_loss: 0.2049 - val_accuracy: 0.9198\n",
      "Epoch 447/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1497 - accuracy: 0.9320 - val_loss: 0.2104 - val_accuracy: 0.9172\n",
      "Epoch 448/1000\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.1453 - accuracy: 0.9330 - val_loss: 0.1862 - val_accuracy: 0.9229\n",
      "Epoch 449/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1434 - accuracy: 0.9346 - val_loss: 0.1851 - val_accuracy: 0.9240\n",
      "Epoch 450/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1451 - accuracy: 0.9342 - val_loss: 0.1798 - val_accuracy: 0.9240\n",
      "Epoch 451/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1400 - accuracy: 0.9360 - val_loss: 0.1814 - val_accuracy: 0.9270\n",
      "Epoch 452/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1490 - accuracy: 0.9322 - val_loss: 0.1865 - val_accuracy: 0.9213\n",
      "Epoch 453/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1422 - accuracy: 0.9344 - val_loss: 0.1756 - val_accuracy: 0.9289\n",
      "Epoch 454/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1555 - accuracy: 0.9300 - val_loss: 0.1932 - val_accuracy: 0.9217\n",
      "Epoch 455/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1642 - accuracy: 0.9265 - val_loss: 0.1842 - val_accuracy: 0.9213\n",
      "Epoch 456/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1415 - accuracy: 0.9354 - val_loss: 0.1866 - val_accuracy: 0.9213\n",
      "Epoch 457/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1402 - accuracy: 0.9354 - val_loss: 0.1986 - val_accuracy: 0.9230\n",
      "Epoch 458/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1464 - accuracy: 0.9337 - val_loss: 0.1797 - val_accuracy: 0.9222\n",
      "Epoch 459/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1476 - accuracy: 0.9322 - val_loss: 0.1893 - val_accuracy: 0.9231\n",
      "Epoch 460/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1453 - accuracy: 0.9341 - val_loss: 0.1747 - val_accuracy: 0.9249\n",
      "Epoch 461/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1465 - accuracy: 0.9329 - val_loss: 0.2059 - val_accuracy: 0.9187\n",
      "Epoch 462/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1480 - accuracy: 0.9331 - val_loss: 0.2004 - val_accuracy: 0.9196\n",
      "Epoch 463/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1428 - accuracy: 0.9345 - val_loss: 0.1820 - val_accuracy: 0.9239\n",
      "Epoch 464/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1385 - accuracy: 0.9362 - val_loss: 0.1810 - val_accuracy: 0.9272\n",
      "Epoch 465/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1411 - accuracy: 0.9346 - val_loss: 0.1787 - val_accuracy: 0.9257\n",
      "Epoch 466/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1490 - accuracy: 0.9327 - val_loss: 0.1831 - val_accuracy: 0.9254\n",
      "Epoch 467/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1402 - accuracy: 0.9363 - val_loss: 0.1780 - val_accuracy: 0.9262\n",
      "Epoch 468/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1470 - accuracy: 0.9325 - val_loss: 0.1826 - val_accuracy: 0.9230\n",
      "Epoch 469/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1511 - accuracy: 0.9317 - val_loss: 0.1862 - val_accuracy: 0.9198\n",
      "Epoch 470/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1431 - accuracy: 0.9341 - val_loss: 0.1775 - val_accuracy: 0.9269\n",
      "Epoch 471/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1395 - accuracy: 0.9368 - val_loss: 0.1843 - val_accuracy: 0.9250\n",
      "Epoch 472/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1430 - accuracy: 0.9345 - val_loss: 0.1826 - val_accuracy: 0.9229\n",
      "Epoch 473/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1493 - accuracy: 0.9326 - val_loss: 0.2285 - val_accuracy: 0.9098\n",
      "Epoch 474/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1471 - accuracy: 0.9336 - val_loss: 0.1911 - val_accuracy: 0.9237\n",
      "Epoch 475/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1543 - accuracy: 0.9299 - val_loss: 0.1823 - val_accuracy: 0.9247\n",
      "Epoch 476/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1422 - accuracy: 0.9348 - val_loss: 0.1881 - val_accuracy: 0.9218\n",
      "Epoch 477/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.1463 - accuracy: 0.9332 - val_loss: 0.1739 - val_accuracy: 0.9255\n",
      "Epoch 478/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1405 - accuracy: 0.9362 - val_loss: 0.1817 - val_accuracy: 0.9255\n",
      "Epoch 479/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1438 - accuracy: 0.9344 - val_loss: 0.1916 - val_accuracy: 0.9183\n",
      "Epoch 480/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 0.1396 - accuracy: 0.9358 - val_loss: 0.1800 - val_accuracy: 0.9252\n",
      "Epoch 481/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.1467 - accuracy: 0.9327 - val_loss: 0.1743 - val_accuracy: 0.9252\n",
      "Epoch 482/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.1465 - accuracy: 0.9330 - val_loss: 0.1719 - val_accuracy: 0.9272\n",
      "Epoch 483/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1346 - accuracy: 0.9375 - val_loss: 0.1791 - val_accuracy: 0.9249\n",
      "Epoch 484/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1388 - accuracy: 0.9356 - val_loss: 0.1740 - val_accuracy: 0.9271\n",
      "Epoch 485/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1403 - accuracy: 0.9354 - val_loss: 0.1808 - val_accuracy: 0.9238\n",
      "Epoch 486/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1474 - accuracy: 0.9333 - val_loss: 0.1825 - val_accuracy: 0.9237\n",
      "Epoch 487/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1415 - accuracy: 0.9355 - val_loss: 0.1844 - val_accuracy: 0.9246\n",
      "Epoch 488/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1404 - accuracy: 0.9358 - val_loss: 0.1926 - val_accuracy: 0.9207\n",
      "Epoch 489/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1599 - accuracy: 0.9281 - val_loss: 0.2122 - val_accuracy: 0.9143\n",
      "Epoch 490/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1411 - accuracy: 0.9351 - val_loss: 0.1772 - val_accuracy: 0.9274\n",
      "Epoch 491/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.1487 - accuracy: 0.9326 - val_loss: 0.1772 - val_accuracy: 0.9250\n",
      "Epoch 492/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1558 - accuracy: 0.9309 - val_loss: 0.1809 - val_accuracy: 0.9235\n",
      "Epoch 493/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1395 - accuracy: 0.9365 - val_loss: 0.1756 - val_accuracy: 0.9258\n",
      "Epoch 494/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1437 - accuracy: 0.9342 - val_loss: 0.1793 - val_accuracy: 0.9258\n",
      "Epoch 495/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1419 - accuracy: 0.9358 - val_loss: 0.1779 - val_accuracy: 0.9284\n",
      "Epoch 496/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1427 - accuracy: 0.9352 - val_loss: 0.1729 - val_accuracy: 0.9278\n",
      "Epoch 497/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1353 - accuracy: 0.9374 - val_loss: 0.1854 - val_accuracy: 0.9255\n",
      "Epoch 498/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1468 - accuracy: 0.9325 - val_loss: 0.1919 - val_accuracy: 0.9188\n",
      "Epoch 499/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1550 - accuracy: 0.9301 - val_loss: 0.1762 - val_accuracy: 0.9272\n",
      "Epoch 500/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1389 - accuracy: 0.9359 - val_loss: 0.1762 - val_accuracy: 0.9269\n",
      "Epoch 501/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1306 - accuracy: 0.9400 - val_loss: 0.1731 - val_accuracy: 0.9272\n",
      "Epoch 502/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1447 - accuracy: 0.9333 - val_loss: 0.1796 - val_accuracy: 0.9252\n",
      "Epoch 503/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1411 - accuracy: 0.9354 - val_loss: 0.1928 - val_accuracy: 0.9213\n",
      "Epoch 504/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1540 - accuracy: 0.9306 - val_loss: 0.1745 - val_accuracy: 0.9252\n",
      "Epoch 505/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1378 - accuracy: 0.9357 - val_loss: 0.1770 - val_accuracy: 0.9263\n",
      "Epoch 506/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1366 - accuracy: 0.9364 - val_loss: 0.1760 - val_accuracy: 0.9265\n",
      "Epoch 507/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1436 - accuracy: 0.9345 - val_loss: 0.1882 - val_accuracy: 0.9237\n",
      "Epoch 508/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1453 - accuracy: 0.9343 - val_loss: 0.1746 - val_accuracy: 0.9277\n",
      "Epoch 509/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1437 - accuracy: 0.9344 - val_loss: 0.1826 - val_accuracy: 0.9229\n",
      "Epoch 510/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1462 - accuracy: 0.9328 - val_loss: 0.1946 - val_accuracy: 0.9200\n",
      "Epoch 511/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1430 - accuracy: 0.9343 - val_loss: 0.1759 - val_accuracy: 0.9271\n",
      "Epoch 512/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1380 - accuracy: 0.9365 - val_loss: 0.1738 - val_accuracy: 0.9273\n",
      "Epoch 513/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1409 - accuracy: 0.9351 - val_loss: 0.1930 - val_accuracy: 0.9183\n",
      "Epoch 514/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1395 - accuracy: 0.9357 - val_loss: 0.1710 - val_accuracy: 0.9283\n",
      "Epoch 515/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1445 - accuracy: 0.9336 - val_loss: 0.1801 - val_accuracy: 0.9251\n",
      "Epoch 516/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1325 - accuracy: 0.9389 - val_loss: 0.1843 - val_accuracy: 0.9239\n",
      "Epoch 517/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1372 - accuracy: 0.9363 - val_loss: 0.1906 - val_accuracy: 0.9230\n",
      "Epoch 518/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1430 - accuracy: 0.9350 - val_loss: 0.1795 - val_accuracy: 0.9252\n",
      "Epoch 519/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1460 - accuracy: 0.9335 - val_loss: 0.1946 - val_accuracy: 0.9218\n",
      "Epoch 520/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1421 - accuracy: 0.9343 - val_loss: 0.1952 - val_accuracy: 0.9231\n",
      "Epoch 521/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1379 - accuracy: 0.9367 - val_loss: 0.2150 - val_accuracy: 0.9155\n",
      "Epoch 522/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1453 - accuracy: 0.9339 - val_loss: 0.1811 - val_accuracy: 0.9220\n",
      "Epoch 523/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1323 - accuracy: 0.9381 - val_loss: 0.2004 - val_accuracy: 0.9217\n",
      "Epoch 524/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1537 - accuracy: 0.9300 - val_loss: 0.2026 - val_accuracy: 0.9194\n",
      "Epoch 525/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1426 - accuracy: 0.9348 - val_loss: 0.1760 - val_accuracy: 0.9267\n",
      "Epoch 526/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1364 - accuracy: 0.9369 - val_loss: 0.1844 - val_accuracy: 0.9241\n",
      "Epoch 527/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1382 - accuracy: 0.9358 - val_loss: 0.1843 - val_accuracy: 0.9245\n",
      "Epoch 528/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1388 - accuracy: 0.9361 - val_loss: 0.1762 - val_accuracy: 0.9251\n",
      "Epoch 529/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1429 - accuracy: 0.9339 - val_loss: 0.1870 - val_accuracy: 0.9250\n",
      "Epoch 530/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1399 - accuracy: 0.9363 - val_loss: 0.1746 - val_accuracy: 0.9264\n",
      "Epoch 531/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1327 - accuracy: 0.9384 - val_loss: 0.1907 - val_accuracy: 0.9205\n",
      "Epoch 532/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1468 - accuracy: 0.9334 - val_loss: 0.1850 - val_accuracy: 0.9227\n",
      "Epoch 533/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1384 - accuracy: 0.9362 - val_loss: 0.1733 - val_accuracy: 0.9284\n",
      "Epoch 534/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1312 - accuracy: 0.9385 - val_loss: 0.1750 - val_accuracy: 0.9263\n",
      "Epoch 535/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1384 - accuracy: 0.9363 - val_loss: 0.1800 - val_accuracy: 0.9275\n",
      "Epoch 536/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1368 - accuracy: 0.9379 - val_loss: 0.1898 - val_accuracy: 0.9210\n",
      "Epoch 537/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1377 - accuracy: 0.9368 - val_loss: 0.1854 - val_accuracy: 0.9240\n",
      "Epoch 538/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1360 - accuracy: 0.9371 - val_loss: 0.1769 - val_accuracy: 0.9235\n",
      "Epoch 539/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1370 - accuracy: 0.9364 - val_loss: 0.1771 - val_accuracy: 0.9266\n",
      "Epoch 540/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1385 - accuracy: 0.9368 - val_loss: 0.1771 - val_accuracy: 0.9252\n",
      "Epoch 541/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1374 - accuracy: 0.9373 - val_loss: 0.1783 - val_accuracy: 0.9255\n",
      "Epoch 542/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1470 - accuracy: 0.9326 - val_loss: 0.1847 - val_accuracy: 0.9238\n",
      "Epoch 543/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1307 - accuracy: 0.9398 - val_loss: 0.1844 - val_accuracy: 0.9255\n",
      "Epoch 544/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1355 - accuracy: 0.9370 - val_loss: 0.1796 - val_accuracy: 0.9249\n",
      "Epoch 545/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1408 - accuracy: 0.9347 - val_loss: 0.1760 - val_accuracy: 0.9256\n",
      "Epoch 546/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1380 - accuracy: 0.9363 - val_loss: 0.1825 - val_accuracy: 0.9263\n",
      "Epoch 547/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1375 - accuracy: 0.9363 - val_loss: 0.1973 - val_accuracy: 0.9178\n",
      "Epoch 548/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1536 - accuracy: 0.9301 - val_loss: 0.1818 - val_accuracy: 0.9231\n",
      "Epoch 549/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1520 - accuracy: 0.9312 - val_loss: 0.2408 - val_accuracy: 0.9078\n",
      "Epoch 550/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1555 - accuracy: 0.9308 - val_loss: 0.1873 - val_accuracy: 0.9260\n",
      "Epoch 551/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1324 - accuracy: 0.9384 - val_loss: 0.2033 - val_accuracy: 0.9199\n",
      "Epoch 552/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1417 - accuracy: 0.9350 - val_loss: 0.1755 - val_accuracy: 0.9262\n",
      "Epoch 553/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1283 - accuracy: 0.9405 - val_loss: 0.1753 - val_accuracy: 0.9288\n",
      "Epoch 554/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1274 - accuracy: 0.9413 - val_loss: 0.1808 - val_accuracy: 0.9254\n",
      "Epoch 555/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1435 - accuracy: 0.9339 - val_loss: 0.1780 - val_accuracy: 0.9254\n",
      "Epoch 556/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1326 - accuracy: 0.9384 - val_loss: 0.1762 - val_accuracy: 0.9257\n",
      "Epoch 557/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1345 - accuracy: 0.9377 - val_loss: 0.1788 - val_accuracy: 0.9288\n",
      "Epoch 558/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1366 - accuracy: 0.9378 - val_loss: 0.2024 - val_accuracy: 0.9206\n",
      "Epoch 559/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1429 - accuracy: 0.9346 - val_loss: 0.1755 - val_accuracy: 0.9282\n",
      "Epoch 560/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1383 - accuracy: 0.9358 - val_loss: 0.1852 - val_accuracy: 0.9228\n",
      "Epoch 561/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1342 - accuracy: 0.9384 - val_loss: 0.1739 - val_accuracy: 0.9289\n",
      "Epoch 562/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1390 - accuracy: 0.9363 - val_loss: 0.1884 - val_accuracy: 0.9229\n",
      "Epoch 563/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1385 - accuracy: 0.9362 - val_loss: 0.1885 - val_accuracy: 0.9221\n",
      "Epoch 564/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1389 - accuracy: 0.9356 - val_loss: 0.1754 - val_accuracy: 0.9280\n",
      "Epoch 565/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1290 - accuracy: 0.9404 - val_loss: 0.1818 - val_accuracy: 0.9245\n",
      "Epoch 566/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1332 - accuracy: 0.9384 - val_loss: 0.1838 - val_accuracy: 0.9262\n",
      "Epoch 567/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1430 - accuracy: 0.9341 - val_loss: 0.1907 - val_accuracy: 0.9239\n",
      "Epoch 568/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1323 - accuracy: 0.9388 - val_loss: 0.1993 - val_accuracy: 0.9181\n",
      "Epoch 569/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1378 - accuracy: 0.9355 - val_loss: 0.1828 - val_accuracy: 0.9237\n",
      "Epoch 570/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1333 - accuracy: 0.9390 - val_loss: 0.1757 - val_accuracy: 0.9263\n",
      "Epoch 571/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1324 - accuracy: 0.9388 - val_loss: 0.1801 - val_accuracy: 0.9244\n",
      "Epoch 572/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1367 - accuracy: 0.9370 - val_loss: 0.1923 - val_accuracy: 0.9253\n",
      "Epoch 573/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1400 - accuracy: 0.9363 - val_loss: 0.1758 - val_accuracy: 0.9257\n",
      "Epoch 574/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1367 - accuracy: 0.9367 - val_loss: 0.1965 - val_accuracy: 0.9193\n",
      "Epoch 575/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1315 - accuracy: 0.9395 - val_loss: 0.1888 - val_accuracy: 0.9239\n",
      "Epoch 576/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1276 - accuracy: 0.9409 - val_loss: 0.1845 - val_accuracy: 0.9234\n",
      "Epoch 577/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1353 - accuracy: 0.9377 - val_loss: 0.1924 - val_accuracy: 0.9197\n",
      "Epoch 578/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1387 - accuracy: 0.9358 - val_loss: 0.1805 - val_accuracy: 0.9263\n",
      "Epoch 579/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1305 - accuracy: 0.9393 - val_loss: 0.1900 - val_accuracy: 0.9261\n",
      "Epoch 580/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1354 - accuracy: 0.9372 - val_loss: 0.1923 - val_accuracy: 0.9227\n",
      "Epoch 581/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1357 - accuracy: 0.9373 - val_loss: 0.1905 - val_accuracy: 0.9239\n",
      "Epoch 582/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1373 - accuracy: 0.9368 - val_loss: 0.1794 - val_accuracy: 0.9274\n",
      "Epoch 583/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1304 - accuracy: 0.9390 - val_loss: 0.1837 - val_accuracy: 0.9274\n",
      "Epoch 584/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1450 - accuracy: 0.9339 - val_loss: 0.1903 - val_accuracy: 0.9224\n",
      "Epoch 585/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 0.1368 - accuracy: 0.9368 - val_loss: 0.1877 - val_accuracy: 0.9211\n",
      "Epoch 586/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1307 - accuracy: 0.9394 - val_loss: 0.1799 - val_accuracy: 0.9263\n",
      "Epoch 587/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1296 - accuracy: 0.9403 - val_loss: 0.1801 - val_accuracy: 0.9263\n",
      "Epoch 588/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1384 - accuracy: 0.9366 - val_loss: 0.1843 - val_accuracy: 0.9247\n",
      "Epoch 589/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1369 - accuracy: 0.9368 - val_loss: 0.1844 - val_accuracy: 0.9257\n",
      "Epoch 590/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1297 - accuracy: 0.9396 - val_loss: 0.1866 - val_accuracy: 0.9257\n",
      "Epoch 591/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1400 - accuracy: 0.9349 - val_loss: 0.1775 - val_accuracy: 0.9276\n",
      "Epoch 592/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1312 - accuracy: 0.9396 - val_loss: 0.1862 - val_accuracy: 0.9251\n",
      "Epoch 593/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1272 - accuracy: 0.9416 - val_loss: 0.1900 - val_accuracy: 0.9236\n",
      "Epoch 594/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1437 - accuracy: 0.9343 - val_loss: 0.1816 - val_accuracy: 0.9227\n",
      "Epoch 595/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1448 - accuracy: 0.9348 - val_loss: 0.1830 - val_accuracy: 0.9234\n",
      "Epoch 596/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1357 - accuracy: 0.9371 - val_loss: 0.1747 - val_accuracy: 0.9284\n",
      "Epoch 597/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1417 - accuracy: 0.9347 - val_loss: 0.2001 - val_accuracy: 0.9200\n",
      "Epoch 598/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1466 - accuracy: 0.9336 - val_loss: 0.1791 - val_accuracy: 0.9274\n",
      "Epoch 599/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1289 - accuracy: 0.9403 - val_loss: 0.1786 - val_accuracy: 0.9260\n",
      "Epoch 600/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1267 - accuracy: 0.9411 - val_loss: 0.1788 - val_accuracy: 0.9268\n",
      "Epoch 601/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1239 - accuracy: 0.9418 - val_loss: 0.1789 - val_accuracy: 0.9282\n",
      "Epoch 602/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1456 - accuracy: 0.9337 - val_loss: 0.2118 - val_accuracy: 0.9168\n",
      "Epoch 603/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1324 - accuracy: 0.9389 - val_loss: 0.1922 - val_accuracy: 0.9228\n",
      "Epoch 604/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1356 - accuracy: 0.9375 - val_loss: 0.1771 - val_accuracy: 0.9267\n",
      "Epoch 605/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1269 - accuracy: 0.9410 - val_loss: 0.1921 - val_accuracy: 0.9243\n",
      "Epoch 606/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1290 - accuracy: 0.9408 - val_loss: 0.1810 - val_accuracy: 0.9275\n",
      "Epoch 607/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1422 - accuracy: 0.9351 - val_loss: 0.1973 - val_accuracy: 0.9230\n",
      "Epoch 608/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1443 - accuracy: 0.9338 - val_loss: 0.1859 - val_accuracy: 0.9260\n",
      "Epoch 609/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1361 - accuracy: 0.9373 - val_loss: 0.1871 - val_accuracy: 0.9249\n",
      "Epoch 610/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1257 - accuracy: 0.9407 - val_loss: 0.1797 - val_accuracy: 0.9283\n",
      "Epoch 611/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1301 - accuracy: 0.9400 - val_loss: 0.1826 - val_accuracy: 0.9262\n",
      "Epoch 612/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1296 - accuracy: 0.9399 - val_loss: 0.1881 - val_accuracy: 0.9227\n",
      "Epoch 613/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1315 - accuracy: 0.9395 - val_loss: 0.1791 - val_accuracy: 0.9272\n",
      "Epoch 614/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1334 - accuracy: 0.9383 - val_loss: 0.1847 - val_accuracy: 0.9242\n",
      "Epoch 615/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1265 - accuracy: 0.9413 - val_loss: 0.1814 - val_accuracy: 0.9254\n",
      "Epoch 616/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1444 - accuracy: 0.9342 - val_loss: 0.1858 - val_accuracy: 0.9273\n",
      "Epoch 617/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1352 - accuracy: 0.9368 - val_loss: 0.1792 - val_accuracy: 0.9249\n",
      "Epoch 618/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1386 - accuracy: 0.9359 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 619/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1351 - accuracy: 0.9378 - val_loss: 0.1775 - val_accuracy: 0.9278\n",
      "Epoch 620/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1350 - accuracy: 0.9369 - val_loss: 0.1783 - val_accuracy: 0.9288\n",
      "Epoch 621/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1264 - accuracy: 0.9410 - val_loss: 0.1778 - val_accuracy: 0.9276\n",
      "Epoch 622/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1257 - accuracy: 0.9417 - val_loss: 0.1757 - val_accuracy: 0.9264\n",
      "Epoch 623/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1308 - accuracy: 0.9397 - val_loss: 0.1885 - val_accuracy: 0.9235\n",
      "Epoch 624/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1287 - accuracy: 0.9408 - val_loss: 0.1831 - val_accuracy: 0.9240\n",
      "Epoch 625/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1255 - accuracy: 0.9417 - val_loss: 0.1817 - val_accuracy: 0.9278\n",
      "Epoch 626/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1340 - accuracy: 0.9383 - val_loss: 0.1837 - val_accuracy: 0.9283\n",
      "Epoch 627/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1443 - accuracy: 0.9343 - val_loss: 0.1788 - val_accuracy: 0.9267\n",
      "Epoch 628/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1239 - accuracy: 0.9429 - val_loss: 0.1798 - val_accuracy: 0.9286\n",
      "Epoch 629/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1263 - accuracy: 0.9414 - val_loss: 0.1916 - val_accuracy: 0.9236\n",
      "Epoch 630/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1383 - accuracy: 0.9360 - val_loss: 0.1868 - val_accuracy: 0.9244\n",
      "Epoch 631/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1299 - accuracy: 0.9396 - val_loss: 0.1812 - val_accuracy: 0.9276\n",
      "Epoch 632/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1272 - accuracy: 0.9408 - val_loss: 0.1833 - val_accuracy: 0.9259\n",
      "Epoch 633/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1356 - accuracy: 0.9375 - val_loss: 0.1799 - val_accuracy: 0.9293\n",
      "Epoch 634/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1271 - accuracy: 0.9403 - val_loss: 0.1774 - val_accuracy: 0.9280\n",
      "Epoch 635/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1401 - accuracy: 0.9356 - val_loss: 0.1871 - val_accuracy: 0.9233\n",
      "Epoch 636/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1311 - accuracy: 0.9391 - val_loss: 0.1884 - val_accuracy: 0.9246\n",
      "Epoch 637/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1290 - accuracy: 0.9400 - val_loss: 0.1869 - val_accuracy: 0.9243\n",
      "Epoch 638/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1399 - accuracy: 0.9357 - val_loss: 0.1827 - val_accuracy: 0.9259\n",
      "Epoch 639/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1224 - accuracy: 0.9428 - val_loss: 0.1843 - val_accuracy: 0.9280\n",
      "Epoch 640/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1381 - accuracy: 0.9357 - val_loss: 0.1809 - val_accuracy: 0.9259\n",
      "Epoch 641/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1303 - accuracy: 0.9407 - val_loss: 0.1848 - val_accuracy: 0.9224\n",
      "Epoch 642/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1350 - accuracy: 0.9374 - val_loss: 0.1790 - val_accuracy: 0.9291\n",
      "Epoch 643/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1301 - accuracy: 0.9399 - val_loss: 0.1793 - val_accuracy: 0.9262\n",
      "Epoch 644/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1229 - accuracy: 0.9426 - val_loss: 0.1818 - val_accuracy: 0.9271\n",
      "Epoch 645/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1299 - accuracy: 0.9407 - val_loss: 0.1854 - val_accuracy: 0.9231\n",
      "Epoch 646/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1331 - accuracy: 0.9379 - val_loss: 0.2128 - val_accuracy: 0.9187\n",
      "Epoch 647/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1332 - accuracy: 0.9386 - val_loss: 0.1866 - val_accuracy: 0.9275\n",
      "Epoch 648/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1332 - accuracy: 0.9392 - val_loss: 0.1886 - val_accuracy: 0.9240\n",
      "Epoch 649/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1241 - accuracy: 0.9421 - val_loss: 0.1782 - val_accuracy: 0.9264\n",
      "Epoch 650/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1294 - accuracy: 0.9396 - val_loss: 0.1952 - val_accuracy: 0.9228\n",
      "Epoch 651/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1364 - accuracy: 0.9374 - val_loss: 0.1815 - val_accuracy: 0.9249\n",
      "Epoch 652/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1293 - accuracy: 0.9401 - val_loss: 0.1903 - val_accuracy: 0.9234\n",
      "Epoch 653/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1266 - accuracy: 0.9410 - val_loss: 0.1745 - val_accuracy: 0.9283\n",
      "Epoch 654/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1269 - accuracy: 0.9407 - val_loss: 0.1860 - val_accuracy: 0.9263\n",
      "Epoch 655/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1311 - accuracy: 0.9391 - val_loss: 0.1884 - val_accuracy: 0.9274\n",
      "Epoch 656/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1273 - accuracy: 0.9409 - val_loss: 0.1809 - val_accuracy: 0.9239\n",
      "Epoch 657/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1284 - accuracy: 0.9406 - val_loss: 0.1840 - val_accuracy: 0.9263\n",
      "Epoch 658/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1225 - accuracy: 0.9429 - val_loss: 0.1934 - val_accuracy: 0.9223\n",
      "Epoch 659/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1303 - accuracy: 0.9393 - val_loss: 0.1789 - val_accuracy: 0.9265\n",
      "Epoch 660/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1237 - accuracy: 0.9424 - val_loss: 0.1793 - val_accuracy: 0.9300\n",
      "Epoch 661/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1379 - accuracy: 0.9357 - val_loss: 0.2246 - val_accuracy: 0.9129\n",
      "Epoch 662/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1295 - accuracy: 0.9398 - val_loss: 0.1947 - val_accuracy: 0.9260\n",
      "Epoch 663/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1256 - accuracy: 0.9417 - val_loss: 0.2048 - val_accuracy: 0.9221\n",
      "Epoch 664/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1301 - accuracy: 0.9397 - val_loss: 0.1937 - val_accuracy: 0.9225\n",
      "Epoch 665/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1350 - accuracy: 0.9374 - val_loss: 0.1900 - val_accuracy: 0.9236\n",
      "Epoch 666/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1326 - accuracy: 0.9384 - val_loss: 0.1802 - val_accuracy: 0.9280\n",
      "Epoch 667/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1270 - accuracy: 0.9412 - val_loss: 0.1808 - val_accuracy: 0.9270\n",
      "Epoch 668/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1249 - accuracy: 0.9423 - val_loss: 0.1843 - val_accuracy: 0.9272\n",
      "Epoch 669/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1271 - accuracy: 0.9412 - val_loss: 0.1826 - val_accuracy: 0.9271\n",
      "Epoch 670/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1229 - accuracy: 0.9427 - val_loss: 0.1791 - val_accuracy: 0.9274\n",
      "Epoch 671/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1308 - accuracy: 0.9393 - val_loss: 0.2037 - val_accuracy: 0.9244\n",
      "Epoch 672/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1274 - accuracy: 0.9407 - val_loss: 0.1799 - val_accuracy: 0.9300\n",
      "Epoch 673/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1425 - accuracy: 0.9361 - val_loss: 0.1760 - val_accuracy: 0.9291\n",
      "Epoch 674/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1199 - accuracy: 0.9442 - val_loss: 0.1898 - val_accuracy: 0.9230\n",
      "Epoch 675/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1273 - accuracy: 0.9408 - val_loss: 0.1893 - val_accuracy: 0.9276\n",
      "Epoch 676/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1214 - accuracy: 0.9435 - val_loss: 0.1931 - val_accuracy: 0.9260\n",
      "Epoch 677/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1347 - accuracy: 0.9375 - val_loss: 0.1795 - val_accuracy: 0.9271\n",
      "Epoch 678/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1301 - accuracy: 0.9398 - val_loss: 0.1837 - val_accuracy: 0.9262\n",
      "Epoch 679/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1340 - accuracy: 0.9381 - val_loss: 0.1812 - val_accuracy: 0.9267\n",
      "Epoch 680/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1200 - accuracy: 0.9441 - val_loss: 0.1767 - val_accuracy: 0.9289\n",
      "Epoch 681/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1221 - accuracy: 0.9429 - val_loss: 0.1803 - val_accuracy: 0.9290\n",
      "Epoch 682/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1242 - accuracy: 0.9420 - val_loss: 0.1969 - val_accuracy: 0.9271\n",
      "Epoch 683/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1436 - accuracy: 0.9334 - val_loss: 0.2352 - val_accuracy: 0.9093\n",
      "Epoch 684/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1319 - accuracy: 0.9388 - val_loss: 0.1955 - val_accuracy: 0.9209\n",
      "Epoch 685/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1307 - accuracy: 0.9401 - val_loss: 0.2022 - val_accuracy: 0.9227\n",
      "Epoch 686/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1245 - accuracy: 0.9427 - val_loss: 0.1792 - val_accuracy: 0.9279\n",
      "Epoch 687/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1268 - accuracy: 0.9416 - val_loss: 0.1766 - val_accuracy: 0.9288\n",
      "Epoch 688/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1185 - accuracy: 0.9441 - val_loss: 0.1829 - val_accuracy: 0.9273\n",
      "Epoch 689/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1228 - accuracy: 0.9432 - val_loss: 0.2021 - val_accuracy: 0.9222\n",
      "Epoch 690/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1215 - accuracy: 0.9434 - val_loss: 0.1941 - val_accuracy: 0.9242\n",
      "Epoch 691/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1341 - accuracy: 0.9379 - val_loss: 0.1974 - val_accuracy: 0.9257\n",
      "Epoch 692/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1273 - accuracy: 0.9407 - val_loss: 0.1836 - val_accuracy: 0.9282\n",
      "Epoch 693/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1267 - accuracy: 0.9420 - val_loss: 0.1835 - val_accuracy: 0.9258\n",
      "Epoch 694/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.1201 - accuracy: 0.9441 - val_loss: 0.1849 - val_accuracy: 0.9267\n",
      "Epoch 695/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1181 - accuracy: 0.9449 - val_loss: 0.1808 - val_accuracy: 0.9300\n",
      "Epoch 696/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1369 - accuracy: 0.9374 - val_loss: 0.1884 - val_accuracy: 0.9250\n",
      "Epoch 697/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1288 - accuracy: 0.9405 - val_loss: 0.1861 - val_accuracy: 0.9237\n",
      "Epoch 698/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1236 - accuracy: 0.9420 - val_loss: 0.1837 - val_accuracy: 0.9254\n",
      "Epoch 699/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1376 - accuracy: 0.9360 - val_loss: 0.1976 - val_accuracy: 0.9216\n",
      "Epoch 700/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1352 - accuracy: 0.9372 - val_loss: 0.1832 - val_accuracy: 0.9255\n",
      "Epoch 701/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1232 - accuracy: 0.9426 - val_loss: 0.1810 - val_accuracy: 0.9273\n",
      "Epoch 702/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1286 - accuracy: 0.9398 - val_loss: 0.1819 - val_accuracy: 0.9300\n",
      "Epoch 703/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1224 - accuracy: 0.9431 - val_loss: 0.1833 - val_accuracy: 0.9285\n",
      "Epoch 704/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1211 - accuracy: 0.9435 - val_loss: 0.1878 - val_accuracy: 0.9277\n",
      "Epoch 705/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1228 - accuracy: 0.9432 - val_loss: 0.1854 - val_accuracy: 0.9272\n",
      "Epoch 706/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1228 - accuracy: 0.9428 - val_loss: 0.1871 - val_accuracy: 0.9269\n",
      "Epoch 707/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1248 - accuracy: 0.9418 - val_loss: 0.2000 - val_accuracy: 0.9203\n",
      "Epoch 708/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1252 - accuracy: 0.9417 - val_loss: 0.1883 - val_accuracy: 0.9235\n",
      "Epoch 709/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1265 - accuracy: 0.9414 - val_loss: 0.1899 - val_accuracy: 0.9259\n",
      "Epoch 710/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1300 - accuracy: 0.9402 - val_loss: 0.1976 - val_accuracy: 0.9248\n",
      "Epoch 711/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1214 - accuracy: 0.9437 - val_loss: 0.1835 - val_accuracy: 0.9261\n",
      "Epoch 712/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1190 - accuracy: 0.9447 - val_loss: 0.1980 - val_accuracy: 0.9211\n",
      "Epoch 713/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1314 - accuracy: 0.9393 - val_loss: 0.1803 - val_accuracy: 0.9276\n",
      "Epoch 714/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1162 - accuracy: 0.9459 - val_loss: 0.1865 - val_accuracy: 0.9244\n",
      "Epoch 715/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1262 - accuracy: 0.9413 - val_loss: 0.1835 - val_accuracy: 0.9279\n",
      "Epoch 716/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1433 - accuracy: 0.9351 - val_loss: 0.1954 - val_accuracy: 0.9228\n",
      "Epoch 717/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1290 - accuracy: 0.9403 - val_loss: 0.1864 - val_accuracy: 0.9271\n",
      "Epoch 718/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1240 - accuracy: 0.9424 - val_loss: 0.1846 - val_accuracy: 0.9279\n",
      "Epoch 719/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1195 - accuracy: 0.9446 - val_loss: 0.1807 - val_accuracy: 0.9283\n",
      "Epoch 720/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1220 - accuracy: 0.9426 - val_loss: 0.1806 - val_accuracy: 0.9284\n",
      "Epoch 721/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1328 - accuracy: 0.9386 - val_loss: 0.1817 - val_accuracy: 0.9257\n",
      "Epoch 722/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1335 - accuracy: 0.9380 - val_loss: 0.1801 - val_accuracy: 0.9275\n",
      "Epoch 723/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1219 - accuracy: 0.9435 - val_loss: 0.1871 - val_accuracy: 0.9245\n",
      "Epoch 724/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1249 - accuracy: 0.9417 - val_loss: 0.1839 - val_accuracy: 0.9270\n",
      "Epoch 725/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1401 - accuracy: 0.9361 - val_loss: 0.1954 - val_accuracy: 0.9229\n",
      "Epoch 726/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1173 - accuracy: 0.9452 - val_loss: 0.1853 - val_accuracy: 0.9260\n",
      "Epoch 727/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1213 - accuracy: 0.9429 - val_loss: 0.1848 - val_accuracy: 0.9277\n",
      "Epoch 728/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1185 - accuracy: 0.9446 - val_loss: 0.1854 - val_accuracy: 0.9265\n",
      "Epoch 729/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1262 - accuracy: 0.9406 - val_loss: 0.2007 - val_accuracy: 0.9207\n",
      "Epoch 730/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1364 - accuracy: 0.9373 - val_loss: 0.1906 - val_accuracy: 0.9258\n",
      "Epoch 731/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1175 - accuracy: 0.9450 - val_loss: 0.1905 - val_accuracy: 0.9264\n",
      "Epoch 732/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1144 - accuracy: 0.9461 - val_loss: 0.1875 - val_accuracy: 0.9264\n",
      "Epoch 733/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1212 - accuracy: 0.9439 - val_loss: 0.1949 - val_accuracy: 0.9216\n",
      "Epoch 734/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1235 - accuracy: 0.9428 - val_loss: 0.1897 - val_accuracy: 0.9247\n",
      "Epoch 735/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1358 - accuracy: 0.9380 - val_loss: 0.1955 - val_accuracy: 0.9217\n",
      "Epoch 736/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 0.1293 - accuracy: 0.9395 - val_loss: 0.1845 - val_accuracy: 0.9263\n",
      "Epoch 737/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1247 - accuracy: 0.9423 - val_loss: 0.1862 - val_accuracy: 0.9269\n",
      "Epoch 738/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1321 - accuracy: 0.9393 - val_loss: 0.1815 - val_accuracy: 0.9288\n",
      "Epoch 739/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1159 - accuracy: 0.9456 - val_loss: 0.1930 - val_accuracy: 0.9266\n",
      "Epoch 740/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1207 - accuracy: 0.9444 - val_loss: 0.1823 - val_accuracy: 0.9266\n",
      "Epoch 741/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1206 - accuracy: 0.9436 - val_loss: 0.1961 - val_accuracy: 0.9241\n",
      "Epoch 742/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1176 - accuracy: 0.9451 - val_loss: 0.1812 - val_accuracy: 0.9280\n",
      "Epoch 743/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1309 - accuracy: 0.9395 - val_loss: 0.1858 - val_accuracy: 0.9265\n",
      "Epoch 744/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1172 - accuracy: 0.9449 - val_loss: 0.1997 - val_accuracy: 0.9234\n",
      "Epoch 745/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1234 - accuracy: 0.9429 - val_loss: 0.1883 - val_accuracy: 0.9290\n",
      "Epoch 746/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1342 - accuracy: 0.9389 - val_loss: 0.1968 - val_accuracy: 0.9213\n",
      "Epoch 747/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1252 - accuracy: 0.9418 - val_loss: 0.1864 - val_accuracy: 0.9276\n",
      "Epoch 748/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1198 - accuracy: 0.9440 - val_loss: 0.1865 - val_accuracy: 0.9257\n",
      "Epoch 749/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1222 - accuracy: 0.9428 - val_loss: 0.1918 - val_accuracy: 0.9233\n",
      "Epoch 750/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1375 - accuracy: 0.9373 - val_loss: 0.1913 - val_accuracy: 0.9265\n",
      "Epoch 751/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1205 - accuracy: 0.9436 - val_loss: 0.1958 - val_accuracy: 0.9240\n",
      "Epoch 752/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1240 - accuracy: 0.9422 - val_loss: 0.1921 - val_accuracy: 0.9251\n",
      "Epoch 753/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1349 - accuracy: 0.9379 - val_loss: 0.1878 - val_accuracy: 0.9239\n",
      "Epoch 754/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1177 - accuracy: 0.9441 - val_loss: 0.1814 - val_accuracy: 0.9275\n",
      "Epoch 755/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1137 - accuracy: 0.9469 - val_loss: 0.1836 - val_accuracy: 0.9279\n",
      "Epoch 756/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1173 - accuracy: 0.9457 - val_loss: 0.1971 - val_accuracy: 0.9221\n",
      "Epoch 757/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1230 - accuracy: 0.9427 - val_loss: 0.1785 - val_accuracy: 0.9284\n",
      "Epoch 758/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1180 - accuracy: 0.9445 - val_loss: 0.1937 - val_accuracy: 0.9240\n",
      "Epoch 759/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1234 - accuracy: 0.9423 - val_loss: 0.1885 - val_accuracy: 0.9260\n",
      "Epoch 760/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1170 - accuracy: 0.9454 - val_loss: 0.1823 - val_accuracy: 0.9246\n",
      "Epoch 761/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1170 - accuracy: 0.9453 - val_loss: 0.1893 - val_accuracy: 0.9249\n",
      "Epoch 762/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1202 - accuracy: 0.9432 - val_loss: 0.2029 - val_accuracy: 0.9250\n",
      "Epoch 763/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1248 - accuracy: 0.9418 - val_loss: 0.2003 - val_accuracy: 0.9234\n",
      "Epoch 764/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1222 - accuracy: 0.9427 - val_loss: 0.1992 - val_accuracy: 0.9257\n",
      "Epoch 765/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1228 - accuracy: 0.9433 - val_loss: 0.2117 - val_accuracy: 0.9188\n",
      "Epoch 766/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1320 - accuracy: 0.9396 - val_loss: 0.1923 - val_accuracy: 0.9236\n",
      "Epoch 767/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1242 - accuracy: 0.9416 - val_loss: 0.1917 - val_accuracy: 0.9213\n",
      "Epoch 768/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1191 - accuracy: 0.9443 - val_loss: 0.1920 - val_accuracy: 0.9273\n",
      "Epoch 769/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1188 - accuracy: 0.9433 - val_loss: 0.1839 - val_accuracy: 0.9258\n",
      "Epoch 770/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1202 - accuracy: 0.9439 - val_loss: 0.1994 - val_accuracy: 0.9217\n",
      "Epoch 771/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1180 - accuracy: 0.9452 - val_loss: 0.1896 - val_accuracy: 0.9270\n",
      "Epoch 772/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1269 - accuracy: 0.9409 - val_loss: 0.1930 - val_accuracy: 0.9211\n",
      "Epoch 773/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1280 - accuracy: 0.9409 - val_loss: 0.1853 - val_accuracy: 0.9252\n",
      "Epoch 774/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1153 - accuracy: 0.9456 - val_loss: 0.2032 - val_accuracy: 0.9250\n",
      "Epoch 775/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1213 - accuracy: 0.9431 - val_loss: 0.1879 - val_accuracy: 0.9284\n",
      "Epoch 776/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1153 - accuracy: 0.9460 - val_loss: 0.1989 - val_accuracy: 0.9250\n",
      "Epoch 777/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1555 - accuracy: 0.9316 - val_loss: 0.1898 - val_accuracy: 0.9268\n",
      "Epoch 778/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1296 - accuracy: 0.9402 - val_loss: 0.1853 - val_accuracy: 0.9263\n",
      "Epoch 779/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1177 - accuracy: 0.9450 - val_loss: 0.1834 - val_accuracy: 0.9250\n",
      "Epoch 780/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1175 - accuracy: 0.9455 - val_loss: 0.1933 - val_accuracy: 0.9235\n",
      "Epoch 781/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1159 - accuracy: 0.9458 - val_loss: 0.1829 - val_accuracy: 0.9286\n",
      "Epoch 782/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1144 - accuracy: 0.9472 - val_loss: 0.1918 - val_accuracy: 0.9251\n",
      "Epoch 783/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1253 - accuracy: 0.9421 - val_loss: 0.1894 - val_accuracy: 0.9250\n",
      "Epoch 784/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1166 - accuracy: 0.9456 - val_loss: 0.1867 - val_accuracy: 0.9305\n",
      "Epoch 785/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1176 - accuracy: 0.9458 - val_loss: 0.1916 - val_accuracy: 0.9243\n",
      "Epoch 786/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1254 - accuracy: 0.9425 - val_loss: 0.1808 - val_accuracy: 0.9283\n",
      "Epoch 787/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1244 - accuracy: 0.9420 - val_loss: 0.1937 - val_accuracy: 0.9266\n",
      "Epoch 788/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1141 - accuracy: 0.9460 - val_loss: 0.1976 - val_accuracy: 0.9224\n",
      "Epoch 789/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1337 - accuracy: 0.9379 - val_loss: 0.2157 - val_accuracy: 0.9162\n",
      "Epoch 790/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.1222 - accuracy: 0.9436 - val_loss: 0.1789 - val_accuracy: 0.9284\n",
      "Epoch 791/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1213 - accuracy: 0.9439 - val_loss: 0.1837 - val_accuracy: 0.9286\n",
      "Epoch 792/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1172 - accuracy: 0.9454 - val_loss: 0.1957 - val_accuracy: 0.9239\n",
      "Epoch 793/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1199 - accuracy: 0.9435 - val_loss: 0.1851 - val_accuracy: 0.9277\n",
      "Epoch 794/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1258 - accuracy: 0.9417 - val_loss: 0.1826 - val_accuracy: 0.9266\n",
      "Epoch 795/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1172 - accuracy: 0.9446 - val_loss: 0.1802 - val_accuracy: 0.9302\n",
      "Epoch 796/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1138 - accuracy: 0.9466 - val_loss: 0.1864 - val_accuracy: 0.9281\n",
      "Epoch 797/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1274 - accuracy: 0.9409 - val_loss: 0.2009 - val_accuracy: 0.9254\n",
      "Epoch 798/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1163 - accuracy: 0.9456 - val_loss: 0.1963 - val_accuracy: 0.9260\n",
      "Epoch 799/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1119 - accuracy: 0.9474 - val_loss: 0.1941 - val_accuracy: 0.9284\n",
      "Epoch 800/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1111 - accuracy: 0.9478 - val_loss: 0.1994 - val_accuracy: 0.9213\n",
      "Epoch 801/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1219 - accuracy: 0.9433 - val_loss: 0.1951 - val_accuracy: 0.9231\n",
      "Epoch 802/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1389 - accuracy: 0.9370 - val_loss: 0.2001 - val_accuracy: 0.9232\n",
      "Epoch 803/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1190 - accuracy: 0.9447 - val_loss: 0.1912 - val_accuracy: 0.9274\n",
      "Epoch 804/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1175 - accuracy: 0.9446 - val_loss: 0.1860 - val_accuracy: 0.9276\n",
      "Epoch 805/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1229 - accuracy: 0.9432 - val_loss: 0.2161 - val_accuracy: 0.9179\n",
      "Epoch 806/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1240 - accuracy: 0.9420 - val_loss: 0.1864 - val_accuracy: 0.9280\n",
      "Epoch 807/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1216 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9241\n",
      "Epoch 808/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1161 - accuracy: 0.9453 - val_loss: 0.1898 - val_accuracy: 0.9285\n",
      "Epoch 809/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1299 - accuracy: 0.9404 - val_loss: 0.1903 - val_accuracy: 0.9261\n",
      "Epoch 810/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1204 - accuracy: 0.9441 - val_loss: 0.1998 - val_accuracy: 0.9230\n",
      "Epoch 811/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1319 - accuracy: 0.9385 - val_loss: 0.1848 - val_accuracy: 0.9268\n",
      "Epoch 812/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1249 - accuracy: 0.9420 - val_loss: 0.1864 - val_accuracy: 0.9272\n",
      "Epoch 813/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1236 - accuracy: 0.9424 - val_loss: 0.2085 - val_accuracy: 0.9184\n",
      "Epoch 814/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1245 - accuracy: 0.9423 - val_loss: 0.1838 - val_accuracy: 0.9290\n",
      "Epoch 815/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1119 - accuracy: 0.9474 - val_loss: 0.2150 - val_accuracy: 0.9180\n",
      "Epoch 816/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1293 - accuracy: 0.9397 - val_loss: 0.1891 - val_accuracy: 0.9290\n",
      "Epoch 817/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1186 - accuracy: 0.9449 - val_loss: 0.1825 - val_accuracy: 0.9308\n",
      "Epoch 818/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1166 - accuracy: 0.9453 - val_loss: 0.1895 - val_accuracy: 0.9256\n",
      "Epoch 819/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1295 - accuracy: 0.9406 - val_loss: 0.2204 - val_accuracy: 0.9158\n",
      "Epoch 820/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1774 - accuracy: 0.9257 - val_loss: 0.1918 - val_accuracy: 0.9253\n",
      "Epoch 821/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1211 - accuracy: 0.9435 - val_loss: 0.1893 - val_accuracy: 0.9263\n",
      "Epoch 822/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1185 - accuracy: 0.9446 - val_loss: 0.1872 - val_accuracy: 0.9247\n",
      "Epoch 823/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1135 - accuracy: 0.9470 - val_loss: 0.1883 - val_accuracy: 0.9275\n",
      "Epoch 824/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1211 - accuracy: 0.9432 - val_loss: 0.1904 - val_accuracy: 0.9255\n",
      "Epoch 825/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1181 - accuracy: 0.9450 - val_loss: 0.1848 - val_accuracy: 0.9270\n",
      "Epoch 826/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1215 - accuracy: 0.9437 - val_loss: 0.1853 - val_accuracy: 0.9276\n",
      "Epoch 827/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1173 - accuracy: 0.9455 - val_loss: 0.1983 - val_accuracy: 0.9234\n",
      "Epoch 828/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1285 - accuracy: 0.9404 - val_loss: 0.1903 - val_accuracy: 0.9256\n",
      "Epoch 829/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1233 - accuracy: 0.9424 - val_loss: 0.1810 - val_accuracy: 0.9297\n",
      "Epoch 830/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1081 - accuracy: 0.9495 - val_loss: 0.1820 - val_accuracy: 0.9261\n",
      "Epoch 831/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1138 - accuracy: 0.9463 - val_loss: 0.1898 - val_accuracy: 0.9244\n",
      "Epoch 832/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1320 - accuracy: 0.9391 - val_loss: 0.1995 - val_accuracy: 0.9259\n",
      "Epoch 833/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1191 - accuracy: 0.9441 - val_loss: 0.2117 - val_accuracy: 0.9238\n",
      "Epoch 834/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1145 - accuracy: 0.9465 - val_loss: 0.1880 - val_accuracy: 0.9289\n",
      "Epoch 835/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1241 - accuracy: 0.9424 - val_loss: 0.1855 - val_accuracy: 0.9278\n",
      "Epoch 836/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1112 - accuracy: 0.9478 - val_loss: 0.1860 - val_accuracy: 0.9291\n",
      "Epoch 837/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1182 - accuracy: 0.9449 - val_loss: 0.1857 - val_accuracy: 0.9290\n",
      "Epoch 838/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1238 - accuracy: 0.9427 - val_loss: 0.1982 - val_accuracy: 0.9252\n",
      "Epoch 839/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1265 - accuracy: 0.9408 - val_loss: 0.1914 - val_accuracy: 0.9267\n",
      "Epoch 840/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1211 - accuracy: 0.9438 - val_loss: 0.1870 - val_accuracy: 0.9285\n",
      "Epoch 841/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1234 - accuracy: 0.9422 - val_loss: 0.1984 - val_accuracy: 0.9246\n",
      "Epoch 842/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1158 - accuracy: 0.9457 - val_loss: 0.1908 - val_accuracy: 0.9272\n",
      "Epoch 843/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1109 - accuracy: 0.9483 - val_loss: 0.1834 - val_accuracy: 0.9281\n",
      "Epoch 844/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1093 - accuracy: 0.9488 - val_loss: 0.1830 - val_accuracy: 0.9301\n",
      "Epoch 845/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1190 - accuracy: 0.9453 - val_loss: 0.1909 - val_accuracy: 0.9286\n",
      "Epoch 846/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1148 - accuracy: 0.9461 - val_loss: 0.1944 - val_accuracy: 0.9286\n",
      "Epoch 847/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1178 - accuracy: 0.9452 - val_loss: 0.1862 - val_accuracy: 0.9276\n",
      "Epoch 848/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1254 - accuracy: 0.9428 - val_loss: 0.2072 - val_accuracy: 0.9214\n",
      "Epoch 849/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1190 - accuracy: 0.9453 - val_loss: 0.1924 - val_accuracy: 0.9245\n",
      "Epoch 850/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1210 - accuracy: 0.9437 - val_loss: 0.1954 - val_accuracy: 0.9256\n",
      "Epoch 851/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1155 - accuracy: 0.9460 - val_loss: 0.1866 - val_accuracy: 0.9300\n",
      "Epoch 852/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1118 - accuracy: 0.9477 - val_loss: 0.1894 - val_accuracy: 0.9274\n",
      "Epoch 853/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1250 - accuracy: 0.9416 - val_loss: 0.1912 - val_accuracy: 0.9253\n",
      "Epoch 854/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1182 - accuracy: 0.9449 - val_loss: 0.1924 - val_accuracy: 0.9268\n",
      "Epoch 855/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1216 - accuracy: 0.9439 - val_loss: 0.1969 - val_accuracy: 0.9251\n",
      "Epoch 856/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1260 - accuracy: 0.9416 - val_loss: 0.1866 - val_accuracy: 0.9253\n",
      "Epoch 857/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1113 - accuracy: 0.9473 - val_loss: 0.1965 - val_accuracy: 0.9258\n",
      "Epoch 858/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1176 - accuracy: 0.9451 - val_loss: 0.2044 - val_accuracy: 0.9210\n",
      "Epoch 859/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1247 - accuracy: 0.9418 - val_loss: 0.1868 - val_accuracy: 0.9260\n",
      "Epoch 860/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1115 - accuracy: 0.9478 - val_loss: 0.1895 - val_accuracy: 0.9263\n",
      "Epoch 861/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1137 - accuracy: 0.9467 - val_loss: 0.1968 - val_accuracy: 0.9238\n",
      "Epoch 862/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1127 - accuracy: 0.9473 - val_loss: 0.1909 - val_accuracy: 0.9268\n",
      "Epoch 863/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1124 - accuracy: 0.9472 - val_loss: 0.1878 - val_accuracy: 0.9295\n",
      "Epoch 864/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1135 - accuracy: 0.9466 - val_loss: 0.2105 - val_accuracy: 0.9242\n",
      "Epoch 865/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1071 - accuracy: 0.9499 - val_loss: 0.1914 - val_accuracy: 0.9255\n",
      "Epoch 866/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1396 - accuracy: 0.9370 - val_loss: 0.2207 - val_accuracy: 0.9157\n",
      "Epoch 867/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1230 - accuracy: 0.9426 - val_loss: 0.1949 - val_accuracy: 0.9267\n",
      "Epoch 868/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1132 - accuracy: 0.9475 - val_loss: 0.1926 - val_accuracy: 0.9286\n",
      "Epoch 869/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1263 - accuracy: 0.9414 - val_loss: 0.1989 - val_accuracy: 0.9212\n",
      "Epoch 870/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1165 - accuracy: 0.9453 - val_loss: 0.1918 - val_accuracy: 0.9251\n",
      "Epoch 871/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1278 - accuracy: 0.9396 - val_loss: 0.1853 - val_accuracy: 0.9284\n",
      "Epoch 872/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1235 - accuracy: 0.9435 - val_loss: 0.1877 - val_accuracy: 0.9300\n",
      "Epoch 873/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1110 - accuracy: 0.9478 - val_loss: 0.1809 - val_accuracy: 0.9298\n",
      "Epoch 874/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1102 - accuracy: 0.9486 - val_loss: 0.1961 - val_accuracy: 0.9234\n",
      "Epoch 875/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1135 - accuracy: 0.9471 - val_loss: 0.1852 - val_accuracy: 0.9306\n",
      "Epoch 876/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1112 - accuracy: 0.9480 - val_loss: 0.1993 - val_accuracy: 0.9274\n",
      "Epoch 877/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1161 - accuracy: 0.9463 - val_loss: 0.2088 - val_accuracy: 0.9206\n",
      "Epoch 878/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1272 - accuracy: 0.9410 - val_loss: 0.1996 - val_accuracy: 0.9256\n",
      "Epoch 879/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1177 - accuracy: 0.9448 - val_loss: 0.1889 - val_accuracy: 0.9281\n",
      "Epoch 880/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1297 - accuracy: 0.9403 - val_loss: 0.1854 - val_accuracy: 0.9290\n",
      "Epoch 881/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1128 - accuracy: 0.9478 - val_loss: 0.2059 - val_accuracy: 0.9237\n",
      "Epoch 882/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1395 - accuracy: 0.9372 - val_loss: 0.2159 - val_accuracy: 0.9186\n",
      "Epoch 883/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1176 - accuracy: 0.9455 - val_loss: 0.1860 - val_accuracy: 0.9296\n",
      "Epoch 884/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1112 - accuracy: 0.9484 - val_loss: 0.1944 - val_accuracy: 0.9224\n",
      "Epoch 885/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1206 - accuracy: 0.9439 - val_loss: 0.1897 - val_accuracy: 0.9251\n",
      "Epoch 886/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1149 - accuracy: 0.9467 - val_loss: 0.1885 - val_accuracy: 0.9270\n",
      "Epoch 887/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1093 - accuracy: 0.9489 - val_loss: 0.1904 - val_accuracy: 0.9268\n",
      "Epoch 888/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1115 - accuracy: 0.9479 - val_loss: 0.1896 - val_accuracy: 0.9288\n",
      "Epoch 889/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1063 - accuracy: 0.9493 - val_loss: 0.1953 - val_accuracy: 0.9254\n",
      "Epoch 890/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1126 - accuracy: 0.9471 - val_loss: 0.1945 - val_accuracy: 0.9277\n",
      "Epoch 891/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1123 - accuracy: 0.9476 - val_loss: 0.1972 - val_accuracy: 0.9251\n",
      "Epoch 892/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1166 - accuracy: 0.9451 - val_loss: 0.1923 - val_accuracy: 0.9243\n",
      "Epoch 893/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1112 - accuracy: 0.9481 - val_loss: 0.1939 - val_accuracy: 0.9290\n",
      "Epoch 894/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1086 - accuracy: 0.9486 - val_loss: 0.1986 - val_accuracy: 0.9268\n",
      "Epoch 895/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1212 - accuracy: 0.9440 - val_loss: 0.1916 - val_accuracy: 0.9252\n",
      "Epoch 896/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1155 - accuracy: 0.9459 - val_loss: 0.1987 - val_accuracy: 0.9261\n",
      "Epoch 897/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1113 - accuracy: 0.9477 - val_loss: 0.1949 - val_accuracy: 0.9255\n",
      "Epoch 898/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.1121 - accuracy: 0.9475 - val_loss: 0.1877 - val_accuracy: 0.9275\n",
      "Epoch 899/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.1187 - accuracy: 0.9450 - val_loss: 0.1861 - val_accuracy: 0.9282\n",
      "Epoch 900/1000\n",
      "87/87 [==============================] - 11s 120ms/step - loss: 0.1181 - accuracy: 0.9448 - val_loss: 0.1924 - val_accuracy: 0.9256\n",
      "Epoch 901/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.1093 - accuracy: 0.9487 - val_loss: 0.1965 - val_accuracy: 0.9276\n",
      "Epoch 902/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.1378 - accuracy: 0.9372 - val_loss: 0.1975 - val_accuracy: 0.9218\n",
      "Epoch 903/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 0.1120 - accuracy: 0.9471 - val_loss: 0.1842 - val_accuracy: 0.9296\n",
      "Epoch 904/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1060 - accuracy: 0.9509 - val_loss: 0.1883 - val_accuracy: 0.9257\n",
      "Epoch 905/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 0.1143 - accuracy: 0.9462 - val_loss: 0.1900 - val_accuracy: 0.9271\n",
      "Epoch 906/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1133 - accuracy: 0.9472 - val_loss: 0.1997 - val_accuracy: 0.9259\n",
      "Epoch 907/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1141 - accuracy: 0.9471 - val_loss: 0.1862 - val_accuracy: 0.9280\n",
      "Epoch 908/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1080 - accuracy: 0.9493 - val_loss: 0.2157 - val_accuracy: 0.9195\n",
      "Epoch 909/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1232 - accuracy: 0.9428 - val_loss: 0.2033 - val_accuracy: 0.9216\n",
      "Epoch 910/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1209 - accuracy: 0.9437 - val_loss: 0.1981 - val_accuracy: 0.9269\n",
      "Epoch 911/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1132 - accuracy: 0.9470 - val_loss: 0.1988 - val_accuracy: 0.9239\n",
      "Epoch 912/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1118 - accuracy: 0.9477 - val_loss: 0.1953 - val_accuracy: 0.9286\n",
      "Epoch 913/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1173 - accuracy: 0.9450 - val_loss: 0.1908 - val_accuracy: 0.9265\n",
      "Epoch 914/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1084 - accuracy: 0.9496 - val_loss: 0.1911 - val_accuracy: 0.9283\n",
      "Epoch 915/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1050 - accuracy: 0.9506 - val_loss: 0.1842 - val_accuracy: 0.9274\n",
      "Epoch 916/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1088 - accuracy: 0.9489 - val_loss: 0.2085 - val_accuracy: 0.9220\n",
      "Epoch 917/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1149 - accuracy: 0.9463 - val_loss: 0.2130 - val_accuracy: 0.9230\n",
      "Epoch 918/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1349 - accuracy: 0.9386 - val_loss: 0.2084 - val_accuracy: 0.9234\n",
      "Epoch 919/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1237 - accuracy: 0.9424 - val_loss: 0.1934 - val_accuracy: 0.9262\n",
      "Epoch 920/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1187 - accuracy: 0.9442 - val_loss: 0.1989 - val_accuracy: 0.9273\n",
      "Epoch 921/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1229 - accuracy: 0.9424 - val_loss: 0.1870 - val_accuracy: 0.9281\n",
      "Epoch 922/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1095 - accuracy: 0.9484 - val_loss: 0.1931 - val_accuracy: 0.9268\n",
      "Epoch 923/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1097 - accuracy: 0.9487 - val_loss: 0.1939 - val_accuracy: 0.9274\n",
      "Epoch 924/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1178 - accuracy: 0.9451 - val_loss: 0.1929 - val_accuracy: 0.9275\n",
      "Epoch 925/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1075 - accuracy: 0.9498 - val_loss: 0.1961 - val_accuracy: 0.9265\n",
      "Epoch 926/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1094 - accuracy: 0.9482 - val_loss: 0.2147 - val_accuracy: 0.9172\n",
      "Epoch 927/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1334 - accuracy: 0.9395 - val_loss: 0.1832 - val_accuracy: 0.9280\n",
      "Epoch 928/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1172 - accuracy: 0.9449 - val_loss: 0.2027 - val_accuracy: 0.9256\n",
      "Epoch 929/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1104 - accuracy: 0.9479 - val_loss: 0.1908 - val_accuracy: 0.9283\n",
      "Epoch 930/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1094 - accuracy: 0.9487 - val_loss: 0.2102 - val_accuracy: 0.9212\n",
      "Epoch 931/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1116 - accuracy: 0.9477 - val_loss: 0.1995 - val_accuracy: 0.9262\n",
      "Epoch 932/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1080 - accuracy: 0.9490 - val_loss: 0.1921 - val_accuracy: 0.9283\n",
      "Epoch 933/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1122 - accuracy: 0.9470 - val_loss: 0.2034 - val_accuracy: 0.9247\n",
      "Epoch 934/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1158 - accuracy: 0.9458 - val_loss: 0.1981 - val_accuracy: 0.9206\n",
      "Epoch 935/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1101 - accuracy: 0.9483 - val_loss: 0.1985 - val_accuracy: 0.9285\n",
      "Epoch 936/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1223 - accuracy: 0.9428 - val_loss: 0.2096 - val_accuracy: 0.9187\n",
      "Epoch 937/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1093 - accuracy: 0.9483 - val_loss: 0.1938 - val_accuracy: 0.9281\n",
      "Epoch 938/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1063 - accuracy: 0.9500 - val_loss: 0.1950 - val_accuracy: 0.9264\n",
      "Epoch 939/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1210 - accuracy: 0.9437 - val_loss: 0.2056 - val_accuracy: 0.9252\n",
      "Epoch 940/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1211 - accuracy: 0.9437 - val_loss: 0.1981 - val_accuracy: 0.9226\n",
      "Epoch 941/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1103 - accuracy: 0.9483 - val_loss: 0.1983 - val_accuracy: 0.9275\n",
      "Epoch 942/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1050 - accuracy: 0.9510 - val_loss: 0.1875 - val_accuracy: 0.9302\n",
      "Epoch 943/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1112 - accuracy: 0.9482 - val_loss: 0.1874 - val_accuracy: 0.9306\n",
      "Epoch 944/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1078 - accuracy: 0.9495 - val_loss: 0.1966 - val_accuracy: 0.9249\n",
      "Epoch 945/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1101 - accuracy: 0.9485 - val_loss: 0.1926 - val_accuracy: 0.9289\n",
      "Epoch 946/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1092 - accuracy: 0.9488 - val_loss: 0.2162 - val_accuracy: 0.9212\n",
      "Epoch 947/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1161 - accuracy: 0.9454 - val_loss: 0.2036 - val_accuracy: 0.9239\n",
      "Epoch 948/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1191 - accuracy: 0.9449 - val_loss: 0.1993 - val_accuracy: 0.9273\n",
      "Epoch 949/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1175 - accuracy: 0.9460 - val_loss: 0.2045 - val_accuracy: 0.9233\n",
      "Epoch 950/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1361 - accuracy: 0.9381 - val_loss: 0.2009 - val_accuracy: 0.9191\n",
      "Epoch 951/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1168 - accuracy: 0.9460 - val_loss: 0.1964 - val_accuracy: 0.9280\n",
      "Epoch 952/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1131 - accuracy: 0.9471 - val_loss: 0.1956 - val_accuracy: 0.9280\n",
      "Epoch 953/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1016 - accuracy: 0.9521 - val_loss: 0.2068 - val_accuracy: 0.9264\n",
      "Epoch 954/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1141 - accuracy: 0.9472 - val_loss: 0.1884 - val_accuracy: 0.9292\n",
      "Epoch 955/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1198 - accuracy: 0.9443 - val_loss: 0.2011 - val_accuracy: 0.9220\n",
      "Epoch 956/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1125 - accuracy: 0.9475 - val_loss: 0.1908 - val_accuracy: 0.9270\n",
      "Epoch 957/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1153 - accuracy: 0.9468 - val_loss: 0.2074 - val_accuracy: 0.9234\n",
      "Epoch 958/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1176 - accuracy: 0.9454 - val_loss: 0.2001 - val_accuracy: 0.9224\n",
      "Epoch 959/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1232 - accuracy: 0.9431 - val_loss: 0.2538 - val_accuracy: 0.9086\n",
      "Epoch 960/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1416 - accuracy: 0.9367 - val_loss: 0.1943 - val_accuracy: 0.9274\n",
      "Epoch 961/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1213 - accuracy: 0.9443 - val_loss: 0.1967 - val_accuracy: 0.9261\n",
      "Epoch 962/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 0.1087 - accuracy: 0.9492 - val_loss: 0.1922 - val_accuracy: 0.9277\n",
      "Epoch 963/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1134 - accuracy: 0.9469 - val_loss: 0.1952 - val_accuracy: 0.9265\n",
      "Epoch 964/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1088 - accuracy: 0.9485 - val_loss: 0.1963 - val_accuracy: 0.9292\n",
      "Epoch 965/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1007 - accuracy: 0.9524 - val_loss: 0.2106 - val_accuracy: 0.9247\n",
      "Epoch 966/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.1170 - accuracy: 0.9459 - val_loss: 0.1859 - val_accuracy: 0.9290\n",
      "Epoch 967/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1135 - accuracy: 0.9474 - val_loss: 0.1895 - val_accuracy: 0.9300\n",
      "Epoch 968/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1037 - accuracy: 0.9511 - val_loss: 0.1914 - val_accuracy: 0.9289\n",
      "Epoch 969/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1063 - accuracy: 0.9504 - val_loss: 0.2007 - val_accuracy: 0.9234\n",
      "Epoch 970/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1151 - accuracy: 0.9468 - val_loss: 0.1992 - val_accuracy: 0.9264\n",
      "Epoch 971/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1126 - accuracy: 0.9470 - val_loss: 0.1934 - val_accuracy: 0.9268\n",
      "Epoch 972/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1013 - accuracy: 0.9520 - val_loss: 0.1977 - val_accuracy: 0.9257\n",
      "Epoch 973/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1228 - accuracy: 0.9436 - val_loss: 0.2059 - val_accuracy: 0.9253\n",
      "Epoch 974/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1197 - accuracy: 0.9447 - val_loss: 0.1987 - val_accuracy: 0.9258\n",
      "Epoch 975/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1172 - accuracy: 0.9460 - val_loss: 0.2058 - val_accuracy: 0.9204\n",
      "Epoch 976/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1302 - accuracy: 0.9394 - val_loss: 0.1899 - val_accuracy: 0.9268\n",
      "Epoch 977/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1232 - accuracy: 0.9422 - val_loss: 0.1949 - val_accuracy: 0.9244\n",
      "Epoch 978/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1131 - accuracy: 0.9473 - val_loss: 0.1907 - val_accuracy: 0.9296\n",
      "Epoch 979/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1140 - accuracy: 0.9470 - val_loss: 0.1983 - val_accuracy: 0.9246\n",
      "Epoch 980/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1075 - accuracy: 0.9498 - val_loss: 0.1927 - val_accuracy: 0.9286\n",
      "Epoch 981/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 0.1058 - accuracy: 0.9506 - val_loss: 0.1871 - val_accuracy: 0.9300\n",
      "Epoch 982/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 0.1014 - accuracy: 0.9527 - val_loss: 0.1881 - val_accuracy: 0.9297\n",
      "Epoch 983/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.1323 - accuracy: 0.9406 - val_loss: 0.1962 - val_accuracy: 0.9260\n",
      "Epoch 984/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1151 - accuracy: 0.9465 - val_loss: 0.2047 - val_accuracy: 0.9236\n",
      "Epoch 985/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.1104 - accuracy: 0.9479 - val_loss: 0.1970 - val_accuracy: 0.9299\n",
      "Epoch 986/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1114 - accuracy: 0.9478 - val_loss: 0.1983 - val_accuracy: 0.9284\n",
      "Epoch 987/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.1063 - accuracy: 0.9507 - val_loss: 0.1996 - val_accuracy: 0.9278\n",
      "Epoch 988/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 0.1077 - accuracy: 0.9496 - val_loss: 0.1924 - val_accuracy: 0.9290\n",
      "Epoch 989/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.1034 - accuracy: 0.9514 - val_loss: 0.1961 - val_accuracy: 0.9268\n",
      "Epoch 990/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.1137 - accuracy: 0.9468 - val_loss: 0.1980 - val_accuracy: 0.9278\n",
      "Epoch 991/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1130 - accuracy: 0.9476 - val_loss: 0.2073 - val_accuracy: 0.9217\n",
      "Epoch 992/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 0.1079 - accuracy: 0.9494 - val_loss: 0.1932 - val_accuracy: 0.9275\n",
      "Epoch 993/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.1148 - accuracy: 0.9463 - val_loss: 0.2077 - val_accuracy: 0.9265\n",
      "Epoch 994/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1513 - accuracy: 0.9330 - val_loss: 0.1964 - val_accuracy: 0.9270\n",
      "Epoch 995/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 0.1111 - accuracy: 0.9476 - val_loss: 0.1878 - val_accuracy: 0.9280\n",
      "Epoch 996/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.1013 - accuracy: 0.9521 - val_loss: 0.1940 - val_accuracy: 0.9277\n",
      "Epoch 997/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 0.1092 - accuracy: 0.9487 - val_loss: 0.1968 - val_accuracy: 0.9257\n",
      "Epoch 998/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.1057 - accuracy: 0.9506 - val_loss: 0.1906 - val_accuracy: 0.9278\n",
      "Epoch 999/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.1139 - accuracy: 0.9467 - val_loss: 0.1985 - val_accuracy: 0.9270\n",
      "Epoch 1000/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.1183 - accuracy: 0.9449 - val_loss: 0.1993 - val_accuracy: 0.9237\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.1926 - accuracy: 0.9257\n",
      "Test Loss: 0.1926\n",
      "Test Accuracy: 0.9257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 SimpleRNN 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = GRU(256, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\functional.py:639: UserWarning: Input dict contained keys ['sequence_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 17ms/step - loss: 0.1926 - accuracy: 0.9257\n",
      "Test Accuracy: 92.57\n",
      "Test Loss: 19.26\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, theta, phi, sequence):\n",
    "    loss, acc = model.evaluate({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, theta_test, phi_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_GRU_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Results saved to GRU_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_GRU'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'GRU_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to GRU_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Sample 1:\n",
      "Theta    : [0.59896491]\n",
      "Phi      : [1.88410837]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 4 0 1 4 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 1 1 3]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [1.79516042]\n",
      "Phi      : [4.58068444]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [1.05909973]\n",
      "Phi      : [2.78421501]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 2 4 4 1 1 1 3 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 4 4 1 1 3 2]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [2.8399329]\n",
      "Phi      : [3.59808415]\n",
      "Actual   : [0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 3 1]\n",
      "Predicted: [0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 0 3]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [2.71343771]\n",
      "Phi      : [5.27790046]\n",
      "Actual   : [0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4]\n",
      "Predicted: [0 0 0 4 1 1 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [0.21644573]\n",
      "Phi      : [1.07767189]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [1.37227655]\n",
      "Phi      : [1.83102386]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 3 2 2 4 2 4 4 1 1 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 3 2 2 4 2 4 1 1 1 1]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [0.97932464]\n",
      "Phi      : [1.7698798]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 4 1 1 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [2.76156581]\n",
      "Phi      : [3.01000244]\n",
      "Actual   : [0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 1 4 0]\n",
      "Predicted: [0 0 0 2 2 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 3 3 2 2 4 1 1 3 3 2]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [2.59447535]\n",
      "Phi      : [1.37262216]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
