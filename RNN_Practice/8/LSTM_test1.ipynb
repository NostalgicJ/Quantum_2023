{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('NVspinData_None_-1_230807.csv')\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(seq) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 5s 25ms/step - loss: 1.0743 - accuracy: 0.5595 - val_loss: 0.8739 - val_accuracy: 0.5989\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.8533 - accuracy: 0.6047 - val_loss: 0.8498 - val_accuracy: 0.6029\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.8360 - accuracy: 0.6071 - val_loss: 0.8453 - val_accuracy: 0.6016\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.8203 - accuracy: 0.6096 - val_loss: 0.8188 - val_accuracy: 0.6051\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.8029 - accuracy: 0.6141 - val_loss: 0.8179 - val_accuracy: 0.6110\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.7889 - accuracy: 0.6223 - val_loss: 0.7996 - val_accuracy: 0.6234\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.7759 - accuracy: 0.6320 - val_loss: 0.7790 - val_accuracy: 0.6412\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.7515 - accuracy: 0.6530 - val_loss: 0.7342 - val_accuracy: 0.6679\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.6967 - accuracy: 0.6978 - val_loss: 0.6638 - val_accuracy: 0.7252\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.5802 - accuracy: 0.7862 - val_loss: 0.4966 - val_accuracy: 0.8302\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.4859 - accuracy: 0.8265 - val_loss: 0.4905 - val_accuracy: 0.8157\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.4129 - accuracy: 0.8481 - val_loss: 0.3645 - val_accuracy: 0.8697\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.3839 - accuracy: 0.8574 - val_loss: 0.3808 - val_accuracy: 0.8601\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 0.3771 - accuracy: 0.8614 - val_loss: 0.3581 - val_accuracy: 0.8678\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.3450 - accuracy: 0.8728 - val_loss: 0.3295 - val_accuracy: 0.8806\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.3290 - accuracy: 0.8804 - val_loss: 0.3224 - val_accuracy: 0.8810\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.3227 - accuracy: 0.8809 - val_loss: 0.3034 - val_accuracy: 0.8897\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.3108 - accuracy: 0.8858 - val_loss: 0.3006 - val_accuracy: 0.8907\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.3028 - accuracy: 0.8888 - val_loss: 0.3027 - val_accuracy: 0.8902\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.2955 - accuracy: 0.8917 - val_loss: 0.2896 - val_accuracy: 0.8932\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2886 - accuracy: 0.8949 - val_loss: 0.2862 - val_accuracy: 0.8967\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.2807 - accuracy: 0.8982 - val_loss: 0.2770 - val_accuracy: 0.8979\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.2851 - accuracy: 0.8960 - val_loss: 0.2729 - val_accuracy: 0.9005\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2774 - accuracy: 0.8984 - val_loss: 0.2649 - val_accuracy: 0.9056\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2737 - accuracy: 0.9005 - val_loss: 0.2643 - val_accuracy: 0.9047\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2695 - accuracy: 0.9020 - val_loss: 0.2597 - val_accuracy: 0.9042\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2647 - accuracy: 0.9037 - val_loss: 0.2575 - val_accuracy: 0.9063\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2646 - accuracy: 0.9032 - val_loss: 0.2535 - val_accuracy: 0.9075\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2641 - accuracy: 0.9022 - val_loss: 0.2624 - val_accuracy: 0.9019\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2605 - accuracy: 0.9048 - val_loss: 0.2530 - val_accuracy: 0.9061\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2608 - accuracy: 0.9037 - val_loss: 0.2564 - val_accuracy: 0.9050\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2610 - accuracy: 0.9029 - val_loss: 0.2834 - val_accuracy: 0.8877\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2574 - accuracy: 0.9042 - val_loss: 0.2383 - val_accuracy: 0.9133\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2535 - accuracy: 0.9070 - val_loss: 0.2689 - val_accuracy: 0.8995\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2482 - accuracy: 0.9090 - val_loss: 0.2690 - val_accuracy: 0.8950\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2471 - accuracy: 0.9098 - val_loss: 0.2362 - val_accuracy: 0.9109\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.2610 - accuracy: 0.9032 - val_loss: 0.2336 - val_accuracy: 0.9147\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2395 - accuracy: 0.9124 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2467 - accuracy: 0.9078 - val_loss: 0.2417 - val_accuracy: 0.9086\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.2471 - accuracy: 0.9085 - val_loss: 0.2321 - val_accuracy: 0.9156\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.2546 - accuracy: 0.9054 - val_loss: 0.2661 - val_accuracy: 0.8972\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.2521 - accuracy: 0.9056 - val_loss: 0.2530 - val_accuracy: 0.9081\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.2366 - accuracy: 0.9135 - val_loss: 0.2382 - val_accuracy: 0.9104\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 0.2434 - accuracy: 0.9101 - val_loss: 0.2253 - val_accuracy: 0.9177\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 0.2399 - accuracy: 0.9119 - val_loss: 0.2509 - val_accuracy: 0.9027\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 0.2351 - accuracy: 0.9132 - val_loss: 0.2281 - val_accuracy: 0.9154\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.2382 - accuracy: 0.9119 - val_loss: 0.2336 - val_accuracy: 0.9094\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.2399 - accuracy: 0.9106 - val_loss: 0.2573 - val_accuracy: 0.9078\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 5s 36ms/step - loss: 0.2393 - accuracy: 0.9111 - val_loss: 0.2353 - val_accuracy: 0.9096\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 4s 34ms/step - loss: 0.2376 - accuracy: 0.9118 - val_loss: 0.2410 - val_accuracy: 0.9028\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2429 - accuracy: 0.9024\n",
      "Test Loss: 0.2429\n",
      "Test Accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 LSTM 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "\n",
    "lstm_layer = LSTM(64, return_sequences=True, name='lstm_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=50, batch_size=64)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 814ms/step\n",
      "Results saved to LSTM_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'samle_test_LSTM'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'LSTM_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to LSTM_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from lstm_tuning\\LSTM_model_tuning\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_model(hp):\n",
    "    theta_input = Input(shape=(1,), name='theta_input')\n",
    "    phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "    merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "    repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "    \n",
    "    lstm_layer = LSTM(hp.Int('lstm_units', min_value=32, max_value=256, step=32),\n",
    "                      return_sequences=True, name='lstm_layer')(repeated_vector)\n",
    "    \n",
    "    output = TimeDistributed(Dense(hp.Int('dense_units', min_value=5, max_value=50, step=5),\n",
    "                                   activation='softmax'), name='output_layer')(lstm_layer)\n",
    "\n",
    "    model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "    \n",
    "    # 컴파일 설정\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='lstm_tuning',\n",
    "    project_name='LSTM_model_tuning'\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색\n",
    "tuner.search([theta_train, phi_train], np.expand_dims(sequence_train, -1),\n",
    "             validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)),\n",
    "             epochs=50,\n",
    "             batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the LSTM layer is 256.\n",
      "The optimal learning rate for the optimizer is 0.0014291178080356028.\n",
      "The optimal optimizer is adam.\n",
      "The optimal number of units in the Dense layer is 15.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 최상의 하이퍼파라미터 출력\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the LSTM layer is {best_hps.get('lstm_units')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "The optimal optimizer is {best_hps.get('optimizer')}.\n",
    "The optimal number of units in the Dense layer is {best_hps.get('dense_units')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with hyperparameters: {'lstm_units': 256, 'dense_units': 15, 'optimizer': 'adam', 'learning_rate': 0.0014291178080356028}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 21s 127ms/step - loss: 1.0174 - accuracy: 0.5843 - val_loss: 0.8951 - val_accuracy: 0.5916\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 15s 120ms/step - loss: 0.8475 - accuracy: 0.6049 - val_loss: 0.8442 - val_accuracy: 0.5993\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 0.8226 - accuracy: 0.6083 - val_loss: 0.8170 - val_accuracy: 0.6065\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 15s 120ms/step - loss: 0.8064 - accuracy: 0.6114 - val_loss: 0.8015 - val_accuracy: 0.6119\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 14s 116ms/step - loss: 0.7874 - accuracy: 0.6217 - val_loss: 0.7810 - val_accuracy: 0.6253\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.6659 - accuracy: 0.7128 - val_loss: 0.4906 - val_accuracy: 0.8048\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 14s 117ms/step - loss: 0.3776 - accuracy: 0.8575 - val_loss: 0.3455 - val_accuracy: 0.8598\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.3310 - accuracy: 0.8732 - val_loss: 0.3262 - val_accuracy: 0.8633\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.3025 - accuracy: 0.8846 - val_loss: 0.3187 - val_accuracy: 0.8774\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 18s 142ms/step - loss: 0.2914 - accuracy: 0.8903 - val_loss: 0.2727 - val_accuracy: 0.8953\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 20s 158ms/step - loss: 0.2874 - accuracy: 0.8907 - val_loss: 0.2608 - val_accuracy: 0.9028\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.2751 - accuracy: 0.8971 - val_loss: 0.2689 - val_accuracy: 0.8983\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 0.2755 - accuracy: 0.8967 - val_loss: 0.2680 - val_accuracy: 0.8944\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2583 - accuracy: 0.9040 - val_loss: 0.2538 - val_accuracy: 0.9039\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 0.2559 - accuracy: 0.9038 - val_loss: 0.3031 - val_accuracy: 0.8763\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 0.2725 - accuracy: 0.8962 - val_loss: 0.2928 - val_accuracy: 0.8797\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 14s 114ms/step - loss: 0.2469 - accuracy: 0.9078 - val_loss: 0.2567 - val_accuracy: 0.9027\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 0.2543 - accuracy: 0.9032 - val_loss: 0.2493 - val_accuracy: 0.9070\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 0.2532 - accuracy: 0.9053 - val_loss: 0.2685 - val_accuracy: 0.8952\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.2558 - accuracy: 0.9029 - val_loss: 0.2382 - val_accuracy: 0.9113\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 0.2555 - accuracy: 0.9025 - val_loss: 0.2237 - val_accuracy: 0.9163\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 0.2468 - accuracy: 0.9063 - val_loss: 0.2550 - val_accuracy: 0.9033\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.2375 - accuracy: 0.9091 - val_loss: 0.2348 - val_accuracy: 0.9103\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 0.2369 - accuracy: 0.9089 - val_loss: 0.2830 - val_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 15s 125ms/step - loss: 0.2415 - accuracy: 0.9086 - val_loss: 0.2178 - val_accuracy: 0.9161\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.2346 - accuracy: 0.9105 - val_loss: 0.2181 - val_accuracy: 0.9184\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 0.2443 - accuracy: 0.9064 - val_loss: 0.2289 - val_accuracy: 0.9144\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 0.2345 - accuracy: 0.9109 - val_loss: 0.2918 - val_accuracy: 0.8881\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 0.2285 - accuracy: 0.9132 - val_loss: 0.2685 - val_accuracy: 0.8970\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.2426 - accuracy: 0.9072 - val_loss: 0.2394 - val_accuracy: 0.9041\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 0.2321 - accuracy: 0.9108 - val_loss: 0.2661 - val_accuracy: 0.8954\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 15s 120ms/step - loss: 0.2307 - accuracy: 0.9118 - val_loss: 0.2452 - val_accuracy: 0.9046\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 0.2199 - accuracy: 0.9152 - val_loss: 0.2200 - val_accuracy: 0.9147\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 0.2438 - accuracy: 0.9060 - val_loss: 0.2505 - val_accuracy: 0.9045\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2215 - accuracy: 0.9146 - val_loss: 0.2187 - val_accuracy: 0.9169\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 0.2242 - accuracy: 0.9133 - val_loss: 0.2109 - val_accuracy: 0.9201\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 14s 115ms/step - loss: 0.2195 - accuracy: 0.9149 - val_loss: 0.2239 - val_accuracy: 0.9137\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 0.2155 - accuracy: 0.9178 - val_loss: 0.2232 - val_accuracy: 0.9148\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 0.2199 - accuracy: 0.9148 - val_loss: 0.2288 - val_accuracy: 0.9123\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2270 - accuracy: 0.9109 - val_loss: 0.2379 - val_accuracy: 0.9075\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2213 - accuracy: 0.9139 - val_loss: 0.2094 - val_accuracy: 0.9183\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 0.2186 - accuracy: 0.9156 - val_loss: 0.2210 - val_accuracy: 0.9143\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 15s 117ms/step - loss: 0.2134 - accuracy: 0.9162 - val_loss: 0.2011 - val_accuracy: 0.9217\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 0.2203 - accuracy: 0.9152 - val_loss: 0.2224 - val_accuracy: 0.9134\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.2132 - accuracy: 0.9171 - val_loss: 0.2504 - val_accuracy: 0.8994\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.2207 - accuracy: 0.9146 - val_loss: 0.2409 - val_accuracy: 0.9120\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2174 - accuracy: 0.9161 - val_loss: 0.2112 - val_accuracy: 0.9202\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 15s 117ms/step - loss: 0.2158 - accuracy: 0.9158 - val_loss: 0.2128 - val_accuracy: 0.9163\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2146 - accuracy: 0.9172 - val_loss: 0.2049 - val_accuracy: 0.9216\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2173 - accuracy: 0.9153 - val_loss: 0.2197 - val_accuracy: 0.9149\n",
      "Running with hyperparameters: {'lstm_units': 192, 'dense_units': 35, 'optimizer': 'adam', 'learning_rate': 0.0006261461260984394}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 15s 95ms/step - loss: 1.2926 - accuracy: 0.5633 - val_loss: 0.9604 - val_accuracy: 0.5997\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.9218 - accuracy: 0.6033 - val_loss: 0.9328 - val_accuracy: 0.5880\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.8749 - accuracy: 0.6054 - val_loss: 0.8752 - val_accuracy: 0.5977\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 11s 93ms/step - loss: 0.8454 - accuracy: 0.6070 - val_loss: 0.8401 - val_accuracy: 0.6017\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.8179 - accuracy: 0.6114 - val_loss: 0.8127 - val_accuracy: 0.6117\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 11s 91ms/step - loss: 0.8044 - accuracy: 0.6177 - val_loss: 0.7923 - val_accuracy: 0.6293\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 10s 82ms/step - loss: 0.7830 - accuracy: 0.6344 - val_loss: 0.7984 - val_accuracy: 0.6295\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 10s 83ms/step - loss: 0.7704 - accuracy: 0.6482 - val_loss: 0.7719 - val_accuracy: 0.6379\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 11s 86ms/step - loss: 0.7311 - accuracy: 0.6842 - val_loss: 0.7145 - val_accuracy: 0.7075\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.6681 - accuracy: 0.7246 - val_loss: 0.6298 - val_accuracy: 0.7540\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.5798 - accuracy: 0.7892 - val_loss: 0.4475 - val_accuracy: 0.8578\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 11s 87ms/step - loss: 0.4293 - accuracy: 0.8484 - val_loss: 0.3982 - val_accuracy: 0.8587\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 11s 87ms/step - loss: 0.3728 - accuracy: 0.8645 - val_loss: 0.3662 - val_accuracy: 0.8626\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.3788 - accuracy: 0.8597 - val_loss: 0.3438 - val_accuracy: 0.8792\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 11s 86ms/step - loss: 0.3253 - accuracy: 0.8819 - val_loss: 0.3221 - val_accuracy: 0.8852\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 11s 87ms/step - loss: 0.3315 - accuracy: 0.8773 - val_loss: 0.3063 - val_accuracy: 0.8861\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 11s 87ms/step - loss: 0.3166 - accuracy: 0.8841 - val_loss: 0.2988 - val_accuracy: 0.8931\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 11s 86ms/step - loss: 0.3090 - accuracy: 0.8865 - val_loss: 0.2861 - val_accuracy: 0.8976\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 11s 85ms/step - loss: 0.2935 - accuracy: 0.8925 - val_loss: 0.3116 - val_accuracy: 0.8773\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.2996 - accuracy: 0.8880 - val_loss: 0.2783 - val_accuracy: 0.8981\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 11s 91ms/step - loss: 0.2979 - accuracy: 0.8886 - val_loss: 0.3012 - val_accuracy: 0.8904\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.2867 - accuracy: 0.8931 - val_loss: 0.2833 - val_accuracy: 0.8951\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 11s 87ms/step - loss: 0.2931 - accuracy: 0.8903 - val_loss: 0.3060 - val_accuracy: 0.8810\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2833 - accuracy: 0.8955 - val_loss: 0.2626 - val_accuracy: 0.9064\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 11s 91ms/step - loss: 0.2819 - accuracy: 0.8968 - val_loss: 0.3143 - val_accuracy: 0.8726\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 12s 93ms/step - loss: 0.2795 - accuracy: 0.8955 - val_loss: 0.2694 - val_accuracy: 0.8993\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.2656 - accuracy: 0.9013 - val_loss: 0.2647 - val_accuracy: 0.9045\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2685 - accuracy: 0.9002 - val_loss: 0.2589 - val_accuracy: 0.9057\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 12s 93ms/step - loss: 0.2740 - accuracy: 0.8975 - val_loss: 0.2970 - val_accuracy: 0.8849\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2783 - accuracy: 0.8955 - val_loss: 0.2663 - val_accuracy: 0.8992\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2643 - accuracy: 0.9021 - val_loss: 0.2812 - val_accuracy: 0.8920\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 12s 96ms/step - loss: 0.2649 - accuracy: 0.9016 - val_loss: 0.2605 - val_accuracy: 0.9041\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 12s 98ms/step - loss: 0.2620 - accuracy: 0.9017 - val_loss: 0.2489 - val_accuracy: 0.9081\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 12s 97ms/step - loss: 0.2535 - accuracy: 0.9066 - val_loss: 0.2497 - val_accuracy: 0.9050\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2655 - accuracy: 0.9005 - val_loss: 0.2658 - val_accuracy: 0.9011\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2551 - accuracy: 0.9050 - val_loss: 0.2670 - val_accuracy: 0.9016\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2578 - accuracy: 0.9032 - val_loss: 0.2502 - val_accuracy: 0.9072\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2630 - accuracy: 0.9012 - val_loss: 0.2431 - val_accuracy: 0.9081\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 12s 96ms/step - loss: 0.2521 - accuracy: 0.9060 - val_loss: 0.2336 - val_accuracy: 0.9135\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2592 - accuracy: 0.9022 - val_loss: 0.2519 - val_accuracy: 0.9008\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2388 - accuracy: 0.9105 - val_loss: 0.2479 - val_accuracy: 0.9058\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 12s 98ms/step - loss: 0.2433 - accuracy: 0.9086 - val_loss: 0.2372 - val_accuracy: 0.9122\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 13s 104ms/step - loss: 0.2400 - accuracy: 0.9114 - val_loss: 0.2331 - val_accuracy: 0.9127\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 13s 104ms/step - loss: 0.2424 - accuracy: 0.9086 - val_loss: 0.2549 - val_accuracy: 0.9040\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 12s 101ms/step - loss: 0.2457 - accuracy: 0.9065 - val_loss: 0.2589 - val_accuracy: 0.9031\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2424 - accuracy: 0.9089 - val_loss: 0.2372 - val_accuracy: 0.9112\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2448 - accuracy: 0.9078 - val_loss: 0.2377 - val_accuracy: 0.9122\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 12s 93ms/step - loss: 0.2572 - accuracy: 0.9021 - val_loss: 0.2374 - val_accuracy: 0.9126\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 11s 93ms/step - loss: 0.2387 - accuracy: 0.9096 - val_loss: 0.2234 - val_accuracy: 0.9172\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 12s 94ms/step - loss: 0.2346 - accuracy: 0.9111 - val_loss: 0.2782 - val_accuracy: 0.8953\n",
      "Running with hyperparameters: {'lstm_units': 64, 'dense_units': 35, 'optimizer': 'adam', 'learning_rate': 0.0002464202939394493}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 11s 46ms/step - loss: 2.4182 - accuracy: 0.4364 - val_loss: 1.6067 - val_accuracy: 0.4997\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 5s 36ms/step - loss: 1.3608 - accuracy: 0.5331 - val_loss: 1.1788 - val_accuracy: 0.5802\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 1.0727 - accuracy: 0.5949 - val_loss: 1.0213 - val_accuracy: 0.5949\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.9798 - accuracy: 0.5993 - val_loss: 0.9654 - val_accuracy: 0.5942\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.9445 - accuracy: 0.5989 - val_loss: 0.9392 - val_accuracy: 0.5947\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 5s 36ms/step - loss: 0.9217 - accuracy: 0.5996 - val_loss: 0.9197 - val_accuracy: 0.5944\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.9052 - accuracy: 0.6002 - val_loss: 0.9098 - val_accuracy: 0.5971\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8930 - accuracy: 0.6009 - val_loss: 0.8947 - val_accuracy: 0.5990\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 0.8821 - accuracy: 0.6027 - val_loss: 0.8852 - val_accuracy: 0.5975\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8729 - accuracy: 0.6043 - val_loss: 0.8784 - val_accuracy: 0.6003\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8651 - accuracy: 0.6046 - val_loss: 0.8709 - val_accuracy: 0.6006\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.8588 - accuracy: 0.6055 - val_loss: 0.8631 - val_accuracy: 0.6009\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 5s 41ms/step - loss: 0.8521 - accuracy: 0.6069 - val_loss: 0.8579 - val_accuracy: 0.6013\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 5s 42ms/step - loss: 0.8476 - accuracy: 0.6076 - val_loss: 0.8535 - val_accuracy: 0.6029\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 5s 42ms/step - loss: 0.8423 - accuracy: 0.6083 - val_loss: 0.8504 - val_accuracy: 0.6049\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 5s 43ms/step - loss: 0.8396 - accuracy: 0.6086 - val_loss: 0.8514 - val_accuracy: 0.6039\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.8351 - accuracy: 0.6089 - val_loss: 0.8439 - val_accuracy: 0.6056\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 5s 41ms/step - loss: 0.8316 - accuracy: 0.6094 - val_loss: 0.8441 - val_accuracy: 0.6041\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 0.8286 - accuracy: 0.6089 - val_loss: 0.8352 - val_accuracy: 0.6039\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.8249 - accuracy: 0.6086 - val_loss: 0.8313 - val_accuracy: 0.6058\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.8219 - accuracy: 0.6087 - val_loss: 0.8286 - val_accuracy: 0.6042\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8188 - accuracy: 0.6086 - val_loss: 0.8266 - val_accuracy: 0.6041\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.8167 - accuracy: 0.6088 - val_loss: 0.8236 - val_accuracy: 0.6041\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.8134 - accuracy: 0.6095 - val_loss: 0.8204 - val_accuracy: 0.6060\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8117 - accuracy: 0.6096 - val_loss: 0.8192 - val_accuracy: 0.6041\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 5s 36ms/step - loss: 0.8101 - accuracy: 0.6100 - val_loss: 0.8174 - val_accuracy: 0.6057\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.8069 - accuracy: 0.6112 - val_loss: 0.8160 - val_accuracy: 0.6085\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.8068 - accuracy: 0.6121 - val_loss: 0.8144 - val_accuracy: 0.6100\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.8039 - accuracy: 0.6129 - val_loss: 0.8130 - val_accuracy: 0.6072\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.8018 - accuracy: 0.6141 - val_loss: 0.8194 - val_accuracy: 0.6091\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.8004 - accuracy: 0.6148 - val_loss: 0.8082 - val_accuracy: 0.6096\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7988 - accuracy: 0.6152 - val_loss: 0.8062 - val_accuracy: 0.6092\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 4s 33ms/step - loss: 0.7967 - accuracy: 0.6158 - val_loss: 0.8083 - val_accuracy: 0.6145\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7954 - accuracy: 0.6164 - val_loss: 0.8058 - val_accuracy: 0.6123\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7936 - accuracy: 0.6184 - val_loss: 0.8010 - val_accuracy: 0.6154\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7928 - accuracy: 0.6183 - val_loss: 0.7992 - val_accuracy: 0.6134\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7900 - accuracy: 0.6192 - val_loss: 0.7973 - val_accuracy: 0.6146\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7878 - accuracy: 0.6192 - val_loss: 0.7965 - val_accuracy: 0.6149\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 0.7852 - accuracy: 0.6203 - val_loss: 0.7971 - val_accuracy: 0.6128\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.7828 - accuracy: 0.6219 - val_loss: 0.7943 - val_accuracy: 0.6184\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 0.7800 - accuracy: 0.6233 - val_loss: 0.7870 - val_accuracy: 0.6231\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 5s 41ms/step - loss: 0.7773 - accuracy: 0.6250 - val_loss: 0.7835 - val_accuracy: 0.6228\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.7743 - accuracy: 0.6269 - val_loss: 0.7857 - val_accuracy: 0.6249\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7728 - accuracy: 0.6287 - val_loss: 0.7780 - val_accuracy: 0.6256\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 0.7705 - accuracy: 0.6310 - val_loss: 0.7768 - val_accuracy: 0.6249\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7665 - accuracy: 0.6343 - val_loss: 0.7724 - val_accuracy: 0.6305\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7631 - accuracy: 0.6385 - val_loss: 0.7697 - val_accuracy: 0.6341\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.7617 - accuracy: 0.6402 - val_loss: 0.7650 - val_accuracy: 0.6395\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7574 - accuracy: 0.6440 - val_loss: 0.7630 - val_accuracy: 0.6386\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 4s 36ms/step - loss: 0.7520 - accuracy: 0.6489 - val_loss: 0.7614 - val_accuracy: 0.6436\n",
      "Running with hyperparameters: {'lstm_units': 32, 'dense_units': 10, 'optimizer': 'adam', 'learning_rate': 0.0025661817326560264}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 9s 31ms/step - loss: 1.0952 - accuracy: 0.5709 - val_loss: 0.8938 - val_accuracy: 0.5933\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8490 - accuracy: 0.6002 - val_loss: 0.8462 - val_accuracy: 0.5949\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.8281 - accuracy: 0.6039 - val_loss: 0.8315 - val_accuracy: 0.5949\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.8199 - accuracy: 0.6043 - val_loss: 0.8322 - val_accuracy: 0.6035\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8114 - accuracy: 0.6062 - val_loss: 0.8181 - val_accuracy: 0.6010\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.8032 - accuracy: 0.6077 - val_loss: 0.8100 - val_accuracy: 0.6001\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7952 - accuracy: 0.6125 - val_loss: 0.7929 - val_accuracy: 0.6151\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7830 - accuracy: 0.6180 - val_loss: 0.7883 - val_accuracy: 0.6142\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7782 - accuracy: 0.6217 - val_loss: 0.7759 - val_accuracy: 0.6237\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7675 - accuracy: 0.6290 - val_loss: 0.7806 - val_accuracy: 0.6201\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7619 - accuracy: 0.6326 - val_loss: 0.7680 - val_accuracy: 0.6370\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7477 - accuracy: 0.6398 - val_loss: 0.7684 - val_accuracy: 0.6322\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7401 - accuracy: 0.6447 - val_loss: 0.7304 - val_accuracy: 0.6522\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7395 - accuracy: 0.6460 - val_loss: 0.7243 - val_accuracy: 0.6552\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7193 - accuracy: 0.6616 - val_loss: 0.7310 - val_accuracy: 0.6614\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.6985 - accuracy: 0.6793 - val_loss: 0.6768 - val_accuracy: 0.6931\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.6319 - accuracy: 0.7313 - val_loss: 0.5070 - val_accuracy: 0.8148\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.4918 - accuracy: 0.8119 - val_loss: 0.4410 - val_accuracy: 0.8366\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.4832 - accuracy: 0.8120 - val_loss: 0.5152 - val_accuracy: 0.8041\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4647 - accuracy: 0.8206 - val_loss: 0.4012 - val_accuracy: 0.8523\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.4230 - accuracy: 0.8349 - val_loss: 0.3885 - val_accuracy: 0.8519\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.4226 - accuracy: 0.8367 - val_loss: 0.4580 - val_accuracy: 0.8254\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4036 - accuracy: 0.8497 - val_loss: 0.3724 - val_accuracy: 0.8614\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3513 - accuracy: 0.8737 - val_loss: 0.3601 - val_accuracy: 0.8612\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3400 - accuracy: 0.8745 - val_loss: 0.3314 - val_accuracy: 0.8771\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3186 - accuracy: 0.8845 - val_loss: 0.3249 - val_accuracy: 0.8788\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.3108 - accuracy: 0.8867 - val_loss: 0.3022 - val_accuracy: 0.8838\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3062 - accuracy: 0.8883 - val_loss: 0.3037 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2981 - accuracy: 0.8909 - val_loss: 0.2913 - val_accuracy: 0.8926\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2988 - accuracy: 0.8913 - val_loss: 0.2932 - val_accuracy: 0.8907\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2901 - accuracy: 0.8943 - val_loss: 0.3229 - val_accuracy: 0.8709\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2826 - accuracy: 0.8967 - val_loss: 0.2776 - val_accuracy: 0.9022\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2823 - accuracy: 0.8972 - val_loss: 0.2644 - val_accuracy: 0.9048\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2820 - accuracy: 0.8958 - val_loss: 0.2709 - val_accuracy: 0.9023\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2829 - accuracy: 0.8964 - val_loss: 0.2799 - val_accuracy: 0.8949\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2744 - accuracy: 0.8994 - val_loss: 0.2756 - val_accuracy: 0.8978\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2814 - accuracy: 0.8966 - val_loss: 0.2794 - val_accuracy: 0.8977\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2832 - accuracy: 0.8948 - val_loss: 0.2646 - val_accuracy: 0.9037\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2761 - accuracy: 0.8992 - val_loss: 0.2676 - val_accuracy: 0.9034\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2728 - accuracy: 0.9002 - val_loss: 0.2634 - val_accuracy: 0.9046\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2811 - accuracy: 0.8958 - val_loss: 0.2634 - val_accuracy: 0.9037\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2683 - accuracy: 0.9014 - val_loss: 0.2588 - val_accuracy: 0.9046\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2754 - accuracy: 0.8987 - val_loss: 0.2681 - val_accuracy: 0.9008\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.2647 - accuracy: 0.9035 - val_loss: 0.2496 - val_accuracy: 0.9109\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2649 - accuracy: 0.9018 - val_loss: 0.2584 - val_accuracy: 0.9059\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2615 - accuracy: 0.9053 - val_loss: 0.2582 - val_accuracy: 0.9050\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2609 - accuracy: 0.9048 - val_loss: 0.2542 - val_accuracy: 0.9085\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2615 - accuracy: 0.9055 - val_loss: 0.2619 - val_accuracy: 0.9039\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.2653 - accuracy: 0.9025 - val_loss: 0.2589 - val_accuracy: 0.9049\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2609 - accuracy: 0.9053 - val_loss: 0.2642 - val_accuracy: 0.9005\n",
      "Running with hyperparameters: {'lstm_units': 32, 'dense_units': 15, 'optimizer': 'adam', 'learning_rate': 0.009975043393739301}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 8s 29ms/step - loss: 1.0137 - accuracy: 0.5728 - val_loss: 0.8513 - val_accuracy: 0.5956\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8253 - accuracy: 0.6036 - val_loss: 0.8215 - val_accuracy: 0.6061\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.8138 - accuracy: 0.6070 - val_loss: 0.8148 - val_accuracy: 0.6023\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.8091 - accuracy: 0.6095 - val_loss: 0.8037 - val_accuracy: 0.6109\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7980 - accuracy: 0.6159 - val_loss: 0.8354 - val_accuracy: 0.6022\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7903 - accuracy: 0.6188 - val_loss: 0.8011 - val_accuracy: 0.6162\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7835 - accuracy: 0.6235 - val_loss: 0.7796 - val_accuracy: 0.6298\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7729 - accuracy: 0.6313 - val_loss: 0.7724 - val_accuracy: 0.6378\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.7108 - accuracy: 0.6906 - val_loss: 0.6388 - val_accuracy: 0.7603\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4671 - accuracy: 0.8322 - val_loss: 0.4010 - val_accuracy: 0.8671\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3959 - accuracy: 0.8618 - val_loss: 0.3861 - val_accuracy: 0.8716\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3751 - accuracy: 0.8686 - val_loss: 0.3473 - val_accuracy: 0.8882\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3599 - accuracy: 0.8728 - val_loss: 0.3698 - val_accuracy: 0.8718\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3610 - accuracy: 0.8696 - val_loss: 0.3535 - val_accuracy: 0.8676\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3302 - accuracy: 0.8807 - val_loss: 0.3424 - val_accuracy: 0.8818\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3322 - accuracy: 0.8800 - val_loss: 0.3540 - val_accuracy: 0.8707\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.3256 - accuracy: 0.8834 - val_loss: 0.3027 - val_accuracy: 0.8909\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3175 - accuracy: 0.8859 - val_loss: 0.3095 - val_accuracy: 0.8902\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.3180 - accuracy: 0.8849 - val_loss: 0.3268 - val_accuracy: 0.8758\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.3164 - accuracy: 0.8835 - val_loss: 0.2896 - val_accuracy: 0.8968\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.3027 - accuracy: 0.8905 - val_loss: 0.3017 - val_accuracy: 0.8931\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2982 - accuracy: 0.8923 - val_loss: 0.3179 - val_accuracy: 0.8927\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2990 - accuracy: 0.8911 - val_loss: 0.3035 - val_accuracy: 0.8964\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3054 - accuracy: 0.8892 - val_loss: 0.3408 - val_accuracy: 0.8712\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2879 - accuracy: 0.8949 - val_loss: 0.3013 - val_accuracy: 0.8905\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2930 - accuracy: 0.8939 - val_loss: 0.2749 - val_accuracy: 0.9011\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2838 - accuracy: 0.8964 - val_loss: 0.2716 - val_accuracy: 0.8974\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2931 - accuracy: 0.8932 - val_loss: 0.2604 - val_accuracy: 0.9067\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2808 - accuracy: 0.8981 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2783 - accuracy: 0.8977 - val_loss: 0.2566 - val_accuracy: 0.9058\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2764 - accuracy: 0.8990 - val_loss: 0.2577 - val_accuracy: 0.9067\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2895 - accuracy: 0.8944 - val_loss: 0.2712 - val_accuracy: 0.9005\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2918 - accuracy: 0.8931 - val_loss: 0.2715 - val_accuracy: 0.9020\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2837 - accuracy: 0.8967 - val_loss: 0.2868 - val_accuracy: 0.8901\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2753 - accuracy: 0.8994 - val_loss: 0.2700 - val_accuracy: 0.9005\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2754 - accuracy: 0.8989 - val_loss: 0.3326 - val_accuracy: 0.8755\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2738 - accuracy: 0.9006 - val_loss: 0.2658 - val_accuracy: 0.9012\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2687 - accuracy: 0.9012 - val_loss: 0.2978 - val_accuracy: 0.8873\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2740 - accuracy: 0.8994 - val_loss: 0.2571 - val_accuracy: 0.9043\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2630 - accuracy: 0.9040 - val_loss: 0.2473 - val_accuracy: 0.9107\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2671 - accuracy: 0.9026 - val_loss: 0.2777 - val_accuracy: 0.8939\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.2674 - accuracy: 0.9019 - val_loss: 0.2446 - val_accuracy: 0.9098\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2741 - accuracy: 0.8999 - val_loss: 0.2781 - val_accuracy: 0.8957\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2643 - accuracy: 0.9023 - val_loss: 0.2451 - val_accuracy: 0.9101\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2670 - accuracy: 0.9012 - val_loss: 0.2393 - val_accuracy: 0.9130\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2680 - accuracy: 0.9014 - val_loss: 0.2517 - val_accuracy: 0.9048\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.2610 - accuracy: 0.9043 - val_loss: 0.2512 - val_accuracy: 0.9067\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2565 - accuracy: 0.9066 - val_loss: 0.2590 - val_accuracy: 0.9040\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2660 - accuracy: 0.9017 - val_loss: 0.2619 - val_accuracy: 0.9043\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2556 - accuracy: 0.9063 - val_loss: 0.2616 - val_accuracy: 0.9040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'tuned_LSTM_models_results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 최상의 하이퍼파라미터 조합 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 각 하이퍼파라미터 조합에 대한 학습 곡선을 그릴 예정\n",
    "for idx, hp in enumerate(best_hps):\n",
    "    print(f\"Running with hyperparameters: {hp.values}\")\n",
    "    model = build_model(hp)\n",
    "    history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                        validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), \n",
    "                        epochs=50, batch_size=64)  # 고정된 배치 크기 사용\n",
    "    \n",
    "    # Plot the loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Trial {idx+1} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Trial {idx+1} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 결과를 PNG 파일로 저장\n",
    "    plt.savefig(os.path.join(results_dir, f'trial_{idx+1}_results.png'))\n",
    "    plt.close()  # 현재 그린 그래프를 닫아 새로운 그래프를 그릴 준비\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
