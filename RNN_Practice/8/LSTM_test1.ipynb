{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('NVspinData_None_-1_230807.csv')\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(seq) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 4s 22ms/step - loss: 1.0331 - accuracy: 0.5699 - val_loss: 0.8768 - val_accuracy: 0.6012\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.8563 - accuracy: 0.6065 - val_loss: 0.8485 - val_accuracy: 0.6061\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.8338 - accuracy: 0.6105 - val_loss: 0.8318 - val_accuracy: 0.6072\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8164 - accuracy: 0.6158 - val_loss: 0.8244 - val_accuracy: 0.6159\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.7972 - accuracy: 0.6254 - val_loss: 0.7958 - val_accuracy: 0.6289\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.7760 - accuracy: 0.6387 - val_loss: 0.7650 - val_accuracy: 0.6562\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.7374 - accuracy: 0.6721 - val_loss: 0.7181 - val_accuracy: 0.7010\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.6428 - accuracy: 0.7453 - val_loss: 0.6127 - val_accuracy: 0.7554\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.4980 - accuracy: 0.8209 - val_loss: 0.5604 - val_accuracy: 0.7988\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.4322 - accuracy: 0.8409 - val_loss: 0.3787 - val_accuracy: 0.8599\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3492 - accuracy: 0.8731 - val_loss: 0.3411 - val_accuracy: 0.8751\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.3280 - accuracy: 0.8800 - val_loss: 0.3301 - val_accuracy: 0.8750\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.3106 - accuracy: 0.8857 - val_loss: 0.3143 - val_accuracy: 0.8860\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3072 - accuracy: 0.8866 - val_loss: 0.3232 - val_accuracy: 0.8812\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2964 - accuracy: 0.8911 - val_loss: 0.3091 - val_accuracy: 0.8825\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.2926 - accuracy: 0.8927 - val_loss: 0.2951 - val_accuracy: 0.8875\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2826 - accuracy: 0.8962 - val_loss: 0.2918 - val_accuracy: 0.8925\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2842 - accuracy: 0.8954 - val_loss: 0.2846 - val_accuracy: 0.8923\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 0.2846 - accuracy: 0.8945 - val_loss: 0.2790 - val_accuracy: 0.8943\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2812 - accuracy: 0.8962 - val_loss: 0.2957 - val_accuracy: 0.8902\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2768 - accuracy: 0.8985 - val_loss: 0.2688 - val_accuracy: 0.9002\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 0.2746 - accuracy: 0.8995 - val_loss: 0.2916 - val_accuracy: 0.8945\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 4s 35ms/step - loss: 0.2668 - accuracy: 0.9020 - val_loss: 0.2687 - val_accuracy: 0.8994\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 0.2706 - accuracy: 0.8992 - val_loss: 0.2724 - val_accuracy: 0.9001\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2663 - accuracy: 0.9028 - val_loss: 0.2668 - val_accuracy: 0.9035\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2656 - accuracy: 0.9024 - val_loss: 0.2745 - val_accuracy: 0.8971\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 4s 28ms/step - loss: 0.2596 - accuracy: 0.9048 - val_loss: 0.2764 - val_accuracy: 0.8933\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2570 - accuracy: 0.9063 - val_loss: 0.2644 - val_accuracy: 0.9002\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2760 - accuracy: 0.9000 - val_loss: 0.2596 - val_accuracy: 0.9040\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2567 - accuracy: 0.9062 - val_loss: 0.2653 - val_accuracy: 0.8996\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2479 - accuracy: 0.9101 - val_loss: 0.2830 - val_accuracy: 0.9003\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2602 - accuracy: 0.9045 - val_loss: 0.2875 - val_accuracy: 0.8942\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2740 - accuracy: 0.8973 - val_loss: 0.2428 - val_accuracy: 0.9126\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2526 - accuracy: 0.9064 - val_loss: 0.2514 - val_accuracy: 0.9068\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2462 - accuracy: 0.9106 - val_loss: 0.2565 - val_accuracy: 0.9076\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2501 - accuracy: 0.9075 - val_loss: 0.2449 - val_accuracy: 0.9118\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2573 - accuracy: 0.9049 - val_loss: 0.2512 - val_accuracy: 0.9052\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2502 - accuracy: 0.9089 - val_loss: 0.2395 - val_accuracy: 0.9117\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2515 - accuracy: 0.9069 - val_loss: 0.2493 - val_accuracy: 0.9060\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2580 - accuracy: 0.9052 - val_loss: 0.2679 - val_accuracy: 0.9016\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2407 - accuracy: 0.9115 - val_loss: 0.2398 - val_accuracy: 0.9132\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 0.2457 - accuracy: 0.9094 - val_loss: 0.2723 - val_accuracy: 0.8992\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2416 - accuracy: 0.9118 - val_loss: 0.2590 - val_accuracy: 0.9064\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.2462 - accuracy: 0.9090 - val_loss: 0.2591 - val_accuracy: 0.9049\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.2416 - accuracy: 0.9110 - val_loss: 0.2403 - val_accuracy: 0.9094\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2374 - accuracy: 0.9123 - val_loss: 0.2887 - val_accuracy: 0.8914\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.2477 - accuracy: 0.9079 - val_loss: 0.2430 - val_accuracy: 0.9104\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2345 - accuracy: 0.9134 - val_loss: 0.2447 - val_accuracy: 0.9091\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2378 - accuracy: 0.9120 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 0.2369 - accuracy: 0.9120 - val_loss: 0.2645 - val_accuracy: 0.9030\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2408 - accuracy: 0.9122\n",
      "Test Loss: 0.2408\n",
      "Test Accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 LSTM 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "\n",
    "lstm_layer = LSTM(64, return_sequences=True, name='lstm_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=50, batch_size=64)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n",
      "Results saved to LSTM_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'samle_test_LSTM'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'LSTM_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to LSTM_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from lstm_tuning\\LSTM_model_tuning\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_model(hp):\n",
    "    theta_input = Input(shape=(1,), name='theta_input')\n",
    "    phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "    merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "    repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "    \n",
    "    lstm_layer = LSTM(hp.Int('lstm_units', min_value=32, max_value=256, step=32),\n",
    "                      return_sequences=True, name='lstm_layer')(repeated_vector)\n",
    "    \n",
    "    output = TimeDistributed(Dense(hp.Int('dense_units', min_value=5, max_value=50, step=5),\n",
    "                                   activation='softmax'), name='output_layer')(lstm_layer)\n",
    "\n",
    "    model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "    \n",
    "    # 컴파일 설정\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='lstm_tuning',\n",
    "    project_name='LSTM_model_tuning'\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색\n",
    "tuner.search([theta_train, phi_train], np.expand_dims(sequence_train, -1),\n",
    "             validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)),\n",
    "             epochs=50,\n",
    "             batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of units in the LSTM layer is 256.\n",
      "The optimal learning rate for the optimizer is 0.0014291178080356028.\n",
      "The optimal optimizer is adam.\n",
      "The optimal number of units in the Dense layer is 15.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 최상의 하이퍼파라미터 출력\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the LSTM layer is {best_hps.get('lstm_units')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "The optimal optimizer is {best_hps.get('optimizer')}.\n",
    "The optimal number of units in the Dense layer is {best_hps.get('dense_units')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with hyperparameters: {'lstm_units': 256, 'dense_units': 15, 'optimizer': 'adam', 'learning_rate': 0.0014291178080356028}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 19s 135ms/step - loss: 1.0228 - accuracy: 0.5817 - val_loss: 0.9010 - val_accuracy: 0.5917\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 17s 133ms/step - loss: 0.8573 - accuracy: 0.6019 - val_loss: 0.8400 - val_accuracy: 0.6018\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 0.8195 - accuracy: 0.6084 - val_loss: 0.8140 - val_accuracy: 0.6162\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.7971 - accuracy: 0.6178 - val_loss: 0.7891 - val_accuracy: 0.6236\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 0.7253 - accuracy: 0.6779 - val_loss: 0.6856 - val_accuracy: 0.7266\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 0.5119 - accuracy: 0.8014 - val_loss: 0.4062 - val_accuracy: 0.8415\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.3445 - accuracy: 0.8717 - val_loss: 0.3328 - val_accuracy: 0.8745\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.3349 - accuracy: 0.8728 - val_loss: 0.3134 - val_accuracy: 0.8803\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 20s 159ms/step - loss: 0.3144 - accuracy: 0.8819 - val_loss: 0.2929 - val_accuracy: 0.8920\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2936 - accuracy: 0.8889 - val_loss: 0.2698 - val_accuracy: 0.8988\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.2942 - accuracy: 0.8895 - val_loss: 0.2958 - val_accuracy: 0.8915\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 0.2801 - accuracy: 0.8957 - val_loss: 0.3448 - val_accuracy: 0.8736\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 0.2812 - accuracy: 0.8956 - val_loss: 0.3704 - val_accuracy: 0.8716\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 0.2723 - accuracy: 0.8966 - val_loss: 0.2574 - val_accuracy: 0.9038\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2585 - accuracy: 0.9031 - val_loss: 0.2608 - val_accuracy: 0.9030\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 17s 136ms/step - loss: 0.2605 - accuracy: 0.9018 - val_loss: 0.3129 - val_accuracy: 0.8798\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 16s 127ms/step - loss: 0.2534 - accuracy: 0.9044 - val_loss: 0.2842 - val_accuracy: 0.8932\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 16s 126ms/step - loss: 0.2638 - accuracy: 0.9005 - val_loss: 0.3426 - val_accuracy: 0.8779\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 16s 132ms/step - loss: 0.2508 - accuracy: 0.9056 - val_loss: 0.2704 - val_accuracy: 0.8988\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 16s 129ms/step - loss: 0.2467 - accuracy: 0.9068 - val_loss: 0.2368 - val_accuracy: 0.9112\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 0.2469 - accuracy: 0.9051 - val_loss: 0.2444 - val_accuracy: 0.9061\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 18s 141ms/step - loss: 0.2488 - accuracy: 0.9054 - val_loss: 0.2415 - val_accuracy: 0.9058\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 17s 139ms/step - loss: 0.2375 - accuracy: 0.9088 - val_loss: 0.2390 - val_accuracy: 0.9118\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 17s 138ms/step - loss: 0.2428 - accuracy: 0.9071 - val_loss: 0.2554 - val_accuracy: 0.9078\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 0.2502 - accuracy: 0.9044 - val_loss: 0.2257 - val_accuracy: 0.9150\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 17s 139ms/step - loss: 0.2323 - accuracy: 0.9111 - val_loss: 0.2313 - val_accuracy: 0.9130\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 0.2432 - accuracy: 0.9066 - val_loss: 0.2280 - val_accuracy: 0.9123\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 17s 141ms/step - loss: 0.2266 - accuracy: 0.9130 - val_loss: 0.2355 - val_accuracy: 0.9083\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 0.2419 - accuracy: 0.9083 - val_loss: 0.2298 - val_accuracy: 0.9111\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 0.2340 - accuracy: 0.9091 - val_loss: 0.2542 - val_accuracy: 0.9029\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 19s 153ms/step - loss: 0.2386 - accuracy: 0.9087 - val_loss: 0.2881 - val_accuracy: 0.8931\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 17s 135ms/step - loss: 0.2310 - accuracy: 0.9119 - val_loss: 0.2156 - val_accuracy: 0.9156\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 18s 148ms/step - loss: 0.2314 - accuracy: 0.9117 - val_loss: 0.2152 - val_accuracy: 0.9187\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 0.2223 - accuracy: 0.9145 - val_loss: 0.2234 - val_accuracy: 0.9104\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 0.2208 - accuracy: 0.9147 - val_loss: 0.2209 - val_accuracy: 0.9165\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 16s 133ms/step - loss: 0.2254 - accuracy: 0.9132 - val_loss: 0.2325 - val_accuracy: 0.9075\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.2271 - accuracy: 0.9118 - val_loss: 0.2208 - val_accuracy: 0.9151\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.2242 - accuracy: 0.9121 - val_loss: 0.2077 - val_accuracy: 0.9213\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2174 - accuracy: 0.9146 - val_loss: 0.2564 - val_accuracy: 0.8990\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 18s 148ms/step - loss: 0.2215 - accuracy: 0.9140 - val_loss: 0.2102 - val_accuracy: 0.9186\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 17s 133ms/step - loss: 0.2148 - accuracy: 0.9156 - val_loss: 0.2504 - val_accuracy: 0.9041\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.2249 - accuracy: 0.9134 - val_loss: 0.2237 - val_accuracy: 0.9107\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.2132 - accuracy: 0.9169 - val_loss: 0.2212 - val_accuracy: 0.9132\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.2183 - accuracy: 0.9140 - val_loss: 0.2009 - val_accuracy: 0.9218\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 17s 137ms/step - loss: 0.2179 - accuracy: 0.9145 - val_loss: 0.2252 - val_accuracy: 0.9098\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 0.2071 - accuracy: 0.9190 - val_loss: 0.2240 - val_accuracy: 0.9102\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 15s 124ms/step - loss: 0.2093 - accuracy: 0.9179 - val_loss: 0.2173 - val_accuracy: 0.9129\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 14s 109ms/step - loss: 0.2124 - accuracy: 0.9175 - val_loss: 0.2111 - val_accuracy: 0.9146\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 15s 119ms/step - loss: 0.2127 - accuracy: 0.9162 - val_loss: 0.2176 - val_accuracy: 0.9185\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 0.2074 - accuracy: 0.9173 - val_loss: 0.2021 - val_accuracy: 0.9202\n",
      "Running with hyperparameters: {'lstm_units': 192, 'dense_units': 35, 'optimizer': 'adam', 'learning_rate': 0.0006261461260984394}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 16s 109ms/step - loss: 1.2952 - accuracy: 0.5584 - val_loss: 1.0031 - val_accuracy: 0.5869\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 0.9265 - accuracy: 0.6022 - val_loss: 0.9050 - val_accuracy: 0.5995\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 0.8797 - accuracy: 0.6041 - val_loss: 0.8692 - val_accuracy: 0.5999\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 13s 101ms/step - loss: 0.8495 - accuracy: 0.6082 - val_loss: 0.8483 - val_accuracy: 0.6070\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 0.8313 - accuracy: 0.6108 - val_loss: 0.8280 - val_accuracy: 0.6057\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 0.8156 - accuracy: 0.6152 - val_loss: 0.8315 - val_accuracy: 0.6104\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 0.8004 - accuracy: 0.6189 - val_loss: 0.8301 - val_accuracy: 0.6106\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 13s 103ms/step - loss: 0.7849 - accuracy: 0.6275 - val_loss: 0.7832 - val_accuracy: 0.6346\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 13s 104ms/step - loss: 0.7662 - accuracy: 0.6367 - val_loss: 0.7765 - val_accuracy: 0.6371\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 0.7548 - accuracy: 0.6506 - val_loss: 0.7403 - val_accuracy: 0.6674\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 13s 104ms/step - loss: 0.6108 - accuracy: 0.7610 - val_loss: 0.5983 - val_accuracy: 0.7752\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 13s 105ms/step - loss: 0.4296 - accuracy: 0.8449 - val_loss: 0.3876 - val_accuracy: 0.8658\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 13s 106ms/step - loss: 0.3838 - accuracy: 0.8590 - val_loss: 0.3635 - val_accuracy: 0.8690\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.3445 - accuracy: 0.8763 - val_loss: 0.3795 - val_accuracy: 0.8509\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.3408 - accuracy: 0.8757 - val_loss: 0.3301 - val_accuracy: 0.8767\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.3194 - accuracy: 0.8831 - val_loss: 0.3256 - val_accuracy: 0.8868\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 11s 91ms/step - loss: 0.3178 - accuracy: 0.8836 - val_loss: 0.3164 - val_accuracy: 0.8822\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.3107 - accuracy: 0.8861 - val_loss: 0.3082 - val_accuracy: 0.8866\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2973 - accuracy: 0.8916 - val_loss: 0.2882 - val_accuracy: 0.8970\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2891 - accuracy: 0.8947 - val_loss: 0.3009 - val_accuracy: 0.8887\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2939 - accuracy: 0.8919 - val_loss: 0.2868 - val_accuracy: 0.8956\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2797 - accuracy: 0.8974 - val_loss: 0.3222 - val_accuracy: 0.8705\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2870 - accuracy: 0.8924 - val_loss: 0.3016 - val_accuracy: 0.8829\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.2718 - accuracy: 0.9000 - val_loss: 0.2837 - val_accuracy: 0.8956\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2747 - accuracy: 0.8981 - val_loss: 0.2598 - val_accuracy: 0.9036\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2585 - accuracy: 0.9055 - val_loss: 0.2929 - val_accuracy: 0.8901\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2792 - accuracy: 0.8954 - val_loss: 0.2929 - val_accuracy: 0.8911\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2614 - accuracy: 0.9034 - val_loss: 0.2766 - val_accuracy: 0.8975\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2603 - accuracy: 0.9038 - val_loss: 0.2713 - val_accuracy: 0.9023\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 11s 92ms/step - loss: 0.2625 - accuracy: 0.9027 - val_loss: 0.2640 - val_accuracy: 0.9009\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2734 - accuracy: 0.8978 - val_loss: 0.2524 - val_accuracy: 0.9068\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2528 - accuracy: 0.9062 - val_loss: 0.2532 - val_accuracy: 0.9053\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2572 - accuracy: 0.9050 - val_loss: 0.2649 - val_accuracy: 0.9049\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2471 - accuracy: 0.9096 - val_loss: 0.2528 - val_accuracy: 0.9078\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2483 - accuracy: 0.9074 - val_loss: 0.2581 - val_accuracy: 0.9064\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2499 - accuracy: 0.9078 - val_loss: 0.2539 - val_accuracy: 0.9051\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2501 - accuracy: 0.9075 - val_loss: 0.2624 - val_accuracy: 0.9047\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.2529 - accuracy: 0.9056 - val_loss: 0.2519 - val_accuracy: 0.9076\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2514 - accuracy: 0.9066 - val_loss: 0.2531 - val_accuracy: 0.9053\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 12s 95ms/step - loss: 0.2529 - accuracy: 0.9060 - val_loss: 0.2486 - val_accuracy: 0.9062\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 11s 93ms/step - loss: 0.2400 - accuracy: 0.9115 - val_loss: 0.2789 - val_accuracy: 0.9032\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2485 - accuracy: 0.9078 - val_loss: 0.2526 - val_accuracy: 0.9038\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2502 - accuracy: 0.9073 - val_loss: 0.2367 - val_accuracy: 0.9126\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.2567 - accuracy: 0.9042 - val_loss: 0.2443 - val_accuracy: 0.9090\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2510 - accuracy: 0.9070 - val_loss: 0.2418 - val_accuracy: 0.9096\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2391 - accuracy: 0.9120 - val_loss: 0.2366 - val_accuracy: 0.9116\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 11s 90ms/step - loss: 0.2412 - accuracy: 0.9105 - val_loss: 0.2530 - val_accuracy: 0.9036\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 11s 89ms/step - loss: 0.2492 - accuracy: 0.9060 - val_loss: 0.2464 - val_accuracy: 0.9070\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.2381 - accuracy: 0.9103 - val_loss: 0.2690 - val_accuracy: 0.8965\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 11s 88ms/step - loss: 0.2378 - accuracy: 0.9110 - val_loss: 0.2299 - val_accuracy: 0.9144\n",
      "Running with hyperparameters: {'lstm_units': 64, 'dense_units': 35, 'optimizer': 'adam', 'learning_rate': 0.0002464202939394493}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 5s 28ms/step - loss: 2.4241 - accuracy: 0.4451 - val_loss: 1.5902 - val_accuracy: 0.4998\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 1.2977 - accuracy: 0.5602 - val_loss: 1.1177 - val_accuracy: 0.5858\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 1.0450 - accuracy: 0.5931 - val_loss: 1.0086 - val_accuracy: 0.5923\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.9757 - accuracy: 0.5975 - val_loss: 0.9632 - val_accuracy: 0.5950\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.9429 - accuracy: 0.5982 - val_loss: 0.9388 - val_accuracy: 0.5925\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.9207 - accuracy: 0.5995 - val_loss: 0.9204 - val_accuracy: 0.5943\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.9043 - accuracy: 0.6001 - val_loss: 0.9071 - val_accuracy: 0.5969\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8914 - accuracy: 0.6011 - val_loss: 0.8974 - val_accuracy: 0.5957\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8826 - accuracy: 0.6001 - val_loss: 0.8847 - val_accuracy: 0.5949\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8727 - accuracy: 0.6012 - val_loss: 0.8770 - val_accuracy: 0.5972\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8648 - accuracy: 0.6014 - val_loss: 0.8705 - val_accuracy: 0.5983\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8592 - accuracy: 0.6017 - val_loss: 0.8637 - val_accuracy: 0.5969\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8522 - accuracy: 0.6022 - val_loss: 0.8596 - val_accuracy: 0.5977\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8469 - accuracy: 0.6033 - val_loss: 0.8528 - val_accuracy: 0.5975\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8425 - accuracy: 0.6036 - val_loss: 0.8485 - val_accuracy: 0.5987\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8391 - accuracy: 0.6040 - val_loss: 0.8440 - val_accuracy: 0.6038\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8351 - accuracy: 0.6046 - val_loss: 0.8435 - val_accuracy: 0.6052\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8307 - accuracy: 0.6061 - val_loss: 0.8364 - val_accuracy: 0.6043\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8265 - accuracy: 0.6084 - val_loss: 0.8351 - val_accuracy: 0.6041\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.8233 - accuracy: 0.6097 - val_loss: 0.8373 - val_accuracy: 0.6055\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8203 - accuracy: 0.6101 - val_loss: 0.8260 - val_accuracy: 0.6074\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8168 - accuracy: 0.6106 - val_loss: 0.8239 - val_accuracy: 0.6084\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.8135 - accuracy: 0.6119 - val_loss: 0.8247 - val_accuracy: 0.6086\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8118 - accuracy: 0.6104 - val_loss: 0.8204 - val_accuracy: 0.6081\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.8082 - accuracy: 0.6115 - val_loss: 0.8179 - val_accuracy: 0.6091\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8061 - accuracy: 0.6117 - val_loss: 0.8127 - val_accuracy: 0.6122\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8035 - accuracy: 0.6125 - val_loss: 0.8109 - val_accuracy: 0.6083\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8015 - accuracy: 0.6125 - val_loss: 0.8087 - val_accuracy: 0.6093\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7992 - accuracy: 0.6136 - val_loss: 0.8137 - val_accuracy: 0.6114\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7984 - accuracy: 0.6136 - val_loss: 0.8083 - val_accuracy: 0.6113\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7956 - accuracy: 0.6156 - val_loss: 0.8041 - val_accuracy: 0.6146\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7925 - accuracy: 0.6180 - val_loss: 0.8011 - val_accuracy: 0.6162\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7913 - accuracy: 0.6190 - val_loss: 0.8008 - val_accuracy: 0.6186\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7894 - accuracy: 0.6188 - val_loss: 0.8006 - val_accuracy: 0.6113\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7871 - accuracy: 0.6201 - val_loss: 0.7940 - val_accuracy: 0.6160\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7848 - accuracy: 0.6199 - val_loss: 0.7925 - val_accuracy: 0.6180\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7829 - accuracy: 0.6210 - val_loss: 0.7899 - val_accuracy: 0.6209\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7798 - accuracy: 0.6221 - val_loss: 0.7930 - val_accuracy: 0.6120\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7783 - accuracy: 0.6225 - val_loss: 0.7886 - val_accuracy: 0.6194\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7775 - accuracy: 0.6233 - val_loss: 0.7840 - val_accuracy: 0.6198\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.7752 - accuracy: 0.6224 - val_loss: 0.7821 - val_accuracy: 0.6173\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7734 - accuracy: 0.6226 - val_loss: 0.7800 - val_accuracy: 0.6205\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7706 - accuracy: 0.6240 - val_loss: 0.7792 - val_accuracy: 0.6233\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7693 - accuracy: 0.6245 - val_loss: 0.7764 - val_accuracy: 0.6183\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7668 - accuracy: 0.6240 - val_loss: 0.7756 - val_accuracy: 0.6200\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.7656 - accuracy: 0.6255 - val_loss: 0.7760 - val_accuracy: 0.6224\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.7644 - accuracy: 0.6258 - val_loss: 0.7708 - val_accuracy: 0.6203\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.7624 - accuracy: 0.6260 - val_loss: 0.7709 - val_accuracy: 0.6181\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.7597 - accuracy: 0.6265 - val_loss: 0.7681 - val_accuracy: 0.6213\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.7592 - accuracy: 0.6269 - val_loss: 0.7663 - val_accuracy: 0.6219\n",
      "Running with hyperparameters: {'lstm_units': 32, 'dense_units': 10, 'optimizer': 'adam', 'learning_rate': 0.0025661817326560264}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 5s 29ms/step - loss: 1.1414 - accuracy: 0.5631 - val_loss: 0.8740 - val_accuracy: 0.5980\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8495 - accuracy: 0.6027 - val_loss: 0.8552 - val_accuracy: 0.5971\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.8316 - accuracy: 0.6038 - val_loss: 0.8327 - val_accuracy: 0.5996\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8181 - accuracy: 0.6037 - val_loss: 0.8209 - val_accuracy: 0.6041\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8030 - accuracy: 0.6108 - val_loss: 0.8062 - val_accuracy: 0.6112\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7868 - accuracy: 0.6182 - val_loss: 0.7905 - val_accuracy: 0.6192\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7759 - accuracy: 0.6272 - val_loss: 0.7809 - val_accuracy: 0.6267\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7559 - accuracy: 0.6428 - val_loss: 0.7610 - val_accuracy: 0.6257\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7190 - accuracy: 0.6731 - val_loss: 0.7075 - val_accuracy: 0.6924\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.6479 - accuracy: 0.7249 - val_loss: 0.6496 - val_accuracy: 0.7282\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.5560 - accuracy: 0.7886 - val_loss: 0.5012 - val_accuracy: 0.8179\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.4681 - accuracy: 0.8255 - val_loss: 0.4354 - val_accuracy: 0.8369\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.4146 - accuracy: 0.8464 - val_loss: 0.4176 - val_accuracy: 0.8406\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3836 - accuracy: 0.8570 - val_loss: 0.3645 - val_accuracy: 0.8660\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3685 - accuracy: 0.8606 - val_loss: 0.3579 - val_accuracy: 0.8693\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3618 - accuracy: 0.8614 - val_loss: 0.3302 - val_accuracy: 0.8773\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3257 - accuracy: 0.8801 - val_loss: 0.3421 - val_accuracy: 0.8728\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3243 - accuracy: 0.8801 - val_loss: 0.3068 - val_accuracy: 0.8902\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3264 - accuracy: 0.8768 - val_loss: 0.3205 - val_accuracy: 0.8775\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3168 - accuracy: 0.8814 - val_loss: 0.3140 - val_accuracy: 0.8826\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3199 - accuracy: 0.8786 - val_loss: 0.3085 - val_accuracy: 0.8894\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2969 - accuracy: 0.8907 - val_loss: 0.2962 - val_accuracy: 0.8894\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.2996 - accuracy: 0.8884 - val_loss: 0.3094 - val_accuracy: 0.8827\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.3007 - accuracy: 0.8869 - val_loss: 0.3020 - val_accuracy: 0.8855\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2963 - accuracy: 0.8909 - val_loss: 0.3111 - val_accuracy: 0.8821\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2961 - accuracy: 0.8902 - val_loss: 0.2893 - val_accuracy: 0.8913\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2940 - accuracy: 0.8904 - val_loss: 0.3142 - val_accuracy: 0.8836\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2916 - accuracy: 0.8926 - val_loss: 0.2941 - val_accuracy: 0.8855\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2848 - accuracy: 0.8935 - val_loss: 0.2988 - val_accuracy: 0.8865\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2901 - accuracy: 0.8921 - val_loss: 0.2863 - val_accuracy: 0.8925\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2856 - accuracy: 0.8939 - val_loss: 0.2792 - val_accuracy: 0.8988\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2861 - accuracy: 0.8937 - val_loss: 0.2733 - val_accuracy: 0.8994\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2828 - accuracy: 0.8965 - val_loss: 0.2892 - val_accuracy: 0.8937\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.2723 - accuracy: 0.9002 - val_loss: 0.2691 - val_accuracy: 0.9018\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2810 - accuracy: 0.8960 - val_loss: 0.2702 - val_accuracy: 0.8997\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.2781 - accuracy: 0.8969 - val_loss: 0.2912 - val_accuracy: 0.8929\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2744 - accuracy: 0.8992 - val_loss: 0.3299 - val_accuracy: 0.8778\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2761 - accuracy: 0.8962 - val_loss: 0.2625 - val_accuracy: 0.9021\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2599 - accuracy: 0.9049 - val_loss: 0.2732 - val_accuracy: 0.8965\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2666 - accuracy: 0.9019 - val_loss: 0.3176 - val_accuracy: 0.8778\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2708 - accuracy: 0.8983 - val_loss: 0.2628 - val_accuracy: 0.9014\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2634 - accuracy: 0.9017 - val_loss: 0.2797 - val_accuracy: 0.8959\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2637 - accuracy: 0.9029 - val_loss: 0.2764 - val_accuracy: 0.8922\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2699 - accuracy: 0.8990 - val_loss: 0.2808 - val_accuracy: 0.8972\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2623 - accuracy: 0.9030 - val_loss: 0.2993 - val_accuracy: 0.8810\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2598 - accuracy: 0.9039 - val_loss: 0.2751 - val_accuracy: 0.9030\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2657 - accuracy: 0.9015 - val_loss: 0.2659 - val_accuracy: 0.9023\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2613 - accuracy: 0.9031 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2576 - accuracy: 0.9052 - val_loss: 0.2621 - val_accuracy: 0.8994\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2730 - accuracy: 0.8984 - val_loss: 0.2704 - val_accuracy: 0.8940\n",
      "Running with hyperparameters: {'lstm_units': 32, 'dense_units': 15, 'optimizer': 'adam', 'learning_rate': 0.009975043393739301}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 6s 26ms/step - loss: 1.1020 - accuracy: 0.5569 - val_loss: 0.8543 - val_accuracy: 0.5909\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8308 - accuracy: 0.5995 - val_loss: 0.8243 - val_accuracy: 0.6032\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.8194 - accuracy: 0.6049 - val_loss: 0.8108 - val_accuracy: 0.6141\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7955 - accuracy: 0.6129 - val_loss: 0.8697 - val_accuracy: 0.6023\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.7921 - accuracy: 0.6188 - val_loss: 0.7807 - val_accuracy: 0.6384\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7114 - accuracy: 0.6930 - val_loss: 0.6060 - val_accuracy: 0.7445\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.4817 - accuracy: 0.8182 - val_loss: 0.3956 - val_accuracy: 0.8564\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.3719 - accuracy: 0.8653 - val_loss: 0.3576 - val_accuracy: 0.8685\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.3552 - accuracy: 0.8680 - val_loss: 0.3355 - val_accuracy: 0.8800\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.3345 - accuracy: 0.8749 - val_loss: 0.3178 - val_accuracy: 0.8808\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3424 - accuracy: 0.8729 - val_loss: 0.3411 - val_accuracy: 0.8696\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3232 - accuracy: 0.8781 - val_loss: 0.3090 - val_accuracy: 0.8851\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3123 - accuracy: 0.8824 - val_loss: 0.2945 - val_accuracy: 0.8894\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2984 - accuracy: 0.8887 - val_loss: 0.3125 - val_accuracy: 0.8841\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.3101 - accuracy: 0.8848 - val_loss: 0.2834 - val_accuracy: 0.8940\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3005 - accuracy: 0.8876 - val_loss: 0.2963 - val_accuracy: 0.8866\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2793 - accuracy: 0.8956 - val_loss: 0.2997 - val_accuracy: 0.8863\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2865 - accuracy: 0.8915 - val_loss: 0.3254 - val_accuracy: 0.8819\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2920 - accuracy: 0.8913 - val_loss: 0.2858 - val_accuracy: 0.8951\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2671 - accuracy: 0.9004 - val_loss: 0.2751 - val_accuracy: 0.8946\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2796 - accuracy: 0.8957 - val_loss: 0.2837 - val_accuracy: 0.8929\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2798 - accuracy: 0.8955 - val_loss: 0.2663 - val_accuracy: 0.8995\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2702 - accuracy: 0.8996 - val_loss: 0.2826 - val_accuracy: 0.8978\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2657 - accuracy: 0.9019 - val_loss: 0.2663 - val_accuracy: 0.9025\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2703 - accuracy: 0.8991 - val_loss: 0.3256 - val_accuracy: 0.8810\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.2591 - accuracy: 0.9040 - val_loss: 0.2558 - val_accuracy: 0.9045\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2552 - accuracy: 0.9062 - val_loss: 0.2582 - val_accuracy: 0.9047\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2558 - accuracy: 0.9058 - val_loss: 0.2482 - val_accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2562 - accuracy: 0.9047 - val_loss: 0.2456 - val_accuracy: 0.9076\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2591 - accuracy: 0.9048 - val_loss: 0.2742 - val_accuracy: 0.8954\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2538 - accuracy: 0.9058 - val_loss: 0.2827 - val_accuracy: 0.8941\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2650 - accuracy: 0.9012 - val_loss: 0.2475 - val_accuracy: 0.9101\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2435 - accuracy: 0.9100 - val_loss: 0.2422 - val_accuracy: 0.9095\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2549 - accuracy: 0.9053 - val_loss: 0.2456 - val_accuracy: 0.9068\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2683 - accuracy: 0.9005 - val_loss: 0.2406 - val_accuracy: 0.9112\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2494 - accuracy: 0.9071 - val_loss: 0.2470 - val_accuracy: 0.9087\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2497 - accuracy: 0.9076 - val_loss: 0.2681 - val_accuracy: 0.8984\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2521 - accuracy: 0.9072 - val_loss: 0.2490 - val_accuracy: 0.9057\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2504 - accuracy: 0.9065 - val_loss: 0.2619 - val_accuracy: 0.9036\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2515 - accuracy: 0.9070 - val_loss: 0.2734 - val_accuracy: 0.8957\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2389 - accuracy: 0.9118 - val_loss: 0.2583 - val_accuracy: 0.9023\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2589 - accuracy: 0.9036 - val_loss: 0.2440 - val_accuracy: 0.9083\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2442 - accuracy: 0.9091 - val_loss: 0.2410 - val_accuracy: 0.9078\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2466 - accuracy: 0.9086 - val_loss: 0.2432 - val_accuracy: 0.9081\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.2380 - accuracy: 0.9111 - val_loss: 0.2538 - val_accuracy: 0.9005\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2444 - accuracy: 0.9084 - val_loss: 0.2523 - val_accuracy: 0.9062\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2562 - accuracy: 0.9038 - val_loss: 0.2588 - val_accuracy: 0.8998\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2451 - accuracy: 0.9087 - val_loss: 0.2681 - val_accuracy: 0.8978\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2408 - accuracy: 0.9102 - val_loss: 0.2781 - val_accuracy: 0.8952\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2393 - accuracy: 0.9110 - val_loss: 0.2808 - val_accuracy: 0.9049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'tuned_LSTM_models_results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 최상의 하이퍼파라미터 조합 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 각 하이퍼파라미터 조합에 대한 학습 곡선을 그릴 예정\n",
    "for idx, hp in enumerate(best_hps):\n",
    "    # Hyperparameters from the trial\n",
    "    optimizer = hp['optimizer']\n",
    "    learning_rate = hp['learning_rate']\n",
    "    lstm_units = hp['lstm_units']\n",
    "\n",
    "    print(f\"Running with hyperparameters: {hp.values}\")\n",
    "    model = build_model(hp)\n",
    "    history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                        validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), \n",
    "                        epochs=50, batch_size=64)  # 고정된 배치 크기 사용\n",
    "    \n",
    "    # Plot the loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Trial {idx+1} - Loss (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {lstm_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Trial {idx+1} - Accuracy (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {lstm_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 결과를 PNG 파일로 저장\n",
    "    plt.savefig(os.path.join(results_dir, f'trial_{idx+1}_results.png'))\n",
    "    plt.close()  # 현재 그린 그래프를 닫아 새로운 그래프를 그릴 준비\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
