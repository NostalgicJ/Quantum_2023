{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('NVspinData_None_-1_230807.csv')\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(seq) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 2s 8ms/step - loss: 1.1030 - accuracy: 0.5363 - val_loss: 0.8990 - val_accuracy: 0.5972\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8587 - accuracy: 0.5977 - val_loss: 0.8696 - val_accuracy: 0.5998\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8411 - accuracy: 0.5989 - val_loss: 0.8264 - val_accuracy: 0.6061\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8280 - accuracy: 0.6016 - val_loss: 0.8129 - val_accuracy: 0.6100\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8216 - accuracy: 0.6044 - val_loss: 0.8112 - val_accuracy: 0.6094\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8145 - accuracy: 0.6084 - val_loss: 0.7991 - val_accuracy: 0.6169\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7945 - accuracy: 0.6316 - val_loss: 0.7322 - val_accuracy: 0.6908\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.5559 - accuracy: 0.7919 - val_loss: 0.4520 - val_accuracy: 0.8423\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.8548 - val_loss: 0.3989 - val_accuracy: 0.8670\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8640 - val_loss: 0.3911 - val_accuracy: 0.8661\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3807 - accuracy: 0.8716 - val_loss: 0.3737 - val_accuracy: 0.8702\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.8718 - val_loss: 0.3576 - val_accuracy: 0.8837\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.3695 - accuracy: 0.8748 - val_loss: 0.3500 - val_accuracy: 0.8820\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3576 - accuracy: 0.8790 - val_loss: 0.3374 - val_accuracy: 0.8896\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.3449 - accuracy: 0.8849 - val_loss: 0.3512 - val_accuracy: 0.8776\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3395 - accuracy: 0.8868 - val_loss: 0.3327 - val_accuracy: 0.8887\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3364 - accuracy: 0.8864 - val_loss: 0.3319 - val_accuracy: 0.8861\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3295 - accuracy: 0.8878 - val_loss: 0.3268 - val_accuracy: 0.8914\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.3337 - accuracy: 0.8851 - val_loss: 0.3077 - val_accuracy: 0.8961\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3201 - accuracy: 0.8909 - val_loss: 0.3390 - val_accuracy: 0.8850\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3121 - accuracy: 0.8919 - val_loss: 0.3012 - val_accuracy: 0.8952\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3088 - accuracy: 0.8926 - val_loss: 0.2884 - val_accuracy: 0.9001\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2998 - accuracy: 0.8955 - val_loss: 0.2976 - val_accuracy: 0.8954\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3004 - accuracy: 0.8949 - val_loss: 0.2991 - val_accuracy: 0.8930\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2941 - accuracy: 0.8958 - val_loss: 0.2809 - val_accuracy: 0.8987\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2929 - accuracy: 0.8946 - val_loss: 0.2688 - val_accuracy: 0.9048\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2901 - accuracy: 0.8955 - val_loss: 0.2731 - val_accuracy: 0.9034\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2849 - accuracy: 0.8968 - val_loss: 0.2767 - val_accuracy: 0.8984\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2821 - accuracy: 0.8972 - val_loss: 0.2831 - val_accuracy: 0.8962\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2784 - accuracy: 0.8984 - val_loss: 0.2666 - val_accuracy: 0.9023\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2779 - accuracy: 0.8986 - val_loss: 0.2791 - val_accuracy: 0.8942\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2661 - accuracy: 0.9030 - val_loss: 0.3106 - val_accuracy: 0.8841\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2690 - accuracy: 0.9014 - val_loss: 0.2663 - val_accuracy: 0.9021\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.9016 - val_loss: 0.2581 - val_accuracy: 0.9038\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.2778 - accuracy: 0.8982 - val_loss: 0.2693 - val_accuracy: 0.8999\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2647 - accuracy: 0.9036 - val_loss: 0.2588 - val_accuracy: 0.9047\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.9027 - val_loss: 0.2450 - val_accuracy: 0.9109\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2583 - accuracy: 0.9048 - val_loss: 0.2760 - val_accuracy: 0.9003\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2575 - accuracy: 0.9058 - val_loss: 0.2609 - val_accuracy: 0.9036\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.2668 - accuracy: 0.9016 - val_loss: 0.2787 - val_accuracy: 0.8968\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.9014 - val_loss: 0.2524 - val_accuracy: 0.9061\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2550 - accuracy: 0.9055 - val_loss: 0.2498 - val_accuracy: 0.9074\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2545 - accuracy: 0.9061 - val_loss: 0.2618 - val_accuracy: 0.9036\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2572 - accuracy: 0.9056 - val_loss: 0.2373 - val_accuracy: 0.9116\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.9029 - val_loss: 0.2344 - val_accuracy: 0.9127\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2496 - accuracy: 0.9077 - val_loss: 0.2611 - val_accuracy: 0.9044\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2489 - accuracy: 0.9081 - val_loss: 0.2521 - val_accuracy: 0.9043\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2511 - accuracy: 0.9070 - val_loss: 0.2400 - val_accuracy: 0.9096\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2609 - accuracy: 0.9031 - val_loss: 0.2451 - val_accuracy: 0.9054\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2476 - accuracy: 0.9086 - val_loss: 0.2288 - val_accuracy: 0.9161\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9147\n",
      "Test Loss: 0.2323\n",
      "Test Accuracy: 0.9147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 SimpleRNN 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = SimpleRNN(64, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=50, batch_size=64)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"SimpleRNN_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 가중치만 저장\n",
    "# model.save_weights(\"model_weights.h5\")\n",
    "\n",
    "# # 구조만 저장\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_structure.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "\n",
    "# # 가중치 불러오기\n",
    "# model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "# # 구조만 불러오기\n",
    "# from tensorflow.keras.models import model_from_json\n",
    "# with open(\"model_structure.json\", \"r\") as json_file:\n",
    "#     model_json = json_file.read()\n",
    "# loaded_model = model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 201ms/step\n",
      "Results saved to simpleRNN_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'samle_test_simpleRNN'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'simpleRNN_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to simpleRNN_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from rnn_tuning\\SimpleRNN_model_tuning\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of units in the SimpleRNN layer is 96.\n",
      "The optimal learning rate for the optimizer is 0.0030088511849749758.\n",
      "The optimal optimizer is rmsprop.\n",
      "The optimal number of units in the Dense layer is 5.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeojung\\AppData\\Local\\Temp\\ipykernel_25676\\225860558.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_model(hp):\n",
    "    theta_input = Input(shape=(1,), name='theta_input')\n",
    "    phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "    merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "    repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "    \n",
    "    rnn_layer = SimpleRNN(hp.Int('rnn_units', min_value=16, max_value=128, step=16),\n",
    "                          return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "    \n",
    "    output = TimeDistributed(Dense(hp.Int('dense_units', min_value=5, max_value=50, step=5),\n",
    "                                   activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "    model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "    \n",
    "    # 컴파일 설정\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='rnn_tuning',\n",
    "    project_name='SimpleRNN_model_tuning'\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색\n",
    "tuner.search([theta_train, phi_train], np.expand_dims(sequence_train, -1),\n",
    "             validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)),\n",
    "             epochs=50,\n",
    "             batch_size=64)\n",
    "\n",
    "# 최상의 하이퍼파라미터 출력\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the SimpleRNN layer is {best_hps.get('rnn_units')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "The optimal optimizer is {best_hps.get('optimizer')}.\n",
    "The optimal number of units in the Dense layer is {best_hps.get('dense_units')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with hyperparameters: {'rnn_units': 96, 'dense_units': 5, 'optimizer': 'rmsprop', 'learning_rate': 0.0030088511849749758}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 2s 9ms/step - loss: 1.1508 - accuracy: 0.5397 - val_loss: 0.9059 - val_accuracy: 0.6139\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8645 - accuracy: 0.6535 - val_loss: 0.9011 - val_accuracy: 0.6217\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.6559 - accuracy: 0.7379 - val_loss: 0.6307 - val_accuracy: 0.7524\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.5661 - accuracy: 0.7779 - val_loss: 0.4765 - val_accuracy: 0.8206\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.7937 - val_loss: 0.4608 - val_accuracy: 0.8210\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.4849 - accuracy: 0.8038 - val_loss: 0.5990 - val_accuracy: 0.7384\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.4633 - accuracy: 0.8123 - val_loss: 0.4882 - val_accuracy: 0.8057\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.4362 - accuracy: 0.8247 - val_loss: 0.4326 - val_accuracy: 0.8306\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8306 - val_loss: 0.5306 - val_accuracy: 0.7803\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.4058 - accuracy: 0.8376 - val_loss: 0.3750 - val_accuracy: 0.8592\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3925 - accuracy: 0.8447 - val_loss: 0.4723 - val_accuracy: 0.8057\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3823 - accuracy: 0.8487 - val_loss: 0.4100 - val_accuracy: 0.8423\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8530 - val_loss: 0.3797 - val_accuracy: 0.8449\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.3667 - accuracy: 0.8546 - val_loss: 0.3442 - val_accuracy: 0.8647\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3597 - accuracy: 0.8586 - val_loss: 0.3465 - val_accuracy: 0.8628\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3465 - accuracy: 0.8643 - val_loss: 0.3277 - val_accuracy: 0.8733\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3502 - accuracy: 0.8631 - val_loss: 0.3750 - val_accuracy: 0.8535\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.3403 - accuracy: 0.8668 - val_loss: 0.4039 - val_accuracy: 0.8382\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.3388 - accuracy: 0.8682 - val_loss: 0.3944 - val_accuracy: 0.8513\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3336 - accuracy: 0.8695 - val_loss: 0.3548 - val_accuracy: 0.8622\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.3282 - accuracy: 0.8743 - val_loss: 0.3771 - val_accuracy: 0.8660\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.3248 - accuracy: 0.8732 - val_loss: 0.3935 - val_accuracy: 0.8496\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.3200 - accuracy: 0.8747 - val_loss: 0.4427 - val_accuracy: 0.8350\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.3155 - accuracy: 0.8775 - val_loss: 0.4299 - val_accuracy: 0.8392\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.3061 - accuracy: 0.8819 - val_loss: 0.3270 - val_accuracy: 0.8761\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.3115 - accuracy: 0.8788 - val_loss: 0.3369 - val_accuracy: 0.8746\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3032 - accuracy: 0.8823 - val_loss: 0.3614 - val_accuracy: 0.8661\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3041 - accuracy: 0.8832 - val_loss: 0.4331 - val_accuracy: 0.8500\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3030 - accuracy: 0.8835 - val_loss: 0.3315 - val_accuracy: 0.8751\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2991 - accuracy: 0.8836 - val_loss: 0.2732 - val_accuracy: 0.8986\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2952 - accuracy: 0.8860 - val_loss: 0.2779 - val_accuracy: 0.8934\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.2962 - accuracy: 0.8860 - val_loss: 0.3600 - val_accuracy: 0.8558\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2922 - accuracy: 0.8867 - val_loss: 0.2979 - val_accuracy: 0.8905\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.2915 - accuracy: 0.8881 - val_loss: 0.3023 - val_accuracy: 0.8820\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.2856 - accuracy: 0.8902 - val_loss: 0.3902 - val_accuracy: 0.8527\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2805 - accuracy: 0.8919 - val_loss: 0.4061 - val_accuracy: 0.8420\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.2838 - accuracy: 0.8914 - val_loss: 0.3830 - val_accuracy: 0.8556\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2847 - accuracy: 0.8906 - val_loss: 0.2936 - val_accuracy: 0.8933\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.2889 - accuracy: 0.8910 - val_loss: 0.4082 - val_accuracy: 0.8397\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2835 - accuracy: 0.8929 - val_loss: 0.2875 - val_accuracy: 0.8962\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2878 - accuracy: 0.8919 - val_loss: 0.2580 - val_accuracy: 0.9070\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2782 - accuracy: 0.8950 - val_loss: 0.2593 - val_accuracy: 0.9017\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2950 - accuracy: 0.8935 - val_loss: 0.2738 - val_accuracy: 0.8973\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.2758 - accuracy: 0.8941 - val_loss: 0.3154 - val_accuracy: 0.8777\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2775 - accuracy: 0.8937 - val_loss: 0.2820 - val_accuracy: 0.8919\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.2727 - accuracy: 0.8959 - val_loss: 0.3082 - val_accuracy: 0.8862\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.2757 - accuracy: 0.8938 - val_loss: 0.3426 - val_accuracy: 0.8787\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2737 - accuracy: 0.8937 - val_loss: 0.3104 - val_accuracy: 0.8816\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2670 - accuracy: 0.8984 - val_loss: 0.3729 - val_accuracy: 0.8678\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.2766 - accuracy: 0.8939 - val_loss: 0.3208 - val_accuracy: 0.8778\n",
      "Running with hyperparameters: {'rnn_units': 64, 'dense_units': 40, 'optimizer': 'adam', 'learning_rate': 0.008901042597893304}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 4s 18ms/step - loss: 1.1533 - accuracy: 0.5448 - val_loss: 1.1525 - val_accuracy: 0.5197\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.9097 - accuracy: 0.5875 - val_loss: 0.8594 - val_accuracy: 0.5943\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8715 - accuracy: 0.5933 - val_loss: 0.8245 - val_accuracy: 0.6043\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8196 - accuracy: 0.6015 - val_loss: 0.8007 - val_accuracy: 0.6051\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8094 - accuracy: 0.6066 - val_loss: 0.8287 - val_accuracy: 0.6053\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8128 - accuracy: 0.6088 - val_loss: 0.7906 - val_accuracy: 0.6260\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7966 - accuracy: 0.6179 - val_loss: 0.7980 - val_accuracy: 0.6209\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7859 - accuracy: 0.6236 - val_loss: 0.7779 - val_accuracy: 0.6323\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7716 - accuracy: 0.6403 - val_loss: 0.7795 - val_accuracy: 0.6532\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 20ms/step - loss: 0.8078 - accuracy: 0.6408 - val_loss: 0.8318 - val_accuracy: 0.6034\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.7810 - accuracy: 0.6259 - val_loss: 0.7554 - val_accuracy: 0.6448\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.7879 - accuracy: 0.6285 - val_loss: 0.8076 - val_accuracy: 0.6192\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.7799 - accuracy: 0.6358 - val_loss: 0.8127 - val_accuracy: 0.6102\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.7900 - accuracy: 0.6253 - val_loss: 0.7541 - val_accuracy: 0.6488\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 1.0304 - accuracy: 0.5758 - val_loss: 1.0546 - val_accuracy: 0.5630\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.9479 - accuracy: 0.5804 - val_loss: 0.8163 - val_accuracy: 0.6142\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.8101 - accuracy: 0.6451 - val_loss: 0.8219 - val_accuracy: 0.6066\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.7962 - accuracy: 0.6128 - val_loss: 0.7781 - val_accuracy: 0.6192\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7771 - accuracy: 0.6391 - val_loss: 0.7850 - val_accuracy: 0.6835\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8331 - accuracy: 0.6054 - val_loss: 0.8057 - val_accuracy: 0.6094\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7969 - accuracy: 0.6095 - val_loss: 0.7839 - val_accuracy: 0.6160\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7795 - accuracy: 0.6183 - val_loss: 0.7619 - val_accuracy: 0.6240\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.6274 - val_loss: 0.7614 - val_accuracy: 0.6275\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7490 - accuracy: 0.6370 - val_loss: 0.7821 - val_accuracy: 0.6401\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.7499 - accuracy: 0.6650 - val_loss: 0.6385 - val_accuracy: 0.7646\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 20ms/step - loss: 0.7730 - accuracy: 0.7008 - val_loss: 0.8883 - val_accuracy: 0.5955\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8197 - accuracy: 0.6062 - val_loss: 0.7872 - val_accuracy: 0.6143\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7640 - accuracy: 0.6402 - val_loss: 0.7354 - val_accuracy: 0.6621\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8965 - accuracy: 0.6186 - val_loss: 1.0418 - val_accuracy: 0.5600\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.9602 - accuracy: 0.5826 - val_loss: 0.8744 - val_accuracy: 0.5965\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8257 - accuracy: 0.6016 - val_loss: 0.8075 - val_accuracy: 0.6035\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8037 - accuracy: 0.6078 - val_loss: 0.7978 - val_accuracy: 0.6082\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7921 - accuracy: 0.6124 - val_loss: 0.7810 - val_accuracy: 0.6146\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7837 - accuracy: 0.6189 - val_loss: 0.7729 - val_accuracy: 0.6273\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7741 - accuracy: 0.6265 - val_loss: 0.7825 - val_accuracy: 0.6250\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7650 - accuracy: 0.6330 - val_loss: 0.7499 - val_accuracy: 0.6454\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.7619 - accuracy: 0.6424 - val_loss: 0.8310 - val_accuracy: 0.6198\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.7575 - accuracy: 0.6456 - val_loss: 0.7302 - val_accuracy: 0.6619\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.7066 - accuracy: 0.6692 - val_loss: 0.6618 - val_accuracy: 0.6895\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.9438 - accuracy: 0.6025 - val_loss: 1.0314 - val_accuracy: 0.5850\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.9497 - accuracy: 0.5858 - val_loss: 0.8853 - val_accuracy: 0.5940\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 19ms/step - loss: 0.9690 - accuracy: 0.5809 - val_loss: 0.9158 - val_accuracy: 0.5934\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.9352 - accuracy: 0.5941 - val_loss: 0.9115 - val_accuracy: 0.6049\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.9253 - accuracy: 0.5943 - val_loss: 0.9338 - val_accuracy: 0.5892\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 21ms/step - loss: 0.9540 - accuracy: 0.5872 - val_loss: 0.9801 - val_accuracy: 0.5841\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.9910 - accuracy: 0.5769 - val_loss: 0.9107 - val_accuracy: 0.6011\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.9266 - accuracy: 0.6182 - val_loss: 0.9913 - val_accuracy: 0.5794\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 1.0344 - accuracy: 0.5817 - val_loss: 1.1723 - val_accuracy: 0.5726\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 1.0788 - accuracy: 0.5543 - val_loss: 0.9479 - val_accuracy: 0.5864\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.9436 - accuracy: 0.5863 - val_loss: 0.9462 - val_accuracy: 0.5818\n",
      "Running with hyperparameters: {'rnn_units': 48, 'dense_units': 30, 'optimizer': 'adam', 'learning_rate': 0.002608814649486346}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 15ms/step - loss: 1.2964 - accuracy: 0.5200 - val_loss: 0.9276 - val_accuracy: 0.5904\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8982 - accuracy: 0.5919 - val_loss: 0.8396 - val_accuracy: 0.5988\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8398 - accuracy: 0.5974 - val_loss: 0.8415 - val_accuracy: 0.5995\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.8281 - accuracy: 0.5999 - val_loss: 0.8176 - val_accuracy: 0.6021\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8205 - accuracy: 0.6024 - val_loss: 0.8164 - val_accuracy: 0.6015\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8138 - accuracy: 0.6034 - val_loss: 0.8158 - val_accuracy: 0.6041\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8131 - accuracy: 0.6043 - val_loss: 0.8149 - val_accuracy: 0.6017\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8127 - accuracy: 0.6043 - val_loss: 0.8327 - val_accuracy: 0.6038\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8085 - accuracy: 0.6056 - val_loss: 0.8009 - val_accuracy: 0.6094\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8057 - accuracy: 0.6072 - val_loss: 0.8044 - val_accuracy: 0.6068\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8031 - accuracy: 0.6087 - val_loss: 0.8177 - val_accuracy: 0.6100\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7984 - accuracy: 0.6107 - val_loss: 0.7911 - val_accuracy: 0.6153\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7929 - accuracy: 0.6160 - val_loss: 0.7870 - val_accuracy: 0.6204\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7909 - accuracy: 0.6188 - val_loss: 0.7852 - val_accuracy: 0.6208\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.7856 - accuracy: 0.6223 - val_loss: 0.7786 - val_accuracy: 0.6325\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7228 - accuracy: 0.6899 - val_loss: 0.6414 - val_accuracy: 0.7427\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.6085 - accuracy: 0.7651 - val_loss: 0.6124 - val_accuracy: 0.7627\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.5903 - accuracy: 0.7781 - val_loss: 0.5977 - val_accuracy: 0.7851\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.5345 - accuracy: 0.8048 - val_loss: 0.6068 - val_accuracy: 0.7828\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.4665 - accuracy: 0.8378 - val_loss: 0.4141 - val_accuracy: 0.8586\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.4384 - accuracy: 0.8482 - val_loss: 0.4162 - val_accuracy: 0.8559\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3981 - accuracy: 0.8639 - val_loss: 0.3937 - val_accuracy: 0.8664\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3940 - accuracy: 0.8653 - val_loss: 0.3981 - val_accuracy: 0.8623\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3898 - accuracy: 0.8667 - val_loss: 0.4051 - val_accuracy: 0.8599\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.3871 - accuracy: 0.8660 - val_loss: 0.3828 - val_accuracy: 0.8717\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3743 - accuracy: 0.8726 - val_loss: 0.3902 - val_accuracy: 0.8637\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.3760 - accuracy: 0.8715 - val_loss: 0.3868 - val_accuracy: 0.8686\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3613 - accuracy: 0.8778 - val_loss: 0.3849 - val_accuracy: 0.8663\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3605 - accuracy: 0.8773 - val_loss: 0.3792 - val_accuracy: 0.8711\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3658 - accuracy: 0.8754 - val_loss: 0.3597 - val_accuracy: 0.8777\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.3576 - accuracy: 0.8787 - val_loss: 0.3687 - val_accuracy: 0.8708\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3480 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.3465 - accuracy: 0.8826 - val_loss: 0.3404 - val_accuracy: 0.8883\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3476 - accuracy: 0.8828 - val_loss: 0.3524 - val_accuracy: 0.8813\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3422 - accuracy: 0.8838 - val_loss: 0.3632 - val_accuracy: 0.8740\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8856 - val_loss: 0.3657 - val_accuracy: 0.8739\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3353 - accuracy: 0.8863 - val_loss: 0.3387 - val_accuracy: 0.8894\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.3393 - accuracy: 0.8853 - val_loss: 0.3451 - val_accuracy: 0.8806\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3348 - accuracy: 0.8873 - val_loss: 0.3335 - val_accuracy: 0.8909\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3386 - accuracy: 0.8850 - val_loss: 0.3232 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3281 - accuracy: 0.8892 - val_loss: 0.3381 - val_accuracy: 0.8893\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.3292 - accuracy: 0.8887 - val_loss: 0.3434 - val_accuracy: 0.8856\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3328 - accuracy: 0.8873 - val_loss: 0.3353 - val_accuracy: 0.8910\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3302 - accuracy: 0.8884 - val_loss: 0.3596 - val_accuracy: 0.8831\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.3303 - accuracy: 0.8882 - val_loss: 0.3177 - val_accuracy: 0.8974\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.3230 - accuracy: 0.8904 - val_loss: 0.3668 - val_accuracy: 0.8812\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.3249 - accuracy: 0.8901 - val_loss: 0.3229 - val_accuracy: 0.8937\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3209 - accuracy: 0.8915 - val_loss: 0.3351 - val_accuracy: 0.8854\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8914 - val_loss: 0.3238 - val_accuracy: 0.8929\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.3147 - accuracy: 0.8940 - val_loss: 0.3341 - val_accuracy: 0.8854\n",
      "Running with hyperparameters: {'rnn_units': 48, 'dense_units': 40, 'optimizer': 'rmsprop', 'learning_rate': 0.00033235390013150126}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 16ms/step - loss: 2.0499 - accuracy: 0.4367 - val_loss: 1.4833 - val_accuracy: 0.4829\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 1.3585 - accuracy: 0.4880 - val_loss: 1.2216 - val_accuracy: 0.4963\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 1.1108 - accuracy: 0.5533 - val_loss: 0.9939 - val_accuracy: 0.5896\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.9512 - accuracy: 0.5917 - val_loss: 0.9100 - val_accuracy: 0.5950\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.9021 - accuracy: 0.5949 - val_loss: 0.9191 - val_accuracy: 0.5869\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8803 - accuracy: 0.5964 - val_loss: 0.8685 - val_accuracy: 0.5987\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8664 - accuracy: 0.5972 - val_loss: 0.8867 - val_accuracy: 0.5903\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8591 - accuracy: 0.5974 - val_loss: 0.8493 - val_accuracy: 0.6021\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8542 - accuracy: 0.5969 - val_loss: 0.8359 - val_accuracy: 0.6014\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8468 - accuracy: 0.5967 - val_loss: 0.8347 - val_accuracy: 0.6003\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8436 - accuracy: 0.5965 - val_loss: 0.8339 - val_accuracy: 0.6007\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8408 - accuracy: 0.5960 - val_loss: 0.8307 - val_accuracy: 0.5964\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8379 - accuracy: 0.5964 - val_loss: 0.8259 - val_accuracy: 0.6023\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8357 - accuracy: 0.5969 - val_loss: 0.8316 - val_accuracy: 0.6011\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8332 - accuracy: 0.5972 - val_loss: 0.8553 - val_accuracy: 0.5962\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8316 - accuracy: 0.5979 - val_loss: 0.8222 - val_accuracy: 0.5974\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8309 - accuracy: 0.5976 - val_loss: 0.8204 - val_accuracy: 0.6024\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8281 - accuracy: 0.5990 - val_loss: 0.8616 - val_accuracy: 0.5917\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8270 - accuracy: 0.5995 - val_loss: 0.8183 - val_accuracy: 0.6022\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8246 - accuracy: 0.6002 - val_loss: 0.8233 - val_accuracy: 0.6033\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8240 - accuracy: 0.6010 - val_loss: 0.8776 - val_accuracy: 0.5986\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8227 - accuracy: 0.6014 - val_loss: 0.8357 - val_accuracy: 0.6025\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.8216 - accuracy: 0.6024 - val_loss: 0.8131 - val_accuracy: 0.6042\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8195 - accuracy: 0.6033 - val_loss: 0.8256 - val_accuracy: 0.6045\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8190 - accuracy: 0.6039 - val_loss: 0.8110 - val_accuracy: 0.6054\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.8180 - accuracy: 0.6037 - val_loss: 0.8185 - val_accuracy: 0.6065\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8162 - accuracy: 0.6047 - val_loss: 0.8087 - val_accuracy: 0.6080\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8149 - accuracy: 0.6050 - val_loss: 0.8177 - val_accuracy: 0.6067\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8139 - accuracy: 0.6060 - val_loss: 0.8132 - val_accuracy: 0.6097\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8127 - accuracy: 0.6057 - val_loss: 0.8413 - val_accuracy: 0.6032\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8120 - accuracy: 0.6063 - val_loss: 0.8180 - val_accuracy: 0.6060\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8118 - accuracy: 0.6056 - val_loss: 0.8043 - val_accuracy: 0.6094\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8098 - accuracy: 0.6064 - val_loss: 0.8032 - val_accuracy: 0.6108\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8095 - accuracy: 0.6061 - val_loss: 0.8065 - val_accuracy: 0.6084\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8085 - accuracy: 0.6064 - val_loss: 0.8018 - val_accuracy: 0.6083\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8078 - accuracy: 0.6063 - val_loss: 0.8222 - val_accuracy: 0.6058\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8069 - accuracy: 0.6064 - val_loss: 0.8081 - val_accuracy: 0.6076\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8059 - accuracy: 0.6073 - val_loss: 0.7996 - val_accuracy: 0.6091\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8049 - accuracy: 0.6071 - val_loss: 0.8112 - val_accuracy: 0.6102\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8040 - accuracy: 0.6078 - val_loss: 0.7993 - val_accuracy: 0.6094\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8040 - accuracy: 0.6080 - val_loss: 0.8013 - val_accuracy: 0.6096\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8035 - accuracy: 0.6074 - val_loss: 0.7985 - val_accuracy: 0.6076\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8030 - accuracy: 0.6076 - val_loss: 0.7962 - val_accuracy: 0.6086\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8022 - accuracy: 0.6080 - val_loss: 0.7998 - val_accuracy: 0.6077\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8015 - accuracy: 0.6084 - val_loss: 0.8004 - val_accuracy: 0.6090\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8011 - accuracy: 0.6086 - val_loss: 0.8097 - val_accuracy: 0.6096\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8007 - accuracy: 0.6085 - val_loss: 0.7984 - val_accuracy: 0.6112\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8001 - accuracy: 0.6088 - val_loss: 0.7946 - val_accuracy: 0.6103\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7999 - accuracy: 0.6091 - val_loss: 0.7936 - val_accuracy: 0.6111\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7985 - accuracy: 0.6092 - val_loss: 0.8330 - val_accuracy: 0.6029\n",
      "Running with hyperparameters: {'rnn_units': 80, 'dense_units': 25, 'optimizer': 'rmsprop', 'learning_rate': 0.00010499426807036376}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 17ms/step - loss: 2.1972 - accuracy: 0.4118 - val_loss: 1.6371 - val_accuracy: 0.4863\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 1.4298 - accuracy: 0.4918 - val_loss: 1.2689 - val_accuracy: 0.5063\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 1.1606 - accuracy: 0.5498 - val_loss: 1.0512 - val_accuracy: 0.5821\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.9712 - accuracy: 0.5888 - val_loss: 0.9148 - val_accuracy: 0.5958\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8984 - accuracy: 0.5922 - val_loss: 0.8912 - val_accuracy: 0.5916\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8738 - accuracy: 0.5929 - val_loss: 0.8747 - val_accuracy: 0.5952\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8605 - accuracy: 0.5926 - val_loss: 0.8614 - val_accuracy: 0.5941\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8518 - accuracy: 0.5922 - val_loss: 0.8612 - val_accuracy: 0.5947\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8457 - accuracy: 0.5930 - val_loss: 0.8372 - val_accuracy: 0.5949\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8419 - accuracy: 0.5931 - val_loss: 0.8401 - val_accuracy: 0.5945\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8376 - accuracy: 0.5944 - val_loss: 0.8314 - val_accuracy: 0.5938\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8346 - accuracy: 0.5942 - val_loss: 0.8361 - val_accuracy: 0.5948\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8322 - accuracy: 0.5958 - val_loss: 0.8267 - val_accuracy: 0.5964\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8296 - accuracy: 0.5963 - val_loss: 0.8280 - val_accuracy: 0.5973\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8282 - accuracy: 0.5966 - val_loss: 0.8268 - val_accuracy: 0.5972\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8266 - accuracy: 0.5972 - val_loss: 0.8218 - val_accuracy: 0.5990\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8246 - accuracy: 0.5975 - val_loss: 0.8216 - val_accuracy: 0.5996\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8231 - accuracy: 0.5991 - val_loss: 0.8199 - val_accuracy: 0.5992\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8219 - accuracy: 0.5998 - val_loss: 0.8184 - val_accuracy: 0.6006\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8199 - accuracy: 0.6011 - val_loss: 0.8169 - val_accuracy: 0.6019\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8191 - accuracy: 0.6017 - val_loss: 0.8331 - val_accuracy: 0.5985\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8176 - accuracy: 0.6030 - val_loss: 0.8155 - val_accuracy: 0.6041\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8160 - accuracy: 0.6039 - val_loss: 0.8244 - val_accuracy: 0.6050\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8153 - accuracy: 0.6051 - val_loss: 0.8255 - val_accuracy: 0.6032\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8142 - accuracy: 0.6060 - val_loss: 0.8179 - val_accuracy: 0.6058\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.8127 - accuracy: 0.6073 - val_loss: 0.8299 - val_accuracy: 0.6069\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8115 - accuracy: 0.6083 - val_loss: 0.8089 - val_accuracy: 0.6099\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8101 - accuracy: 0.6103 - val_loss: 0.8079 - val_accuracy: 0.6117\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.8087 - accuracy: 0.6114 - val_loss: 0.8253 - val_accuracy: 0.6077\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8071 - accuracy: 0.6129 - val_loss: 0.8057 - val_accuracy: 0.6139\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.8053 - accuracy: 0.6145 - val_loss: 0.8049 - val_accuracy: 0.6154\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8033 - accuracy: 0.6162 - val_loss: 0.8019 - val_accuracy: 0.6201\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.8008 - accuracy: 0.6210 - val_loss: 0.8194 - val_accuracy: 0.6191\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7957 - accuracy: 0.6281 - val_loss: 0.7916 - val_accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.7764 - accuracy: 0.6517 - val_loss: 0.7640 - val_accuracy: 0.6563\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7472 - accuracy: 0.6726 - val_loss: 0.7312 - val_accuracy: 0.6885\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.7104 - accuracy: 0.7121 - val_loss: 0.7055 - val_accuracy: 0.7358\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.6569 - accuracy: 0.7516 - val_loss: 0.6454 - val_accuracy: 0.7522\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.6264 - accuracy: 0.7601 - val_loss: 0.6212 - val_accuracy: 0.7622\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.6084 - accuracy: 0.7646 - val_loss: 0.6061 - val_accuracy: 0.7633\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.5935 - accuracy: 0.7680 - val_loss: 0.6004 - val_accuracy: 0.7631\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.5740 - accuracy: 0.7730 - val_loss: 0.5712 - val_accuracy: 0.7741\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.5451 - accuracy: 0.7913 - val_loss: 0.5363 - val_accuracy: 0.7980\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.5106 - accuracy: 0.8158 - val_loss: 0.4970 - val_accuracy: 0.8256\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.4662 - accuracy: 0.8390 - val_loss: 0.4530 - val_accuracy: 0.8445\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.4367 - accuracy: 0.8499 - val_loss: 0.4326 - val_accuracy: 0.8515\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.4200 - accuracy: 0.8566 - val_loss: 0.4159 - val_accuracy: 0.8616\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.4124 - accuracy: 0.8603 - val_loss: 0.4122 - val_accuracy: 0.8595\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.4050 - accuracy: 0.8637 - val_loss: 0.4094 - val_accuracy: 0.8640\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.4014 - accuracy: 0.8649 - val_loss: 0.4025 - val_accuracy: 0.8666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'tuned_simpleRNN_models_results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 최상의 하이퍼파라미터 조합 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 각 하이퍼파라미터 조합에 대한 학습 곡선을 그릴 예정\n",
    "for idx, hp in enumerate(best_hps):\n",
    "    # Hyperparameters from the trial\n",
    "    optimizer = hp['optimizer']\n",
    "    learning_rate = hp['learning_rate']\n",
    "    rnn_units = hp['rnn_units']\n",
    "\n",
    "    print(f\"Running with hyperparameters: {hp.values}\")\n",
    "    model = build_model(hp)\n",
    "    history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                        validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), \n",
    "                        epochs=50, batch_size=64)  # 고정된 배치 크기 사용\n",
    "    \n",
    "    # Plot the loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Trial {idx+1} - Loss (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {rnn_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Trial {idx+1} - Accuracy (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {rnn_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 결과를 PNG 파일로 저장\n",
    "    plt.savefig(os.path.join(results_dir, f'trial_{idx+1}_results.png'))\n",
    "    plt.close()  # 현재 그린 그래프를 닫아 새로운 그래프를 그릴 준비"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
