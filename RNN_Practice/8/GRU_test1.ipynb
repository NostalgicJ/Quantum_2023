{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('NVspinData_None_-1_230807.csv')\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(seq) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 15ms/step - loss: 1.1552 - accuracy: 0.5319 - val_loss: 0.8755 - val_accuracy: 0.6027\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8502 - accuracy: 0.6010 - val_loss: 0.8386 - val_accuracy: 0.6055\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8312 - accuracy: 0.6033 - val_loss: 0.8282 - val_accuracy: 0.6066\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.8214 - accuracy: 0.6062 - val_loss: 0.8155 - val_accuracy: 0.6081\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8134 - accuracy: 0.6086 - val_loss: 0.8034 - val_accuracy: 0.6098\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8044 - accuracy: 0.6165 - val_loss: 0.7960 - val_accuracy: 0.6248\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.8006 - accuracy: 0.6201 - val_loss: 0.7930 - val_accuracy: 0.6252\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7897 - accuracy: 0.6286 - val_loss: 0.7820 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.7820 - accuracy: 0.6316 - val_loss: 0.7816 - val_accuracy: 0.6283\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.7722 - accuracy: 0.6331 - val_loss: 0.7568 - val_accuracy: 0.6410\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7545 - accuracy: 0.6430 - val_loss: 0.7362 - val_accuracy: 0.6546\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.7237 - accuracy: 0.6651 - val_loss: 0.7173 - val_accuracy: 0.6631\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.6909 - accuracy: 0.6881 - val_loss: 0.6550 - val_accuracy: 0.7114\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.6356 - accuracy: 0.7256 - val_loss: 0.6060 - val_accuracy: 0.7382\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.5242 - accuracy: 0.7948 - val_loss: 0.4435 - val_accuracy: 0.8368\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.4347 - accuracy: 0.8368 - val_loss: 0.4243 - val_accuracy: 0.8422\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3887 - accuracy: 0.8580 - val_loss: 0.3652 - val_accuracy: 0.8689\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3599 - accuracy: 0.8678 - val_loss: 0.3440 - val_accuracy: 0.8748\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3441 - accuracy: 0.8732 - val_loss: 0.3311 - val_accuracy: 0.8796\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3345 - accuracy: 0.8763 - val_loss: 0.3237 - val_accuracy: 0.8811\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3154 - accuracy: 0.8848 - val_loss: 0.3190 - val_accuracy: 0.8804\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3161 - accuracy: 0.8822 - val_loss: 0.3359 - val_accuracy: 0.8743\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.3018 - accuracy: 0.8878 - val_loss: 0.2973 - val_accuracy: 0.8911\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2960 - accuracy: 0.8907 - val_loss: 0.3113 - val_accuracy: 0.8838\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2909 - accuracy: 0.8925 - val_loss: 0.2968 - val_accuracy: 0.8908\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2834 - accuracy: 0.8956 - val_loss: 0.2876 - val_accuracy: 0.8951\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2816 - accuracy: 0.8958 - val_loss: 0.2736 - val_accuracy: 0.9017\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2775 - accuracy: 0.8971 - val_loss: 0.2752 - val_accuracy: 0.8987\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2781 - accuracy: 0.8972 - val_loss: 0.2894 - val_accuracy: 0.8899\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.2728 - accuracy: 0.8989 - val_loss: 0.2840 - val_accuracy: 0.8950\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2709 - accuracy: 0.8995 - val_loss: 0.2829 - val_accuracy: 0.8931\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2654 - accuracy: 0.9018 - val_loss: 0.2701 - val_accuracy: 0.8987\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2643 - accuracy: 0.9021 - val_loss: 0.2932 - val_accuracy: 0.8890\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2666 - accuracy: 0.9006 - val_loss: 0.2692 - val_accuracy: 0.8995\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2627 - accuracy: 0.9026 - val_loss: 0.2714 - val_accuracy: 0.8975\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2601 - accuracy: 0.9026 - val_loss: 0.2557 - val_accuracy: 0.9057\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2545 - accuracy: 0.9055 - val_loss: 0.2587 - val_accuracy: 0.9046\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2552 - accuracy: 0.9051 - val_loss: 0.2582 - val_accuracy: 0.9023\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2598 - accuracy: 0.9022 - val_loss: 0.2727 - val_accuracy: 0.8951\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2530 - accuracy: 0.9054 - val_loss: 0.2560 - val_accuracy: 0.9040\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2465 - accuracy: 0.9079 - val_loss: 0.2469 - val_accuracy: 0.9084\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2517 - accuracy: 0.9054 - val_loss: 0.2578 - val_accuracy: 0.9029\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2501 - accuracy: 0.9068 - val_loss: 0.2699 - val_accuracy: 0.9017\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2553 - accuracy: 0.9034 - val_loss: 0.2467 - val_accuracy: 0.9061\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2437 - accuracy: 0.9083 - val_loss: 0.2481 - val_accuracy: 0.9091\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2461 - accuracy: 0.9072 - val_loss: 0.2666 - val_accuracy: 0.8994\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2442 - accuracy: 0.9082 - val_loss: 0.2491 - val_accuracy: 0.9059\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2409 - accuracy: 0.9098 - val_loss: 0.2502 - val_accuracy: 0.9063\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.2357 - accuracy: 0.9113 - val_loss: 0.2351 - val_accuracy: 0.9137\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2363 - accuracy: 0.9110 - val_loss: 0.2478 - val_accuracy: 0.9070\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.9120\n",
      "Test Loss: 0.2426\n",
      "Test Accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 GRU 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "\n",
    "gru_layer = GRU(64, return_sequences=True, name='gru_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(gru_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=50, batch_size=64)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"GRU_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"GRU_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 310ms/step\n",
      "Results saved to GRU_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'samle_test_GRU'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'GRU_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to GRU_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from gru_tuning\\GRU_model_tuning\\tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_model(hp):\n",
    "    theta_input = Input(shape=(1,), name='theta_input')\n",
    "    phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "    merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "    repeated_vector = RepeatVector(max_seq_length)(merged)\n",
    "    \n",
    "    gru_layer = GRU(hp.Int('gru_units', min_value=32, max_value=256, step=32),\n",
    "                      return_sequences=True, name='gru_layer')(repeated_vector)\n",
    "    \n",
    "    output = TimeDistributed(Dense(hp.Int('dense_units', min_value=5, max_value=50, step=5),\n",
    "                                   activation='softmax'), name='output_layer')(gru_layer)\n",
    "\n",
    "    model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "    \n",
    "    # 컴파일 설정\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='gru_tuning',\n",
    "    project_name='GRU_model_tuning'\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색\n",
    "tuner.search([theta_train, phi_train], np.expand_dims(sequence_train, -1),\n",
    "             validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)),\n",
    "             epochs=50,\n",
    "             batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of units in the GRU layer is 160.\n",
      "The optimal learning rate for the optimizer is 0.0017224708407553916.\n",
      "The optimal optimizer is adam.\n",
      "The optimal number of units in the Dense layer is 40.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 최상의 하이퍼파라미터 출력\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the GRU layer is {best_hps.get('gru_units')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "The optimal optimizer is {best_hps.get('optimizer')}.\n",
    "The optimal number of units in the Dense layer is {best_hps.get('dense_units')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with hyperparameters: {'gru_units': 160, 'dense_units': 40, 'optimizer': 'adam', 'learning_rate': 0.0017224708407553916}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 12s 85ms/step - loss: 1.0947 - accuracy: 0.5736 - val_loss: 0.8598 - val_accuracy: 0.6007\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 14s 114ms/step - loss: 0.8476 - accuracy: 0.6000 - val_loss: 0.8191 - val_accuracy: 0.6071\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 15s 122ms/step - loss: 0.8277 - accuracy: 0.6023 - val_loss: 0.8086 - val_accuracy: 0.6093\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 21s 167ms/step - loss: 0.8226 - accuracy: 0.6039 - val_loss: 0.8070 - val_accuracy: 0.6118\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 21s 168ms/step - loss: 0.8074 - accuracy: 0.6082 - val_loss: 0.7907 - val_accuracy: 0.6170\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 21s 168ms/step - loss: 0.8011 - accuracy: 0.6119 - val_loss: 0.8091 - val_accuracy: 0.6145\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 21s 168ms/step - loss: 0.7898 - accuracy: 0.6191 - val_loss: 0.7776 - val_accuracy: 0.6262\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 22s 180ms/step - loss: 0.7812 - accuracy: 0.6299 - val_loss: 0.7639 - val_accuracy: 0.6441\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 26s 206ms/step - loss: 0.7350 - accuracy: 0.6811 - val_loss: 0.6220 - val_accuracy: 0.7691\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 0.5170 - accuracy: 0.8084 - val_loss: 0.4006 - val_accuracy: 0.8555\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 25s 201ms/step - loss: 0.3754 - accuracy: 0.8595 - val_loss: 0.3921 - val_accuracy: 0.8577\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 28s 229ms/step - loss: 0.3395 - accuracy: 0.8724 - val_loss: 0.3944 - val_accuracy: 0.8475\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 23s 188ms/step - loss: 0.3256 - accuracy: 0.8783 - val_loss: 0.3891 - val_accuracy: 0.8555\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 23s 187ms/step - loss: 0.3254 - accuracy: 0.8778 - val_loss: 0.3285 - val_accuracy: 0.8736\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 25s 198ms/step - loss: 0.3095 - accuracy: 0.8818 - val_loss: 0.3041 - val_accuracy: 0.8857\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 22s 180ms/step - loss: 0.2864 - accuracy: 0.8931 - val_loss: 0.3093 - val_accuracy: 0.8801\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 25s 205ms/step - loss: 0.2913 - accuracy: 0.8902 - val_loss: 0.3103 - val_accuracy: 0.8811\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 25s 201ms/step - loss: 0.2811 - accuracy: 0.8934 - val_loss: 0.2774 - val_accuracy: 0.8964\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 28s 225ms/step - loss: 0.2692 - accuracy: 0.8987 - val_loss: 0.2806 - val_accuracy: 0.8926\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 29s 233ms/step - loss: 0.2760 - accuracy: 0.8955 - val_loss: 0.3108 - val_accuracy: 0.8792\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 29s 233ms/step - loss: 0.2870 - accuracy: 0.8909 - val_loss: 0.2812 - val_accuracy: 0.8921\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 30s 245ms/step - loss: 0.2657 - accuracy: 0.9006 - val_loss: 0.3146 - val_accuracy: 0.8818\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 29s 233ms/step - loss: 0.2673 - accuracy: 0.8987 - val_loss: 0.3252 - val_accuracy: 0.8824\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 32s 260ms/step - loss: 0.2572 - accuracy: 0.9029 - val_loss: 0.2599 - val_accuracy: 0.9001\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 37s 298ms/step - loss: 0.2637 - accuracy: 0.9007 - val_loss: 0.2975 - val_accuracy: 0.8918\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.2653 - accuracy: 0.9004 - val_loss: 0.2507 - val_accuracy: 0.9065\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 31s 251ms/step - loss: 0.2463 - accuracy: 0.9087 - val_loss: 0.2990 - val_accuracy: 0.8908\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 37s 293ms/step - loss: 0.2605 - accuracy: 0.9018 - val_loss: 0.2992 - val_accuracy: 0.8867\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 33s 268ms/step - loss: 0.2574 - accuracy: 0.9030 - val_loss: 0.2639 - val_accuracy: 0.9031\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 37s 299ms/step - loss: 0.2568 - accuracy: 0.9033 - val_loss: 0.2643 - val_accuracy: 0.8986\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 28s 226ms/step - loss: 0.2401 - accuracy: 0.9097 - val_loss: 0.2561 - val_accuracy: 0.9047\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 32s 255ms/step - loss: 0.2392 - accuracy: 0.9095 - val_loss: 0.2638 - val_accuracy: 0.9064\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 28s 229ms/step - loss: 0.2352 - accuracy: 0.9121 - val_loss: 0.2425 - val_accuracy: 0.9107\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.2504 - accuracy: 0.9068 - val_loss: 0.2619 - val_accuracy: 0.8994\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 40s 320ms/step - loss: 0.2420 - accuracy: 0.9106 - val_loss: 0.2603 - val_accuracy: 0.8999\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 25s 200ms/step - loss: 0.2397 - accuracy: 0.9101 - val_loss: 0.3547 - val_accuracy: 0.8829\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 28s 230ms/step - loss: 0.2409 - accuracy: 0.9099 - val_loss: 0.2494 - val_accuracy: 0.9060\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 30s 243ms/step - loss: 0.2481 - accuracy: 0.9072 - val_loss: 0.2306 - val_accuracy: 0.9139\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 27s 216ms/step - loss: 0.2414 - accuracy: 0.9102 - val_loss: 0.2493 - val_accuracy: 0.9081\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 28s 230ms/step - loss: 0.2465 - accuracy: 0.9075 - val_loss: 0.2497 - val_accuracy: 0.9085\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 26s 214ms/step - loss: 0.2318 - accuracy: 0.9131 - val_loss: 0.2387 - val_accuracy: 0.9099\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 29s 231ms/step - loss: 0.2388 - accuracy: 0.9095 - val_loss: 0.2865 - val_accuracy: 0.8903\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 29s 232ms/step - loss: 0.2325 - accuracy: 0.9120 - val_loss: 0.2433 - val_accuracy: 0.9105\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 27s 219ms/step - loss: 0.2346 - accuracy: 0.9120 - val_loss: 0.2386 - val_accuracy: 0.9115\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 25s 204ms/step - loss: 0.2355 - accuracy: 0.9129 - val_loss: 0.2585 - val_accuracy: 0.9036\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 25s 204ms/step - loss: 0.2304 - accuracy: 0.9132 - val_loss: 0.2409 - val_accuracy: 0.9092\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 0.2339 - accuracy: 0.9112 - val_loss: 0.2344 - val_accuracy: 0.9129\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 0.2497 - accuracy: 0.9057 - val_loss: 0.2488 - val_accuracy: 0.9054\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 25s 205ms/step - loss: 0.2250 - accuracy: 0.9158 - val_loss: 0.2391 - val_accuracy: 0.9095\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 26s 208ms/step - loss: 0.2310 - accuracy: 0.9133 - val_loss: 0.2749 - val_accuracy: 0.8955\n",
      "Running with hyperparameters: {'gru_units': 96, 'dense_units': 5, 'optimizer': 'adam', 'learning_rate': 0.00045043853818359366}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 12s 74ms/step - loss: 1.2034 - accuracy: 0.5332 - val_loss: 0.9104 - val_accuracy: 0.5966\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 9s 70ms/step - loss: 0.8765 - accuracy: 0.5976 - val_loss: 0.8538 - val_accuracy: 0.6042\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 9s 71ms/step - loss: 0.8451 - accuracy: 0.6009 - val_loss: 0.8258 - val_accuracy: 0.6071\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 9s 71ms/step - loss: 0.8310 - accuracy: 0.6002 - val_loss: 0.8282 - val_accuracy: 0.6082\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.8240 - accuracy: 0.6030 - val_loss: 0.8121 - val_accuracy: 0.6083\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 9s 73ms/step - loss: 0.8163 - accuracy: 0.6079 - val_loss: 0.8031 - val_accuracy: 0.6169\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 9s 75ms/step - loss: 0.8115 - accuracy: 0.6102 - val_loss: 0.7983 - val_accuracy: 0.6133\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.8061 - accuracy: 0.6121 - val_loss: 0.7930 - val_accuracy: 0.6152\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.8011 - accuracy: 0.6153 - val_loss: 0.7879 - val_accuracy: 0.6216\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 9s 70ms/step - loss: 0.7968 - accuracy: 0.6173 - val_loss: 0.7854 - val_accuracy: 0.6242\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7924 - accuracy: 0.6203 - val_loss: 0.7926 - val_accuracy: 0.6236\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7876 - accuracy: 0.6253 - val_loss: 0.7796 - val_accuracy: 0.6311\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7812 - accuracy: 0.6327 - val_loss: 0.7662 - val_accuracy: 0.6416\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7692 - accuracy: 0.6439 - val_loss: 0.7515 - val_accuracy: 0.6527\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7530 - accuracy: 0.6546 - val_loss: 0.7312 - val_accuracy: 0.6680\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.7263 - accuracy: 0.6724 - val_loss: 0.7001 - val_accuracy: 0.6905\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 8s 67ms/step - loss: 0.6839 - accuracy: 0.7064 - val_loss: 0.6603 - val_accuracy: 0.7341\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 8s 67ms/step - loss: 0.6357 - accuracy: 0.7493 - val_loss: 0.6336 - val_accuracy: 0.7607\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 8s 67ms/step - loss: 0.5681 - accuracy: 0.7910 - val_loss: 0.5404 - val_accuracy: 0.7910\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.5065 - accuracy: 0.8104 - val_loss: 0.5657 - val_accuracy: 0.7663\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.4607 - accuracy: 0.8296 - val_loss: 0.4371 - val_accuracy: 0.8407\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.4318 - accuracy: 0.8408 - val_loss: 0.4196 - val_accuracy: 0.8474\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 8s 67ms/step - loss: 0.4052 - accuracy: 0.8518 - val_loss: 0.3992 - val_accuracy: 0.8529\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 8s 66ms/step - loss: 0.3883 - accuracy: 0.8580 - val_loss: 0.3794 - val_accuracy: 0.8595\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 8s 67ms/step - loss: 0.3666 - accuracy: 0.8673 - val_loss: 0.3723 - val_accuracy: 0.8657\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 9s 76ms/step - loss: 0.3507 - accuracy: 0.8735 - val_loss: 0.3676 - val_accuracy: 0.8584\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 9s 71ms/step - loss: 0.3334 - accuracy: 0.8801 - val_loss: 0.3312 - val_accuracy: 0.8813\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 10s 81ms/step - loss: 0.3229 - accuracy: 0.8839 - val_loss: 0.3265 - val_accuracy: 0.8817\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.3136 - accuracy: 0.8863 - val_loss: 0.3475 - val_accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.3104 - accuracy: 0.8861 - val_loss: 0.3055 - val_accuracy: 0.8884\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 9s 76ms/step - loss: 0.2972 - accuracy: 0.8919 - val_loss: 0.2985 - val_accuracy: 0.8917\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 9s 74ms/step - loss: 0.2949 - accuracy: 0.8925 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.2874 - accuracy: 0.8945 - val_loss: 0.2928 - val_accuracy: 0.8929\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 9s 76ms/step - loss: 0.2832 - accuracy: 0.8956 - val_loss: 0.2951 - val_accuracy: 0.8915\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 9s 73ms/step - loss: 0.2781 - accuracy: 0.8972 - val_loss: 0.2853 - val_accuracy: 0.8945\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 9s 73ms/step - loss: 0.2791 - accuracy: 0.8968 - val_loss: 0.2848 - val_accuracy: 0.8964\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 9s 76ms/step - loss: 0.2740 - accuracy: 0.8995 - val_loss: 0.2820 - val_accuracy: 0.8954\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.2874 - val_accuracy: 0.8929\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2688 - accuracy: 0.9004 - val_loss: 0.2697 - val_accuracy: 0.8999\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2629 - accuracy: 0.9023 - val_loss: 0.2735 - val_accuracy: 0.8988\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2630 - accuracy: 0.9025 - val_loss: 0.2803 - val_accuracy: 0.8984\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 9s 69ms/step - loss: 0.2620 - accuracy: 0.9028 - val_loss: 0.2655 - val_accuracy: 0.9008\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 9s 75ms/step - loss: 0.2582 - accuracy: 0.9039 - val_loss: 0.2582 - val_accuracy: 0.9051\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 9s 73ms/step - loss: 0.2560 - accuracy: 0.9051 - val_loss: 0.2775 - val_accuracy: 0.8989\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 9s 72ms/step - loss: 0.2516 - accuracy: 0.9062 - val_loss: 0.2690 - val_accuracy: 0.9012\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2529 - accuracy: 0.9068 - val_loss: 0.2581 - val_accuracy: 0.9058\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2428 - accuracy: 0.9101 - val_loss: 0.2585 - val_accuracy: 0.9030\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 8s 68ms/step - loss: 0.2437 - accuracy: 0.9096 - val_loss: 0.2552 - val_accuracy: 0.9041\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 9s 69ms/step - loss: 0.2508 - accuracy: 0.9064 - val_loss: 0.2718 - val_accuracy: 0.8997\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 9s 70ms/step - loss: 0.2453 - accuracy: 0.9096 - val_loss: 0.2516 - val_accuracy: 0.9081\n",
      "Running with hyperparameters: {'gru_units': 256, 'dense_units': 40, 'optimizer': 'rmsprop', 'learning_rate': 0.0031970844993649736}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 23s 170ms/step - loss: 1.1598 - accuracy: 0.5398 - val_loss: 0.9020 - val_accuracy: 0.5934\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 22s 176ms/step - loss: 0.9419 - accuracy: 0.5769 - val_loss: 0.9654 - val_accuracy: 0.5777\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 23s 183ms/step - loss: 0.9109 - accuracy: 0.5828 - val_loss: 0.8742 - val_accuracy: 0.5942\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 22s 178ms/step - loss: 0.8897 - accuracy: 0.5870 - val_loss: 0.8525 - val_accuracy: 0.5972\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 19s 157ms/step - loss: 0.8765 - accuracy: 0.5903 - val_loss: 0.8834 - val_accuracy: 0.5943\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 25s 200ms/step - loss: 0.8641 - accuracy: 0.5950 - val_loss: 0.8207 - val_accuracy: 0.6065\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 21s 166ms/step - loss: 0.8481 - accuracy: 0.5991 - val_loss: 0.8664 - val_accuracy: 0.5976\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 24s 190ms/step - loss: 0.8427 - accuracy: 0.6015 - val_loss: 0.8140 - val_accuracy: 0.6135\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 23s 188ms/step - loss: 0.8308 - accuracy: 0.6104 - val_loss: 0.7457 - val_accuracy: 0.6830\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 24s 197ms/step - loss: 0.8033 - accuracy: 0.6381 - val_loss: 0.7968 - val_accuracy: 0.6394\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 25s 198ms/step - loss: 0.6381 - accuracy: 0.7398 - val_loss: 0.5577 - val_accuracy: 0.7629\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 24s 192ms/step - loss: 0.5343 - accuracy: 0.7835 - val_loss: 0.4020 - val_accuracy: 0.8475\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 0.4852 - accuracy: 0.8051 - val_loss: 0.4593 - val_accuracy: 0.8060\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 22s 178ms/step - loss: 0.4461 - accuracy: 0.8218 - val_loss: 0.4764 - val_accuracy: 0.8135\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 27s 215ms/step - loss: 0.4323 - accuracy: 0.8275 - val_loss: 0.4789 - val_accuracy: 0.8196\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 23s 189ms/step - loss: 0.4093 - accuracy: 0.8364 - val_loss: 0.4216 - val_accuracy: 0.8315\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 26s 206ms/step - loss: 0.3980 - accuracy: 0.8431 - val_loss: 0.3264 - val_accuracy: 0.8776\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 23s 181ms/step - loss: 0.3866 - accuracy: 0.8476 - val_loss: 0.4114 - val_accuracy: 0.8207\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 25s 203ms/step - loss: 0.3730 - accuracy: 0.8534 - val_loss: 0.4267 - val_accuracy: 0.8289\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 20s 161ms/step - loss: 0.3655 - accuracy: 0.8541 - val_loss: 0.3148 - val_accuracy: 0.8795\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.3626 - accuracy: 0.8572 - val_loss: 0.4165 - val_accuracy: 0.8296\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 18s 148ms/step - loss: 0.3517 - accuracy: 0.8616 - val_loss: 0.6214 - val_accuracy: 0.7697\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 0.3422 - accuracy: 0.8648 - val_loss: 0.5370 - val_accuracy: 0.7837\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 0.3394 - accuracy: 0.8662 - val_loss: 0.3664 - val_accuracy: 0.8442\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.3273 - accuracy: 0.8706 - val_loss: 0.3018 - val_accuracy: 0.8855\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.3275 - accuracy: 0.8713 - val_loss: 0.2686 - val_accuracy: 0.8990\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.3233 - accuracy: 0.8732 - val_loss: 0.3710 - val_accuracy: 0.8708\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 19s 152ms/step - loss: 0.3131 - accuracy: 0.8779 - val_loss: 0.3949 - val_accuracy: 0.8501\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 0.3123 - accuracy: 0.8779 - val_loss: 0.3232 - val_accuracy: 0.8781\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 18s 148ms/step - loss: 0.3080 - accuracy: 0.8797 - val_loss: 0.3030 - val_accuracy: 0.8816\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 17s 140ms/step - loss: 0.3036 - accuracy: 0.8817 - val_loss: 0.2931 - val_accuracy: 0.8827\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 0.2998 - accuracy: 0.8837 - val_loss: 0.2731 - val_accuracy: 0.8963\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 0.2983 - accuracy: 0.8837 - val_loss: 0.3014 - val_accuracy: 0.8814\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 19s 157ms/step - loss: 0.2963 - accuracy: 0.8848 - val_loss: 0.2967 - val_accuracy: 0.8897\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2957 - accuracy: 0.8839 - val_loss: 0.2523 - val_accuracy: 0.9047\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2923 - accuracy: 0.8852 - val_loss: 0.2788 - val_accuracy: 0.8985\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 19s 157ms/step - loss: 0.2889 - accuracy: 0.8877 - val_loss: 0.2722 - val_accuracy: 0.8951\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2845 - accuracy: 0.8907 - val_loss: 0.2630 - val_accuracy: 0.9046\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.2783 - accuracy: 0.8924 - val_loss: 0.2608 - val_accuracy: 0.8998\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 18s 142ms/step - loss: 0.2790 - accuracy: 0.8922 - val_loss: 0.3060 - val_accuracy: 0.8797\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.2845 - accuracy: 0.8910 - val_loss: 0.2839 - val_accuracy: 0.8949\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2777 - accuracy: 0.8907 - val_loss: 0.2690 - val_accuracy: 0.8959\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2767 - accuracy: 0.8927 - val_loss: 0.3272 - val_accuracy: 0.8662\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 0.2753 - accuracy: 0.8924 - val_loss: 0.2519 - val_accuracy: 0.9033\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2755 - accuracy: 0.8937 - val_loss: 0.2586 - val_accuracy: 0.9017\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.2708 - accuracy: 0.8952 - val_loss: 0.2469 - val_accuracy: 0.9045\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 18s 149ms/step - loss: 0.2713 - accuracy: 0.8950 - val_loss: 0.4055 - val_accuracy: 0.8569\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 18s 144ms/step - loss: 0.2690 - accuracy: 0.8943 - val_loss: 0.2484 - val_accuracy: 0.9056\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 18s 146ms/step - loss: 0.2657 - accuracy: 0.8968 - val_loss: 0.2598 - val_accuracy: 0.9016\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 18s 143ms/step - loss: 0.2648 - accuracy: 0.8982 - val_loss: 0.2750 - val_accuracy: 0.8920\n",
      "Running with hyperparameters: {'gru_units': 96, 'dense_units': 5, 'optimizer': 'adam', 'learning_rate': 0.00024926334039539883}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 9s 58ms/step - loss: 1.3721 - accuracy: 0.4916 - val_loss: 1.1025 - val_accuracy: 0.5668\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.9640 - accuracy: 0.5886 - val_loss: 0.8855 - val_accuracy: 0.6042\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.8746 - accuracy: 0.6007 - val_loss: 0.8508 - val_accuracy: 0.6068\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8523 - accuracy: 0.6007 - val_loss: 0.8364 - val_accuracy: 0.6062\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8418 - accuracy: 0.5989 - val_loss: 0.8282 - val_accuracy: 0.6045\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8334 - accuracy: 0.5989 - val_loss: 0.8296 - val_accuracy: 0.6049\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8289 - accuracy: 0.6023 - val_loss: 0.8143 - val_accuracy: 0.6077\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8222 - accuracy: 0.6038 - val_loss: 0.8127 - val_accuracy: 0.6096\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.8176 - accuracy: 0.6055 - val_loss: 0.8070 - val_accuracy: 0.6083\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8145 - accuracy: 0.6061 - val_loss: 0.8028 - val_accuracy: 0.6088\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8111 - accuracy: 0.6075 - val_loss: 0.8032 - val_accuracy: 0.6141\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8090 - accuracy: 0.6117 - val_loss: 0.8000 - val_accuracy: 0.6145\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.8053 - accuracy: 0.6132 - val_loss: 0.7966 - val_accuracy: 0.6196\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.8023 - accuracy: 0.6157 - val_loss: 0.7928 - val_accuracy: 0.6223\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.7994 - accuracy: 0.6166 - val_loss: 0.7901 - val_accuracy: 0.6230\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.7962 - accuracy: 0.6195 - val_loss: 0.7853 - val_accuracy: 0.6275\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.7923 - accuracy: 0.6231 - val_loss: 0.7813 - val_accuracy: 0.6289\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.7881 - accuracy: 0.6274 - val_loss: 0.7770 - val_accuracy: 0.6337\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.7827 - accuracy: 0.6332 - val_loss: 0.7705 - val_accuracy: 0.6405\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.7761 - accuracy: 0.6400 - val_loss: 0.7644 - val_accuracy: 0.6484\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 7s 60ms/step - loss: 0.7700 - accuracy: 0.6458 - val_loss: 0.7571 - val_accuracy: 0.6571\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 7s 58ms/step - loss: 0.7611 - accuracy: 0.6529 - val_loss: 0.7491 - val_accuracy: 0.6610\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.7511 - accuracy: 0.6622 - val_loss: 0.7353 - val_accuracy: 0.6711\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.7293 - accuracy: 0.6792 - val_loss: 0.7117 - val_accuracy: 0.6893\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.7032 - accuracy: 0.6941 - val_loss: 0.6768 - val_accuracy: 0.7066\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.6389 - accuracy: 0.7355 - val_loss: 0.5210 - val_accuracy: 0.8101\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.4462 - accuracy: 0.8418 - val_loss: 0.4043 - val_accuracy: 0.8579\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.3841 - accuracy: 0.8677 - val_loss: 0.3710 - val_accuracy: 0.8721\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.3603 - accuracy: 0.8761 - val_loss: 0.3548 - val_accuracy: 0.8767\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.3419 - accuracy: 0.8820 - val_loss: 0.3382 - val_accuracy: 0.8822\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.3278 - accuracy: 0.8858 - val_loss: 0.3293 - val_accuracy: 0.8862\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.3196 - accuracy: 0.8885 - val_loss: 0.3299 - val_accuracy: 0.8811\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.3130 - accuracy: 0.8889 - val_loss: 0.3202 - val_accuracy: 0.8861\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.3046 - accuracy: 0.8916 - val_loss: 0.3055 - val_accuracy: 0.8917\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2983 - accuracy: 0.8932 - val_loss: 0.3022 - val_accuracy: 0.8898\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2938 - accuracy: 0.8931 - val_loss: 0.3029 - val_accuracy: 0.8902\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 7s 60ms/step - loss: 0.2891 - accuracy: 0.8940 - val_loss: 0.2972 - val_accuracy: 0.8906\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.2858 - accuracy: 0.8956 - val_loss: 0.2925 - val_accuracy: 0.8901\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.2803 - accuracy: 0.8975 - val_loss: 0.2863 - val_accuracy: 0.8952\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2782 - accuracy: 0.8973 - val_loss: 0.2800 - val_accuracy: 0.8949\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.2721 - accuracy: 0.8998 - val_loss: 0.2886 - val_accuracy: 0.8955\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 7s 57ms/step - loss: 0.2705 - accuracy: 0.9000 - val_loss: 0.2776 - val_accuracy: 0.8957\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2693 - accuracy: 0.8996 - val_loss: 0.2737 - val_accuracy: 0.8964\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2668 - accuracy: 0.9004 - val_loss: 0.2697 - val_accuracy: 0.9008\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 7s 56ms/step - loss: 0.2626 - accuracy: 0.9027 - val_loss: 0.2683 - val_accuracy: 0.9011\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.2612 - accuracy: 0.9035 - val_loss: 0.2649 - val_accuracy: 0.9025\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.2601 - accuracy: 0.9033 - val_loss: 0.2685 - val_accuracy: 0.8983\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.2579 - accuracy: 0.9044 - val_loss: 0.2655 - val_accuracy: 0.9001\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 7s 55ms/step - loss: 0.2607 - accuracy: 0.9040 - val_loss: 0.2701 - val_accuracy: 0.9002\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 7s 54ms/step - loss: 0.2541 - accuracy: 0.9065 - val_loss: 0.2559 - val_accuracy: 0.9048\n",
      "Running with hyperparameters: {'gru_units': 64, 'dense_units': 45, 'optimizer': 'adam', 'learning_rate': 0.001036847203444838}\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 5s 26ms/step - loss: 1.6236 - accuracy: 0.4716 - val_loss: 0.9647 - val_accuracy: 0.5951\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8993 - accuracy: 0.5962 - val_loss: 0.8592 - val_accuracy: 0.6037\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8600 - accuracy: 0.5979 - val_loss: 0.8435 - val_accuracy: 0.6037\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8454 - accuracy: 0.5991 - val_loss: 0.8328 - val_accuracy: 0.6033\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8390 - accuracy: 0.5987 - val_loss: 0.8256 - val_accuracy: 0.6022\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.8334 - accuracy: 0.5996 - val_loss: 0.8208 - val_accuracy: 0.6056\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.8282 - accuracy: 0.6000 - val_loss: 0.8161 - val_accuracy: 0.6054\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8249 - accuracy: 0.6017 - val_loss: 0.8187 - val_accuracy: 0.6033\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.8209 - accuracy: 0.6034 - val_loss: 0.8127 - val_accuracy: 0.6066\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8179 - accuracy: 0.6043 - val_loss: 0.8195 - val_accuracy: 0.6098\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8152 - accuracy: 0.6057 - val_loss: 0.8024 - val_accuracy: 0.6121\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8118 - accuracy: 0.6083 - val_loss: 0.8005 - val_accuracy: 0.6127\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.8090 - accuracy: 0.6089 - val_loss: 0.8002 - val_accuracy: 0.6115\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8087 - accuracy: 0.6100 - val_loss: 0.7986 - val_accuracy: 0.6157\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8036 - accuracy: 0.6106 - val_loss: 0.7920 - val_accuracy: 0.6164\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.8011 - accuracy: 0.6123 - val_loss: 0.7893 - val_accuracy: 0.6193\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7966 - accuracy: 0.6143 - val_loss: 0.7854 - val_accuracy: 0.6207\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7960 - accuracy: 0.6151 - val_loss: 0.7840 - val_accuracy: 0.6221\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.7900 - accuracy: 0.6178 - val_loss: 0.7801 - val_accuracy: 0.6228\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7860 - accuracy: 0.6189 - val_loss: 0.7740 - val_accuracy: 0.6283\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7789 - accuracy: 0.6230 - val_loss: 0.7671 - val_accuracy: 0.6342\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7778 - accuracy: 0.6251 - val_loss: 0.7752 - val_accuracy: 0.6338\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7662 - accuracy: 0.6367 - val_loss: 0.7518 - val_accuracy: 0.6509\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.7460 - accuracy: 0.6522 - val_loss: 0.7427 - val_accuracy: 0.6739\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.6918 - accuracy: 0.7252 - val_loss: 0.6008 - val_accuracy: 0.7769\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.5690 - accuracy: 0.7937 - val_loss: 0.5316 - val_accuracy: 0.8058\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4999 - accuracy: 0.8242 - val_loss: 0.4680 - val_accuracy: 0.8343\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4362 - accuracy: 0.8516 - val_loss: 0.4158 - val_accuracy: 0.8595\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.4022 - accuracy: 0.8638 - val_loss: 0.3872 - val_accuracy: 0.8689\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.3862 - accuracy: 0.8673 - val_loss: 0.3824 - val_accuracy: 0.8664\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3670 - accuracy: 0.8736 - val_loss: 0.3791 - val_accuracy: 0.8581\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3501 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8682\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3385 - accuracy: 0.8770 - val_loss: 0.3542 - val_accuracy: 0.8729\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3310 - accuracy: 0.8781 - val_loss: 0.3268 - val_accuracy: 0.8814\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3136 - accuracy: 0.8860 - val_loss: 0.3246 - val_accuracy: 0.8810\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.3063 - accuracy: 0.8885 - val_loss: 0.3031 - val_accuracy: 0.8898\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2994 - accuracy: 0.8904 - val_loss: 0.3003 - val_accuracy: 0.8885\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2969 - accuracy: 0.8907 - val_loss: 0.3071 - val_accuracy: 0.8842\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2980 - accuracy: 0.8896 - val_loss: 0.2993 - val_accuracy: 0.8912\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2879 - accuracy: 0.8942 - val_loss: 0.2840 - val_accuracy: 0.8958\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2786 - accuracy: 0.8984 - val_loss: 0.2868 - val_accuracy: 0.8939\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2763 - accuracy: 0.8981 - val_loss: 0.2753 - val_accuracy: 0.8984\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2813 - accuracy: 0.8951 - val_loss: 0.2830 - val_accuracy: 0.8940\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2694 - accuracy: 0.9003 - val_loss: 0.2938 - val_accuracy: 0.8849\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2716 - accuracy: 0.8987 - val_loss: 0.2891 - val_accuracy: 0.8936\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2718 - accuracy: 0.8992 - val_loss: 0.2673 - val_accuracy: 0.9004\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2696 - accuracy: 0.9004 - val_loss: 0.2825 - val_accuracy: 0.8949\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.2674 - accuracy: 0.9006 - val_loss: 0.2617 - val_accuracy: 0.9036\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2641 - accuracy: 0.9023 - val_loss: 0.2794 - val_accuracy: 0.8979\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.2631 - accuracy: 0.9030 - val_loss: 0.2647 - val_accuracy: 0.9029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'tuned_GRU_models_results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 최상의 하이퍼파라미터 조합 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=5)\n",
    "\n",
    "# 각 하이퍼파라미터 조합에 대한 학습 곡선을 그릴 예정\n",
    "for idx, hp in enumerate(best_hps):\n",
    "    # Hyperparameters from the trial\n",
    "    optimizer = hp['optimizer']\n",
    "    learning_rate = hp['learning_rate']\n",
    "    gru_units = hp['gru_units']\n",
    "\n",
    "    print(f\"Running with hyperparameters: {hp.values}\")\n",
    "    model = build_model(hp)\n",
    "    history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                        validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), \n",
    "                        epochs=50, batch_size=64)  # 고정된 배치 크기 사용\n",
    "    \n",
    "    # Plot the loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Trial {idx+1} - Loss (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {gru_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Trial {idx+1} - Accuracy (Optimizer: {optimizer}, LR: {round(learning_rate, 2)}, Units: {gru_units})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 결과를 PNG 파일로 저장\n",
    "    plt.savefig(os.path.join(results_dir, f'trial_{idx+1}_results.png'))\n",
    "    plt.close()  # 현재 그린 그래프를 닫아 새로운 그래프를 그릴 준비"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
