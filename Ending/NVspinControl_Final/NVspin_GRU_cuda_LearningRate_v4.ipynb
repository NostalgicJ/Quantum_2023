{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../../Data/using/dt_2.6/ByAstar_dt_2.6_1016.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "148/148 [==============================] - 2s 9ms/step - loss: 1.0982 - accuracy: 0.5425 - val_loss: 0.8929 - val_accuracy: 0.5813\n",
      "Epoch 2/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8760 - accuracy: 0.5838 - val_loss: 0.8574 - val_accuracy: 0.5868\n",
      "Epoch 3/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8648 - accuracy: 0.5852 - val_loss: 0.8482 - val_accuracy: 0.5921\n",
      "Epoch 4/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8554 - accuracy: 0.5874 - val_loss: 0.8412 - val_accuracy: 0.5942\n",
      "Epoch 5/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8486 - accuracy: 0.5923 - val_loss: 0.8371 - val_accuracy: 0.5969\n",
      "Epoch 6/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8421 - accuracy: 0.5938 - val_loss: 0.8257 - val_accuracy: 0.6030\n",
      "Epoch 7/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8297 - accuracy: 0.6006 - val_loss: 0.8114 - val_accuracy: 0.6120\n",
      "Epoch 8/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7467 - accuracy: 0.6684 - val_loss: 0.4841 - val_accuracy: 0.8372\n",
      "Epoch 9/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4270 - accuracy: 0.8539 - val_loss: 0.3857 - val_accuracy: 0.8632\n",
      "Epoch 10/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3728 - accuracy: 0.8717 - val_loss: 0.3406 - val_accuracy: 0.8841\n",
      "Epoch 11/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3467 - accuracy: 0.8795 - val_loss: 0.3251 - val_accuracy: 0.8883\n",
      "Epoch 12/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.8816 - val_loss: 0.3194 - val_accuracy: 0.8877\n",
      "Epoch 13/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3198 - accuracy: 0.8860 - val_loss: 0.3196 - val_accuracy: 0.8874\n",
      "Epoch 14/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3182 - accuracy: 0.8844 - val_loss: 0.2996 - val_accuracy: 0.8937\n",
      "Epoch 15/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3086 - accuracy: 0.8878 - val_loss: 0.3061 - val_accuracy: 0.8886\n",
      "Epoch 16/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3041 - accuracy: 0.8891 - val_loss: 0.2917 - val_accuracy: 0.8940\n",
      "Epoch 17/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2977 - accuracy: 0.8905 - val_loss: 0.2857 - val_accuracy: 0.8964\n",
      "Epoch 18/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2932 - accuracy: 0.8920 - val_loss: 0.2825 - val_accuracy: 0.8973\n",
      "Epoch 19/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2936 - accuracy: 0.8906 - val_loss: 0.2730 - val_accuracy: 0.8993\n",
      "Epoch 20/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2891 - accuracy: 0.8924 - val_loss: 0.2790 - val_accuracy: 0.8959\n",
      "Epoch 21/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2826 - accuracy: 0.8942 - val_loss: 0.2732 - val_accuracy: 0.8970\n",
      "Epoch 22/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2799 - accuracy: 0.8948 - val_loss: 0.2948 - val_accuracy: 0.8858\n",
      "Epoch 23/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2819 - accuracy: 0.8934 - val_loss: 0.2665 - val_accuracy: 0.9018\n",
      "Epoch 24/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2791 - accuracy: 0.8941 - val_loss: 0.2586 - val_accuracy: 0.9039\n",
      "Epoch 25/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.8935 - val_loss: 0.2661 - val_accuracy: 0.8986\n",
      "Epoch 26/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2749 - accuracy: 0.8950 - val_loss: 0.2931 - val_accuracy: 0.8862\n",
      "Epoch 27/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2754 - accuracy: 0.8939 - val_loss: 0.2627 - val_accuracy: 0.9001\n",
      "Epoch 28/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2713 - accuracy: 0.8957 - val_loss: 0.2644 - val_accuracy: 0.8989\n",
      "Epoch 29/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2697 - accuracy: 0.8962 - val_loss: 0.2560 - val_accuracy: 0.9035\n",
      "Epoch 30/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2712 - accuracy: 0.8954 - val_loss: 0.2768 - val_accuracy: 0.8934\n",
      "Epoch 31/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.8964 - val_loss: 0.2937 - val_accuracy: 0.8843\n",
      "Epoch 32/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2659 - accuracy: 0.8977 - val_loss: 0.2741 - val_accuracy: 0.8941\n",
      "Epoch 33/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2678 - accuracy: 0.8969 - val_loss: 0.2489 - val_accuracy: 0.9053\n",
      "Epoch 34/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2664 - accuracy: 0.8971 - val_loss: 0.2575 - val_accuracy: 0.9012\n",
      "Epoch 35/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2677 - accuracy: 0.8958 - val_loss: 0.2548 - val_accuracy: 0.9018\n",
      "Epoch 36/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2618 - accuracy: 0.8987 - val_loss: 0.2484 - val_accuracy: 0.9058\n",
      "Epoch 37/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2653 - accuracy: 0.8968 - val_loss: 0.2639 - val_accuracy: 0.8993\n",
      "Epoch 38/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2599 - accuracy: 0.8989 - val_loss: 0.2486 - val_accuracy: 0.9038\n",
      "Epoch 39/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2647 - accuracy: 0.8972 - val_loss: 0.2505 - val_accuracy: 0.9030\n",
      "Epoch 40/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2592 - accuracy: 0.8991 - val_loss: 0.2595 - val_accuracy: 0.8998\n",
      "Epoch 41/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2595 - accuracy: 0.8989 - val_loss: 0.2577 - val_accuracy: 0.9008\n",
      "Epoch 42/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2642 - accuracy: 0.8964 - val_loss: 0.2836 - val_accuracy: 0.8886\n",
      "Epoch 43/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2650 - accuracy: 0.8963 - val_loss: 0.2594 - val_accuracy: 0.8972\n",
      "Epoch 44/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2548 - accuracy: 0.9003 - val_loss: 0.2489 - val_accuracy: 0.9046\n",
      "Epoch 45/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2580 - accuracy: 0.8987 - val_loss: 0.2484 - val_accuracy: 0.9038\n",
      "Epoch 46/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2632 - accuracy: 0.8970 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 47/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2549 - accuracy: 0.9002 - val_loss: 0.2456 - val_accuracy: 0.9049\n",
      "Epoch 48/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2566 - accuracy: 0.8990 - val_loss: 0.2513 - val_accuracy: 0.9035\n",
      "Epoch 49/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2536 - accuracy: 0.9006 - val_loss: 0.2504 - val_accuracy: 0.9018\n",
      "Epoch 50/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2545 - accuracy: 0.9006 - val_loss: 0.2539 - val_accuracy: 0.9000\n",
      "Epoch 51/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2542 - accuracy: 0.9002 - val_loss: 0.2695 - val_accuracy: 0.8938\n",
      "Epoch 52/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2580 - accuracy: 0.8987 - val_loss: 0.2722 - val_accuracy: 0.8938\n",
      "Epoch 53/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2576 - accuracy: 0.8990 - val_loss: 0.2446 - val_accuracy: 0.9044\n",
      "Epoch 54/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2528 - accuracy: 0.9003 - val_loss: 0.2595 - val_accuracy: 0.8973\n",
      "Epoch 55/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2579 - accuracy: 0.8984 - val_loss: 0.2427 - val_accuracy: 0.9049\n",
      "Epoch 56/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2550 - accuracy: 0.8994 - val_loss: 0.2573 - val_accuracy: 0.8991\n",
      "Epoch 57/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2573 - accuracy: 0.8979 - val_loss: 0.2426 - val_accuracy: 0.9055\n",
      "Epoch 58/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2503 - accuracy: 0.9011 - val_loss: 0.2455 - val_accuracy: 0.9034\n",
      "Epoch 59/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2530 - accuracy: 0.9003 - val_loss: 0.2402 - val_accuracy: 0.9061\n",
      "Epoch 60/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2523 - accuracy: 0.9006 - val_loss: 0.2668 - val_accuracy: 0.8939\n",
      "Epoch 61/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2542 - accuracy: 0.8990 - val_loss: 0.2386 - val_accuracy: 0.9072\n",
      "Epoch 62/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2518 - accuracy: 0.9005 - val_loss: 0.2452 - val_accuracy: 0.9041\n",
      "Epoch 63/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2520 - accuracy: 0.9005 - val_loss: 0.2375 - val_accuracy: 0.9074\n",
      "Epoch 64/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2510 - accuracy: 0.9007 - val_loss: 0.2450 - val_accuracy: 0.9040\n",
      "Epoch 65/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2507 - accuracy: 0.9002 - val_loss: 0.2519 - val_accuracy: 0.9002\n",
      "Epoch 66/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2485 - accuracy: 0.9016 - val_loss: 0.2482 - val_accuracy: 0.9021\n",
      "Epoch 67/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2490 - accuracy: 0.9017 - val_loss: 0.2377 - val_accuracy: 0.9072\n",
      "Epoch 68/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2460 - accuracy: 0.9028 - val_loss: 0.2432 - val_accuracy: 0.9047\n",
      "Epoch 69/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2487 - accuracy: 0.9009 - val_loss: 0.2404 - val_accuracy: 0.9052\n",
      "Epoch 70/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2476 - accuracy: 0.9015 - val_loss: 0.2479 - val_accuracy: 0.9019\n",
      "Epoch 71/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2479 - accuracy: 0.9016 - val_loss: 0.2430 - val_accuracy: 0.9038\n",
      "Epoch 72/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2492 - accuracy: 0.9006 - val_loss: 0.2365 - val_accuracy: 0.9071\n",
      "Epoch 73/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2464 - accuracy: 0.9012 - val_loss: 0.2368 - val_accuracy: 0.9058\n",
      "Epoch 74/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2441 - accuracy: 0.9030 - val_loss: 0.2417 - val_accuracy: 0.9035\n",
      "Epoch 75/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2460 - accuracy: 0.9021 - val_loss: 0.2485 - val_accuracy: 0.9012\n",
      "Epoch 76/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2462 - accuracy: 0.9018 - val_loss: 0.2319 - val_accuracy: 0.9088\n",
      "Epoch 77/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2461 - accuracy: 0.9015 - val_loss: 0.2390 - val_accuracy: 0.9071\n",
      "Epoch 78/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9015 - val_loss: 0.2524 - val_accuracy: 0.8999\n",
      "Epoch 79/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9014 - val_loss: 0.2544 - val_accuracy: 0.8986\n",
      "Epoch 80/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2443 - accuracy: 0.9020 - val_loss: 0.2396 - val_accuracy: 0.9065\n",
      "Epoch 81/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2473 - accuracy: 0.9011 - val_loss: 0.2482 - val_accuracy: 0.9007\n",
      "Epoch 82/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.9021 - val_loss: 0.2439 - val_accuracy: 0.9049\n",
      "Epoch 83/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2424 - accuracy: 0.9030 - val_loss: 0.2392 - val_accuracy: 0.9050\n",
      "Epoch 84/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.9022 - val_loss: 0.2347 - val_accuracy: 0.9070\n",
      "Epoch 85/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2428 - accuracy: 0.9032 - val_loss: 0.2378 - val_accuracy: 0.9056\n",
      "Epoch 86/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2416 - accuracy: 0.9030 - val_loss: 0.2454 - val_accuracy: 0.9013\n",
      "Epoch 87/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2481 - accuracy: 0.9002 - val_loss: 0.2407 - val_accuracy: 0.9049\n",
      "Epoch 88/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2406 - accuracy: 0.9035 - val_loss: 0.2349 - val_accuracy: 0.9066\n",
      "Epoch 89/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2427 - accuracy: 0.9023 - val_loss: 0.2458 - val_accuracy: 0.9024\n",
      "Epoch 90/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2426 - accuracy: 0.9031 - val_loss: 0.2359 - val_accuracy: 0.9069\n",
      "Epoch 91/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2413 - accuracy: 0.9027 - val_loss: 0.2368 - val_accuracy: 0.9058\n",
      "Epoch 92/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2396 - accuracy: 0.9035 - val_loss: 0.2322 - val_accuracy: 0.9081\n",
      "Epoch 93/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.9025 - val_loss: 0.2306 - val_accuracy: 0.9088\n",
      "Epoch 94/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9035 - val_loss: 0.2269 - val_accuracy: 0.9103\n",
      "Epoch 95/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2413 - accuracy: 0.9032 - val_loss: 0.2461 - val_accuracy: 0.9019\n",
      "Epoch 96/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2424 - accuracy: 0.9023 - val_loss: 0.2295 - val_accuracy: 0.9078\n",
      "Epoch 97/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2398 - accuracy: 0.9032 - val_loss: 0.2302 - val_accuracy: 0.9076\n",
      "Epoch 98/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9032 - val_loss: 0.2468 - val_accuracy: 0.9011\n",
      "Epoch 99/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.9016 - val_loss: 0.2461 - val_accuracy: 0.9016\n",
      "Epoch 100/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2388 - accuracy: 0.9036 - val_loss: 0.2433 - val_accuracy: 0.9011\n",
      "Epoch 101/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2416 - accuracy: 0.9028 - val_loss: 0.2376 - val_accuracy: 0.9035\n",
      "Epoch 102/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2384 - accuracy: 0.9039 - val_loss: 0.2303 - val_accuracy: 0.9073\n",
      "Epoch 103/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2405 - accuracy: 0.9026 - val_loss: 0.2350 - val_accuracy: 0.9064\n",
      "Epoch 104/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2344 - accuracy: 0.9052 - val_loss: 0.2283 - val_accuracy: 0.9079\n",
      "Epoch 105/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2371 - accuracy: 0.9043 - val_loss: 0.2292 - val_accuracy: 0.9089\n",
      "Epoch 106/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2386 - accuracy: 0.9038 - val_loss: 0.2350 - val_accuracy: 0.9061\n",
      "Epoch 107/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2347 - accuracy: 0.9048 - val_loss: 0.2284 - val_accuracy: 0.9092\n",
      "Epoch 108/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2363 - accuracy: 0.9043 - val_loss: 0.2459 - val_accuracy: 0.9033\n",
      "Epoch 109/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2388 - accuracy: 0.9034 - val_loss: 0.2314 - val_accuracy: 0.9068\n",
      "Epoch 110/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2368 - accuracy: 0.9039 - val_loss: 0.2272 - val_accuracy: 0.9086\n",
      "Epoch 111/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2330 - accuracy: 0.9061 - val_loss: 0.2261 - val_accuracy: 0.9094\n",
      "Epoch 112/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2328 - accuracy: 0.9057 - val_loss: 0.2298 - val_accuracy: 0.9082\n",
      "Epoch 113/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2333 - accuracy: 0.9056 - val_loss: 0.2372 - val_accuracy: 0.9038\n",
      "Epoch 114/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2388 - accuracy: 0.9033 - val_loss: 0.2301 - val_accuracy: 0.9078\n",
      "Epoch 115/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2342 - accuracy: 0.9053 - val_loss: 0.2229 - val_accuracy: 0.9100\n",
      "Epoch 116/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2342 - accuracy: 0.9050 - val_loss: 0.2222 - val_accuracy: 0.9106\n",
      "Epoch 117/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2370 - accuracy: 0.9037 - val_loss: 0.2329 - val_accuracy: 0.9063\n",
      "Epoch 118/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.9049 - val_loss: 0.2227 - val_accuracy: 0.9103\n",
      "Epoch 119/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2355 - accuracy: 0.9042 - val_loss: 0.2309 - val_accuracy: 0.9068\n",
      "Epoch 120/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9063 - val_loss: 0.2253 - val_accuracy: 0.9087\n",
      "Epoch 121/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2350 - accuracy: 0.9049 - val_loss: 0.2325 - val_accuracy: 0.9051\n",
      "Epoch 122/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2365 - accuracy: 0.9039 - val_loss: 0.2330 - val_accuracy: 0.9053\n",
      "Epoch 123/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2347 - accuracy: 0.9050 - val_loss: 0.2344 - val_accuracy: 0.9063\n",
      "Epoch 124/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2388 - accuracy: 0.9024 - val_loss: 0.2219 - val_accuracy: 0.9110\n",
      "Epoch 125/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2316 - accuracy: 0.9058 - val_loss: 0.2247 - val_accuracy: 0.9102\n",
      "Epoch 126/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2320 - accuracy: 0.9055 - val_loss: 0.2342 - val_accuracy: 0.9053\n",
      "Epoch 127/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2313 - accuracy: 0.9051 - val_loss: 0.2311 - val_accuracy: 0.9071\n",
      "Epoch 128/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2318 - accuracy: 0.9057 - val_loss: 0.2291 - val_accuracy: 0.9073\n",
      "Epoch 129/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2311 - accuracy: 0.9058 - val_loss: 0.2211 - val_accuracy: 0.9106\n",
      "Epoch 130/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2299 - accuracy: 0.9064 - val_loss: 0.2412 - val_accuracy: 0.9036\n",
      "Epoch 131/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2318 - accuracy: 0.9052 - val_loss: 0.2261 - val_accuracy: 0.9096\n",
      "Epoch 132/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2319 - accuracy: 0.9058 - val_loss: 0.2254 - val_accuracy: 0.9083\n",
      "Epoch 133/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2295 - accuracy: 0.9067 - val_loss: 0.2226 - val_accuracy: 0.9102\n",
      "Epoch 134/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9063 - val_loss: 0.2343 - val_accuracy: 0.9047\n",
      "Epoch 135/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2337 - accuracy: 0.9046 - val_loss: 0.2185 - val_accuracy: 0.9108\n",
      "Epoch 136/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2285 - accuracy: 0.9064 - val_loss: 0.2266 - val_accuracy: 0.9090\n",
      "Epoch 137/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9060 - val_loss: 0.2213 - val_accuracy: 0.9125\n",
      "Epoch 138/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9067 - val_loss: 0.2301 - val_accuracy: 0.9074\n",
      "Epoch 139/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2298 - accuracy: 0.9061 - val_loss: 0.2351 - val_accuracy: 0.9051\n",
      "Epoch 140/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2262 - accuracy: 0.9072 - val_loss: 0.2229 - val_accuracy: 0.9092\n",
      "Epoch 141/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2279 - accuracy: 0.9066 - val_loss: 0.2306 - val_accuracy: 0.9061\n",
      "Epoch 142/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2284 - accuracy: 0.9063 - val_loss: 0.2244 - val_accuracy: 0.9094\n",
      "Epoch 143/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9062 - val_loss: 0.2190 - val_accuracy: 0.9115\n",
      "Epoch 144/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2243 - accuracy: 0.9083 - val_loss: 0.2204 - val_accuracy: 0.9114\n",
      "Epoch 145/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2283 - accuracy: 0.9067 - val_loss: 0.2206 - val_accuracy: 0.9107\n",
      "Epoch 146/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2272 - accuracy: 0.9071 - val_loss: 0.2381 - val_accuracy: 0.9051\n",
      "Epoch 147/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2281 - accuracy: 0.9064 - val_loss: 0.2211 - val_accuracy: 0.9108\n",
      "Epoch 148/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2217 - accuracy: 0.9092 - val_loss: 0.2452 - val_accuracy: 0.9035\n",
      "Epoch 149/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2269 - accuracy: 0.9076 - val_loss: 0.2147 - val_accuracy: 0.9119\n",
      "Epoch 150/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2316 - accuracy: 0.9055 - val_loss: 0.2300 - val_accuracy: 0.9068\n",
      "Epoch 151/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2246 - accuracy: 0.9082 - val_loss: 0.2228 - val_accuracy: 0.9082\n",
      "Epoch 152/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 0.2209 - val_accuracy: 0.9101\n",
      "Epoch 153/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2273 - accuracy: 0.9073 - val_loss: 0.2222 - val_accuracy: 0.9091\n",
      "Epoch 154/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9068 - val_loss: 0.2345 - val_accuracy: 0.9050\n",
      "Epoch 155/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2246 - accuracy: 0.9078 - val_loss: 0.2160 - val_accuracy: 0.9120\n",
      "Epoch 156/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2238 - accuracy: 0.9083 - val_loss: 0.2208 - val_accuracy: 0.9098\n",
      "Epoch 157/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9057 - val_loss: 0.2163 - val_accuracy: 0.9128\n",
      "Epoch 158/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2272 - accuracy: 0.9076 - val_loss: 0.2244 - val_accuracy: 0.9110\n",
      "Epoch 159/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9091 - val_loss: 0.2129 - val_accuracy: 0.9133\n",
      "Epoch 160/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2213 - accuracy: 0.9087 - val_loss: 0.2179 - val_accuracy: 0.9104\n",
      "Epoch 161/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2237 - accuracy: 0.9082 - val_loss: 0.2216 - val_accuracy: 0.9099\n",
      "Epoch 162/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2245 - accuracy: 0.9088 - val_loss: 0.2230 - val_accuracy: 0.9104\n",
      "Epoch 163/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2254 - accuracy: 0.9078 - val_loss: 0.2186 - val_accuracy: 0.9122\n",
      "Epoch 164/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2225 - accuracy: 0.9087 - val_loss: 0.2152 - val_accuracy: 0.9122\n",
      "Epoch 165/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2184 - accuracy: 0.9102 - val_loss: 0.2163 - val_accuracy: 0.9124\n",
      "Epoch 166/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2224 - accuracy: 0.9088 - val_loss: 0.2284 - val_accuracy: 0.9091\n",
      "Epoch 167/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2217 - accuracy: 0.9090 - val_loss: 0.2129 - val_accuracy: 0.9131\n",
      "Epoch 168/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2233 - accuracy: 0.9079 - val_loss: 0.2212 - val_accuracy: 0.9116\n",
      "Epoch 169/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2230 - accuracy: 0.9085 - val_loss: 0.2145 - val_accuracy: 0.9118\n",
      "Epoch 170/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9081 - val_loss: 0.2169 - val_accuracy: 0.9101\n",
      "Epoch 171/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2242 - accuracy: 0.9078 - val_loss: 0.2224 - val_accuracy: 0.9094\n",
      "Epoch 172/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2227 - accuracy: 0.9086 - val_loss: 0.2128 - val_accuracy: 0.9139\n",
      "Epoch 173/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2209 - accuracy: 0.9090 - val_loss: 0.2152 - val_accuracy: 0.9126\n",
      "Epoch 174/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2178 - accuracy: 0.9100 - val_loss: 0.2129 - val_accuracy: 0.9134\n",
      "Epoch 175/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2232 - accuracy: 0.9080 - val_loss: 0.2149 - val_accuracy: 0.9130\n",
      "Epoch 176/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.9086 - val_loss: 0.2192 - val_accuracy: 0.9109\n",
      "Epoch 177/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.9084 - val_loss: 0.2113 - val_accuracy: 0.9136\n",
      "Epoch 178/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2178 - accuracy: 0.9103 - val_loss: 0.2089 - val_accuracy: 0.9144\n",
      "Epoch 179/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2232 - accuracy: 0.9074 - val_loss: 0.2252 - val_accuracy: 0.9113\n",
      "Epoch 180/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2184 - accuracy: 0.9100 - val_loss: 0.2135 - val_accuracy: 0.9127\n",
      "Epoch 181/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2188 - accuracy: 0.9099 - val_loss: 0.2121 - val_accuracy: 0.9130\n",
      "Epoch 182/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2196 - accuracy: 0.9097 - val_loss: 0.2323 - val_accuracy: 0.9050\n",
      "Epoch 183/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2173 - accuracy: 0.9106 - val_loss: 0.2143 - val_accuracy: 0.9115\n",
      "Epoch 184/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2203 - accuracy: 0.9091 - val_loss: 0.2103 - val_accuracy: 0.9135\n",
      "Epoch 185/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9092 - val_loss: 0.2262 - val_accuracy: 0.9082\n",
      "Epoch 186/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2193 - accuracy: 0.9098 - val_loss: 0.2207 - val_accuracy: 0.9095\n",
      "Epoch 187/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2177 - accuracy: 0.9101 - val_loss: 0.2214 - val_accuracy: 0.9094\n",
      "Epoch 188/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2176 - accuracy: 0.9103 - val_loss: 0.2112 - val_accuracy: 0.9136\n",
      "Epoch 189/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2169 - accuracy: 0.9104 - val_loss: 0.2246 - val_accuracy: 0.9084\n",
      "Epoch 190/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2177 - accuracy: 0.9102 - val_loss: 0.2156 - val_accuracy: 0.9118\n",
      "Epoch 191/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2145 - accuracy: 0.9115 - val_loss: 0.2118 - val_accuracy: 0.9142\n",
      "Epoch 192/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9111 - val_loss: 0.2114 - val_accuracy: 0.9135\n",
      "Epoch 193/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2190 - accuracy: 0.9097 - val_loss: 0.2138 - val_accuracy: 0.9129\n",
      "Epoch 194/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2190 - accuracy: 0.9097 - val_loss: 0.2126 - val_accuracy: 0.9132\n",
      "Epoch 195/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2168 - accuracy: 0.9110 - val_loss: 0.2206 - val_accuracy: 0.9094\n",
      "Epoch 196/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2172 - accuracy: 0.9103 - val_loss: 0.2109 - val_accuracy: 0.9139\n",
      "Epoch 197/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2134 - accuracy: 0.9116 - val_loss: 0.2206 - val_accuracy: 0.9095\n",
      "Epoch 198/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2199 - accuracy: 0.9096 - val_loss: 0.2125 - val_accuracy: 0.9133\n",
      "Epoch 199/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2179 - accuracy: 0.9102 - val_loss: 0.2152 - val_accuracy: 0.9127\n",
      "Epoch 200/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2133 - accuracy: 0.9117 - val_loss: 0.2201 - val_accuracy: 0.9092\n",
      "Epoch 201/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2173 - accuracy: 0.9105 - val_loss: 0.2066 - val_accuracy: 0.9153\n",
      "Epoch 202/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2151 - accuracy: 0.9111 - val_loss: 0.2092 - val_accuracy: 0.9144\n",
      "Epoch 203/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.9109 - val_loss: 0.2236 - val_accuracy: 0.9086\n",
      "Epoch 204/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2159 - accuracy: 0.9113 - val_loss: 0.2652 - val_accuracy: 0.8926\n",
      "Epoch 205/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2151 - accuracy: 0.9114 - val_loss: 0.2077 - val_accuracy: 0.9152\n",
      "Epoch 206/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2146 - accuracy: 0.9111 - val_loss: 0.2172 - val_accuracy: 0.9113\n",
      "Epoch 207/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2148 - accuracy: 0.9114 - val_loss: 0.2067 - val_accuracy: 0.9147\n",
      "Epoch 208/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2122 - accuracy: 0.9125 - val_loss: 0.2122 - val_accuracy: 0.9134\n",
      "Epoch 209/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2187 - accuracy: 0.9100 - val_loss: 0.2058 - val_accuracy: 0.9157\n",
      "Epoch 210/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2135 - accuracy: 0.9114 - val_loss: 0.2204 - val_accuracy: 0.9095\n",
      "Epoch 211/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2170 - accuracy: 0.9108 - val_loss: 0.2228 - val_accuracy: 0.9096\n",
      "Epoch 212/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2123 - accuracy: 0.9123 - val_loss: 0.2093 - val_accuracy: 0.9141\n",
      "Epoch 213/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2135 - accuracy: 0.9116 - val_loss: 0.2114 - val_accuracy: 0.9140\n",
      "Epoch 214/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2133 - accuracy: 0.9120 - val_loss: 0.2100 - val_accuracy: 0.9148\n",
      "Epoch 215/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2128 - accuracy: 0.9117 - val_loss: 0.2053 - val_accuracy: 0.9166\n",
      "Epoch 216/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2157 - accuracy: 0.9109 - val_loss: 0.2075 - val_accuracy: 0.9166\n",
      "Epoch 217/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2102 - accuracy: 0.9133 - val_loss: 0.2143 - val_accuracy: 0.9121\n",
      "Epoch 218/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2136 - accuracy: 0.9118 - val_loss: 0.2209 - val_accuracy: 0.9093\n",
      "Epoch 219/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2095 - accuracy: 0.9131 - val_loss: 0.2084 - val_accuracy: 0.9154\n",
      "Epoch 220/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2134 - accuracy: 0.9118 - val_loss: 0.2077 - val_accuracy: 0.9161\n",
      "Epoch 221/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2108 - accuracy: 0.9128 - val_loss: 0.2002 - val_accuracy: 0.9183\n",
      "Epoch 222/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2153 - accuracy: 0.9111 - val_loss: 0.2063 - val_accuracy: 0.9150\n",
      "Epoch 223/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2136 - accuracy: 0.9114 - val_loss: 0.2099 - val_accuracy: 0.9127\n",
      "Epoch 224/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2141 - accuracy: 0.9114 - val_loss: 0.2075 - val_accuracy: 0.9158\n",
      "Epoch 225/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2162 - accuracy: 0.9103 - val_loss: 0.2030 - val_accuracy: 0.9169\n",
      "Epoch 226/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2106 - accuracy: 0.9127 - val_loss: 0.2037 - val_accuracy: 0.9167\n",
      "Epoch 227/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2105 - accuracy: 0.9128 - val_loss: 0.2039 - val_accuracy: 0.9173\n",
      "Epoch 228/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2127 - accuracy: 0.9121 - val_loss: 0.2273 - val_accuracy: 0.9061\n",
      "Epoch 229/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2124 - accuracy: 0.9124 - val_loss: 0.2072 - val_accuracy: 0.9156\n",
      "Epoch 230/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2084 - accuracy: 0.9138 - val_loss: 0.2060 - val_accuracy: 0.9163\n",
      "Epoch 231/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9139 - val_loss: 0.2003 - val_accuracy: 0.9180\n",
      "Epoch 232/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2101 - accuracy: 0.9137 - val_loss: 0.2056 - val_accuracy: 0.9153\n",
      "Epoch 233/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2087 - accuracy: 0.9137 - val_loss: 0.2240 - val_accuracy: 0.9106\n",
      "Epoch 234/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2121 - accuracy: 0.9124 - val_loss: 0.2068 - val_accuracy: 0.9161\n",
      "Epoch 235/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2083 - accuracy: 0.9136 - val_loss: 0.2129 - val_accuracy: 0.9130\n",
      "Epoch 236/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2123 - accuracy: 0.9125 - val_loss: 0.2239 - val_accuracy: 0.9089\n",
      "Epoch 237/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9128 - val_loss: 0.2076 - val_accuracy: 0.9145\n",
      "Epoch 238/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2087 - accuracy: 0.9135 - val_loss: 0.2049 - val_accuracy: 0.9167\n",
      "Epoch 239/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2124 - accuracy: 0.9124 - val_loss: 0.2106 - val_accuracy: 0.9139\n",
      "Epoch 240/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2067 - accuracy: 0.9144 - val_loss: 0.2100 - val_accuracy: 0.9145\n",
      "Epoch 241/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2108 - accuracy: 0.9129 - val_loss: 0.2021 - val_accuracy: 0.9176\n",
      "Epoch 242/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2068 - accuracy: 0.9144 - val_loss: 0.2087 - val_accuracy: 0.9148\n",
      "Epoch 243/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2149 - accuracy: 0.9117 - val_loss: 0.2033 - val_accuracy: 0.9171\n",
      "Epoch 244/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2104 - accuracy: 0.9136 - val_loss: 0.2099 - val_accuracy: 0.9137\n",
      "Epoch 245/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2121 - accuracy: 0.9128 - val_loss: 0.2137 - val_accuracy: 0.9122\n",
      "Epoch 246/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2069 - accuracy: 0.9143 - val_loss: 0.2021 - val_accuracy: 0.9167\n",
      "Epoch 247/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2080 - accuracy: 0.9142 - val_loss: 0.2046 - val_accuracy: 0.9164\n",
      "Epoch 248/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2106 - accuracy: 0.9128 - val_loss: 0.2196 - val_accuracy: 0.9101\n",
      "Epoch 249/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2078 - accuracy: 0.9143 - val_loss: 0.2066 - val_accuracy: 0.9154\n",
      "Epoch 250/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2065 - accuracy: 0.9145 - val_loss: 0.2029 - val_accuracy: 0.9168\n",
      "Epoch 251/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2120 - accuracy: 0.9117 - val_loss: 0.2274 - val_accuracy: 0.9079\n",
      "Epoch 252/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2073 - accuracy: 0.9141 - val_loss: 0.2069 - val_accuracy: 0.9154\n",
      "Epoch 253/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.9141 - val_loss: 0.2011 - val_accuracy: 0.9180\n",
      "Epoch 254/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2092 - accuracy: 0.9134 - val_loss: 0.2104 - val_accuracy: 0.9154\n",
      "Epoch 255/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2097 - accuracy: 0.9129 - val_loss: 0.2091 - val_accuracy: 0.9155\n",
      "Epoch 256/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2037 - accuracy: 0.9154 - val_loss: 0.2045 - val_accuracy: 0.9161\n",
      "Epoch 257/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2076 - accuracy: 0.9140 - val_loss: 0.2147 - val_accuracy: 0.9140\n",
      "Epoch 258/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2083 - accuracy: 0.9141 - val_loss: 0.2054 - val_accuracy: 0.9161\n",
      "Epoch 259/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2100 - accuracy: 0.9131 - val_loss: 0.2103 - val_accuracy: 0.9150\n",
      "Epoch 260/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9135 - val_loss: 0.2033 - val_accuracy: 0.9169\n",
      "Epoch 261/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2062 - accuracy: 0.9146 - val_loss: 0.2155 - val_accuracy: 0.9118\n",
      "Epoch 262/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2089 - accuracy: 0.9138 - val_loss: 0.2083 - val_accuracy: 0.9148\n",
      "Epoch 263/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9163 - val_loss: 0.2102 - val_accuracy: 0.9139\n",
      "Epoch 264/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2120 - accuracy: 0.9125 - val_loss: 0.2018 - val_accuracy: 0.9176\n",
      "Epoch 265/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2087 - accuracy: 0.9142 - val_loss: 0.2044 - val_accuracy: 0.9160\n",
      "Epoch 266/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2043 - accuracy: 0.9155 - val_loss: 0.2042 - val_accuracy: 0.9161\n",
      "Epoch 267/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2055 - accuracy: 0.9149 - val_loss: 0.2012 - val_accuracy: 0.9170\n",
      "Epoch 268/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2063 - accuracy: 0.9149 - val_loss: 0.2297 - val_accuracy: 0.9063\n",
      "Epoch 269/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2043 - accuracy: 0.9156 - val_loss: 0.2009 - val_accuracy: 0.9182\n",
      "Epoch 270/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2026 - accuracy: 0.9160 - val_loss: 0.2259 - val_accuracy: 0.9091\n",
      "Epoch 271/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2051 - accuracy: 0.9150 - val_loss: 0.1997 - val_accuracy: 0.9176\n",
      "Epoch 272/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2063 - accuracy: 0.9145 - val_loss: 0.2073 - val_accuracy: 0.9144\n",
      "Epoch 273/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2029 - accuracy: 0.9163 - val_loss: 0.2035 - val_accuracy: 0.9170\n",
      "Epoch 274/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9151 - val_loss: 0.2131 - val_accuracy: 0.9129\n",
      "Epoch 275/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2107 - accuracy: 0.9129 - val_loss: 0.2086 - val_accuracy: 0.9159\n",
      "Epoch 276/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9157 - val_loss: 0.1961 - val_accuracy: 0.9190\n",
      "Epoch 277/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2033 - accuracy: 0.9161 - val_loss: 0.2016 - val_accuracy: 0.9190\n",
      "Epoch 278/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2052 - accuracy: 0.9154 - val_loss: 0.2264 - val_accuracy: 0.9108\n",
      "Epoch 279/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2068 - accuracy: 0.9144 - val_loss: 0.2048 - val_accuracy: 0.9159\n",
      "Epoch 280/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2041 - accuracy: 0.9153 - val_loss: 0.1996 - val_accuracy: 0.9185\n",
      "Epoch 281/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9155 - val_loss: 0.2009 - val_accuracy: 0.9180\n",
      "Epoch 282/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.9158 - val_loss: 0.2045 - val_accuracy: 0.9163\n",
      "Epoch 283/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2066 - accuracy: 0.9142 - val_loss: 0.2043 - val_accuracy: 0.9170\n",
      "Epoch 284/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2043 - accuracy: 0.9155 - val_loss: 0.2019 - val_accuracy: 0.9160\n",
      "Epoch 285/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9153 - val_loss: 0.1993 - val_accuracy: 0.9181\n",
      "Epoch 286/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9156 - val_loss: 0.2043 - val_accuracy: 0.9158\n",
      "Epoch 287/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2005 - accuracy: 0.9168 - val_loss: 0.2077 - val_accuracy: 0.9146\n",
      "Epoch 288/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.9157 - val_loss: 0.2103 - val_accuracy: 0.9135\n",
      "Epoch 289/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2018 - accuracy: 0.9164 - val_loss: 0.2073 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9152 - val_loss: 0.2055 - val_accuracy: 0.9159\n",
      "Epoch 291/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2001 - accuracy: 0.9170 - val_loss: 0.1994 - val_accuracy: 0.9190\n",
      "Epoch 292/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2065 - accuracy: 0.9149 - val_loss: 0.1982 - val_accuracy: 0.9190\n",
      "Epoch 293/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.9154 - val_loss: 0.2019 - val_accuracy: 0.9176\n",
      "Epoch 294/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2030 - accuracy: 0.9160 - val_loss: 0.1968 - val_accuracy: 0.9200\n",
      "Epoch 295/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2066 - accuracy: 0.9149 - val_loss: 0.1952 - val_accuracy: 0.9201\n",
      "Epoch 296/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9173 - val_loss: 0.1985 - val_accuracy: 0.9191\n",
      "Epoch 297/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1991 - accuracy: 0.9172 - val_loss: 0.1970 - val_accuracy: 0.9195\n",
      "Epoch 298/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2042 - accuracy: 0.9156 - val_loss: 0.2119 - val_accuracy: 0.9139\n",
      "Epoch 299/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.9153 - val_loss: 0.1954 - val_accuracy: 0.9208\n",
      "Epoch 300/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2004 - accuracy: 0.9166 - val_loss: 0.2059 - val_accuracy: 0.9161\n",
      "Epoch 301/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9156 - val_loss: 0.1956 - val_accuracy: 0.9205\n",
      "Epoch 302/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9149 - val_loss: 0.1984 - val_accuracy: 0.9197\n",
      "Epoch 303/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1982 - accuracy: 0.9177 - val_loss: 0.2005 - val_accuracy: 0.9187\n",
      "Epoch 304/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2008 - accuracy: 0.9165 - val_loss: 0.2105 - val_accuracy: 0.9151\n",
      "Epoch 305/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1990 - accuracy: 0.9169 - val_loss: 0.1982 - val_accuracy: 0.9190\n",
      "Epoch 306/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2003 - accuracy: 0.9171 - val_loss: 0.1972 - val_accuracy: 0.9197\n",
      "Epoch 307/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2032 - accuracy: 0.9161 - val_loss: 0.2192 - val_accuracy: 0.9101\n",
      "Epoch 308/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2030 - accuracy: 0.9158 - val_loss: 0.1974 - val_accuracy: 0.9190\n",
      "Epoch 309/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1997 - accuracy: 0.9171 - val_loss: 0.2082 - val_accuracy: 0.9157\n",
      "Epoch 310/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9180 - val_loss: 0.2052 - val_accuracy: 0.9166\n",
      "Epoch 311/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9150 - val_loss: 0.2046 - val_accuracy: 0.9155\n",
      "Epoch 312/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1979 - accuracy: 0.9174 - val_loss: 0.2013 - val_accuracy: 0.9167\n",
      "Epoch 313/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2059 - accuracy: 0.9151 - val_loss: 0.2086 - val_accuracy: 0.9156\n",
      "Epoch 314/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9168 - val_loss: 0.2019 - val_accuracy: 0.9178\n",
      "Epoch 315/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2024 - accuracy: 0.9164 - val_loss: 0.1923 - val_accuracy: 0.9207\n",
      "Epoch 316/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1995 - accuracy: 0.9175 - val_loss: 0.2005 - val_accuracy: 0.9181\n",
      "Epoch 317/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9175 - val_loss: 0.1923 - val_accuracy: 0.9215\n",
      "Epoch 318/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2006 - accuracy: 0.9162 - val_loss: 0.2012 - val_accuracy: 0.9189\n",
      "Epoch 319/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1996 - accuracy: 0.9170 - val_loss: 0.2043 - val_accuracy: 0.9182\n",
      "Epoch 320/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2045 - accuracy: 0.9151 - val_loss: 0.1998 - val_accuracy: 0.9176\n",
      "Epoch 321/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9174 - val_loss: 0.1938 - val_accuracy: 0.9209\n",
      "Epoch 322/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1983 - accuracy: 0.9173 - val_loss: 0.1969 - val_accuracy: 0.9202\n",
      "Epoch 323/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2050 - accuracy: 0.9153 - val_loss: 0.2034 - val_accuracy: 0.9178\n",
      "Epoch 324/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2011 - accuracy: 0.9169 - val_loss: 0.1994 - val_accuracy: 0.9192\n",
      "Epoch 325/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9172 - val_loss: 0.1978 - val_accuracy: 0.9187\n",
      "Epoch 326/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2019 - accuracy: 0.9158 - val_loss: 0.2047 - val_accuracy: 0.9168\n",
      "Epoch 327/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9160 - val_loss: 0.1962 - val_accuracy: 0.9192\n",
      "Epoch 328/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1971 - accuracy: 0.9178 - val_loss: 0.1997 - val_accuracy: 0.9175\n",
      "Epoch 329/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9172 - val_loss: 0.1962 - val_accuracy: 0.9202\n",
      "Epoch 330/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1965 - accuracy: 0.9180 - val_loss: 0.1930 - val_accuracy: 0.9210\n",
      "Epoch 331/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2001 - accuracy: 0.9169 - val_loss: 0.1990 - val_accuracy: 0.9188\n",
      "Epoch 332/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1987 - accuracy: 0.9175 - val_loss: 0.2007 - val_accuracy: 0.9182\n",
      "Epoch 333/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1985 - accuracy: 0.9173 - val_loss: 0.2052 - val_accuracy: 0.9163\n",
      "Epoch 334/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1987 - accuracy: 0.9176 - val_loss: 0.1958 - val_accuracy: 0.9201\n",
      "Epoch 335/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1997 - accuracy: 0.9168 - val_loss: 0.1991 - val_accuracy: 0.9183\n",
      "Epoch 336/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1967 - accuracy: 0.9185 - val_loss: 0.2063 - val_accuracy: 0.9152\n",
      "Epoch 337/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1977 - accuracy: 0.9177 - val_loss: 0.1905 - val_accuracy: 0.9211\n",
      "Epoch 338/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1975 - accuracy: 0.9179 - val_loss: 0.2046 - val_accuracy: 0.9164\n",
      "Epoch 339/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9178 - val_loss: 0.1934 - val_accuracy: 0.9209\n",
      "Epoch 340/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9178 - val_loss: 0.2002 - val_accuracy: 0.9181\n",
      "Epoch 341/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9177 - val_loss: 0.1940 - val_accuracy: 0.9213\n",
      "Epoch 342/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1993 - accuracy: 0.9171 - val_loss: 0.1975 - val_accuracy: 0.9192\n",
      "Epoch 343/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1979 - accuracy: 0.9176 - val_loss: 0.1941 - val_accuracy: 0.9195\n",
      "Epoch 344/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9180 - val_loss: 0.2041 - val_accuracy: 0.9159\n",
      "Epoch 345/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1971 - accuracy: 0.9177 - val_loss: 0.1947 - val_accuracy: 0.9211\n",
      "Epoch 346/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9179 - val_loss: 0.1953 - val_accuracy: 0.9199\n",
      "Epoch 347/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1939 - accuracy: 0.9193 - val_loss: 0.1973 - val_accuracy: 0.9204\n",
      "Epoch 348/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1990 - accuracy: 0.9175 - val_loss: 0.2103 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1966 - accuracy: 0.9181 - val_loss: 0.2071 - val_accuracy: 0.9154\n",
      "Epoch 350/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1948 - accuracy: 0.9184 - val_loss: 0.2049 - val_accuracy: 0.9165\n",
      "Epoch 351/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9175 - val_loss: 0.2035 - val_accuracy: 0.9174\n",
      "Epoch 352/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1996 - accuracy: 0.9165 - val_loss: 0.1934 - val_accuracy: 0.9209\n",
      "Epoch 353/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9193 - val_loss: 0.2068 - val_accuracy: 0.9160\n",
      "Epoch 354/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9183 - val_loss: 0.1931 - val_accuracy: 0.9209\n",
      "Epoch 355/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1961 - accuracy: 0.9185 - val_loss: 0.2089 - val_accuracy: 0.9157\n",
      "Epoch 356/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2007 - accuracy: 0.9165 - val_loss: 0.2030 - val_accuracy: 0.9182\n",
      "Epoch 357/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1983 - accuracy: 0.9177 - val_loss: 0.1938 - val_accuracy: 0.9204\n",
      "Epoch 358/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9179 - val_loss: 0.2102 - val_accuracy: 0.9137\n",
      "Epoch 359/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1960 - accuracy: 0.9181 - val_loss: 0.1985 - val_accuracy: 0.9176\n",
      "Epoch 360/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1978 - accuracy: 0.9179 - val_loss: 0.1955 - val_accuracy: 0.9195\n",
      "Epoch 361/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1935 - accuracy: 0.9191 - val_loss: 0.1976 - val_accuracy: 0.9186\n",
      "Epoch 362/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1970 - accuracy: 0.9178 - val_loss: 0.1998 - val_accuracy: 0.9183\n",
      "Epoch 363/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9177 - val_loss: 0.2023 - val_accuracy: 0.9165\n",
      "Epoch 364/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1981 - accuracy: 0.9177 - val_loss: 0.1908 - val_accuracy: 0.9205\n",
      "Epoch 365/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1929 - accuracy: 0.9190 - val_loss: 0.1970 - val_accuracy: 0.9184\n",
      "Epoch 366/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1974 - accuracy: 0.9181 - val_loss: 0.2067 - val_accuracy: 0.9168\n",
      "Epoch 367/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1958 - accuracy: 0.9185 - val_loss: 0.1912 - val_accuracy: 0.9213\n",
      "Epoch 368/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1965 - accuracy: 0.9179 - val_loss: 0.1899 - val_accuracy: 0.9218\n",
      "Epoch 369/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1920 - accuracy: 0.9198 - val_loss: 0.1947 - val_accuracy: 0.9198\n",
      "Epoch 370/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9190 - val_loss: 0.1905 - val_accuracy: 0.9217\n",
      "Epoch 371/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1988 - accuracy: 0.9173 - val_loss: 0.2026 - val_accuracy: 0.9166\n",
      "Epoch 372/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.9188 - val_loss: 0.1908 - val_accuracy: 0.9215\n",
      "Epoch 373/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1962 - accuracy: 0.9179 - val_loss: 0.1884 - val_accuracy: 0.9222\n",
      "Epoch 374/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1949 - accuracy: 0.9188 - val_loss: 0.1880 - val_accuracy: 0.9233\n",
      "Epoch 375/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1907 - accuracy: 0.9206 - val_loss: 0.1923 - val_accuracy: 0.9209\n",
      "Epoch 376/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1936 - accuracy: 0.9188 - val_loss: 0.2052 - val_accuracy: 0.9203\n",
      "Epoch 377/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1959 - accuracy: 0.9181 - val_loss: 0.1902 - val_accuracy: 0.9211\n",
      "Epoch 378/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1981 - accuracy: 0.9180 - val_loss: 0.2021 - val_accuracy: 0.9177\n",
      "Epoch 379/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1967 - accuracy: 0.9183 - val_loss: 0.1915 - val_accuracy: 0.9213\n",
      "Epoch 380/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1892 - accuracy: 0.9209 - val_loss: 0.1933 - val_accuracy: 0.9207\n",
      "Epoch 381/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.9187 - val_loss: 0.1901 - val_accuracy: 0.9215\n",
      "Epoch 382/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9171 - val_loss: 0.1964 - val_accuracy: 0.9191\n",
      "Epoch 383/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1963 - accuracy: 0.9180 - val_loss: 0.1982 - val_accuracy: 0.9191\n",
      "Epoch 384/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1960 - accuracy: 0.9185 - val_loss: 0.1903 - val_accuracy: 0.9221\n",
      "Epoch 385/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1939 - accuracy: 0.9195 - val_loss: 0.1913 - val_accuracy: 0.9213\n",
      "Epoch 386/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9190 - val_loss: 0.1928 - val_accuracy: 0.9210\n",
      "Epoch 387/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1930 - accuracy: 0.9190 - val_loss: 0.1887 - val_accuracy: 0.9220\n",
      "Epoch 388/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1904 - accuracy: 0.9205 - val_loss: 0.1936 - val_accuracy: 0.9197\n",
      "Epoch 389/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1925 - accuracy: 0.9199 - val_loss: 0.1899 - val_accuracy: 0.9221\n",
      "Epoch 390/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1953 - accuracy: 0.9188 - val_loss: 0.1875 - val_accuracy: 0.9233\n",
      "Epoch 391/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1931 - accuracy: 0.9191 - val_loss: 0.1925 - val_accuracy: 0.9206\n",
      "Epoch 392/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1935 - accuracy: 0.9192 - val_loss: 0.2169 - val_accuracy: 0.9107\n",
      "Epoch 393/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.9189 - val_loss: 0.1933 - val_accuracy: 0.9208\n",
      "Epoch 394/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9179 - val_loss: 0.2165 - val_accuracy: 0.9125\n",
      "Epoch 395/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1934 - accuracy: 0.9193 - val_loss: 0.2142 - val_accuracy: 0.9124\n",
      "Epoch 396/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1932 - accuracy: 0.9193 - val_loss: 0.1933 - val_accuracy: 0.9201\n",
      "Epoch 397/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1913 - accuracy: 0.9197 - val_loss: 0.1946 - val_accuracy: 0.9194\n",
      "Epoch 398/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1920 - accuracy: 0.9203 - val_loss: 0.1918 - val_accuracy: 0.9210\n",
      "Epoch 399/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1896 - accuracy: 0.9203 - val_loss: 0.1876 - val_accuracy: 0.9226\n",
      "Epoch 400/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1945 - accuracy: 0.9193 - val_loss: 0.1925 - val_accuracy: 0.9212\n",
      "Epoch 401/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1889 - accuracy: 0.9206 - val_loss: 0.1898 - val_accuracy: 0.9212\n",
      "Epoch 402/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1956 - accuracy: 0.9185 - val_loss: 0.1906 - val_accuracy: 0.9209\n",
      "Epoch 403/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1918 - accuracy: 0.9196 - val_loss: 0.2226 - val_accuracy: 0.9087\n",
      "Epoch 404/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1926 - accuracy: 0.9196 - val_loss: 0.1933 - val_accuracy: 0.9198\n",
      "Epoch 405/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1888 - accuracy: 0.9207 - val_loss: 0.1952 - val_accuracy: 0.9186\n",
      "Epoch 406/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9188 - val_loss: 0.1924 - val_accuracy: 0.9206\n",
      "Epoch 407/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1936 - accuracy: 0.9195 - val_loss: 0.2280 - val_accuracy: 0.9063\n",
      "Epoch 408/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1957 - accuracy: 0.9183 - val_loss: 0.1860 - val_accuracy: 0.9231\n",
      "Epoch 409/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9211 - val_loss: 0.1890 - val_accuracy: 0.9234\n",
      "Epoch 410/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1900 - accuracy: 0.9206 - val_loss: 0.2096 - val_accuracy: 0.9151\n",
      "Epoch 411/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1954 - accuracy: 0.9189 - val_loss: 0.1882 - val_accuracy: 0.9223\n",
      "Epoch 412/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1907 - accuracy: 0.9199 - val_loss: 0.1929 - val_accuracy: 0.9205\n",
      "Epoch 413/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1920 - accuracy: 0.9201 - val_loss: 0.1881 - val_accuracy: 0.9227\n",
      "Epoch 414/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1926 - accuracy: 0.9192 - val_loss: 0.2128 - val_accuracy: 0.9129\n",
      "Epoch 415/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1953 - accuracy: 0.9186 - val_loss: 0.2268 - val_accuracy: 0.9082\n",
      "Epoch 416/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1917 - accuracy: 0.9197 - val_loss: 0.1882 - val_accuracy: 0.9229\n",
      "Epoch 417/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1965 - accuracy: 0.9182 - val_loss: 0.1925 - val_accuracy: 0.9205\n",
      "Epoch 418/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1955 - accuracy: 0.9187 - val_loss: 0.1864 - val_accuracy: 0.9235\n",
      "Epoch 419/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9208 - val_loss: 0.2041 - val_accuracy: 0.9151\n",
      "Epoch 420/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.9188 - val_loss: 0.2013 - val_accuracy: 0.9204\n",
      "Epoch 421/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9209 - val_loss: 0.1893 - val_accuracy: 0.9214\n",
      "Epoch 422/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1877 - accuracy: 0.9206 - val_loss: 0.1899 - val_accuracy: 0.9218\n",
      "Epoch 423/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1907 - accuracy: 0.9205 - val_loss: 0.1907 - val_accuracy: 0.9208\n",
      "Epoch 424/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1930 - accuracy: 0.9194 - val_loss: 0.1918 - val_accuracy: 0.9220\n",
      "Epoch 425/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1918 - accuracy: 0.9193 - val_loss: 0.1921 - val_accuracy: 0.9209\n",
      "Epoch 426/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1918 - accuracy: 0.9203 - val_loss: 0.1955 - val_accuracy: 0.9183\n",
      "Epoch 427/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1942 - accuracy: 0.9190 - val_loss: 0.1907 - val_accuracy: 0.9210\n",
      "Epoch 428/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1905 - accuracy: 0.9204 - val_loss: 0.1857 - val_accuracy: 0.9231\n",
      "Epoch 429/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1908 - accuracy: 0.9202 - val_loss: 0.1975 - val_accuracy: 0.9182\n",
      "Epoch 430/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9206 - val_loss: 0.1827 - val_accuracy: 0.9248\n",
      "Epoch 431/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9214 - val_loss: 0.1842 - val_accuracy: 0.9245\n",
      "Epoch 432/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1914 - accuracy: 0.9202 - val_loss: 0.2102 - val_accuracy: 0.9146\n",
      "Epoch 433/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9200 - val_loss: 0.1842 - val_accuracy: 0.9238\n",
      "Epoch 434/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9209 - val_loss: 0.1991 - val_accuracy: 0.9201\n",
      "Epoch 435/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1960 - accuracy: 0.9184 - val_loss: 0.1878 - val_accuracy: 0.9227\n",
      "Epoch 436/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1919 - accuracy: 0.9197 - val_loss: 0.2114 - val_accuracy: 0.9136\n",
      "Epoch 437/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1912 - accuracy: 0.9199 - val_loss: 0.1915 - val_accuracy: 0.9212\n",
      "Epoch 438/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1899 - accuracy: 0.9202 - val_loss: 0.1927 - val_accuracy: 0.9209\n",
      "Epoch 439/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.9208 - val_loss: 0.1845 - val_accuracy: 0.9233\n",
      "Epoch 440/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1908 - accuracy: 0.9204 - val_loss: 0.1910 - val_accuracy: 0.9209\n",
      "Epoch 441/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1928 - accuracy: 0.9196 - val_loss: 0.1918 - val_accuracy: 0.9213\n",
      "Epoch 442/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1899 - accuracy: 0.9202 - val_loss: 0.1902 - val_accuracy: 0.9218\n",
      "Epoch 443/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.9208 - val_loss: 0.1864 - val_accuracy: 0.9229\n",
      "Epoch 444/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1884 - accuracy: 0.9211 - val_loss: 0.1924 - val_accuracy: 0.9208\n",
      "Epoch 445/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1930 - accuracy: 0.9195 - val_loss: 0.1900 - val_accuracy: 0.9217\n",
      "Epoch 446/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9207 - val_loss: 0.1900 - val_accuracy: 0.9210\n",
      "Epoch 447/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1892 - accuracy: 0.9205 - val_loss: 0.1898 - val_accuracy: 0.9212\n",
      "Epoch 448/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1900 - accuracy: 0.9201 - val_loss: 0.1922 - val_accuracy: 0.9200\n",
      "Epoch 449/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1878 - accuracy: 0.9215 - val_loss: 0.1893 - val_accuracy: 0.9234\n",
      "Epoch 450/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9210 - val_loss: 0.1944 - val_accuracy: 0.9192\n",
      "Epoch 451/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9215 - val_loss: 0.1897 - val_accuracy: 0.9213\n",
      "Epoch 452/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1898 - accuracy: 0.9204 - val_loss: 0.1895 - val_accuracy: 0.9211\n",
      "Epoch 453/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1863 - accuracy: 0.9220 - val_loss: 0.1881 - val_accuracy: 0.9209\n",
      "Epoch 454/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1902 - accuracy: 0.9201 - val_loss: 0.1942 - val_accuracy: 0.9202\n",
      "Epoch 455/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1862 - accuracy: 0.9214 - val_loss: 0.2031 - val_accuracy: 0.9158\n",
      "Epoch 456/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1897 - accuracy: 0.9201 - val_loss: 0.1918 - val_accuracy: 0.9209\n",
      "Epoch 457/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9212 - val_loss: 0.1858 - val_accuracy: 0.9228\n",
      "Epoch 458/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1889 - accuracy: 0.9205 - val_loss: 0.2179 - val_accuracy: 0.9109\n",
      "Epoch 459/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1874 - accuracy: 0.9215 - val_loss: 0.1855 - val_accuracy: 0.9238\n",
      "Epoch 460/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1870 - accuracy: 0.9213 - val_loss: 0.1919 - val_accuracy: 0.9207\n",
      "Epoch 461/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1893 - accuracy: 0.9205 - val_loss: 0.1897 - val_accuracy: 0.9211\n",
      "Epoch 462/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1859 - accuracy: 0.9218 - val_loss: 0.1906 - val_accuracy: 0.9212\n",
      "Epoch 463/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1878 - accuracy: 0.9211 - val_loss: 0.1887 - val_accuracy: 0.9216\n",
      "Epoch 464/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9209 - val_loss: 0.1841 - val_accuracy: 0.9242\n",
      "Epoch 465/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1892 - accuracy: 0.9206 - val_loss: 0.1915 - val_accuracy: 0.9210\n",
      "Epoch 466/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1862 - accuracy: 0.9217 - val_loss: 0.1915 - val_accuracy: 0.9223\n",
      "Epoch 467/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9202 - val_loss: 0.1883 - val_accuracy: 0.9226\n",
      "Epoch 468/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.9217 - val_loss: 0.1953 - val_accuracy: 0.9200\n",
      "Epoch 469/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9210 - val_loss: 0.1895 - val_accuracy: 0.9223\n",
      "Epoch 470/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1865 - accuracy: 0.9219 - val_loss: 0.1875 - val_accuracy: 0.9230\n",
      "Epoch 471/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9212 - val_loss: 0.1865 - val_accuracy: 0.9235\n",
      "Epoch 472/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1885 - accuracy: 0.9209 - val_loss: 0.1909 - val_accuracy: 0.9207\n",
      "Epoch 473/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1864 - accuracy: 0.9216 - val_loss: 0.1815 - val_accuracy: 0.9245\n",
      "Epoch 474/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9216 - val_loss: 0.1868 - val_accuracy: 0.9232\n",
      "Epoch 475/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9205 - val_loss: 0.1935 - val_accuracy: 0.9207\n",
      "Epoch 476/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1905 - accuracy: 0.9199 - val_loss: 0.1927 - val_accuracy: 0.9190\n",
      "Epoch 477/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.9203 - val_loss: 0.1843 - val_accuracy: 0.9231\n",
      "Epoch 478/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1859 - accuracy: 0.9219 - val_loss: 0.1928 - val_accuracy: 0.9202\n",
      "Epoch 479/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1852 - accuracy: 0.9219 - val_loss: 0.1873 - val_accuracy: 0.9236\n",
      "Epoch 480/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1913 - accuracy: 0.9202 - val_loss: 0.1948 - val_accuracy: 0.9187\n",
      "Epoch 481/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1875 - accuracy: 0.9215 - val_loss: 0.1885 - val_accuracy: 0.9217\n",
      "Epoch 482/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.2042 - val_accuracy: 0.9161\n",
      "Epoch 483/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1878 - accuracy: 0.9212 - val_loss: 0.1989 - val_accuracy: 0.9186\n",
      "Epoch 484/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1862 - accuracy: 0.9216 - val_loss: 0.2027 - val_accuracy: 0.9164\n",
      "Epoch 485/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1861 - accuracy: 0.9218 - val_loss: 0.1979 - val_accuracy: 0.9186\n",
      "Epoch 486/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1850 - accuracy: 0.9221 - val_loss: 0.1856 - val_accuracy: 0.9227\n",
      "Epoch 487/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9219 - val_loss: 0.1935 - val_accuracy: 0.9210\n",
      "Epoch 488/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1862 - accuracy: 0.9220 - val_loss: 0.1862 - val_accuracy: 0.9239\n",
      "Epoch 489/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1864 - accuracy: 0.9214 - val_loss: 0.2007 - val_accuracy: 0.9175\n",
      "Epoch 490/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9209 - val_loss: 0.1937 - val_accuracy: 0.9195\n",
      "Epoch 491/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1885 - accuracy: 0.9209 - val_loss: 0.1882 - val_accuracy: 0.9219\n",
      "Epoch 492/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9215 - val_loss: 0.2022 - val_accuracy: 0.9167\n",
      "Epoch 493/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1854 - accuracy: 0.9220 - val_loss: 0.1829 - val_accuracy: 0.9244\n",
      "Epoch 494/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9220 - val_loss: 0.1828 - val_accuracy: 0.9239\n",
      "Epoch 495/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1898 - accuracy: 0.9207 - val_loss: 0.1823 - val_accuracy: 0.9246\n",
      "Epoch 496/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9209 - val_loss: 0.2192 - val_accuracy: 0.9119\n",
      "Epoch 497/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9214 - val_loss: 0.1785 - val_accuracy: 0.9254\n",
      "Epoch 498/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9231 - val_loss: 0.1842 - val_accuracy: 0.9237\n",
      "Epoch 499/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1871 - accuracy: 0.9217 - val_loss: 0.1916 - val_accuracy: 0.9207\n",
      "Epoch 500/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9216 - val_loss: 0.1871 - val_accuracy: 0.9223\n",
      "Epoch 501/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1893 - accuracy: 0.9204 - val_loss: 0.1866 - val_accuracy: 0.9231\n",
      "Epoch 502/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9217 - val_loss: 0.1850 - val_accuracy: 0.9229\n",
      "Epoch 503/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1819 - accuracy: 0.9231 - val_loss: 0.1933 - val_accuracy: 0.9201\n",
      "Epoch 504/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1859 - accuracy: 0.9217 - val_loss: 0.1815 - val_accuracy: 0.9241\n",
      "Epoch 505/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1888 - accuracy: 0.9204 - val_loss: 0.1918 - val_accuracy: 0.9211\n",
      "Epoch 506/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9228 - val_loss: 0.1939 - val_accuracy: 0.9199\n",
      "Epoch 507/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1850 - accuracy: 0.9218 - val_loss: 0.1858 - val_accuracy: 0.9227\n",
      "Epoch 508/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1850 - accuracy: 0.9223 - val_loss: 0.1918 - val_accuracy: 0.9207\n",
      "Epoch 509/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1897 - accuracy: 0.9210 - val_loss: 0.1869 - val_accuracy: 0.9239\n",
      "Epoch 510/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1826 - accuracy: 0.9234 - val_loss: 0.1861 - val_accuracy: 0.9235\n",
      "Epoch 511/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9213 - val_loss: 0.1915 - val_accuracy: 0.9217\n",
      "Epoch 512/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9226 - val_loss: 0.1844 - val_accuracy: 0.9233\n",
      "Epoch 513/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1857 - accuracy: 0.9218 - val_loss: 0.1948 - val_accuracy: 0.9202\n",
      "Epoch 514/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9226 - val_loss: 0.1948 - val_accuracy: 0.9200\n",
      "Epoch 515/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9224 - val_loss: 0.1849 - val_accuracy: 0.9240\n",
      "Epoch 516/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9229 - val_loss: 0.1808 - val_accuracy: 0.9248\n",
      "Epoch 517/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9223 - val_loss: 0.1969 - val_accuracy: 0.9191\n",
      "Epoch 518/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9226 - val_loss: 0.1881 - val_accuracy: 0.9220\n",
      "Epoch 519/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9203 - val_loss: 0.1842 - val_accuracy: 0.9241\n",
      "Epoch 520/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1847 - accuracy: 0.9225 - val_loss: 0.1862 - val_accuracy: 0.9225\n",
      "Epoch 521/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9224 - val_loss: 0.1917 - val_accuracy: 0.9209\n",
      "Epoch 522/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9236 - val_loss: 0.1787 - val_accuracy: 0.9260\n",
      "Epoch 523/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9224 - val_loss: 0.1931 - val_accuracy: 0.9193\n",
      "Epoch 524/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1933 - accuracy: 0.9191 - val_loss: 0.1970 - val_accuracy: 0.9183\n",
      "Epoch 525/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9229 - val_loss: 0.1839 - val_accuracy: 0.9238\n",
      "Epoch 526/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1886 - accuracy: 0.9208 - val_loss: 0.1859 - val_accuracy: 0.9227\n",
      "Epoch 527/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9218 - val_loss: 0.1970 - val_accuracy: 0.9204\n",
      "Epoch 528/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9226 - val_loss: 0.1839 - val_accuracy: 0.9234\n",
      "Epoch 529/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9218 - val_loss: 0.1858 - val_accuracy: 0.9247\n",
      "Epoch 530/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9226 - val_loss: 0.1827 - val_accuracy: 0.9234\n",
      "Epoch 531/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9226 - val_loss: 0.1932 - val_accuracy: 0.9201\n",
      "Epoch 532/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9233 - val_loss: 0.1939 - val_accuracy: 0.9199\n",
      "Epoch 533/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9221 - val_loss: 0.1888 - val_accuracy: 0.9228\n",
      "Epoch 534/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1804 - accuracy: 0.9240 - val_loss: 0.1824 - val_accuracy: 0.9241\n",
      "Epoch 535/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9220 - val_loss: 0.1842 - val_accuracy: 0.9238\n",
      "Epoch 536/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9227 - val_loss: 0.1855 - val_accuracy: 0.9227\n",
      "Epoch 537/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1882 - accuracy: 0.9207 - val_loss: 0.1943 - val_accuracy: 0.9194\n",
      "Epoch 538/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1882 - accuracy: 0.9211 - val_loss: 0.1894 - val_accuracy: 0.9221\n",
      "Epoch 539/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9229 - val_loss: 0.1861 - val_accuracy: 0.9228\n",
      "Epoch 540/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1838 - accuracy: 0.9222 - val_loss: 0.1872 - val_accuracy: 0.9221\n",
      "Epoch 541/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1834 - accuracy: 0.9227 - val_loss: 0.1877 - val_accuracy: 0.9225\n",
      "Epoch 542/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9223 - val_loss: 0.1879 - val_accuracy: 0.9216\n",
      "Epoch 543/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9229 - val_loss: 0.1929 - val_accuracy: 0.9206\n",
      "Epoch 544/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1863 - accuracy: 0.9212 - val_loss: 0.1820 - val_accuracy: 0.9243\n",
      "Epoch 545/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1841 - accuracy: 0.9223 - val_loss: 0.2096 - val_accuracy: 0.9143\n",
      "Epoch 546/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1854 - accuracy: 0.9218 - val_loss: 0.2013 - val_accuracy: 0.9191\n",
      "Epoch 547/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1847 - accuracy: 0.9223 - val_loss: 0.1805 - val_accuracy: 0.9240\n",
      "Epoch 548/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9216 - val_loss: 0.1988 - val_accuracy: 0.9179\n",
      "Epoch 549/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1836 - accuracy: 0.9226 - val_loss: 0.1819 - val_accuracy: 0.9240\n",
      "Epoch 550/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1848 - accuracy: 0.9224 - val_loss: 0.1870 - val_accuracy: 0.9229\n",
      "Epoch 551/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1812 - accuracy: 0.9235 - val_loss: 0.1847 - val_accuracy: 0.9237\n",
      "Epoch 552/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1823 - accuracy: 0.9230 - val_loss: 0.1855 - val_accuracy: 0.9240\n",
      "Epoch 553/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9224 - val_loss: 0.1802 - val_accuracy: 0.9250\n",
      "Epoch 554/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9242 - val_loss: 0.1785 - val_accuracy: 0.9252\n",
      "Epoch 555/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9229 - val_loss: 0.1863 - val_accuracy: 0.9221\n",
      "Epoch 556/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9235 - val_loss: 0.2012 - val_accuracy: 0.9180\n",
      "Epoch 557/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1852 - accuracy: 0.9216 - val_loss: 0.1779 - val_accuracy: 0.9260\n",
      "Epoch 558/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1849 - accuracy: 0.9222 - val_loss: 0.1777 - val_accuracy: 0.9259\n",
      "Epoch 559/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1846 - accuracy: 0.9226 - val_loss: 0.1815 - val_accuracy: 0.9247\n",
      "Epoch 560/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9228 - val_loss: 0.2011 - val_accuracy: 0.9178\n",
      "Epoch 561/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1816 - accuracy: 0.9228 - val_loss: 0.1807 - val_accuracy: 0.9252\n",
      "Epoch 562/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9227 - val_loss: 0.1829 - val_accuracy: 0.9248\n",
      "Epoch 563/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1827 - accuracy: 0.9228 - val_loss: 0.1820 - val_accuracy: 0.9252\n",
      "Epoch 564/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9222 - val_loss: 0.1930 - val_accuracy: 0.9207\n",
      "Epoch 565/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1875 - accuracy: 0.9210 - val_loss: 0.1820 - val_accuracy: 0.9240\n",
      "Epoch 566/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9226 - val_loss: 0.1947 - val_accuracy: 0.9188\n",
      "Epoch 567/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1817 - accuracy: 0.9232 - val_loss: 0.1850 - val_accuracy: 0.9232\n",
      "Epoch 568/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9228 - val_loss: 0.1980 - val_accuracy: 0.9184\n",
      "Epoch 569/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9228 - val_loss: 0.1829 - val_accuracy: 0.9252\n",
      "Epoch 570/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.9239 - val_loss: 0.1799 - val_accuracy: 0.9250\n",
      "Epoch 571/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1877 - accuracy: 0.9209 - val_loss: 0.1853 - val_accuracy: 0.9221\n",
      "Epoch 572/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.9238 - val_loss: 0.1872 - val_accuracy: 0.9221\n",
      "Epoch 573/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1790 - accuracy: 0.9245 - val_loss: 0.1867 - val_accuracy: 0.9235\n",
      "Epoch 574/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9217 - val_loss: 0.1825 - val_accuracy: 0.9243\n",
      "Epoch 575/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9240 - val_loss: 0.1845 - val_accuracy: 0.9226\n",
      "Epoch 576/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9222 - val_loss: 0.2086 - val_accuracy: 0.9136\n",
      "Epoch 577/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1832 - accuracy: 0.9226 - val_loss: 0.1828 - val_accuracy: 0.9244\n",
      "Epoch 578/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9233 - val_loss: 0.1887 - val_accuracy: 0.9209\n",
      "Epoch 579/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9228 - val_loss: 0.1861 - val_accuracy: 0.9223\n",
      "Epoch 580/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9229 - val_loss: 0.1805 - val_accuracy: 0.9243\n",
      "Epoch 581/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9237 - val_loss: 0.1894 - val_accuracy: 0.9212\n",
      "Epoch 582/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1819 - accuracy: 0.9232 - val_loss: 0.1843 - val_accuracy: 0.9232\n",
      "Epoch 583/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1846 - accuracy: 0.9221 - val_loss: 0.1776 - val_accuracy: 0.9263\n",
      "Epoch 584/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9224 - val_loss: 0.1954 - val_accuracy: 0.9195\n",
      "Epoch 585/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9242 - val_loss: 0.1964 - val_accuracy: 0.9196\n",
      "Epoch 586/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.9238 - val_loss: 0.1898 - val_accuracy: 0.9211\n",
      "Epoch 587/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9238 - val_loss: 0.1855 - val_accuracy: 0.9233\n",
      "Epoch 588/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.9216 - val_loss: 0.1921 - val_accuracy: 0.9213\n",
      "Epoch 589/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9229 - val_loss: 0.1825 - val_accuracy: 0.9242\n",
      "Epoch 590/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9237 - val_loss: 0.1771 - val_accuracy: 0.9255\n",
      "Epoch 591/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.9240 - val_loss: 0.1851 - val_accuracy: 0.9240\n",
      "Epoch 592/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9235 - val_loss: 0.1830 - val_accuracy: 0.9235\n",
      "Epoch 593/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1780 - accuracy: 0.9243 - val_loss: 0.1858 - val_accuracy: 0.9218\n",
      "Epoch 594/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1773 - accuracy: 0.9249 - val_loss: 0.1910 - val_accuracy: 0.9199\n",
      "Epoch 595/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1867 - accuracy: 0.9211 - val_loss: 0.1794 - val_accuracy: 0.9254\n",
      "Epoch 596/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9243 - val_loss: 0.1792 - val_accuracy: 0.9250\n",
      "Epoch 597/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1792 - accuracy: 0.9239 - val_loss: 0.1843 - val_accuracy: 0.9228\n",
      "Epoch 598/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1816 - accuracy: 0.9232 - val_loss: 0.1808 - val_accuracy: 0.9245\n",
      "Epoch 599/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1824 - accuracy: 0.9228 - val_loss: 0.1845 - val_accuracy: 0.9237\n",
      "Epoch 600/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9230 - val_loss: 0.1787 - val_accuracy: 0.9258\n",
      "Epoch 601/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9234 - val_loss: 0.1767 - val_accuracy: 0.9259\n",
      "Epoch 602/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1808 - accuracy: 0.9236 - val_loss: 0.1952 - val_accuracy: 0.9190\n",
      "Epoch 603/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1790 - accuracy: 0.9242 - val_loss: 0.1792 - val_accuracy: 0.9248\n",
      "Epoch 604/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1822 - accuracy: 0.9233 - val_loss: 0.1862 - val_accuracy: 0.9225\n",
      "Epoch 605/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9248 - val_loss: 0.1842 - val_accuracy: 0.9236\n",
      "Epoch 606/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9244 - val_loss: 0.1824 - val_accuracy: 0.9239\n",
      "Epoch 607/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9236 - val_loss: 0.1826 - val_accuracy: 0.9243\n",
      "Epoch 608/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9243 - val_loss: 0.1758 - val_accuracy: 0.9269\n",
      "Epoch 609/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1799 - accuracy: 0.9240 - val_loss: 0.1832 - val_accuracy: 0.9240\n",
      "Epoch 610/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9241 - val_loss: 0.1778 - val_accuracy: 0.9248\n",
      "Epoch 611/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1822 - accuracy: 0.9230 - val_loss: 0.1817 - val_accuracy: 0.9242\n",
      "Epoch 612/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1791 - accuracy: 0.9241 - val_loss: 0.1851 - val_accuracy: 0.9228\n",
      "Epoch 613/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1799 - accuracy: 0.9242 - val_loss: 0.1775 - val_accuracy: 0.9259\n",
      "Epoch 614/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9232 - val_loss: 0.1758 - val_accuracy: 0.9266\n",
      "Epoch 615/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9233 - val_loss: 0.1950 - val_accuracy: 0.9198\n",
      "Epoch 616/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9222 - val_loss: 0.1898 - val_accuracy: 0.9206\n",
      "Epoch 617/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9243 - val_loss: 0.1810 - val_accuracy: 0.9249\n",
      "Epoch 618/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9244 - val_loss: 0.1807 - val_accuracy: 0.9245\n",
      "Epoch 619/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9239 - val_loss: 0.1789 - val_accuracy: 0.9252\n",
      "Epoch 620/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9223 - val_loss: 0.2007 - val_accuracy: 0.9172\n",
      "Epoch 621/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1794 - accuracy: 0.9240 - val_loss: 0.1882 - val_accuracy: 0.9223\n",
      "Epoch 622/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9234 - val_loss: 0.1853 - val_accuracy: 0.9231\n",
      "Epoch 623/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9221 - val_loss: 0.1882 - val_accuracy: 0.9219\n",
      "Epoch 624/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9234 - val_loss: 0.2063 - val_accuracy: 0.9152\n",
      "Epoch 625/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1783 - accuracy: 0.9246 - val_loss: 0.1872 - val_accuracy: 0.9226\n",
      "Epoch 626/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1784 - accuracy: 0.9240 - val_loss: 0.1909 - val_accuracy: 0.9216\n",
      "Epoch 627/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1819 - accuracy: 0.9230 - val_loss: 0.1806 - val_accuracy: 0.9248\n",
      "Epoch 628/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9245 - val_loss: 0.1901 - val_accuracy: 0.9219\n",
      "Epoch 629/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9250 - val_loss: 0.1872 - val_accuracy: 0.9224\n",
      "Epoch 630/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1832 - accuracy: 0.9227 - val_loss: 0.1775 - val_accuracy: 0.9262\n",
      "Epoch 631/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9245 - val_loss: 0.1825 - val_accuracy: 0.9241\n",
      "Epoch 632/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1814 - accuracy: 0.9233 - val_loss: 0.1868 - val_accuracy: 0.9225\n",
      "Epoch 633/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1791 - accuracy: 0.9242 - val_loss: 0.1795 - val_accuracy: 0.9253\n",
      "Epoch 634/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.9238 - val_loss: 0.1853 - val_accuracy: 0.9227\n",
      "Epoch 635/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1805 - accuracy: 0.9237 - val_loss: 0.1802 - val_accuracy: 0.9253\n",
      "Epoch 636/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1783 - accuracy: 0.9245 - val_loss: 0.1786 - val_accuracy: 0.9254\n",
      "Epoch 637/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1834 - accuracy: 0.9225 - val_loss: 0.1788 - val_accuracy: 0.9251\n",
      "Epoch 638/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9248 - val_loss: 0.1745 - val_accuracy: 0.9271\n",
      "Epoch 639/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9247 - val_loss: 0.1804 - val_accuracy: 0.9241\n",
      "Epoch 640/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9247 - val_loss: 0.1833 - val_accuracy: 0.9237\n",
      "Epoch 641/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1799 - accuracy: 0.9241 - val_loss: 0.1777 - val_accuracy: 0.9261\n",
      "Epoch 642/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1817 - accuracy: 0.9230 - val_loss: 0.1789 - val_accuracy: 0.9255\n",
      "Epoch 643/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9239 - val_loss: 0.1831 - val_accuracy: 0.9239\n",
      "Epoch 644/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1797 - accuracy: 0.9238 - val_loss: 0.1809 - val_accuracy: 0.9235\n",
      "Epoch 645/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9240 - val_loss: 0.1876 - val_accuracy: 0.9217\n",
      "Epoch 646/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9238 - val_loss: 0.1837 - val_accuracy: 0.9227\n",
      "Epoch 647/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9243 - val_loss: 0.1919 - val_accuracy: 0.9228\n",
      "Epoch 648/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.9235 - val_loss: 0.1858 - val_accuracy: 0.9222\n",
      "Epoch 649/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9246 - val_loss: 0.1785 - val_accuracy: 0.9257\n",
      "Epoch 650/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9245 - val_loss: 0.1784 - val_accuracy: 0.9260\n",
      "Epoch 651/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9242 - val_loss: 0.1862 - val_accuracy: 0.9228\n",
      "Epoch 652/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9230 - val_loss: 0.1780 - val_accuracy: 0.9253\n",
      "Epoch 653/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9249 - val_loss: 0.1896 - val_accuracy: 0.9222\n",
      "Epoch 654/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9249 - val_loss: 0.1852 - val_accuracy: 0.9226\n",
      "Epoch 655/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1785 - accuracy: 0.9246 - val_loss: 0.1813 - val_accuracy: 0.9243\n",
      "Epoch 656/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.9235 - val_loss: 0.1764 - val_accuracy: 0.9267\n",
      "Epoch 657/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1786 - accuracy: 0.9249 - val_loss: 0.1895 - val_accuracy: 0.9211\n",
      "Epoch 658/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1815 - accuracy: 0.9233 - val_loss: 0.1802 - val_accuracy: 0.9252\n",
      "Epoch 659/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9255 - val_loss: 0.1837 - val_accuracy: 0.9234\n",
      "Epoch 660/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1762 - accuracy: 0.9247 - val_loss: 0.1830 - val_accuracy: 0.9241\n",
      "Epoch 661/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9236 - val_loss: 0.1943 - val_accuracy: 0.9190\n",
      "Epoch 662/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9247 - val_loss: 0.1830 - val_accuracy: 0.9232\n",
      "Epoch 663/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9237 - val_loss: 0.1809 - val_accuracy: 0.9251\n",
      "Epoch 664/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1788 - accuracy: 0.9239 - val_loss: 0.1832 - val_accuracy: 0.9229\n",
      "Epoch 665/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9243 - val_loss: 0.1790 - val_accuracy: 0.9250\n",
      "Epoch 666/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9252 - val_loss: 0.1788 - val_accuracy: 0.9250\n",
      "Epoch 667/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9255 - val_loss: 0.1834 - val_accuracy: 0.9242\n",
      "Epoch 668/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1784 - accuracy: 0.9245 - val_loss: 0.1774 - val_accuracy: 0.9256\n",
      "Epoch 669/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9253 - val_loss: 0.1770 - val_accuracy: 0.9262\n",
      "Epoch 670/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9235 - val_loss: 0.1868 - val_accuracy: 0.9230\n",
      "Epoch 671/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9241 - val_loss: 0.1791 - val_accuracy: 0.9250\n",
      "Epoch 672/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1812 - accuracy: 0.9232 - val_loss: 0.1822 - val_accuracy: 0.9243\n",
      "Epoch 673/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1816 - accuracy: 0.9229 - val_loss: 0.1839 - val_accuracy: 0.9239\n",
      "Epoch 674/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1762 - accuracy: 0.9251 - val_loss: 0.1819 - val_accuracy: 0.9241\n",
      "Epoch 675/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1796 - accuracy: 0.9242 - val_loss: 0.1895 - val_accuracy: 0.9218\n",
      "Epoch 676/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9239 - val_loss: 0.1853 - val_accuracy: 0.9228\n",
      "Epoch 677/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1757 - accuracy: 0.9253 - val_loss: 0.1808 - val_accuracy: 0.9251\n",
      "Epoch 678/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9255 - val_loss: 0.1967 - val_accuracy: 0.9192\n",
      "Epoch 679/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1761 - accuracy: 0.9253 - val_loss: 0.1793 - val_accuracy: 0.9260\n",
      "Epoch 680/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9250 - val_loss: 0.1853 - val_accuracy: 0.9228\n",
      "Epoch 681/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1791 - accuracy: 0.9242 - val_loss: 0.1883 - val_accuracy: 0.9223\n",
      "Epoch 682/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1748 - accuracy: 0.9255 - val_loss: 0.2019 - val_accuracy: 0.9175\n",
      "Epoch 683/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1834 - accuracy: 0.9221 - val_loss: 0.1822 - val_accuracy: 0.9245\n",
      "Epoch 684/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1783 - accuracy: 0.9240 - val_loss: 0.1911 - val_accuracy: 0.9209\n",
      "Epoch 685/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9250 - val_loss: 0.1775 - val_accuracy: 0.9261\n",
      "Epoch 686/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9259 - val_loss: 0.1810 - val_accuracy: 0.9243\n",
      "Epoch 687/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.9252 - val_loss: 0.1876 - val_accuracy: 0.9224\n",
      "Epoch 688/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9258 - val_loss: 0.1754 - val_accuracy: 0.9270\n",
      "Epoch 689/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1809 - accuracy: 0.9232 - val_loss: 0.1934 - val_accuracy: 0.9196\n",
      "Epoch 690/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.9238 - val_loss: 0.1810 - val_accuracy: 0.9254\n",
      "Epoch 691/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1778 - accuracy: 0.9245 - val_loss: 0.1778 - val_accuracy: 0.9257\n",
      "Epoch 692/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1768 - accuracy: 0.9249 - val_loss: 0.1798 - val_accuracy: 0.9250\n",
      "Epoch 693/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9243 - val_loss: 0.1795 - val_accuracy: 0.9251\n",
      "Epoch 694/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1751 - accuracy: 0.9255 - val_loss: 0.1800 - val_accuracy: 0.9252\n",
      "Epoch 695/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9246 - val_loss: 0.1839 - val_accuracy: 0.9243\n",
      "Epoch 696/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9252 - val_loss: 0.1744 - val_accuracy: 0.9273\n",
      "Epoch 697/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1761 - accuracy: 0.9252 - val_loss: 0.1787 - val_accuracy: 0.9252\n",
      "Epoch 698/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1766 - accuracy: 0.9250 - val_loss: 0.1827 - val_accuracy: 0.9240\n",
      "Epoch 699/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1802 - accuracy: 0.9236 - val_loss: 0.1796 - val_accuracy: 0.9248\n",
      "Epoch 700/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9248 - val_loss: 0.1799 - val_accuracy: 0.9258\n",
      "Epoch 701/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9247 - val_loss: 0.1981 - val_accuracy: 0.9193\n",
      "Epoch 702/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9236 - val_loss: 0.1894 - val_accuracy: 0.9215\n",
      "Epoch 703/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9262 - val_loss: 0.1843 - val_accuracy: 0.9235\n",
      "Epoch 704/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1766 - accuracy: 0.9253 - val_loss: 0.1934 - val_accuracy: 0.9202\n",
      "Epoch 705/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9256 - val_loss: 0.1846 - val_accuracy: 0.9230\n",
      "Epoch 706/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9247 - val_loss: 0.1828 - val_accuracy: 0.9244\n",
      "Epoch 707/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1773 - accuracy: 0.9242 - val_loss: 0.1819 - val_accuracy: 0.9237\n",
      "Epoch 708/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9248 - val_loss: 0.1800 - val_accuracy: 0.9248\n",
      "Epoch 709/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9249 - val_loss: 0.1954 - val_accuracy: 0.9197\n",
      "Epoch 710/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9234 - val_loss: 0.1848 - val_accuracy: 0.9238\n",
      "Epoch 711/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9260 - val_loss: 0.1761 - val_accuracy: 0.9261\n",
      "Epoch 712/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9247 - val_loss: 0.1905 - val_accuracy: 0.9219\n",
      "Epoch 713/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9243 - val_loss: 0.1853 - val_accuracy: 0.9236\n",
      "Epoch 714/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9257 - val_loss: 0.1847 - val_accuracy: 0.9229\n",
      "Epoch 715/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1785 - accuracy: 0.9243 - val_loss: 0.1947 - val_accuracy: 0.9210\n",
      "Epoch 716/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1777 - accuracy: 0.9244 - val_loss: 0.1801 - val_accuracy: 0.9245\n",
      "Epoch 717/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9253 - val_loss: 0.1755 - val_accuracy: 0.9267\n",
      "Epoch 718/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9259 - val_loss: 0.1804 - val_accuracy: 0.9250\n",
      "Epoch 719/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9255 - val_loss: 0.1809 - val_accuracy: 0.9242\n",
      "Epoch 720/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1765 - accuracy: 0.9251 - val_loss: 0.1790 - val_accuracy: 0.9260\n",
      "Epoch 721/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9256 - val_loss: 0.1816 - val_accuracy: 0.9237\n",
      "Epoch 722/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1771 - accuracy: 0.9247 - val_loss: 0.1741 - val_accuracy: 0.9267\n",
      "Epoch 723/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1777 - accuracy: 0.9245 - val_loss: 0.1805 - val_accuracy: 0.9235\n",
      "Epoch 724/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1754 - accuracy: 0.9255 - val_loss: 0.1817 - val_accuracy: 0.9241\n",
      "Epoch 725/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1749 - accuracy: 0.9251 - val_loss: 0.1794 - val_accuracy: 0.9249\n",
      "Epoch 726/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1783 - accuracy: 0.9243 - val_loss: 0.1962 - val_accuracy: 0.9188\n",
      "Epoch 727/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1773 - accuracy: 0.9246 - val_loss: 0.1788 - val_accuracy: 0.9253\n",
      "Epoch 728/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9256 - val_loss: 0.1792 - val_accuracy: 0.9258\n",
      "Epoch 729/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9257 - val_loss: 0.1856 - val_accuracy: 0.9224\n",
      "Epoch 730/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9248 - val_loss: 0.1828 - val_accuracy: 0.9238\n",
      "Epoch 731/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9248 - val_loss: 0.1804 - val_accuracy: 0.9245\n",
      "Epoch 732/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9261 - val_loss: 0.1764 - val_accuracy: 0.9270\n",
      "Epoch 733/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1778 - accuracy: 0.9242 - val_loss: 0.1782 - val_accuracy: 0.9255\n",
      "Epoch 734/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9252 - val_loss: 0.1882 - val_accuracy: 0.9235\n",
      "Epoch 735/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9253 - val_loss: 0.1874 - val_accuracy: 0.9228\n",
      "Epoch 736/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9256 - val_loss: 0.1848 - val_accuracy: 0.9227\n",
      "Epoch 737/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1797 - accuracy: 0.9240 - val_loss: 0.1805 - val_accuracy: 0.9249\n",
      "Epoch 738/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9249 - val_loss: 0.1781 - val_accuracy: 0.9261\n",
      "Epoch 739/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9258 - val_loss: 0.1813 - val_accuracy: 0.9256\n",
      "Epoch 740/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9250 - val_loss: 0.1771 - val_accuracy: 0.9253\n",
      "Epoch 741/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.9239 - val_loss: 0.1916 - val_accuracy: 0.9189\n",
      "Epoch 742/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9261 - val_loss: 0.1738 - val_accuracy: 0.9270\n",
      "Epoch 743/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9247 - val_loss: 0.1809 - val_accuracy: 0.9247\n",
      "Epoch 744/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1763 - accuracy: 0.9251 - val_loss: 0.1805 - val_accuracy: 0.9241\n",
      "Epoch 745/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1752 - accuracy: 0.9255 - val_loss: 0.1776 - val_accuracy: 0.9257\n",
      "Epoch 746/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1768 - accuracy: 0.9248 - val_loss: 0.1863 - val_accuracy: 0.9229\n",
      "Epoch 747/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9251 - val_loss: 0.1919 - val_accuracy: 0.9205\n",
      "Epoch 748/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9262 - val_loss: 0.1813 - val_accuracy: 0.9236\n",
      "Epoch 749/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9254 - val_loss: 0.1770 - val_accuracy: 0.9268\n",
      "Epoch 750/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1729 - accuracy: 0.9261 - val_loss: 0.2012 - val_accuracy: 0.9185\n",
      "Epoch 751/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1752 - accuracy: 0.9256 - val_loss: 0.1782 - val_accuracy: 0.9250\n",
      "Epoch 752/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9250 - val_loss: 0.1813 - val_accuracy: 0.9238\n",
      "Epoch 753/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1733 - accuracy: 0.9259 - val_loss: 0.1808 - val_accuracy: 0.9245\n",
      "Epoch 754/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9258 - val_loss: 0.1859 - val_accuracy: 0.9224\n",
      "Epoch 755/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9258 - val_loss: 0.1981 - val_accuracy: 0.9178\n",
      "Epoch 756/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1773 - accuracy: 0.9248 - val_loss: 0.1843 - val_accuracy: 0.9229\n",
      "Epoch 757/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1746 - accuracy: 0.9257 - val_loss: 0.1949 - val_accuracy: 0.9196\n",
      "Epoch 758/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9254 - val_loss: 0.1780 - val_accuracy: 0.9252\n",
      "Epoch 759/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9264 - val_loss: 0.1863 - val_accuracy: 0.9236\n",
      "Epoch 760/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1733 - accuracy: 0.9260 - val_loss: 0.1850 - val_accuracy: 0.9235\n",
      "Epoch 761/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9263 - val_loss: 0.1751 - val_accuracy: 0.9266\n",
      "Epoch 762/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9249 - val_loss: 0.1759 - val_accuracy: 0.9268\n",
      "Epoch 763/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9265 - val_loss: 0.1871 - val_accuracy: 0.9234\n",
      "Epoch 764/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9251 - val_loss: 0.1883 - val_accuracy: 0.9225\n",
      "Epoch 765/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9258 - val_loss: 0.1758 - val_accuracy: 0.9264\n",
      "Epoch 766/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9249 - val_loss: 0.1808 - val_accuracy: 0.9243\n",
      "Epoch 767/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9262 - val_loss: 0.1792 - val_accuracy: 0.9257\n",
      "Epoch 768/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9252 - val_loss: 0.1789 - val_accuracy: 0.9259\n",
      "Epoch 769/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9260 - val_loss: 0.1830 - val_accuracy: 0.9233\n",
      "Epoch 770/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9260 - val_loss: 0.1737 - val_accuracy: 0.9276\n",
      "Epoch 771/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9259 - val_loss: 0.1780 - val_accuracy: 0.9256\n",
      "Epoch 772/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1739 - accuracy: 0.9257 - val_loss: 0.1815 - val_accuracy: 0.9257\n",
      "Epoch 773/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9264 - val_loss: 0.1859 - val_accuracy: 0.9237\n",
      "Epoch 774/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9264 - val_loss: 0.1858 - val_accuracy: 0.9216\n",
      "Epoch 775/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9258 - val_loss: 0.1770 - val_accuracy: 0.9250\n",
      "Epoch 776/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9262 - val_loss: 0.1779 - val_accuracy: 0.9254\n",
      "Epoch 777/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9262 - val_loss: 0.1808 - val_accuracy: 0.9254\n",
      "Epoch 778/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9248 - val_loss: 0.1780 - val_accuracy: 0.9252\n",
      "Epoch 779/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1726 - accuracy: 0.9260 - val_loss: 0.1837 - val_accuracy: 0.9232\n",
      "Epoch 780/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1766 - accuracy: 0.9248 - val_loss: 0.1804 - val_accuracy: 0.9245\n",
      "Epoch 781/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9262 - val_loss: 0.1732 - val_accuracy: 0.9271\n",
      "Epoch 782/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9257 - val_loss: 0.1876 - val_accuracy: 0.9209\n",
      "Epoch 783/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9237 - val_loss: 0.1803 - val_accuracy: 0.9251\n",
      "Epoch 784/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9263 - val_loss: 0.1733 - val_accuracy: 0.9279\n",
      "Epoch 785/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1761 - accuracy: 0.9247 - val_loss: 0.1814 - val_accuracy: 0.9231\n",
      "Epoch 786/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9240 - val_loss: 0.1775 - val_accuracy: 0.9253\n",
      "Epoch 787/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1725 - accuracy: 0.9264 - val_loss: 0.1785 - val_accuracy: 0.9249\n",
      "Epoch 788/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1788 - accuracy: 0.9242 - val_loss: 0.1878 - val_accuracy: 0.9224\n",
      "Epoch 789/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9260 - val_loss: 0.1783 - val_accuracy: 0.9251\n",
      "Epoch 790/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9251 - val_loss: 0.1846 - val_accuracy: 0.9243\n",
      "Epoch 791/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9258 - val_loss: 0.1779 - val_accuracy: 0.9251\n",
      "Epoch 792/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1729 - accuracy: 0.9264 - val_loss: 0.1848 - val_accuracy: 0.9225\n",
      "Epoch 793/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1707 - accuracy: 0.9270 - val_loss: 0.1734 - val_accuracy: 0.9270\n",
      "Epoch 794/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9255 - val_loss: 0.1815 - val_accuracy: 0.9240\n",
      "Epoch 795/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9254 - val_loss: 0.1738 - val_accuracy: 0.9276\n",
      "Epoch 796/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9259 - val_loss: 0.1750 - val_accuracy: 0.9268\n",
      "Epoch 797/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9258 - val_loss: 0.1815 - val_accuracy: 0.9237\n",
      "Epoch 798/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9259 - val_loss: 0.1842 - val_accuracy: 0.9231\n",
      "Epoch 799/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1757 - accuracy: 0.9253 - val_loss: 0.1820 - val_accuracy: 0.9235\n",
      "Epoch 800/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9259 - val_loss: 0.1782 - val_accuracy: 0.9261\n",
      "Epoch 801/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1756 - accuracy: 0.9251 - val_loss: 0.1787 - val_accuracy: 0.9252\n",
      "Epoch 802/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9275 - val_loss: 0.1800 - val_accuracy: 0.9250\n",
      "Epoch 803/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9229 - val_loss: 0.1782 - val_accuracy: 0.9255\n",
      "Epoch 804/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9260 - val_loss: 0.1845 - val_accuracy: 0.9236\n",
      "Epoch 805/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1725 - accuracy: 0.9263 - val_loss: 0.1708 - val_accuracy: 0.9275\n",
      "Epoch 806/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1710 - accuracy: 0.9264 - val_loss: 0.1743 - val_accuracy: 0.9266\n",
      "Epoch 807/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9267 - val_loss: 0.1768 - val_accuracy: 0.9260\n",
      "Epoch 808/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9265 - val_loss: 0.1802 - val_accuracy: 0.9244\n",
      "Epoch 809/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9247 - val_loss: 0.1800 - val_accuracy: 0.9249\n",
      "Epoch 810/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1719 - accuracy: 0.9265 - val_loss: 0.2116 - val_accuracy: 0.9146\n",
      "Epoch 811/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9257 - val_loss: 0.1875 - val_accuracy: 0.9216\n",
      "Epoch 812/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9262 - val_loss: 0.1813 - val_accuracy: 0.9250\n",
      "Epoch 813/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9257 - val_loss: 0.1855 - val_accuracy: 0.9235\n",
      "Epoch 814/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.9264 - val_loss: 0.1762 - val_accuracy: 0.9259\n",
      "Epoch 815/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1763 - accuracy: 0.9249 - val_loss: 0.1881 - val_accuracy: 0.9219\n",
      "Epoch 816/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9256 - val_loss: 0.1757 - val_accuracy: 0.9262\n",
      "Epoch 817/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9276 - val_loss: 0.1784 - val_accuracy: 0.9254\n",
      "Epoch 818/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9259 - val_loss: 0.1772 - val_accuracy: 0.9256\n",
      "Epoch 819/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9271 - val_loss: 0.1739 - val_accuracy: 0.9273\n",
      "Epoch 820/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9271 - val_loss: 0.1818 - val_accuracy: 0.9241\n",
      "Epoch 821/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9257 - val_loss: 0.1877 - val_accuracy: 0.9228\n",
      "Epoch 822/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9240 - val_loss: 0.1809 - val_accuracy: 0.9242\n",
      "Epoch 823/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1727 - accuracy: 0.9264 - val_loss: 0.1799 - val_accuracy: 0.9242\n",
      "Epoch 824/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9264 - val_loss: 0.1813 - val_accuracy: 0.9243\n",
      "Epoch 825/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9266 - val_loss: 0.1758 - val_accuracy: 0.9266\n",
      "Epoch 826/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1728 - accuracy: 0.9263 - val_loss: 0.1749 - val_accuracy: 0.9264\n",
      "Epoch 827/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9269 - val_loss: 0.1786 - val_accuracy: 0.9255\n",
      "Epoch 828/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1751 - accuracy: 0.9250 - val_loss: 0.1829 - val_accuracy: 0.9235\n",
      "Epoch 829/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1712 - accuracy: 0.9271 - val_loss: 0.1846 - val_accuracy: 0.9234\n",
      "Epoch 830/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9249 - val_loss: 0.1823 - val_accuracy: 0.9229\n",
      "Epoch 831/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9257 - val_loss: 0.1864 - val_accuracy: 0.9223\n",
      "Epoch 832/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9258 - val_loss: 0.1933 - val_accuracy: 0.9209\n",
      "Epoch 833/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1698 - accuracy: 0.9271 - val_loss: 0.2016 - val_accuracy: 0.9184\n",
      "Epoch 834/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1748 - accuracy: 0.9253 - val_loss: 0.1791 - val_accuracy: 0.9260\n",
      "Epoch 835/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1748 - accuracy: 0.9256 - val_loss: 0.1782 - val_accuracy: 0.9253\n",
      "Epoch 836/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.9264 - val_loss: 0.1987 - val_accuracy: 0.9176\n",
      "Epoch 837/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9258 - val_loss: 0.1940 - val_accuracy: 0.9205\n",
      "Epoch 838/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1753 - accuracy: 0.9254 - val_loss: 0.1817 - val_accuracy: 0.9243\n",
      "Epoch 839/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1726 - accuracy: 0.9265 - val_loss: 0.1788 - val_accuracy: 0.9251\n",
      "Epoch 840/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9272 - val_loss: 0.1786 - val_accuracy: 0.9261\n",
      "Epoch 841/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9260 - val_loss: 0.1770 - val_accuracy: 0.9265\n",
      "Epoch 842/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9230 - val_loss: 0.1927 - val_accuracy: 0.9197\n",
      "Epoch 843/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9261 - val_loss: 0.1764 - val_accuracy: 0.9259\n",
      "Epoch 844/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9274 - val_loss: 0.1777 - val_accuracy: 0.9260\n",
      "Epoch 845/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1712 - accuracy: 0.9266 - val_loss: 0.1761 - val_accuracy: 0.9251\n",
      "Epoch 846/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9271 - val_loss: 0.1707 - val_accuracy: 0.9282\n",
      "Epoch 847/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.9270 - val_loss: 0.1719 - val_accuracy: 0.9278\n",
      "Epoch 848/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9264 - val_loss: 0.1793 - val_accuracy: 0.9245\n",
      "Epoch 849/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1748 - accuracy: 0.9257 - val_loss: 0.1812 - val_accuracy: 0.9239\n",
      "Epoch 850/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9257 - val_loss: 0.1798 - val_accuracy: 0.9256\n",
      "Epoch 851/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1733 - accuracy: 0.9265 - val_loss: 0.1734 - val_accuracy: 0.9272\n",
      "Epoch 852/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1695 - accuracy: 0.9274 - val_loss: 0.1778 - val_accuracy: 0.9251\n",
      "Epoch 853/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9247 - val_loss: 0.1804 - val_accuracy: 0.9243\n",
      "Epoch 854/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9273 - val_loss: 0.1788 - val_accuracy: 0.9251\n",
      "Epoch 855/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9273 - val_loss: 0.1760 - val_accuracy: 0.9265\n",
      "Epoch 856/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1726 - accuracy: 0.9259 - val_loss: 0.1783 - val_accuracy: 0.9250\n",
      "Epoch 857/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9259 - val_loss: 0.1780 - val_accuracy: 0.9256\n",
      "Epoch 858/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9273 - val_loss: 0.1811 - val_accuracy: 0.9239\n",
      "Epoch 859/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1729 - accuracy: 0.9261 - val_loss: 0.1728 - val_accuracy: 0.9269\n",
      "Epoch 860/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9255 - val_loss: 0.1763 - val_accuracy: 0.9255\n",
      "Epoch 861/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.9262 - val_loss: 0.1820 - val_accuracy: 0.9240\n",
      "Epoch 862/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9269 - val_loss: 0.1890 - val_accuracy: 0.9214\n",
      "Epoch 863/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9269 - val_loss: 0.1861 - val_accuracy: 0.9233\n",
      "Epoch 864/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9270 - val_loss: 0.1738 - val_accuracy: 0.9269\n",
      "Epoch 865/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9249 - val_loss: 0.1777 - val_accuracy: 0.9263\n",
      "Epoch 866/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1687 - accuracy: 0.9280 - val_loss: 0.1728 - val_accuracy: 0.9268\n",
      "Epoch 867/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1707 - accuracy: 0.9269 - val_loss: 0.1781 - val_accuracy: 0.9253\n",
      "Epoch 868/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9257 - val_loss: 0.1905 - val_accuracy: 0.9206\n",
      "Epoch 869/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1727 - accuracy: 0.9262 - val_loss: 0.1773 - val_accuracy: 0.9252\n",
      "Epoch 870/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9258 - val_loss: 0.1847 - val_accuracy: 0.9243\n",
      "Epoch 871/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1701 - accuracy: 0.9274 - val_loss: 0.1745 - val_accuracy: 0.9264\n",
      "Epoch 872/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9252 - val_loss: 0.1814 - val_accuracy: 0.9239\n",
      "Epoch 873/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9250 - val_loss: 0.1778 - val_accuracy: 0.9245\n",
      "Epoch 874/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1716 - accuracy: 0.9270 - val_loss: 0.1788 - val_accuracy: 0.9259\n",
      "Epoch 875/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1727 - accuracy: 0.9265 - val_loss: 0.2178 - val_accuracy: 0.9110\n",
      "Epoch 876/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1710 - accuracy: 0.9267 - val_loss: 0.1711 - val_accuracy: 0.9282\n",
      "Epoch 877/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9266 - val_loss: 0.2015 - val_accuracy: 0.9186\n",
      "Epoch 878/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9265 - val_loss: 0.1744 - val_accuracy: 0.9264\n",
      "Epoch 879/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9272 - val_loss: 0.1764 - val_accuracy: 0.9257\n",
      "Epoch 880/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9274 - val_loss: 0.1724 - val_accuracy: 0.9273\n",
      "Epoch 881/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9274 - val_loss: 0.1839 - val_accuracy: 0.9265\n",
      "Epoch 882/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9255 - val_loss: 0.1787 - val_accuracy: 0.9251\n",
      "Epoch 883/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1711 - accuracy: 0.9267 - val_loss: 0.1853 - val_accuracy: 0.9235\n",
      "Epoch 884/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.9264 - val_loss: 0.1724 - val_accuracy: 0.9272\n",
      "Epoch 885/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9271 - val_loss: 0.1782 - val_accuracy: 0.9259\n",
      "Epoch 886/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1714 - accuracy: 0.9270 - val_loss: 0.1782 - val_accuracy: 0.9255\n",
      "Epoch 887/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9256 - val_loss: 0.2104 - val_accuracy: 0.9124\n",
      "Epoch 888/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9255 - val_loss: 0.1923 - val_accuracy: 0.9202\n",
      "Epoch 889/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1715 - accuracy: 0.9267 - val_loss: 0.1748 - val_accuracy: 0.9266\n",
      "Epoch 890/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9270 - val_loss: 0.1779 - val_accuracy: 0.9256\n",
      "Epoch 891/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9266 - val_loss: 0.1758 - val_accuracy: 0.9262\n",
      "Epoch 892/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9274 - val_loss: 0.1785 - val_accuracy: 0.9249\n",
      "Epoch 893/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9259 - val_loss: 0.1757 - val_accuracy: 0.9265\n",
      "Epoch 894/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9268 - val_loss: 0.1786 - val_accuracy: 0.9246\n",
      "Epoch 895/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9280 - val_loss: 0.1845 - val_accuracy: 0.9242\n",
      "Epoch 896/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1756 - accuracy: 0.9253 - val_loss: 0.1785 - val_accuracy: 0.9246\n",
      "Epoch 897/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1688 - accuracy: 0.9274 - val_loss: 0.1717 - val_accuracy: 0.9271\n",
      "Epoch 898/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1694 - accuracy: 0.9273 - val_loss: 0.1942 - val_accuracy: 0.9201\n",
      "Epoch 899/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9269 - val_loss: 0.1735 - val_accuracy: 0.9262\n",
      "Epoch 900/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1714 - accuracy: 0.9268 - val_loss: 0.1716 - val_accuracy: 0.9272\n",
      "Epoch 901/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9266 - val_loss: 0.1802 - val_accuracy: 0.9246\n",
      "Epoch 902/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9260 - val_loss: 0.1849 - val_accuracy: 0.9232\n",
      "Epoch 903/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9263 - val_loss: 0.1949 - val_accuracy: 0.9185\n",
      "Epoch 904/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9273 - val_loss: 0.1724 - val_accuracy: 0.9272\n",
      "Epoch 905/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1681 - accuracy: 0.9281 - val_loss: 0.1865 - val_accuracy: 0.9237\n",
      "Epoch 906/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1774 - accuracy: 0.9247 - val_loss: 0.1779 - val_accuracy: 0.9269\n",
      "Epoch 907/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1677 - accuracy: 0.9284 - val_loss: 0.1723 - val_accuracy: 0.9270\n",
      "Epoch 908/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9267 - val_loss: 0.1723 - val_accuracy: 0.9273\n",
      "Epoch 909/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1716 - accuracy: 0.9264 - val_loss: 0.1709 - val_accuracy: 0.9273\n",
      "Epoch 910/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1676 - accuracy: 0.9282 - val_loss: 0.1748 - val_accuracy: 0.9268\n",
      "Epoch 911/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9270 - val_loss: 0.1809 - val_accuracy: 0.9240\n",
      "Epoch 912/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1689 - accuracy: 0.9277 - val_loss: 0.1788 - val_accuracy: 0.9251\n",
      "Epoch 913/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9254 - val_loss: 0.1768 - val_accuracy: 0.9254\n",
      "Epoch 914/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.9267 - val_loss: 0.1716 - val_accuracy: 0.9277\n",
      "Epoch 915/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1711 - accuracy: 0.9265 - val_loss: 0.1687 - val_accuracy: 0.9286\n",
      "Epoch 916/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.9281 - val_loss: 0.1730 - val_accuracy: 0.9275\n",
      "Epoch 917/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1680 - accuracy: 0.9279 - val_loss: 0.1795 - val_accuracy: 0.9253\n",
      "Epoch 918/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1712 - accuracy: 0.9267 - val_loss: 0.1748 - val_accuracy: 0.9270\n",
      "Epoch 919/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9263 - val_loss: 0.1875 - val_accuracy: 0.9224\n",
      "Epoch 920/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9267 - val_loss: 0.1734 - val_accuracy: 0.9274\n",
      "Epoch 921/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9278 - val_loss: 0.1757 - val_accuracy: 0.9262\n",
      "Epoch 922/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9268 - val_loss: 0.1901 - val_accuracy: 0.9214\n",
      "Epoch 923/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1695 - accuracy: 0.9275 - val_loss: 0.1766 - val_accuracy: 0.9256\n",
      "Epoch 924/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9252 - val_loss: 0.1920 - val_accuracy: 0.9209\n",
      "Epoch 925/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9272 - val_loss: 0.1747 - val_accuracy: 0.9266\n",
      "Epoch 926/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1704 - accuracy: 0.9274 - val_loss: 0.1694 - val_accuracy: 0.9290\n",
      "Epoch 927/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1681 - accuracy: 0.9281 - val_loss: 0.1835 - val_accuracy: 0.9230\n",
      "Epoch 928/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1696 - accuracy: 0.9276 - val_loss: 0.1811 - val_accuracy: 0.9239\n",
      "Epoch 929/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.9248 - val_loss: 0.1772 - val_accuracy: 0.9256\n",
      "Epoch 930/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1696 - accuracy: 0.9275 - val_loss: 0.1766 - val_accuracy: 0.9256\n",
      "Epoch 931/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1679 - accuracy: 0.9279 - val_loss: 0.1729 - val_accuracy: 0.9271\n",
      "Epoch 932/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9274 - val_loss: 0.1785 - val_accuracy: 0.9249\n",
      "Epoch 933/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1707 - accuracy: 0.9271 - val_loss: 0.1754 - val_accuracy: 0.9272\n",
      "Epoch 934/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.9265 - val_loss: 0.1805 - val_accuracy: 0.9242\n",
      "Epoch 935/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9281 - val_loss: 0.1738 - val_accuracy: 0.9273\n",
      "Epoch 936/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9268 - val_loss: 0.1846 - val_accuracy: 0.9232\n",
      "Epoch 937/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1748 - accuracy: 0.9252 - val_loss: 0.1734 - val_accuracy: 0.9271\n",
      "Epoch 938/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9281 - val_loss: 0.1750 - val_accuracy: 0.9261\n",
      "Epoch 939/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9256 - val_loss: 0.1767 - val_accuracy: 0.9259\n",
      "Epoch 940/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1695 - accuracy: 0.9275 - val_loss: 0.1850 - val_accuracy: 0.9230\n",
      "Epoch 941/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9278 - val_loss: 0.1704 - val_accuracy: 0.9281\n",
      "Epoch 942/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9273 - val_loss: 0.1740 - val_accuracy: 0.9274\n",
      "Epoch 943/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1682 - accuracy: 0.9281 - val_loss: 0.1774 - val_accuracy: 0.9265\n",
      "Epoch 944/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1704 - accuracy: 0.9273 - val_loss: 0.1870 - val_accuracy: 0.9220\n",
      "Epoch 945/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9276 - val_loss: 0.1731 - val_accuracy: 0.9276\n",
      "Epoch 946/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9275 - val_loss: 0.1751 - val_accuracy: 0.9276\n",
      "Epoch 947/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1701 - accuracy: 0.9271 - val_loss: 0.1762 - val_accuracy: 0.9258\n",
      "Epoch 948/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.9283 - val_loss: 0.1770 - val_accuracy: 0.9249\n",
      "Epoch 949/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9277 - val_loss: 0.1707 - val_accuracy: 0.9276\n",
      "Epoch 950/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1714 - accuracy: 0.9265 - val_loss: 0.1749 - val_accuracy: 0.9259\n",
      "Epoch 951/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9284 - val_loss: 0.1706 - val_accuracy: 0.9273\n",
      "Epoch 952/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1696 - accuracy: 0.9269 - val_loss: 0.1744 - val_accuracy: 0.9266\n",
      "Epoch 953/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1701 - accuracy: 0.9271 - val_loss: 0.1891 - val_accuracy: 0.9219\n",
      "Epoch 954/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9271 - val_loss: 0.1759 - val_accuracy: 0.9257\n",
      "Epoch 955/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9281 - val_loss: 0.1847 - val_accuracy: 0.9238\n",
      "Epoch 956/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1804 - accuracy: 0.9241 - val_loss: 0.1734 - val_accuracy: 0.9271\n",
      "Epoch 957/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1685 - accuracy: 0.9280 - val_loss: 0.1707 - val_accuracy: 0.9280\n",
      "Epoch 958/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9289 - val_loss: 0.1862 - val_accuracy: 0.9226\n",
      "Epoch 959/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1665 - accuracy: 0.9284 - val_loss: 0.1728 - val_accuracy: 0.9271\n",
      "Epoch 960/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1681 - accuracy: 0.9279 - val_loss: 0.1845 - val_accuracy: 0.9228\n",
      "Epoch 961/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9272 - val_loss: 0.1770 - val_accuracy: 0.9254\n",
      "Epoch 962/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1728 - accuracy: 0.9257 - val_loss: 0.1760 - val_accuracy: 0.9264\n",
      "Epoch 963/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1663 - accuracy: 0.9284 - val_loss: 0.1853 - val_accuracy: 0.9245\n",
      "Epoch 964/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9260 - val_loss: 0.1759 - val_accuracy: 0.9254\n",
      "Epoch 965/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9259 - val_loss: 0.1771 - val_accuracy: 0.9269\n",
      "Epoch 966/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9263 - val_loss: 0.1764 - val_accuracy: 0.9271\n",
      "Epoch 967/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9271 - val_loss: 0.1853 - val_accuracy: 0.9230\n",
      "Epoch 968/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1704 - accuracy: 0.9269 - val_loss: 0.1704 - val_accuracy: 0.9279\n",
      "Epoch 969/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9270 - val_loss: 0.1729 - val_accuracy: 0.9262\n",
      "Epoch 970/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9290 - val_loss: 0.1715 - val_accuracy: 0.9271\n",
      "Epoch 971/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1654 - accuracy: 0.9287 - val_loss: 0.1752 - val_accuracy: 0.9256\n",
      "Epoch 972/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1703 - accuracy: 0.9272 - val_loss: 0.1786 - val_accuracy: 0.9245\n",
      "Epoch 973/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1723 - accuracy: 0.9260 - val_loss: 0.1773 - val_accuracy: 0.9253\n",
      "Epoch 974/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9265 - val_loss: 0.1741 - val_accuracy: 0.9270\n",
      "Epoch 975/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1712 - accuracy: 0.9267 - val_loss: 0.1762 - val_accuracy: 0.9257\n",
      "Epoch 976/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9271 - val_loss: 0.1773 - val_accuracy: 0.9257\n",
      "Epoch 977/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1664 - accuracy: 0.9287 - val_loss: 0.1826 - val_accuracy: 0.9241\n",
      "Epoch 978/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1677 - accuracy: 0.9282 - val_loss: 0.1704 - val_accuracy: 0.9286\n",
      "Epoch 979/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1670 - accuracy: 0.9281 - val_loss: 0.1743 - val_accuracy: 0.9259\n",
      "Epoch 980/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1715 - accuracy: 0.9270 - val_loss: 0.1799 - val_accuracy: 0.9251\n",
      "Epoch 981/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9287 - val_loss: 0.1766 - val_accuracy: 0.9254\n",
      "Epoch 982/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1668 - accuracy: 0.9286 - val_loss: 0.1697 - val_accuracy: 0.9282\n",
      "Epoch 983/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1682 - accuracy: 0.9277 - val_loss: 0.1916 - val_accuracy: 0.9218\n",
      "Epoch 984/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9269 - val_loss: 0.1745 - val_accuracy: 0.9267\n",
      "Epoch 985/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9267 - val_loss: 0.1771 - val_accuracy: 0.9267\n",
      "Epoch 986/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1681 - accuracy: 0.9277 - val_loss: 0.1764 - val_accuracy: 0.9259\n",
      "Epoch 987/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9272 - val_loss: 0.1746 - val_accuracy: 0.9259\n",
      "Epoch 988/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9281 - val_loss: 0.1773 - val_accuracy: 0.9256\n",
      "Epoch 989/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1678 - accuracy: 0.9280 - val_loss: 0.1910 - val_accuracy: 0.9204\n",
      "Epoch 990/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.9282 - val_loss: 0.1751 - val_accuracy: 0.9269\n",
      "Epoch 991/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1676 - accuracy: 0.9279 - val_loss: 0.1901 - val_accuracy: 0.9211\n",
      "Epoch 992/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9259 - val_loss: 0.1762 - val_accuracy: 0.9249\n",
      "Epoch 993/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.9283 - val_loss: 0.1730 - val_accuracy: 0.9276\n",
      "Epoch 994/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1664 - accuracy: 0.9287 - val_loss: 0.1767 - val_accuracy: 0.9257\n",
      "Epoch 995/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.9281 - val_loss: 0.1777 - val_accuracy: 0.9259\n",
      "Epoch 996/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9261 - val_loss: 0.1856 - val_accuracy: 0.9225\n",
      "Epoch 997/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9264 - val_loss: 0.1883 - val_accuracy: 0.9220\n",
      "Epoch 998/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9257 - val_loss: 0.1771 - val_accuracy: 0.9256\n",
      "Epoch 999/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9281 - val_loss: 0.1912 - val_accuracy: 0.9222\n",
      "Epoch 1000/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9269 - val_loss: 0.1781 - val_accuracy: 0.9258\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9215\n",
      "Test Loss: 0.1803\n",
      "Test Accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 GRU 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = GRU(64, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/185 [..............................] - ETA: 38s - loss: 0.2087 - accuracy: 0.9277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeojung/.local/lib/python3.10/site-packages/keras/src/engine/functional.py:639: UserWarning: Input dict contained keys ['sequence_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 4ms/step - loss: 0.1803 - accuracy: 0.9215\n",
      "Test Accuracy: 92.15\n",
      "Test Loss: 18.03\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, theta, phi, sequence):\n",
    "    loss, acc = model.evaluate({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, theta_test, phi_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeojung/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_GRU_model_cuda_LearningRate_30ths_v4.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 324ms/step\n",
      "Results saved to GRU_cuda_results_LearningRate_30ths_v4.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_GRU'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'GRU_cuda_results_LearningRate_30ths_v4.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to GRU_cuda_results_LearningRate_30ths_v4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Sample 1:\n",
      "Theta    : [0.34911289]\n",
      "Phi      : [3.59059618]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [1.64387253]\n",
      "Phi      : [1.01209939]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 1 3 3 3 3 2 2 4 4 1 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 3 3 3 2 2 4 4 1 1]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [2.40437549]\n",
      "Phi      : [2.51983178]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [1.95648198]\n",
      "Phi      : [2.98866625]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 0 3 0 2 4]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 3 2 2 4]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [2.79776597]\n",
      "Phi      : [0.58204481]\n",
      "Actual   : [0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 0 2 4]\n",
      "Predicted: [0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 2 0 4]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [1.28514769]\n",
      "Phi      : [4.06176983]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 4 1 1 3 3 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 3 3 3 3 4]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [2.28274781]\n",
      "Phi      : [4.32428439]\n",
      "Actual   : [0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 0 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 4 4]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [2.86211643]\n",
      "Phi      : [0.05316287]\n",
      "Actual   : [0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 3 0 2 0]\n",
      "Predicted: [0 0 4 1 1 3 3 2 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 3 2 2]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [2.26319203]\n",
      "Phi      : [5.69128973]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 2 2]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [0.44233008]\n",
      "Phi      : [2.45138196]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
