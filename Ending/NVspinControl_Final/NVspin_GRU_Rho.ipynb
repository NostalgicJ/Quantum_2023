{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../../Data/using/dt_2.6/ByAstar_dt_2.6_1016.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "def hermitian_matrix_to_vector(matrix):\n",
    "    # 행렬의 크기를 가져옴\n",
    "    n = matrix.shape[0]\n",
    "\n",
    "    # 에르미트 행렬인지 확인\n",
    "    assert np.allclose(matrix, matrix.conj().T)\n",
    "\n",
    "    # 상삼각 행렬의 원소를 가져와 벡터로 변환\n",
    "    vector = np.zeros((n * (n + 1)) // 2, dtype=complex)\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1):\n",
    "            vector[idx] = matrix[i, j]\n",
    "            idx += 1\n",
    "\n",
    "    return vector\n",
    "\n",
    "# x-rotation operater\n",
    "def Rx(theta):\n",
    "    return np.matrix([  [cos(theta/2),    -1j*sin(theta/2)],\n",
    "                        [-1j*sin(theta/2),    cos(theta/2)]])\n",
    "\n",
    "# z-rotation operater\n",
    "def Rz(phi): \n",
    "    return np.matrix([  [cos(phi/2)-1j*sin(phi/2),  0],\n",
    "                        [0,  cos(phi/2)+1j*sin(phi/2)]])\n",
    "    \n",
    "# Initial state\n",
    "init_wave = np.array([[1], [0]])\n",
    "irho_init = np.kron(init_wave, init_wave.conj().T)\n",
    "\n",
    "def making_rho(theta, phi):\n",
    "\n",
    "    # Target state\n",
    "    # Theta must move first and then phi move.\n",
    "    target_U = Rz(theta) @ Rx(phi) \n",
    "    irho_target = target_U @ irho_init @ target_U.conj().T\n",
    "    \n",
    "    return irho_target\n",
    "\n",
    "df['Rho'] = df.apply(lambda row: hermitian_matrix_to_vector(making_rho(row['Theta'], row['Phi'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.54338977e-01+0.j        , 3.55493008e-05-0.36127338j,\n",
       "       8.45661023e-01+0.j        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rho'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "# rho_train = train_df['Rho'].values.reshape(-1, 1)\n",
    "rho_train_list = train_df['Rho'].apply(lambda x: np.asarray(x).flatten()).tolist()\n",
    "rho_train = tf.constant(np.stack(rho_train_list))\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "# rho_val = val_df['Rho'].values.reshape(-1, 1)\n",
    "rho_val_list = val_df['Rho'].apply(lambda x: np.asarray(x).flatten()).tolist()\n",
    "rho_val = tf.constant(np.stack(rho_val_list))\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "# rho_test = test_df['Rho'].values.reshape(-1, 1)\n",
    "rho_test_list = test_df['Rho'].apply(lambda x: np.asarray(x).flatten()).tolist()\n",
    "rho_test = tf.constant(np.stack(rho_test_list))\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_train shape: (18897, 3)\n",
      "rho_train dtype: <dtype: 'complex128'>\n",
      "rho_val shape: (4725, 3)\n",
      "rho_val dtype: <dtype: 'complex128'>\n"
     ]
    }
   ],
   "source": [
    "print(\"rho_train shape:\", rho_train.shape)\n",
    "print(\"rho_train dtype:\", rho_train.dtype)\n",
    "print(\"rho_val shape:\", rho_val.shape)\n",
    "print(\"rho_val dtype:\", rho_val.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:49:35.027966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 16:49:35.029176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 16:49:35.029986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-17 16:49:35.185717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 16:49:35.186648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 16:49:35.187589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:49:35.581159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 16:49:35.582647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 16:49:35.583612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/148 [===========================>..] - ETA: 0s - loss: 1.3245 - accuracy: 0.4817WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:49:37.299087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 16:49:37.300334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 16:49:37.301155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 2s 9ms/step - loss: 1.3224 - accuracy: 0.4815 - val_loss: 1.2774 - val_accuracy: 0.4825\n",
      "Epoch 2/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.2613 - accuracy: 0.4894 - val_loss: 1.2589 - val_accuracy: 0.4881\n",
      "Epoch 3/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.2536 - accuracy: 0.4905 - val_loss: 1.2594 - val_accuracy: 0.4855\n",
      "Epoch 4/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.2424 - accuracy: 0.4962 - val_loss: 1.2285 - val_accuracy: 0.5040\n",
      "Epoch 5/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.0275 - accuracy: 0.5726 - val_loss: 0.8938 - val_accuracy: 0.6124\n",
      "Epoch 6/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8279 - accuracy: 0.6431 - val_loss: 0.8127 - val_accuracy: 0.6470\n",
      "Epoch 7/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7864 - accuracy: 0.6539 - val_loss: 0.7688 - val_accuracy: 0.6605\n",
      "Epoch 8/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7478 - accuracy: 0.6640 - val_loss: 0.7477 - val_accuracy: 0.6669\n",
      "Epoch 9/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7334 - accuracy: 0.6664 - val_loss: 0.7356 - val_accuracy: 0.6696\n",
      "Epoch 10/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7246 - accuracy: 0.6681 - val_loss: 0.7271 - val_accuracy: 0.6697\n",
      "Epoch 11/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7058 - accuracy: 0.6726 - val_loss: 0.7003 - val_accuracy: 0.6730\n",
      "Epoch 12/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7021 - accuracy: 0.6728 - val_loss: 0.7027 - val_accuracy: 0.6772\n",
      "Epoch 13/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6887 - accuracy: 0.6769 - val_loss: 0.6995 - val_accuracy: 0.6706\n",
      "Epoch 14/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6841 - accuracy: 0.6771 - val_loss: 0.6801 - val_accuracy: 0.6811\n",
      "Epoch 15/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6759 - accuracy: 0.6773 - val_loss: 0.6810 - val_accuracy: 0.6771\n",
      "Epoch 16/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6716 - accuracy: 0.6793 - val_loss: 0.6798 - val_accuracy: 0.6805\n",
      "Epoch 17/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6673 - accuracy: 0.6777 - val_loss: 0.6632 - val_accuracy: 0.6803\n",
      "Epoch 18/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6598 - accuracy: 0.6805 - val_loss: 0.6604 - val_accuracy: 0.6828\n",
      "Epoch 19/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6572 - accuracy: 0.6816 - val_loss: 0.6517 - val_accuracy: 0.6865\n",
      "Epoch 20/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6594 - accuracy: 0.6798 - val_loss: 0.6647 - val_accuracy: 0.6784\n",
      "Epoch 21/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6509 - accuracy: 0.6829 - val_loss: 0.6787 - val_accuracy: 0.6715\n",
      "Epoch 22/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6515 - accuracy: 0.6829 - val_loss: 0.6426 - val_accuracy: 0.6853\n",
      "Epoch 23/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6454 - accuracy: 0.6837 - val_loss: 0.6491 - val_accuracy: 0.6840\n",
      "Epoch 24/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6484 - accuracy: 0.6839 - val_loss: 0.6538 - val_accuracy: 0.6804\n",
      "Epoch 25/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6372 - accuracy: 0.6863 - val_loss: 0.6417 - val_accuracy: 0.6871\n",
      "Epoch 26/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6408 - accuracy: 0.6847 - val_loss: 0.6755 - val_accuracy: 0.6724\n",
      "Epoch 27/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6389 - accuracy: 0.6857 - val_loss: 0.6509 - val_accuracy: 0.6839\n",
      "Epoch 28/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6388 - accuracy: 0.6858 - val_loss: 0.6587 - val_accuracy: 0.6787\n",
      "Epoch 29/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6381 - accuracy: 0.6858 - val_loss: 0.6467 - val_accuracy: 0.6846\n",
      "Epoch 30/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6264 - accuracy: 0.6889 - val_loss: 0.6308 - val_accuracy: 0.6852\n",
      "Epoch 31/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6267 - accuracy: 0.6887 - val_loss: 0.6398 - val_accuracy: 0.6794\n",
      "Epoch 32/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6307 - accuracy: 0.6864 - val_loss: 0.6350 - val_accuracy: 0.6878\n",
      "Epoch 33/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6243 - accuracy: 0.6891 - val_loss: 0.6248 - val_accuracy: 0.6847\n",
      "Epoch 34/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6217 - accuracy: 0.6910 - val_loss: 0.6330 - val_accuracy: 0.6875\n",
      "Epoch 35/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6206 - accuracy: 0.6896 - val_loss: 0.6259 - val_accuracy: 0.6841\n",
      "Epoch 36/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6217 - accuracy: 0.6895 - val_loss: 0.6232 - val_accuracy: 0.6887\n",
      "Epoch 37/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6162 - accuracy: 0.6907 - val_loss: 0.6209 - val_accuracy: 0.6881\n",
      "Epoch 38/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6145 - accuracy: 0.6902 - val_loss: 0.6123 - val_accuracy: 0.6892\n",
      "Epoch 39/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6174 - accuracy: 0.6897 - val_loss: 0.6322 - val_accuracy: 0.6866\n",
      "Epoch 40/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6132 - accuracy: 0.6914 - val_loss: 0.6132 - val_accuracy: 0.6895\n",
      "Epoch 41/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6145 - accuracy: 0.6921 - val_loss: 0.6192 - val_accuracy: 0.6886\n",
      "Epoch 42/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6147 - accuracy: 0.6915 - val_loss: 0.6291 - val_accuracy: 0.6841\n",
      "Epoch 43/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6114 - accuracy: 0.6928 - val_loss: 0.6208 - val_accuracy: 0.6872\n",
      "Epoch 44/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6088 - accuracy: 0.6914 - val_loss: 0.6154 - val_accuracy: 0.6885\n",
      "Epoch 45/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6106 - accuracy: 0.6919 - val_loss: 0.6133 - val_accuracy: 0.6888\n",
      "Epoch 46/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6053 - accuracy: 0.6939 - val_loss: 0.6297 - val_accuracy: 0.6829\n",
      "Epoch 47/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6072 - accuracy: 0.6929 - val_loss: 0.6159 - val_accuracy: 0.6854\n",
      "Epoch 48/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6076 - accuracy: 0.6939 - val_loss: 0.6133 - val_accuracy: 0.6879\n",
      "Epoch 49/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6075 - accuracy: 0.6930 - val_loss: 0.6127 - val_accuracy: 0.6873\n",
      "Epoch 50/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6070 - accuracy: 0.6949 - val_loss: 0.6029 - val_accuracy: 0.6900\n",
      "Epoch 51/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6026 - accuracy: 0.6950 - val_loss: 0.6193 - val_accuracy: 0.6865\n",
      "Epoch 52/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6013 - accuracy: 0.6948 - val_loss: 0.6256 - val_accuracy: 0.6825\n",
      "Epoch 53/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6067 - accuracy: 0.6939 - val_loss: 0.6156 - val_accuracy: 0.6886\n",
      "Epoch 54/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6003 - accuracy: 0.6944 - val_loss: 0.6227 - val_accuracy: 0.6844\n",
      "Epoch 55/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5988 - accuracy: 0.6963 - val_loss: 0.6015 - val_accuracy: 0.6914\n",
      "Epoch 56/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5964 - accuracy: 0.6966 - val_loss: 0.5974 - val_accuracy: 0.6929\n",
      "Epoch 57/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6002 - accuracy: 0.6939 - val_loss: 0.6036 - val_accuracy: 0.6915\n",
      "Epoch 58/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5950 - accuracy: 0.6982 - val_loss: 0.6166 - val_accuracy: 0.6869\n",
      "Epoch 59/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6004 - accuracy: 0.6938 - val_loss: 0.6079 - val_accuracy: 0.6876\n",
      "Epoch 60/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5982 - accuracy: 0.6960 - val_loss: 0.6083 - val_accuracy: 0.6899\n",
      "Epoch 61/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5946 - accuracy: 0.6973 - val_loss: 0.6110 - val_accuracy: 0.6925\n",
      "Epoch 62/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5936 - accuracy: 0.6969 - val_loss: 0.6032 - val_accuracy: 0.6889\n",
      "Epoch 63/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6003 - accuracy: 0.6960 - val_loss: 0.6165 - val_accuracy: 0.6840\n",
      "Epoch 64/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5959 - accuracy: 0.6966 - val_loss: 0.6001 - val_accuracy: 0.6880\n",
      "Epoch 65/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5950 - accuracy: 0.6968 - val_loss: 0.6237 - val_accuracy: 0.6793\n",
      "Epoch 66/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5948 - accuracy: 0.6964 - val_loss: 0.6068 - val_accuracy: 0.6860\n",
      "Epoch 67/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5911 - accuracy: 0.6993 - val_loss: 0.5906 - val_accuracy: 0.6924\n",
      "Epoch 68/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5914 - accuracy: 0.6983 - val_loss: 0.6250 - val_accuracy: 0.6776\n",
      "Epoch 69/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5959 - accuracy: 0.6965 - val_loss: 0.6097 - val_accuracy: 0.6864\n",
      "Epoch 70/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5957 - accuracy: 0.6961 - val_loss: 0.5979 - val_accuracy: 0.6913\n",
      "Epoch 71/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5859 - accuracy: 0.7002 - val_loss: 0.5960 - val_accuracy: 0.6911\n",
      "Epoch 72/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5913 - accuracy: 0.6988 - val_loss: 0.5966 - val_accuracy: 0.6931\n",
      "Epoch 73/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5917 - accuracy: 0.6975 - val_loss: 0.6102 - val_accuracy: 0.6884\n",
      "Epoch 74/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5857 - accuracy: 0.7005 - val_loss: 0.5913 - val_accuracy: 0.6919\n",
      "Epoch 75/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5943 - accuracy: 0.6984 - val_loss: 0.6032 - val_accuracy: 0.6895\n",
      "Epoch 76/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5889 - accuracy: 0.6993 - val_loss: 0.6283 - val_accuracy: 0.6778\n",
      "Epoch 77/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5879 - accuracy: 0.6995 - val_loss: 0.5930 - val_accuracy: 0.6942\n",
      "Epoch 78/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5861 - accuracy: 0.7003 - val_loss: 0.6184 - val_accuracy: 0.6869\n",
      "Epoch 79/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5877 - accuracy: 0.6997 - val_loss: 0.5964 - val_accuracy: 0.6926\n",
      "Epoch 80/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5839 - accuracy: 0.6999 - val_loss: 0.5980 - val_accuracy: 0.6885\n",
      "Epoch 81/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5851 - accuracy: 0.7007 - val_loss: 0.5948 - val_accuracy: 0.6919\n",
      "Epoch 82/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5840 - accuracy: 0.7001 - val_loss: 0.5948 - val_accuracy: 0.6882\n",
      "Epoch 83/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5786 - accuracy: 0.7030 - val_loss: 0.5989 - val_accuracy: 0.6882\n",
      "Epoch 84/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5811 - accuracy: 0.7033 - val_loss: 0.5899 - val_accuracy: 0.6933\n",
      "Epoch 85/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5822 - accuracy: 0.7027 - val_loss: 0.5908 - val_accuracy: 0.6886\n",
      "Epoch 86/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5830 - accuracy: 0.7017 - val_loss: 0.5964 - val_accuracy: 0.6903\n",
      "Epoch 87/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5801 - accuracy: 0.7020 - val_loss: 0.5996 - val_accuracy: 0.6910\n",
      "Epoch 88/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5777 - accuracy: 0.7037 - val_loss: 0.6020 - val_accuracy: 0.6887\n",
      "Epoch 89/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5808 - accuracy: 0.7023 - val_loss: 0.5885 - val_accuracy: 0.6932\n",
      "Epoch 90/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5804 - accuracy: 0.7014 - val_loss: 0.5859 - val_accuracy: 0.6929\n",
      "Epoch 91/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5784 - accuracy: 0.7027 - val_loss: 0.5860 - val_accuracy: 0.6914\n",
      "Epoch 92/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5812 - accuracy: 0.7023 - val_loss: 0.5906 - val_accuracy: 0.6919\n",
      "Epoch 93/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.6994 - val_loss: 0.6040 - val_accuracy: 0.6882\n",
      "Epoch 94/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7039 - val_loss: 0.5863 - val_accuracy: 0.6930\n",
      "Epoch 95/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5756 - accuracy: 0.7045 - val_loss: 0.5912 - val_accuracy: 0.6933\n",
      "Epoch 96/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5764 - accuracy: 0.7035 - val_loss: 0.5851 - val_accuracy: 0.6961\n",
      "Epoch 97/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5737 - accuracy: 0.7063 - val_loss: 0.5946 - val_accuracy: 0.6914\n",
      "Epoch 98/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5817 - accuracy: 0.7022 - val_loss: 0.6071 - val_accuracy: 0.6872\n",
      "Epoch 99/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5729 - accuracy: 0.7049 - val_loss: 0.5974 - val_accuracy: 0.6905\n",
      "Epoch 100/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5753 - accuracy: 0.7046 - val_loss: 0.5867 - val_accuracy: 0.6942\n",
      "Epoch 101/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5709 - accuracy: 0.7053 - val_loss: 0.5930 - val_accuracy: 0.6899\n",
      "Epoch 102/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5711 - accuracy: 0.7058 - val_loss: 0.5913 - val_accuracy: 0.6910\n",
      "Epoch 103/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5775 - accuracy: 0.7043 - val_loss: 0.5853 - val_accuracy: 0.6948\n",
      "Epoch 104/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5767 - accuracy: 0.7035 - val_loss: 0.6280 - val_accuracy: 0.6802\n",
      "Epoch 105/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5770 - accuracy: 0.7050 - val_loss: 0.5900 - val_accuracy: 0.6924\n",
      "Epoch 106/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5751 - accuracy: 0.7042 - val_loss: 0.5872 - val_accuracy: 0.6981\n",
      "Epoch 107/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5713 - accuracy: 0.7052 - val_loss: 0.5893 - val_accuracy: 0.6932\n",
      "Epoch 108/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5748 - accuracy: 0.7051 - val_loss: 0.6187 - val_accuracy: 0.6839\n",
      "Epoch 109/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5713 - accuracy: 0.7062 - val_loss: 0.5864 - val_accuracy: 0.6921\n",
      "Epoch 110/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5730 - accuracy: 0.7064 - val_loss: 0.5864 - val_accuracy: 0.6936\n",
      "Epoch 111/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5839 - accuracy: 0.7031 - val_loss: 0.5953 - val_accuracy: 0.6910\n",
      "Epoch 112/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5742 - accuracy: 0.7047 - val_loss: 0.5931 - val_accuracy: 0.6887\n",
      "Epoch 113/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5683 - accuracy: 0.7080 - val_loss: 0.5872 - val_accuracy: 0.6978\n",
      "Epoch 114/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5700 - accuracy: 0.7076 - val_loss: 0.5911 - val_accuracy: 0.6961\n",
      "Epoch 115/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5711 - accuracy: 0.7070 - val_loss: 0.6086 - val_accuracy: 0.6828\n",
      "Epoch 116/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5691 - accuracy: 0.7085 - val_loss: 0.5784 - val_accuracy: 0.6963\n",
      "Epoch 117/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5708 - accuracy: 0.7064 - val_loss: 0.5858 - val_accuracy: 0.6899\n",
      "Epoch 118/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5663 - accuracy: 0.7078 - val_loss: 0.5902 - val_accuracy: 0.6925\n",
      "Epoch 119/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.7053 - val_loss: 0.6033 - val_accuracy: 0.6759\n",
      "Epoch 120/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5674 - accuracy: 0.7076 - val_loss: 0.5890 - val_accuracy: 0.6891\n",
      "Epoch 121/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5643 - accuracy: 0.7087 - val_loss: 0.5807 - val_accuracy: 0.6940\n",
      "Epoch 122/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5650 - accuracy: 0.7091 - val_loss: 0.5833 - val_accuracy: 0.6954\n",
      "Epoch 123/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5686 - accuracy: 0.7083 - val_loss: 0.5965 - val_accuracy: 0.6882\n",
      "Epoch 124/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7070 - val_loss: 0.5850 - val_accuracy: 0.6948\n",
      "Epoch 125/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5640 - accuracy: 0.7100 - val_loss: 0.5781 - val_accuracy: 0.6916\n",
      "Epoch 126/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5646 - accuracy: 0.7096 - val_loss: 0.6001 - val_accuracy: 0.6911\n",
      "Epoch 127/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5664 - accuracy: 0.7092 - val_loss: 0.5780 - val_accuracy: 0.6957\n",
      "Epoch 128/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5679 - accuracy: 0.7081 - val_loss: 0.5807 - val_accuracy: 0.6945\n",
      "Epoch 129/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7078 - val_loss: 0.5836 - val_accuracy: 0.6938\n",
      "Epoch 130/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5631 - accuracy: 0.7100 - val_loss: 0.5822 - val_accuracy: 0.6923\n",
      "Epoch 131/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5610 - accuracy: 0.7122 - val_loss: 0.5929 - val_accuracy: 0.6929\n",
      "Epoch 132/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5651 - accuracy: 0.7099 - val_loss: 0.5795 - val_accuracy: 0.6940\n",
      "Epoch 133/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5616 - accuracy: 0.7097 - val_loss: 0.5890 - val_accuracy: 0.6935\n",
      "Epoch 134/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7097 - val_loss: 0.5826 - val_accuracy: 0.6942\n",
      "Epoch 135/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5638 - accuracy: 0.7107 - val_loss: 0.6079 - val_accuracy: 0.6835\n",
      "Epoch 136/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5673 - accuracy: 0.7077 - val_loss: 0.5905 - val_accuracy: 0.6948\n",
      "Epoch 137/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5625 - accuracy: 0.7094 - val_loss: 0.5796 - val_accuracy: 0.6951\n",
      "Epoch 138/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5593 - accuracy: 0.7121 - val_loss: 0.5765 - val_accuracy: 0.6899\n",
      "Epoch 139/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5695 - accuracy: 0.7081 - val_loss: 0.5947 - val_accuracy: 0.6910\n",
      "Epoch 140/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5623 - accuracy: 0.7102 - val_loss: 0.5798 - val_accuracy: 0.6960\n",
      "Epoch 141/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5591 - accuracy: 0.7113 - val_loss: 0.5775 - val_accuracy: 0.6936\n",
      "Epoch 142/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5678 - accuracy: 0.7103 - val_loss: 0.6019 - val_accuracy: 0.6882\n",
      "Epoch 143/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5601 - accuracy: 0.7119 - val_loss: 0.6132 - val_accuracy: 0.6919\n",
      "Epoch 144/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.7122 - val_loss: 0.5786 - val_accuracy: 0.6933\n",
      "Epoch 145/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5617 - accuracy: 0.7113 - val_loss: 0.5793 - val_accuracy: 0.6974\n",
      "Epoch 146/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5587 - accuracy: 0.7118 - val_loss: 0.5772 - val_accuracy: 0.6983\n",
      "Epoch 147/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5584 - accuracy: 0.7111 - val_loss: 0.5886 - val_accuracy: 0.6932\n",
      "Epoch 148/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5577 - accuracy: 0.7121 - val_loss: 0.5763 - val_accuracy: 0.6949\n",
      "Epoch 149/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5643 - accuracy: 0.7105 - val_loss: 0.5806 - val_accuracy: 0.6940\n",
      "Epoch 150/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5595 - accuracy: 0.7122 - val_loss: 0.5906 - val_accuracy: 0.6882\n",
      "Epoch 151/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5580 - accuracy: 0.7124 - val_loss: 0.5732 - val_accuracy: 0.6979\n",
      "Epoch 152/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5576 - accuracy: 0.7114 - val_loss: 0.5795 - val_accuracy: 0.6936\n",
      "Epoch 153/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5607 - accuracy: 0.7113 - val_loss: 0.6000 - val_accuracy: 0.6895\n",
      "Epoch 154/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.7111 - val_loss: 0.6003 - val_accuracy: 0.6885\n",
      "Epoch 155/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5565 - accuracy: 0.7131 - val_loss: 0.5882 - val_accuracy: 0.6917\n",
      "Epoch 156/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5588 - accuracy: 0.7131 - val_loss: 0.5886 - val_accuracy: 0.6865\n",
      "Epoch 157/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5580 - accuracy: 0.7126 - val_loss: 0.5804 - val_accuracy: 0.6971\n",
      "Epoch 158/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5627 - accuracy: 0.7115 - val_loss: 0.5960 - val_accuracy: 0.6918\n",
      "Epoch 159/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5614 - accuracy: 0.7108 - val_loss: 0.5808 - val_accuracy: 0.6945\n",
      "Epoch 160/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5548 - accuracy: 0.7139 - val_loss: 0.5777 - val_accuracy: 0.6925\n",
      "Epoch 161/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5565 - accuracy: 0.7140 - val_loss: 0.5772 - val_accuracy: 0.6949\n",
      "Epoch 162/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5545 - accuracy: 0.7150 - val_loss: 0.5740 - val_accuracy: 0.6979\n",
      "Epoch 163/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5582 - accuracy: 0.7129 - val_loss: 0.5818 - val_accuracy: 0.6915\n",
      "Epoch 164/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5550 - accuracy: 0.7133 - val_loss: 0.5994 - val_accuracy: 0.6863\n",
      "Epoch 165/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5574 - accuracy: 0.7132 - val_loss: 0.5871 - val_accuracy: 0.6880\n",
      "Epoch 166/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.7131 - val_loss: 0.5721 - val_accuracy: 0.6932\n",
      "Epoch 167/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7151 - val_loss: 0.5794 - val_accuracy: 0.6970\n",
      "Epoch 168/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7141 - val_loss: 0.5773 - val_accuracy: 0.6926\n",
      "Epoch 169/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7158 - val_loss: 0.5744 - val_accuracy: 0.6931\n",
      "Epoch 170/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5570 - accuracy: 0.7137 - val_loss: 0.5762 - val_accuracy: 0.6944\n",
      "Epoch 171/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5572 - accuracy: 0.7128 - val_loss: 0.5828 - val_accuracy: 0.6890\n",
      "Epoch 172/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5569 - accuracy: 0.7127 - val_loss: 0.5732 - val_accuracy: 0.6972\n",
      "Epoch 173/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.7154 - val_loss: 0.5784 - val_accuracy: 0.6962\n",
      "Epoch 174/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5544 - accuracy: 0.7148 - val_loss: 0.5740 - val_accuracy: 0.6933\n",
      "Epoch 175/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5493 - accuracy: 0.7167 - val_loss: 0.5812 - val_accuracy: 0.6900\n",
      "Epoch 176/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5533 - accuracy: 0.7142 - val_loss: 0.5821 - val_accuracy: 0.6943\n",
      "Epoch 177/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5552 - accuracy: 0.7153 - val_loss: 0.5734 - val_accuracy: 0.6985\n",
      "Epoch 178/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.7147 - val_loss: 0.5810 - val_accuracy: 0.6912\n",
      "Epoch 179/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5563 - accuracy: 0.7133 - val_loss: 0.5724 - val_accuracy: 0.6964\n",
      "Epoch 180/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5469 - accuracy: 0.7190 - val_loss: 0.5747 - val_accuracy: 0.6889\n",
      "Epoch 181/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5526 - accuracy: 0.7150 - val_loss: 0.5846 - val_accuracy: 0.6938\n",
      "Epoch 182/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5571 - accuracy: 0.7146 - val_loss: 0.5859 - val_accuracy: 0.6913\n",
      "Epoch 183/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5553 - accuracy: 0.7153 - val_loss: 0.5801 - val_accuracy: 0.6913\n",
      "Epoch 184/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5498 - accuracy: 0.7166 - val_loss: 0.5798 - val_accuracy: 0.6931\n",
      "Epoch 185/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5482 - accuracy: 0.7175 - val_loss: 0.5748 - val_accuracy: 0.6936\n",
      "Epoch 186/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5565 - accuracy: 0.7152 - val_loss: 0.5838 - val_accuracy: 0.6946\n",
      "Epoch 187/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5498 - accuracy: 0.7157 - val_loss: 0.5758 - val_accuracy: 0.6958\n",
      "Epoch 188/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.7162 - val_loss: 0.5900 - val_accuracy: 0.6910\n",
      "Epoch 189/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7171 - val_loss: 0.5859 - val_accuracy: 0.6955\n",
      "Epoch 190/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5487 - accuracy: 0.7167 - val_loss: 0.5901 - val_accuracy: 0.6938\n",
      "Epoch 191/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5499 - accuracy: 0.7174 - val_loss: 0.5843 - val_accuracy: 0.6951\n",
      "Epoch 192/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5524 - accuracy: 0.7164 - val_loss: 0.5765 - val_accuracy: 0.6943\n",
      "Epoch 193/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5525 - accuracy: 0.7159 - val_loss: 0.5829 - val_accuracy: 0.6976\n",
      "Epoch 194/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5462 - accuracy: 0.7171 - val_loss: 0.5829 - val_accuracy: 0.6937\n",
      "Epoch 195/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5570 - accuracy: 0.7147 - val_loss: 0.5835 - val_accuracy: 0.6898\n",
      "Epoch 196/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7178 - val_loss: 0.5837 - val_accuracy: 0.6948\n",
      "Epoch 197/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.7158 - val_loss: 0.5854 - val_accuracy: 0.6879\n",
      "Epoch 198/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.7178 - val_loss: 0.5812 - val_accuracy: 0.6953\n",
      "Epoch 199/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5490 - accuracy: 0.7178 - val_loss: 0.5848 - val_accuracy: 0.6919\n",
      "Epoch 200/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5514 - accuracy: 0.7162 - val_loss: 0.5742 - val_accuracy: 0.6948\n",
      "Epoch 201/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5477 - accuracy: 0.7182 - val_loss: 0.5858 - val_accuracy: 0.6880\n",
      "Epoch 202/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5494 - accuracy: 0.7187 - val_loss: 0.5737 - val_accuracy: 0.6966\n",
      "Epoch 203/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5514 - accuracy: 0.7181 - val_loss: 0.5867 - val_accuracy: 0.6911\n",
      "Epoch 204/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5452 - accuracy: 0.7188 - val_loss: 0.5817 - val_accuracy: 0.6925\n",
      "Epoch 205/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5478 - accuracy: 0.7175 - val_loss: 0.5811 - val_accuracy: 0.6918\n",
      "Epoch 206/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5506 - accuracy: 0.7182 - val_loss: 0.5889 - val_accuracy: 0.6934\n",
      "Epoch 207/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5440 - accuracy: 0.7191 - val_loss: 0.5772 - val_accuracy: 0.6937\n",
      "Epoch 208/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5479 - accuracy: 0.7181 - val_loss: 0.5749 - val_accuracy: 0.6955\n",
      "Epoch 209/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5495 - accuracy: 0.7173 - val_loss: 0.5746 - val_accuracy: 0.6957\n",
      "Epoch 210/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5419 - accuracy: 0.7203 - val_loss: 0.5659 - val_accuracy: 0.7005\n",
      "Epoch 211/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5454 - accuracy: 0.7197 - val_loss: 0.5841 - val_accuracy: 0.6950\n",
      "Epoch 212/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7188 - val_loss: 0.5781 - val_accuracy: 0.6942\n",
      "Epoch 213/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5425 - accuracy: 0.7203 - val_loss: 0.5781 - val_accuracy: 0.6954\n",
      "Epoch 214/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7189 - val_loss: 0.5813 - val_accuracy: 0.6904\n",
      "Epoch 215/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5493 - accuracy: 0.7167 - val_loss: 0.5804 - val_accuracy: 0.6924\n",
      "Epoch 216/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5436 - accuracy: 0.7203 - val_loss: 0.5776 - val_accuracy: 0.6995\n",
      "Epoch 217/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.7220 - val_loss: 0.5776 - val_accuracy: 0.6942\n",
      "Epoch 218/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5453 - accuracy: 0.7193 - val_loss: 0.5757 - val_accuracy: 0.6956\n",
      "Epoch 219/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5463 - accuracy: 0.7181 - val_loss: 0.5779 - val_accuracy: 0.6910\n",
      "Epoch 220/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5421 - accuracy: 0.7207 - val_loss: 0.5844 - val_accuracy: 0.6965\n",
      "Epoch 221/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7208 - val_loss: 0.5686 - val_accuracy: 0.7001\n",
      "Epoch 222/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5446 - accuracy: 0.7201 - val_loss: 0.5851 - val_accuracy: 0.6920\n",
      "Epoch 223/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5432 - accuracy: 0.7204 - val_loss: 0.5746 - val_accuracy: 0.6954\n",
      "Epoch 224/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5438 - accuracy: 0.7194 - val_loss: 0.5886 - val_accuracy: 0.6936\n",
      "Epoch 225/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7201 - val_loss: 0.5768 - val_accuracy: 0.6955\n",
      "Epoch 226/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5431 - accuracy: 0.7196 - val_loss: 0.5772 - val_accuracy: 0.6994\n",
      "Epoch 227/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5409 - accuracy: 0.7232 - val_loss: 0.5743 - val_accuracy: 0.6967\n",
      "Epoch 228/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5443 - accuracy: 0.7208 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
      "Epoch 229/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7228 - val_loss: 0.5663 - val_accuracy: 0.6987\n",
      "Epoch 230/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7227 - val_loss: 0.5700 - val_accuracy: 0.6964\n",
      "Epoch 231/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5413 - accuracy: 0.7206 - val_loss: 0.5693 - val_accuracy: 0.6963\n",
      "Epoch 232/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.7219 - val_loss: 0.6070 - val_accuracy: 0.6959\n",
      "Epoch 233/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5429 - accuracy: 0.7213 - val_loss: 0.5797 - val_accuracy: 0.6957\n",
      "Epoch 234/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5375 - accuracy: 0.7233 - val_loss: 0.5723 - val_accuracy: 0.6950\n",
      "Epoch 235/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5367 - accuracy: 0.7223 - val_loss: 0.5903 - val_accuracy: 0.6946\n",
      "Epoch 236/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5411 - accuracy: 0.7223 - val_loss: 0.5790 - val_accuracy: 0.6960\n",
      "Epoch 237/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5410 - accuracy: 0.7217 - val_loss: 0.5912 - val_accuracy: 0.6960\n",
      "Epoch 238/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5374 - accuracy: 0.7229 - val_loss: 0.5766 - val_accuracy: 0.6978\n",
      "Epoch 239/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7237 - val_loss: 0.5781 - val_accuracy: 0.6956\n",
      "Epoch 240/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5409 - accuracy: 0.7228 - val_loss: 0.5684 - val_accuracy: 0.7008\n",
      "Epoch 241/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7244 - val_loss: 0.5694 - val_accuracy: 0.7017\n",
      "Epoch 242/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5466 - accuracy: 0.7211 - val_loss: 0.5729 - val_accuracy: 0.6967\n",
      "Epoch 243/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7246 - val_loss: 0.5760 - val_accuracy: 0.6946\n",
      "Epoch 244/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7232 - val_loss: 0.5801 - val_accuracy: 0.6916\n",
      "Epoch 245/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5433 - accuracy: 0.7216 - val_loss: 0.5782 - val_accuracy: 0.6964\n",
      "Epoch 246/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7236 - val_loss: 0.5760 - val_accuracy: 0.6967\n",
      "Epoch 247/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5368 - accuracy: 0.7235 - val_loss: 0.5685 - val_accuracy: 0.6990\n",
      "Epoch 248/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5309 - accuracy: 0.7265 - val_loss: 0.5710 - val_accuracy: 0.6966\n",
      "Epoch 249/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.7219 - val_loss: 0.5699 - val_accuracy: 0.6994\n",
      "Epoch 250/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7227 - val_loss: 0.5700 - val_accuracy: 0.6953\n",
      "Epoch 251/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7222 - val_loss: 0.5775 - val_accuracy: 0.6938\n",
      "Epoch 252/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5389 - accuracy: 0.7231 - val_loss: 0.5893 - val_accuracy: 0.6954\n",
      "Epoch 253/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5371 - accuracy: 0.7242 - val_loss: 0.5718 - val_accuracy: 0.6961\n",
      "Epoch 254/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5370 - accuracy: 0.7256 - val_loss: 0.5722 - val_accuracy: 0.6966\n",
      "Epoch 255/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5374 - accuracy: 0.7236 - val_loss: 0.5815 - val_accuracy: 0.6935\n",
      "Epoch 256/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5373 - accuracy: 0.7246 - val_loss: 0.5751 - val_accuracy: 0.6972\n",
      "Epoch 257/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5365 - accuracy: 0.7251 - val_loss: 0.5713 - val_accuracy: 0.7019\n",
      "Epoch 258/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7244 - val_loss: 0.5661 - val_accuracy: 0.7023\n",
      "Epoch 259/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5362 - accuracy: 0.7231 - val_loss: 0.5785 - val_accuracy: 0.6937\n",
      "Epoch 260/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.7239 - val_loss: 0.5685 - val_accuracy: 0.6963\n",
      "Epoch 261/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.7251 - val_loss: 0.5768 - val_accuracy: 0.6978\n",
      "Epoch 262/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5320 - accuracy: 0.7257 - val_loss: 0.5791 - val_accuracy: 0.6939\n",
      "Epoch 263/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5380 - accuracy: 0.7233 - val_loss: 0.5697 - val_accuracy: 0.6949\n",
      "Epoch 264/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5343 - accuracy: 0.7248 - val_loss: 0.5792 - val_accuracy: 0.6935\n",
      "Epoch 265/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5348 - accuracy: 0.7236 - val_loss: 0.5751 - val_accuracy: 0.6975\n",
      "Epoch 266/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5445 - accuracy: 0.7228 - val_loss: 0.5799 - val_accuracy: 0.6941\n",
      "Epoch 267/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7266 - val_loss: 0.5756 - val_accuracy: 0.6975\n",
      "Epoch 268/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5328 - accuracy: 0.7271 - val_loss: 0.5731 - val_accuracy: 0.6997\n",
      "Epoch 269/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5380 - accuracy: 0.7249 - val_loss: 0.5771 - val_accuracy: 0.6993\n",
      "Epoch 270/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.7257 - val_loss: 0.5794 - val_accuracy: 0.6958\n",
      "Epoch 271/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5329 - accuracy: 0.7267 - val_loss: 0.5819 - val_accuracy: 0.6945\n",
      "Epoch 272/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5351 - accuracy: 0.7259 - val_loss: 0.5733 - val_accuracy: 0.6963\n",
      "Epoch 273/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5328 - accuracy: 0.7263 - val_loss: 0.5749 - val_accuracy: 0.6990\n",
      "Epoch 274/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5374 - accuracy: 0.7239 - val_loss: 0.5828 - val_accuracy: 0.6973\n",
      "Epoch 275/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5326 - accuracy: 0.7257 - val_loss: 0.5780 - val_accuracy: 0.6962\n",
      "Epoch 276/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7253 - val_loss: 0.5734 - val_accuracy: 0.6992\n",
      "Epoch 277/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5303 - accuracy: 0.7261 - val_loss: 0.5651 - val_accuracy: 0.6987\n",
      "Epoch 278/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5308 - accuracy: 0.7276 - val_loss: 0.5741 - val_accuracy: 0.6964\n",
      "Epoch 279/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5318 - accuracy: 0.7263 - val_loss: 0.5729 - val_accuracy: 0.7000\n",
      "Epoch 280/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5377 - accuracy: 0.7249 - val_loss: 0.5727 - val_accuracy: 0.6963\n",
      "Epoch 281/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5275 - accuracy: 0.7290 - val_loss: 0.5696 - val_accuracy: 0.6960\n",
      "Epoch 282/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5343 - accuracy: 0.7248 - val_loss: 0.5703 - val_accuracy: 0.7008\n",
      "Epoch 283/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5311 - accuracy: 0.7269 - val_loss: 0.5781 - val_accuracy: 0.6980\n",
      "Epoch 284/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5337 - accuracy: 0.7267 - val_loss: 0.5812 - val_accuracy: 0.6934\n",
      "Epoch 285/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7272 - val_loss: 0.5742 - val_accuracy: 0.7006\n",
      "Epoch 286/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5269 - accuracy: 0.7290 - val_loss: 0.5668 - val_accuracy: 0.7012\n",
      "Epoch 287/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.7252 - val_loss: 0.5778 - val_accuracy: 0.6949\n",
      "Epoch 288/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7287 - val_loss: 0.5719 - val_accuracy: 0.6994\n",
      "Epoch 289/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7275 - val_loss: 0.5767 - val_accuracy: 0.6967\n",
      "Epoch 290/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7260 - val_loss: 0.5805 - val_accuracy: 0.6943\n",
      "Epoch 291/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5259 - accuracy: 0.7286 - val_loss: 0.5812 - val_accuracy: 0.6911\n",
      "Epoch 292/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5283 - accuracy: 0.7282 - val_loss: 0.5695 - val_accuracy: 0.7000\n",
      "Epoch 293/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7257 - val_loss: 0.5754 - val_accuracy: 0.6947\n",
      "Epoch 294/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.7289 - val_loss: 0.5681 - val_accuracy: 0.7009\n",
      "Epoch 295/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5281 - accuracy: 0.7283 - val_loss: 0.5798 - val_accuracy: 0.6989\n",
      "Epoch 296/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.7279 - val_loss: 0.5722 - val_accuracy: 0.6976\n",
      "Epoch 297/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5358 - accuracy: 0.7269 - val_loss: 0.5801 - val_accuracy: 0.6952\n",
      "Epoch 298/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7255 - val_loss: 0.5712 - val_accuracy: 0.6994\n",
      "Epoch 299/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7291 - val_loss: 0.5714 - val_accuracy: 0.6949\n",
      "Epoch 300/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.7294 - val_loss: 0.5708 - val_accuracy: 0.7004\n",
      "Epoch 301/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.7293 - val_loss: 0.5652 - val_accuracy: 0.7017\n",
      "Epoch 302/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.7285 - val_loss: 0.5720 - val_accuracy: 0.6993\n",
      "Epoch 303/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7307 - val_loss: 0.5772 - val_accuracy: 0.6969\n",
      "Epoch 304/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7275 - val_loss: 0.5694 - val_accuracy: 0.7008\n",
      "Epoch 305/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7306 - val_loss: 0.5720 - val_accuracy: 0.6991\n",
      "Epoch 306/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7283 - val_loss: 0.5702 - val_accuracy: 0.6974\n",
      "Epoch 307/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5275 - accuracy: 0.7297 - val_loss: 0.5747 - val_accuracy: 0.7005\n",
      "Epoch 308/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7294 - val_loss: 0.5773 - val_accuracy: 0.6953\n",
      "Epoch 309/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7282 - val_loss: 0.5721 - val_accuracy: 0.6991\n",
      "Epoch 310/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7312 - val_loss: 0.5827 - val_accuracy: 0.6958\n",
      "Epoch 311/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7296 - val_loss: 0.5752 - val_accuracy: 0.6964\n",
      "Epoch 312/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7291 - val_loss: 0.5867 - val_accuracy: 0.6951\n",
      "Epoch 313/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7305 - val_loss: 0.5675 - val_accuracy: 0.7011\n",
      "Epoch 314/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5289 - accuracy: 0.7285 - val_loss: 0.5762 - val_accuracy: 0.6986\n",
      "Epoch 315/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5266 - accuracy: 0.7298 - val_loss: 0.5704 - val_accuracy: 0.6976\n",
      "Epoch 316/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7296 - val_loss: 0.5901 - val_accuracy: 0.6961\n",
      "Epoch 317/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.7300 - val_loss: 0.5716 - val_accuracy: 0.6976\n",
      "Epoch 318/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7294 - val_loss: 0.5711 - val_accuracy: 0.7005\n",
      "Epoch 319/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7317 - val_loss: 0.5748 - val_accuracy: 0.6983\n",
      "Epoch 320/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7315 - val_loss: 0.5722 - val_accuracy: 0.6986\n",
      "Epoch 321/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7315 - val_loss: 0.5710 - val_accuracy: 0.6982\n",
      "Epoch 322/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.7335 - val_loss: 0.5747 - val_accuracy: 0.6965\n",
      "Epoch 323/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.7298 - val_loss: 0.5792 - val_accuracy: 0.6989\n",
      "Epoch 324/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5279 - accuracy: 0.7282 - val_loss: 0.5713 - val_accuracy: 0.6974\n",
      "Epoch 325/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5215 - accuracy: 0.7329 - val_loss: 0.5753 - val_accuracy: 0.6967\n",
      "Epoch 326/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5266 - accuracy: 0.7301 - val_loss: 0.5862 - val_accuracy: 0.6945\n",
      "Epoch 327/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.7297 - val_loss: 0.5728 - val_accuracy: 0.6987\n",
      "Epoch 328/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5258 - accuracy: 0.7308 - val_loss: 0.5713 - val_accuracy: 0.6972\n",
      "Epoch 329/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5202 - accuracy: 0.7350 - val_loss: 0.5762 - val_accuracy: 0.6971\n",
      "Epoch 330/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5305 - accuracy: 0.7291 - val_loss: 0.5786 - val_accuracy: 0.6952\n",
      "Epoch 331/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5227 - accuracy: 0.7323 - val_loss: 0.5762 - val_accuracy: 0.6956\n",
      "Epoch 332/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5253 - accuracy: 0.7331 - val_loss: 0.5812 - val_accuracy: 0.6991\n",
      "Epoch 333/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7323 - val_loss: 0.5775 - val_accuracy: 0.6954\n",
      "Epoch 334/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5218 - accuracy: 0.7322 - val_loss: 0.5732 - val_accuracy: 0.6968\n",
      "Epoch 335/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7342 - val_loss: 0.5773 - val_accuracy: 0.6963\n",
      "Epoch 336/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.7310 - val_loss: 0.5788 - val_accuracy: 0.6917\n",
      "Epoch 337/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7312 - val_loss: 0.5719 - val_accuracy: 0.6965\n",
      "Epoch 338/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.7331 - val_loss: 0.5719 - val_accuracy: 0.6973\n",
      "Epoch 339/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7332 - val_loss: 0.5804 - val_accuracy: 0.6954\n",
      "Epoch 340/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7332 - val_loss: 0.5782 - val_accuracy: 0.7004\n",
      "Epoch 341/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7329 - val_loss: 0.5719 - val_accuracy: 0.6972\n",
      "Epoch 342/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7315 - val_loss: 0.5855 - val_accuracy: 0.6955\n",
      "Epoch 343/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5212 - accuracy: 0.7338 - val_loss: 0.5788 - val_accuracy: 0.6905\n",
      "Epoch 344/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5243 - accuracy: 0.7316 - val_loss: 0.5792 - val_accuracy: 0.6964\n",
      "Epoch 345/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5227 - accuracy: 0.7327 - val_loss: 0.5757 - val_accuracy: 0.6964\n",
      "Epoch 346/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5261 - accuracy: 0.7326 - val_loss: 0.5931 - val_accuracy: 0.6956\n",
      "Epoch 347/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5252 - accuracy: 0.7322 - val_loss: 0.5745 - val_accuracy: 0.6977\n",
      "Epoch 348/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5196 - accuracy: 0.7337 - val_loss: 0.5710 - val_accuracy: 0.6972\n",
      "Epoch 349/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5221 - accuracy: 0.7336 - val_loss: 0.5726 - val_accuracy: 0.6970\n",
      "Epoch 350/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7309 - val_loss: 0.5738 - val_accuracy: 0.7009\n",
      "Epoch 351/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5196 - accuracy: 0.7342 - val_loss: 0.5670 - val_accuracy: 0.6975\n",
      "Epoch 352/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.7327 - val_loss: 0.5806 - val_accuracy: 0.6910\n",
      "Epoch 353/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5228 - accuracy: 0.7321 - val_loss: 0.5703 - val_accuracy: 0.7024\n",
      "Epoch 354/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5195 - accuracy: 0.7342 - val_loss: 0.5780 - val_accuracy: 0.6947\n",
      "Epoch 355/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7359 - val_loss: 0.5801 - val_accuracy: 0.6976\n",
      "Epoch 356/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5249 - accuracy: 0.7330 - val_loss: 0.5846 - val_accuracy: 0.6875\n",
      "Epoch 357/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7343 - val_loss: 0.5740 - val_accuracy: 0.6957\n",
      "Epoch 358/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5161 - accuracy: 0.7359 - val_loss: 0.5742 - val_accuracy: 0.7000\n",
      "Epoch 359/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7317 - val_loss: 0.5965 - val_accuracy: 0.6966\n",
      "Epoch 360/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5221 - accuracy: 0.7326 - val_loss: 0.5738 - val_accuracy: 0.7004\n",
      "Epoch 361/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5177 - accuracy: 0.7348 - val_loss: 0.5886 - val_accuracy: 0.6955\n",
      "Epoch 362/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.7321 - val_loss: 0.5749 - val_accuracy: 0.6961\n",
      "Epoch 363/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5149 - accuracy: 0.7364 - val_loss: 0.5764 - val_accuracy: 0.6942\n",
      "Epoch 364/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5197 - accuracy: 0.7349 - val_loss: 0.5719 - val_accuracy: 0.6983\n",
      "Epoch 365/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7378 - val_loss: 0.5749 - val_accuracy: 0.6989\n",
      "Epoch 366/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7359 - val_loss: 0.5706 - val_accuracy: 0.7001\n",
      "Epoch 367/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5215 - accuracy: 0.7336 - val_loss: 0.5862 - val_accuracy: 0.6954\n",
      "Epoch 368/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5191 - accuracy: 0.7349 - val_loss: 0.5859 - val_accuracy: 0.6972\n",
      "Epoch 369/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5169 - accuracy: 0.7367 - val_loss: 0.5860 - val_accuracy: 0.6903\n",
      "Epoch 370/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5209 - accuracy: 0.7338 - val_loss: 0.5739 - val_accuracy: 0.6981\n",
      "Epoch 371/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5234 - accuracy: 0.7321 - val_loss: 0.5731 - val_accuracy: 0.7030\n",
      "Epoch 372/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.7347 - val_loss: 0.5859 - val_accuracy: 0.6973\n",
      "Epoch 373/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7354 - val_loss: 0.5737 - val_accuracy: 0.7001\n",
      "Epoch 374/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5170 - accuracy: 0.7350 - val_loss: 0.5724 - val_accuracy: 0.6999\n",
      "Epoch 375/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5184 - accuracy: 0.7352 - val_loss: 0.5773 - val_accuracy: 0.6975\n",
      "Epoch 376/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7342 - val_loss: 0.5697 - val_accuracy: 0.6972\n",
      "Epoch 377/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5154 - accuracy: 0.7370 - val_loss: 0.5733 - val_accuracy: 0.6972\n",
      "Epoch 378/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7353 - val_loss: 0.5813 - val_accuracy: 0.6974\n",
      "Epoch 379/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5180 - accuracy: 0.7346 - val_loss: 0.5772 - val_accuracy: 0.6984\n",
      "Epoch 380/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5125 - accuracy: 0.7387 - val_loss: 0.5709 - val_accuracy: 0.7011\n",
      "Epoch 381/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5139 - accuracy: 0.7365 - val_loss: 0.5907 - val_accuracy: 0.6955\n",
      "Epoch 382/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5182 - accuracy: 0.7356 - val_loss: 0.5911 - val_accuracy: 0.6936\n",
      "Epoch 383/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5211 - accuracy: 0.7339 - val_loss: 0.5770 - val_accuracy: 0.6972\n",
      "Epoch 384/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5130 - accuracy: 0.7381 - val_loss: 0.5744 - val_accuracy: 0.6950\n",
      "Epoch 385/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7343 - val_loss: 0.5827 - val_accuracy: 0.6986\n",
      "Epoch 386/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7352 - val_loss: 0.5815 - val_accuracy: 0.6956\n",
      "Epoch 387/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5141 - accuracy: 0.7378 - val_loss: 0.5711 - val_accuracy: 0.6998\n",
      "Epoch 388/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5153 - accuracy: 0.7365 - val_loss: 0.5770 - val_accuracy: 0.7016\n",
      "Epoch 389/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5122 - accuracy: 0.7367 - val_loss: 0.5733 - val_accuracy: 0.6986\n",
      "Epoch 390/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5139 - accuracy: 0.7380 - val_loss: 0.5800 - val_accuracy: 0.6963\n",
      "Epoch 391/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5134 - accuracy: 0.7365 - val_loss: 0.5718 - val_accuracy: 0.6975\n",
      "Epoch 392/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5176 - accuracy: 0.7360 - val_loss: 0.5775 - val_accuracy: 0.6995\n",
      "Epoch 393/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7342 - val_loss: 0.5782 - val_accuracy: 0.6950\n",
      "Epoch 394/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7372 - val_loss: 0.5772 - val_accuracy: 0.6959\n",
      "Epoch 395/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7340 - val_loss: 0.5824 - val_accuracy: 0.6989\n",
      "Epoch 396/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.7373 - val_loss: 0.5796 - val_accuracy: 0.6990\n",
      "Epoch 397/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5156 - accuracy: 0.7360 - val_loss: 0.5756 - val_accuracy: 0.6973\n",
      "Epoch 398/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7365 - val_loss: 0.5766 - val_accuracy: 0.7004\n",
      "Epoch 399/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5114 - accuracy: 0.7378 - val_loss: 0.6005 - val_accuracy: 0.6892\n",
      "Epoch 400/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5118 - accuracy: 0.7374 - val_loss: 0.5795 - val_accuracy: 0.6982\n",
      "Epoch 401/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7369 - val_loss: 0.5705 - val_accuracy: 0.7016\n",
      "Epoch 402/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5103 - accuracy: 0.7399 - val_loss: 0.5738 - val_accuracy: 0.7001\n",
      "Epoch 403/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5157 - accuracy: 0.7365 - val_loss: 0.5825 - val_accuracy: 0.6973\n",
      "Epoch 404/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7363 - val_loss: 0.5877 - val_accuracy: 0.6953\n",
      "Epoch 405/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.7396 - val_loss: 0.5744 - val_accuracy: 0.6990\n",
      "Epoch 406/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5095 - accuracy: 0.7400 - val_loss: 0.5803 - val_accuracy: 0.6955\n",
      "Epoch 407/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5168 - accuracy: 0.7358 - val_loss: 0.5770 - val_accuracy: 0.6989\n",
      "Epoch 408/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.7395 - val_loss: 0.5748 - val_accuracy: 0.6978\n",
      "Epoch 409/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5148 - accuracy: 0.7377 - val_loss: 0.5783 - val_accuracy: 0.6989\n",
      "Epoch 410/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5125 - accuracy: 0.7379 - val_loss: 0.5781 - val_accuracy: 0.6979\n",
      "Epoch 411/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5116 - accuracy: 0.7387 - val_loss: 0.5754 - val_accuracy: 0.6991\n",
      "Epoch 412/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7385 - val_loss: 0.5847 - val_accuracy: 0.6989\n",
      "Epoch 413/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7349 - val_loss: 0.5777 - val_accuracy: 0.6991\n",
      "Epoch 414/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5108 - accuracy: 0.7381 - val_loss: 0.5765 - val_accuracy: 0.7019\n",
      "Epoch 415/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5108 - accuracy: 0.7387 - val_loss: 0.5750 - val_accuracy: 0.6998\n",
      "Epoch 416/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.7375 - val_loss: 0.5807 - val_accuracy: 0.6969\n",
      "Epoch 417/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5172 - accuracy: 0.7368 - val_loss: 0.5795 - val_accuracy: 0.6985\n",
      "Epoch 418/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5098 - accuracy: 0.7394 - val_loss: 0.5831 - val_accuracy: 0.6990\n",
      "Epoch 419/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5087 - accuracy: 0.7407 - val_loss: 0.5785 - val_accuracy: 0.6957\n",
      "Epoch 420/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5099 - accuracy: 0.7388 - val_loss: 0.5753 - val_accuracy: 0.7012\n",
      "Epoch 421/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5115 - accuracy: 0.7394 - val_loss: 0.5896 - val_accuracy: 0.6930\n",
      "Epoch 422/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5057 - accuracy: 0.7404 - val_loss: 0.5839 - val_accuracy: 0.6912\n",
      "Epoch 423/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7382 - val_loss: 0.5795 - val_accuracy: 0.6964\n",
      "Epoch 424/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5102 - accuracy: 0.7392 - val_loss: 0.5845 - val_accuracy: 0.6966\n",
      "Epoch 425/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5089 - accuracy: 0.7399 - val_loss: 0.5805 - val_accuracy: 0.6989\n",
      "Epoch 426/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5085 - accuracy: 0.7404 - val_loss: 0.5791 - val_accuracy: 0.6957\n",
      "Epoch 427/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.7377 - val_loss: 0.5965 - val_accuracy: 0.6885\n",
      "Epoch 428/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5112 - accuracy: 0.7394 - val_loss: 0.5799 - val_accuracy: 0.6940\n",
      "Epoch 429/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5047 - accuracy: 0.7414 - val_loss: 0.5839 - val_accuracy: 0.6992\n",
      "Epoch 430/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5057 - accuracy: 0.7413 - val_loss: 0.5760 - val_accuracy: 0.7010\n",
      "Epoch 431/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7392 - val_loss: 0.5955 - val_accuracy: 0.6901\n",
      "Epoch 432/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7392 - val_loss: 0.5853 - val_accuracy: 0.6962\n",
      "Epoch 433/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5083 - accuracy: 0.7401 - val_loss: 0.5814 - val_accuracy: 0.6986\n",
      "Epoch 434/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5060 - accuracy: 0.7415 - val_loss: 0.5834 - val_accuracy: 0.6988\n",
      "Epoch 435/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.7393 - val_loss: 0.5840 - val_accuracy: 0.6964\n",
      "Epoch 436/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5119 - accuracy: 0.7392 - val_loss: 0.5759 - val_accuracy: 0.6970\n",
      "Epoch 437/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5120 - accuracy: 0.7391 - val_loss: 0.5829 - val_accuracy: 0.6966\n",
      "Epoch 438/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5107 - accuracy: 0.7411 - val_loss: 0.5775 - val_accuracy: 0.6969\n",
      "Epoch 439/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5070 - accuracy: 0.7409 - val_loss: 0.5912 - val_accuracy: 0.6966\n",
      "Epoch 440/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7426 - val_loss: 0.5802 - val_accuracy: 0.6945\n",
      "Epoch 441/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.7410 - val_loss: 0.5877 - val_accuracy: 0.6961\n",
      "Epoch 442/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.7408 - val_loss: 0.5850 - val_accuracy: 0.6957\n",
      "Epoch 443/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5077 - accuracy: 0.7415 - val_loss: 0.5816 - val_accuracy: 0.7004\n",
      "Epoch 444/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5070 - accuracy: 0.7416 - val_loss: 0.5821 - val_accuracy: 0.6992\n",
      "Epoch 445/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5127 - accuracy: 0.7390 - val_loss: 0.5762 - val_accuracy: 0.6964\n",
      "Epoch 446/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.7422 - val_loss: 0.5780 - val_accuracy: 0.6975\n",
      "Epoch 447/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7444 - val_loss: 0.5829 - val_accuracy: 0.6978\n",
      "Epoch 448/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5095 - accuracy: 0.7403 - val_loss: 0.5819 - val_accuracy: 0.7003\n",
      "Epoch 449/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.7415 - val_loss: 0.5912 - val_accuracy: 0.6941\n",
      "Epoch 450/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.7412 - val_loss: 0.5770 - val_accuracy: 0.6967\n",
      "Epoch 451/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.7398 - val_loss: 0.5954 - val_accuracy: 0.6962\n",
      "Epoch 452/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7404 - val_loss: 0.5742 - val_accuracy: 0.6980\n",
      "Epoch 453/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.7420 - val_loss: 0.5745 - val_accuracy: 0.6976\n",
      "Epoch 454/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7397 - val_loss: 0.5838 - val_accuracy: 0.6976\n",
      "Epoch 455/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5082 - accuracy: 0.7395 - val_loss: 0.5820 - val_accuracy: 0.6919\n",
      "Epoch 456/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.7436 - val_loss: 0.5894 - val_accuracy: 0.6963\n",
      "Epoch 457/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.7433 - val_loss: 0.5833 - val_accuracy: 0.6984\n",
      "Epoch 458/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5032 - accuracy: 0.7425 - val_loss: 0.6018 - val_accuracy: 0.6926\n",
      "Epoch 459/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.7401 - val_loss: 0.5834 - val_accuracy: 0.6946\n",
      "Epoch 460/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5003 - accuracy: 0.7458 - val_loss: 0.5820 - val_accuracy: 0.7001\n",
      "Epoch 461/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5015 - accuracy: 0.7441 - val_loss: 0.5840 - val_accuracy: 0.6939\n",
      "Epoch 462/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5056 - accuracy: 0.7415 - val_loss: 0.5769 - val_accuracy: 0.6999\n",
      "Epoch 463/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5009 - accuracy: 0.7440 - val_loss: 0.5760 - val_accuracy: 0.6986\n",
      "Epoch 464/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.7432 - val_loss: 0.5859 - val_accuracy: 0.6987\n",
      "Epoch 465/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5036 - accuracy: 0.7433 - val_loss: 0.5841 - val_accuracy: 0.6986\n",
      "Epoch 466/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5007 - accuracy: 0.7447 - val_loss: 0.5782 - val_accuracy: 0.6976\n",
      "Epoch 467/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7450 - val_loss: 0.5928 - val_accuracy: 0.6938\n",
      "Epoch 468/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7357 - val_loss: 0.5935 - val_accuracy: 0.6930\n",
      "Epoch 469/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.7436 - val_loss: 0.5844 - val_accuracy: 0.6962\n",
      "Epoch 470/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5004 - accuracy: 0.7434 - val_loss: 0.5770 - val_accuracy: 0.7003\n",
      "Epoch 471/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.7421 - val_loss: 0.5786 - val_accuracy: 0.6970\n",
      "Epoch 472/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5011 - accuracy: 0.7439 - val_loss: 0.5826 - val_accuracy: 0.6999\n",
      "Epoch 473/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5043 - accuracy: 0.7428 - val_loss: 0.5859 - val_accuracy: 0.6954\n",
      "Epoch 474/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5013 - accuracy: 0.7441 - val_loss: 0.5910 - val_accuracy: 0.6942\n",
      "Epoch 475/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.7453 - val_loss: 0.5903 - val_accuracy: 0.6913\n",
      "Epoch 476/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5052 - accuracy: 0.7435 - val_loss: 0.5797 - val_accuracy: 0.6977\n",
      "Epoch 477/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5010 - accuracy: 0.7441 - val_loss: 0.5778 - val_accuracy: 0.6959\n",
      "Epoch 478/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.7418 - val_loss: 0.5785 - val_accuracy: 0.6997\n",
      "Epoch 479/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5006 - accuracy: 0.7446 - val_loss: 0.5851 - val_accuracy: 0.6974\n",
      "Epoch 480/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5002 - accuracy: 0.7444 - val_loss: 0.5938 - val_accuracy: 0.6931\n",
      "Epoch 481/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5063 - accuracy: 0.7424 - val_loss: 0.5798 - val_accuracy: 0.6972\n",
      "Epoch 482/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5029 - accuracy: 0.7437 - val_loss: 0.5851 - val_accuracy: 0.6982\n",
      "Epoch 483/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5006 - accuracy: 0.7443 - val_loss: 0.5942 - val_accuracy: 0.6939\n",
      "Epoch 484/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5032 - accuracy: 0.7431 - val_loss: 0.5894 - val_accuracy: 0.6969\n",
      "Epoch 485/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5017 - accuracy: 0.7442 - val_loss: 0.5827 - val_accuracy: 0.6935\n",
      "Epoch 486/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5009 - accuracy: 0.7438 - val_loss: 0.5828 - val_accuracy: 0.6959\n",
      "Epoch 487/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5007 - accuracy: 0.7449 - val_loss: 0.5899 - val_accuracy: 0.6981\n",
      "Epoch 488/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4988 - accuracy: 0.7458 - val_loss: 0.5821 - val_accuracy: 0.6980\n",
      "Epoch 489/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5085 - accuracy: 0.7425 - val_loss: 0.5805 - val_accuracy: 0.6988\n",
      "Epoch 490/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.7454 - val_loss: 0.5863 - val_accuracy: 0.6946\n",
      "Epoch 491/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5038 - accuracy: 0.7439 - val_loss: 0.5885 - val_accuracy: 0.6993\n",
      "Epoch 492/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4986 - accuracy: 0.7462 - val_loss: 0.5827 - val_accuracy: 0.6957\n",
      "Epoch 493/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5024 - accuracy: 0.7445 - val_loss: 0.5807 - val_accuracy: 0.6981\n",
      "Epoch 494/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4994 - accuracy: 0.7458 - val_loss: 0.5834 - val_accuracy: 0.6959\n",
      "Epoch 495/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5009 - accuracy: 0.7453 - val_loss: 0.5836 - val_accuracy: 0.6987\n",
      "Epoch 496/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5039 - accuracy: 0.7442 - val_loss: 0.5868 - val_accuracy: 0.6974\n",
      "Epoch 497/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4967 - accuracy: 0.7471 - val_loss: 0.5848 - val_accuracy: 0.6976\n",
      "Epoch 498/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5085 - accuracy: 0.7425 - val_loss: 0.5880 - val_accuracy: 0.6978\n",
      "Epoch 499/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4979 - accuracy: 0.7470 - val_loss: 0.5880 - val_accuracy: 0.6916\n",
      "Epoch 500/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5010 - accuracy: 0.7441 - val_loss: 0.5848 - val_accuracy: 0.6994\n",
      "Epoch 501/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5006 - accuracy: 0.7455 - val_loss: 0.5909 - val_accuracy: 0.6974\n",
      "Epoch 502/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.7471 - val_loss: 0.5895 - val_accuracy: 0.6940\n",
      "Epoch 503/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4954 - accuracy: 0.7480 - val_loss: 0.5904 - val_accuracy: 0.6994\n",
      "Epoch 504/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.7471 - val_loss: 0.5874 - val_accuracy: 0.6968\n",
      "Epoch 505/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4991 - accuracy: 0.7451 - val_loss: 0.5902 - val_accuracy: 0.6961\n",
      "Epoch 506/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4943 - accuracy: 0.7491 - val_loss: 0.5885 - val_accuracy: 0.6950\n",
      "Epoch 507/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5040 - accuracy: 0.7428 - val_loss: 0.5929 - val_accuracy: 0.6919\n",
      "Epoch 508/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5036 - accuracy: 0.7441 - val_loss: 0.5903 - val_accuracy: 0.6953\n",
      "Epoch 509/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5010 - accuracy: 0.7452 - val_loss: 0.5951 - val_accuracy: 0.6954\n",
      "Epoch 510/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4987 - accuracy: 0.7468 - val_loss: 0.5889 - val_accuracy: 0.6934\n",
      "Epoch 511/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4973 - accuracy: 0.7467 - val_loss: 0.5937 - val_accuracy: 0.6950\n",
      "Epoch 512/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5036 - accuracy: 0.7437 - val_loss: 0.6009 - val_accuracy: 0.6886\n",
      "Epoch 513/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4938 - accuracy: 0.7499 - val_loss: 0.5868 - val_accuracy: 0.6955\n",
      "Epoch 514/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4983 - accuracy: 0.7462 - val_loss: 0.5871 - val_accuracy: 0.6952\n",
      "Epoch 515/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4945 - accuracy: 0.7481 - val_loss: 0.5941 - val_accuracy: 0.6951\n",
      "Epoch 516/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5000 - accuracy: 0.7460 - val_loss: 0.5833 - val_accuracy: 0.6955\n",
      "Epoch 517/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4942 - accuracy: 0.7474 - val_loss: 0.5833 - val_accuracy: 0.7015\n",
      "Epoch 518/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4943 - accuracy: 0.7484 - val_loss: 0.5801 - val_accuracy: 0.7016\n",
      "Epoch 519/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.7478 - val_loss: 0.6156 - val_accuracy: 0.6897\n",
      "Epoch 520/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5031 - accuracy: 0.7448 - val_loss: 0.6010 - val_accuracy: 0.6961\n",
      "Epoch 521/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4993 - accuracy: 0.7452 - val_loss: 0.5978 - val_accuracy: 0.6946\n",
      "Epoch 522/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4981 - accuracy: 0.7456 - val_loss: 0.5847 - val_accuracy: 0.6988\n",
      "Epoch 523/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.7471 - val_loss: 0.5852 - val_accuracy: 0.6954\n",
      "Epoch 524/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4934 - accuracy: 0.7483 - val_loss: 0.5890 - val_accuracy: 0.6968\n",
      "Epoch 525/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4946 - accuracy: 0.7490 - val_loss: 0.5877 - val_accuracy: 0.6944\n",
      "Epoch 526/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5045 - accuracy: 0.7430 - val_loss: 0.5890 - val_accuracy: 0.6960\n",
      "Epoch 527/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.7465 - val_loss: 0.5852 - val_accuracy: 0.6992\n",
      "Epoch 528/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4956 - accuracy: 0.7492 - val_loss: 0.5885 - val_accuracy: 0.6986\n",
      "Epoch 529/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5096 - accuracy: 0.7421 - val_loss: 0.5894 - val_accuracy: 0.6974\n",
      "Epoch 530/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4948 - accuracy: 0.7466 - val_loss: 0.5816 - val_accuracy: 0.6979\n",
      "Epoch 531/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4941 - accuracy: 0.7502 - val_loss: 0.5929 - val_accuracy: 0.6926\n",
      "Epoch 532/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5018 - accuracy: 0.7462 - val_loss: 0.5920 - val_accuracy: 0.6955\n",
      "Epoch 533/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4960 - accuracy: 0.7484 - val_loss: 0.5808 - val_accuracy: 0.6982\n",
      "Epoch 534/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.7486 - val_loss: 0.5870 - val_accuracy: 0.6939\n",
      "Epoch 535/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4946 - accuracy: 0.7481 - val_loss: 0.5839 - val_accuracy: 0.6980\n",
      "Epoch 536/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.7488 - val_loss: 0.5825 - val_accuracy: 0.6988\n",
      "Epoch 537/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4942 - accuracy: 0.7492 - val_loss: 0.5959 - val_accuracy: 0.6995\n",
      "Epoch 538/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4931 - accuracy: 0.7490 - val_loss: 0.5949 - val_accuracy: 0.6935\n",
      "Epoch 539/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4907 - accuracy: 0.7501 - val_loss: 0.5847 - val_accuracy: 0.6992\n",
      "Epoch 540/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4987 - accuracy: 0.7471 - val_loss: 0.6005 - val_accuracy: 0.6896\n",
      "Epoch 541/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.7488 - val_loss: 0.5936 - val_accuracy: 0.6963\n",
      "Epoch 542/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4935 - accuracy: 0.7494 - val_loss: 0.5988 - val_accuracy: 0.6903\n",
      "Epoch 543/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4914 - accuracy: 0.7497 - val_loss: 0.6057 - val_accuracy: 0.6950\n",
      "Epoch 544/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4905 - accuracy: 0.7514 - val_loss: 0.6065 - val_accuracy: 0.6943\n",
      "Epoch 545/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4960 - accuracy: 0.7480 - val_loss: 0.5890 - val_accuracy: 0.6961\n",
      "Epoch 546/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4982 - accuracy: 0.7461 - val_loss: 0.6054 - val_accuracy: 0.6913\n",
      "Epoch 547/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4988 - accuracy: 0.7469 - val_loss: 0.5929 - val_accuracy: 0.6937\n",
      "Epoch 548/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4916 - accuracy: 0.7500 - val_loss: 0.5878 - val_accuracy: 0.6986\n",
      "Epoch 549/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4926 - accuracy: 0.7497 - val_loss: 0.5911 - val_accuracy: 0.6953\n",
      "Epoch 550/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4966 - accuracy: 0.7486 - val_loss: 0.5975 - val_accuracy: 0.6934\n",
      "Epoch 551/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4931 - accuracy: 0.7490 - val_loss: 0.5842 - val_accuracy: 0.6985\n",
      "Epoch 552/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4898 - accuracy: 0.7508 - val_loss: 0.5881 - val_accuracy: 0.6967\n",
      "Epoch 553/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4878 - accuracy: 0.7525 - val_loss: 0.5925 - val_accuracy: 0.6995\n",
      "Epoch 554/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4912 - accuracy: 0.7510 - val_loss: 0.5927 - val_accuracy: 0.6928\n",
      "Epoch 555/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4939 - accuracy: 0.7489 - val_loss: 0.5919 - val_accuracy: 0.6982\n",
      "Epoch 556/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4954 - accuracy: 0.7493 - val_loss: 0.5924 - val_accuracy: 0.6946\n",
      "Epoch 557/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4919 - accuracy: 0.7508 - val_loss: 0.5943 - val_accuracy: 0.6960\n",
      "Epoch 558/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4924 - accuracy: 0.7511 - val_loss: 0.5842 - val_accuracy: 0.6981\n",
      "Epoch 559/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4982 - accuracy: 0.7473 - val_loss: 0.6020 - val_accuracy: 0.6947\n",
      "Epoch 560/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4905 - accuracy: 0.7512 - val_loss: 0.5856 - val_accuracy: 0.6961\n",
      "Epoch 561/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4943 - accuracy: 0.7489 - val_loss: 0.5916 - val_accuracy: 0.6919\n",
      "Epoch 562/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4941 - accuracy: 0.7493 - val_loss: 0.6034 - val_accuracy: 0.6910\n",
      "Epoch 563/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.7522 - val_loss: 0.6016 - val_accuracy: 0.6917\n",
      "Epoch 564/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4913 - accuracy: 0.7507 - val_loss: 0.6015 - val_accuracy: 0.6915\n",
      "Epoch 565/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4987 - accuracy: 0.7469 - val_loss: 0.5952 - val_accuracy: 0.6890\n",
      "Epoch 566/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.7526 - val_loss: 0.5931 - val_accuracy: 0.6915\n",
      "Epoch 567/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4872 - accuracy: 0.7518 - val_loss: 0.6247 - val_accuracy: 0.6938\n",
      "Epoch 568/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7522 - val_loss: 0.5853 - val_accuracy: 0.7016\n",
      "Epoch 569/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4893 - accuracy: 0.7512 - val_loss: 0.5914 - val_accuracy: 0.6987\n",
      "Epoch 570/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4850 - accuracy: 0.7531 - val_loss: 0.5959 - val_accuracy: 0.6968\n",
      "Epoch 571/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4953 - accuracy: 0.7485 - val_loss: 0.5979 - val_accuracy: 0.6962\n",
      "Epoch 572/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7518 - val_loss: 0.5949 - val_accuracy: 0.6975\n",
      "Epoch 573/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4922 - accuracy: 0.7509 - val_loss: 0.5948 - val_accuracy: 0.6966\n",
      "Epoch 574/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4876 - accuracy: 0.7525 - val_loss: 0.5981 - val_accuracy: 0.6967\n",
      "Epoch 575/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4876 - accuracy: 0.7531 - val_loss: 0.5920 - val_accuracy: 0.6982\n",
      "Epoch 576/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4980 - accuracy: 0.7481 - val_loss: 0.5904 - val_accuracy: 0.6956\n",
      "Epoch 577/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4856 - accuracy: 0.7522 - val_loss: 0.5937 - val_accuracy: 0.6907\n",
      "Epoch 578/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4821 - accuracy: 0.7557 - val_loss: 0.6004 - val_accuracy: 0.6939\n",
      "Epoch 579/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4896 - accuracy: 0.7508 - val_loss: 0.5902 - val_accuracy: 0.6949\n",
      "Epoch 580/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.7510 - val_loss: 0.6066 - val_accuracy: 0.6968\n",
      "Epoch 581/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.7524 - val_loss: 0.5960 - val_accuracy: 0.6970\n",
      "Epoch 582/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4822 - accuracy: 0.7550 - val_loss: 0.6057 - val_accuracy: 0.6898\n",
      "Epoch 583/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4876 - accuracy: 0.7531 - val_loss: 0.5958 - val_accuracy: 0.6932\n",
      "Epoch 584/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4913 - accuracy: 0.7503 - val_loss: 0.6024 - val_accuracy: 0.6934\n",
      "Epoch 585/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4851 - accuracy: 0.7539 - val_loss: 0.5958 - val_accuracy: 0.6943\n",
      "Epoch 586/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4893 - accuracy: 0.7523 - val_loss: 0.5932 - val_accuracy: 0.6963\n",
      "Epoch 587/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4890 - accuracy: 0.7535 - val_loss: 0.5940 - val_accuracy: 0.6974\n",
      "Epoch 588/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4861 - accuracy: 0.7529 - val_loss: 0.6007 - val_accuracy: 0.6964\n",
      "Epoch 589/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4929 - accuracy: 0.7502 - val_loss: 0.6096 - val_accuracy: 0.6931\n",
      "Epoch 590/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4894 - accuracy: 0.7508 - val_loss: 0.6121 - val_accuracy: 0.6896\n",
      "Epoch 591/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7525 - val_loss: 0.5907 - val_accuracy: 0.6958\n",
      "Epoch 592/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4838 - accuracy: 0.7547 - val_loss: 0.5989 - val_accuracy: 0.6949\n",
      "Epoch 593/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7516 - val_loss: 0.5891 - val_accuracy: 0.6994\n",
      "Epoch 594/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.7519 - val_loss: 0.5927 - val_accuracy: 0.6987\n",
      "Epoch 595/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4878 - accuracy: 0.7543 - val_loss: 0.5933 - val_accuracy: 0.6978\n",
      "Epoch 596/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4856 - accuracy: 0.7534 - val_loss: 0.5961 - val_accuracy: 0.6947\n",
      "Epoch 597/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4811 - accuracy: 0.7566 - val_loss: 0.5952 - val_accuracy: 0.6987\n",
      "Epoch 598/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4841 - accuracy: 0.7541 - val_loss: 0.6049 - val_accuracy: 0.6962\n",
      "Epoch 599/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4939 - accuracy: 0.7507 - val_loss: 0.5917 - val_accuracy: 0.6966\n",
      "Epoch 600/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.7538 - val_loss: 0.5959 - val_accuracy: 0.6962\n",
      "Epoch 601/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4871 - accuracy: 0.7525 - val_loss: 0.5968 - val_accuracy: 0.6971\n",
      "Epoch 602/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.7527 - val_loss: 0.5975 - val_accuracy: 0.6950\n",
      "Epoch 603/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4885 - accuracy: 0.7519 - val_loss: 0.6077 - val_accuracy: 0.6938\n",
      "Epoch 604/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4795 - accuracy: 0.7579 - val_loss: 0.6012 - val_accuracy: 0.6961\n",
      "Epoch 605/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4840 - accuracy: 0.7550 - val_loss: 0.5982 - val_accuracy: 0.6935\n",
      "Epoch 606/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4891 - accuracy: 0.7527 - val_loss: 0.5937 - val_accuracy: 0.6976\n",
      "Epoch 607/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4881 - accuracy: 0.7530 - val_loss: 0.6140 - val_accuracy: 0.6946\n",
      "Epoch 608/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4899 - accuracy: 0.7529 - val_loss: 0.6000 - val_accuracy: 0.6932\n",
      "Epoch 609/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7528 - val_loss: 0.5997 - val_accuracy: 0.6963\n",
      "Epoch 610/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7540 - val_loss: 0.5952 - val_accuracy: 0.6986\n",
      "Epoch 611/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4841 - accuracy: 0.7547 - val_loss: 0.5996 - val_accuracy: 0.7004\n",
      "Epoch 612/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4885 - accuracy: 0.7532 - val_loss: 0.6295 - val_accuracy: 0.6854\n",
      "Epoch 613/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4963 - accuracy: 0.7493 - val_loss: 0.6070 - val_accuracy: 0.6943\n",
      "Epoch 614/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.7539 - val_loss: 0.5985 - val_accuracy: 0.6988\n",
      "Epoch 615/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4893 - accuracy: 0.7530 - val_loss: 0.6049 - val_accuracy: 0.6963\n",
      "Epoch 616/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4824 - accuracy: 0.7562 - val_loss: 0.6015 - val_accuracy: 0.6992\n",
      "Epoch 617/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4875 - accuracy: 0.7535 - val_loss: 0.6141 - val_accuracy: 0.6873\n",
      "Epoch 618/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4815 - accuracy: 0.7558 - val_loss: 0.5982 - val_accuracy: 0.6925\n",
      "Epoch 619/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4813 - accuracy: 0.7561 - val_loss: 0.6016 - val_accuracy: 0.6908\n",
      "Epoch 620/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.7548 - val_loss: 0.6275 - val_accuracy: 0.6949\n",
      "Epoch 621/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5006 - accuracy: 0.7471 - val_loss: 0.5954 - val_accuracy: 0.6989\n",
      "Epoch 622/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4821 - accuracy: 0.7552 - val_loss: 0.6027 - val_accuracy: 0.6949\n",
      "Epoch 623/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4872 - accuracy: 0.7544 - val_loss: 0.6322 - val_accuracy: 0.6867\n",
      "Epoch 624/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4909 - accuracy: 0.7513 - val_loss: 0.6039 - val_accuracy: 0.6966\n",
      "Epoch 625/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.7542 - val_loss: 0.5976 - val_accuracy: 0.6939\n",
      "Epoch 626/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4785 - accuracy: 0.7568 - val_loss: 0.6077 - val_accuracy: 0.6892\n",
      "Epoch 627/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.7548 - val_loss: 0.6040 - val_accuracy: 0.6954\n",
      "Epoch 628/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.7556 - val_loss: 0.5961 - val_accuracy: 0.6968\n",
      "Epoch 629/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4820 - accuracy: 0.7557 - val_loss: 0.5979 - val_accuracy: 0.6960\n",
      "Epoch 630/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.7547 - val_loss: 0.6061 - val_accuracy: 0.6972\n",
      "Epoch 631/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.7573 - val_loss: 0.6152 - val_accuracy: 0.6952\n",
      "Epoch 632/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4882 - accuracy: 0.7531 - val_loss: 0.6017 - val_accuracy: 0.6954\n",
      "Epoch 633/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4840 - accuracy: 0.7553 - val_loss: 0.5968 - val_accuracy: 0.6963\n",
      "Epoch 634/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.7576 - val_loss: 0.6198 - val_accuracy: 0.6917\n",
      "Epoch 635/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4793 - accuracy: 0.7586 - val_loss: 0.6012 - val_accuracy: 0.6963\n",
      "Epoch 636/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4768 - accuracy: 0.7585 - val_loss: 0.6103 - val_accuracy: 0.6925\n",
      "Epoch 637/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4748 - accuracy: 0.7597 - val_loss: 0.6135 - val_accuracy: 0.6938\n",
      "Epoch 638/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4804 - accuracy: 0.7568 - val_loss: 0.6113 - val_accuracy: 0.6905\n",
      "Epoch 639/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4853 - accuracy: 0.7549 - val_loss: 0.5965 - val_accuracy: 0.6953\n",
      "Epoch 640/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4787 - accuracy: 0.7577 - val_loss: 0.6034 - val_accuracy: 0.6960\n",
      "Epoch 641/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4814 - accuracy: 0.7566 - val_loss: 0.6087 - val_accuracy: 0.6955\n",
      "Epoch 642/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4884 - accuracy: 0.7533 - val_loss: 0.6000 - val_accuracy: 0.6974\n",
      "Epoch 643/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4796 - accuracy: 0.7585 - val_loss: 0.6018 - val_accuracy: 0.6962\n",
      "Epoch 644/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4851 - accuracy: 0.7550 - val_loss: 0.6027 - val_accuracy: 0.6976\n",
      "Epoch 645/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4778 - accuracy: 0.7593 - val_loss: 0.6010 - val_accuracy: 0.7011\n",
      "Epoch 646/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4818 - accuracy: 0.7558 - val_loss: 0.6076 - val_accuracy: 0.6945\n",
      "Epoch 647/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4863 - accuracy: 0.7539 - val_loss: 0.6047 - val_accuracy: 0.6969\n",
      "Epoch 648/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4796 - accuracy: 0.7570 - val_loss: 0.6055 - val_accuracy: 0.6939\n",
      "Epoch 649/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4721 - accuracy: 0.7618 - val_loss: 0.6138 - val_accuracy: 0.6888\n",
      "Epoch 650/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4785 - accuracy: 0.7584 - val_loss: 0.6027 - val_accuracy: 0.6980\n",
      "Epoch 651/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4884 - accuracy: 0.7525 - val_loss: 0.6061 - val_accuracy: 0.6947\n",
      "Epoch 652/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4818 - accuracy: 0.7555 - val_loss: 0.5978 - val_accuracy: 0.6961\n",
      "Epoch 653/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4768 - accuracy: 0.7599 - val_loss: 0.6103 - val_accuracy: 0.6970\n",
      "Epoch 654/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4825 - accuracy: 0.7557 - val_loss: 0.6016 - val_accuracy: 0.6957\n",
      "Epoch 655/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4811 - accuracy: 0.7577 - val_loss: 0.6154 - val_accuracy: 0.6922\n",
      "Epoch 656/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4799 - accuracy: 0.7572 - val_loss: 0.6058 - val_accuracy: 0.6930\n",
      "Epoch 657/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4783 - accuracy: 0.7583 - val_loss: 0.6031 - val_accuracy: 0.6946\n",
      "Epoch 658/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4772 - accuracy: 0.7588 - val_loss: 0.6045 - val_accuracy: 0.6939\n",
      "Epoch 659/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.7590 - val_loss: 0.6110 - val_accuracy: 0.6923\n",
      "Epoch 660/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4791 - accuracy: 0.7576 - val_loss: 0.6123 - val_accuracy: 0.6909\n",
      "Epoch 661/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4792 - accuracy: 0.7587 - val_loss: 0.6081 - val_accuracy: 0.6981\n",
      "Epoch 662/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4774 - accuracy: 0.7590 - val_loss: 0.6084 - val_accuracy: 0.6953\n",
      "Epoch 663/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4760 - accuracy: 0.7596 - val_loss: 0.6045 - val_accuracy: 0.6939\n",
      "Epoch 664/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4776 - accuracy: 0.7584 - val_loss: 0.6032 - val_accuracy: 0.6921\n",
      "Epoch 665/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4804 - accuracy: 0.7575 - val_loss: 0.6080 - val_accuracy: 0.6947\n",
      "Epoch 666/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4760 - accuracy: 0.7591 - val_loss: 0.6036 - val_accuracy: 0.6952\n",
      "Epoch 667/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4814 - accuracy: 0.7574 - val_loss: 0.6051 - val_accuracy: 0.6962\n",
      "Epoch 668/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4766 - accuracy: 0.7598 - val_loss: 0.6085 - val_accuracy: 0.6917\n",
      "Epoch 669/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4703 - accuracy: 0.7621 - val_loss: 0.6092 - val_accuracy: 0.6929\n",
      "Epoch 670/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4792 - accuracy: 0.7588 - val_loss: 0.6077 - val_accuracy: 0.6956\n",
      "Epoch 671/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.7580 - val_loss: 0.6091 - val_accuracy: 0.6963\n",
      "Epoch 672/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4802 - accuracy: 0.7585 - val_loss: 0.6105 - val_accuracy: 0.6956\n",
      "Epoch 673/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4874 - accuracy: 0.7550 - val_loss: 0.6046 - val_accuracy: 0.6972\n",
      "Epoch 674/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.7571 - val_loss: 0.6100 - val_accuracy: 0.6920\n",
      "Epoch 675/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4705 - accuracy: 0.7621 - val_loss: 0.6170 - val_accuracy: 0.6929\n",
      "Epoch 676/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4773 - accuracy: 0.7587 - val_loss: 0.6128 - val_accuracy: 0.6918\n",
      "Epoch 677/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4812 - accuracy: 0.7572 - val_loss: 0.6105 - val_accuracy: 0.6943\n",
      "Epoch 678/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4778 - accuracy: 0.7568 - val_loss: 0.6112 - val_accuracy: 0.6952\n",
      "Epoch 679/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4752 - accuracy: 0.7608 - val_loss: 0.6270 - val_accuracy: 0.6916\n",
      "Epoch 680/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4801 - accuracy: 0.7573 - val_loss: 0.6053 - val_accuracy: 0.6969\n",
      "Epoch 681/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4752 - accuracy: 0.7598 - val_loss: 0.6047 - val_accuracy: 0.6921\n",
      "Epoch 682/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4763 - accuracy: 0.7600 - val_loss: 0.6027 - val_accuracy: 0.6965\n",
      "Epoch 683/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.7554 - val_loss: 0.6256 - val_accuracy: 0.6860\n",
      "Epoch 684/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4865 - accuracy: 0.7538 - val_loss: 0.6041 - val_accuracy: 0.6951\n",
      "Epoch 685/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4736 - accuracy: 0.7617 - val_loss: 0.6153 - val_accuracy: 0.6930\n",
      "Epoch 686/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4718 - accuracy: 0.7620 - val_loss: 0.6049 - val_accuracy: 0.6957\n",
      "Epoch 687/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4790 - accuracy: 0.7590 - val_loss: 0.6139 - val_accuracy: 0.6950\n",
      "Epoch 688/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4755 - accuracy: 0.7594 - val_loss: 0.6096 - val_accuracy: 0.6913\n",
      "Epoch 689/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4899 - accuracy: 0.7542 - val_loss: 0.6109 - val_accuracy: 0.6927\n",
      "Epoch 690/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7608 - val_loss: 0.6132 - val_accuracy: 0.6936\n",
      "Epoch 691/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4782 - accuracy: 0.7588 - val_loss: 0.6090 - val_accuracy: 0.6956\n",
      "Epoch 692/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4776 - accuracy: 0.7595 - val_loss: 0.6112 - val_accuracy: 0.6913\n",
      "Epoch 693/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4735 - accuracy: 0.7613 - val_loss: 0.6044 - val_accuracy: 0.6948\n",
      "Epoch 694/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4854 - accuracy: 0.7561 - val_loss: 0.6154 - val_accuracy: 0.6932\n",
      "Epoch 695/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.7557 - val_loss: 0.6038 - val_accuracy: 0.6933\n",
      "Epoch 696/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4642 - accuracy: 0.7668 - val_loss: 0.6260 - val_accuracy: 0.6884\n",
      "Epoch 697/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4791 - accuracy: 0.7579 - val_loss: 0.6123 - val_accuracy: 0.6965\n",
      "Epoch 698/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.7618 - val_loss: 0.6078 - val_accuracy: 0.6959\n",
      "Epoch 699/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4783 - accuracy: 0.7584 - val_loss: 0.6098 - val_accuracy: 0.6944\n",
      "Epoch 700/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4670 - accuracy: 0.7645 - val_loss: 0.6134 - val_accuracy: 0.6974\n",
      "Epoch 701/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4812 - accuracy: 0.7580 - val_loss: 0.6103 - val_accuracy: 0.6946\n",
      "Epoch 702/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4725 - accuracy: 0.7615 - val_loss: 0.6115 - val_accuracy: 0.6979\n",
      "Epoch 703/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4708 - accuracy: 0.7630 - val_loss: 0.6051 - val_accuracy: 0.6976\n",
      "Epoch 704/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4776 - accuracy: 0.7585 - val_loss: 0.6161 - val_accuracy: 0.6914\n",
      "Epoch 705/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4751 - accuracy: 0.7594 - val_loss: 0.6122 - val_accuracy: 0.6901\n",
      "Epoch 706/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.7588 - val_loss: 0.6078 - val_accuracy: 0.6918\n",
      "Epoch 707/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4746 - accuracy: 0.7607 - val_loss: 0.6201 - val_accuracy: 0.6855\n",
      "Epoch 708/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4714 - accuracy: 0.7619 - val_loss: 0.6188 - val_accuracy: 0.6936\n",
      "Epoch 709/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.6065 - val_accuracy: 0.6983\n",
      "Epoch 710/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4747 - accuracy: 0.7602 - val_loss: 0.6146 - val_accuracy: 0.6895\n",
      "Epoch 711/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.7625 - val_loss: 0.6168 - val_accuracy: 0.6897\n",
      "Epoch 712/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4689 - accuracy: 0.7638 - val_loss: 0.6094 - val_accuracy: 0.6964\n",
      "Epoch 713/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4677 - accuracy: 0.7654 - val_loss: 0.6231 - val_accuracy: 0.6887\n",
      "Epoch 714/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7615 - val_loss: 0.6129 - val_accuracy: 0.6977\n",
      "Epoch 715/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4716 - accuracy: 0.7630 - val_loss: 0.6099 - val_accuracy: 0.6964\n",
      "Epoch 716/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4728 - accuracy: 0.7616 - val_loss: 0.6205 - val_accuracy: 0.6956\n",
      "Epoch 717/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4772 - accuracy: 0.7603 - val_loss: 0.6175 - val_accuracy: 0.6932\n",
      "Epoch 718/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4650 - accuracy: 0.7662 - val_loss: 0.6143 - val_accuracy: 0.6927\n",
      "Epoch 719/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4777 - accuracy: 0.7591 - val_loss: 0.6251 - val_accuracy: 0.6906\n",
      "Epoch 720/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4680 - accuracy: 0.7645 - val_loss: 0.6117 - val_accuracy: 0.6920\n",
      "Epoch 721/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4765 - accuracy: 0.7606 - val_loss: 0.6171 - val_accuracy: 0.6897\n",
      "Epoch 722/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4851 - accuracy: 0.7558 - val_loss: 0.6144 - val_accuracy: 0.6932\n",
      "Epoch 723/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4710 - accuracy: 0.7621 - val_loss: 0.6151 - val_accuracy: 0.6942\n",
      "Epoch 724/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4714 - accuracy: 0.7621 - val_loss: 0.6111 - val_accuracy: 0.6936\n",
      "Epoch 725/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4672 - accuracy: 0.7652 - val_loss: 0.6137 - val_accuracy: 0.6960\n",
      "Epoch 726/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4718 - accuracy: 0.7627 - val_loss: 0.6135 - val_accuracy: 0.6921\n",
      "Epoch 727/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4678 - accuracy: 0.7642 - val_loss: 0.6120 - val_accuracy: 0.6919\n",
      "Epoch 728/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4783 - accuracy: 0.7594 - val_loss: 0.6262 - val_accuracy: 0.6939\n",
      "Epoch 729/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4750 - accuracy: 0.7616 - val_loss: 0.6140 - val_accuracy: 0.6959\n",
      "Epoch 730/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4718 - accuracy: 0.7622 - val_loss: 0.6109 - val_accuracy: 0.6962\n",
      "Epoch 731/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7646 - val_loss: 0.6106 - val_accuracy: 0.6937\n",
      "Epoch 732/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4788 - accuracy: 0.7584 - val_loss: 0.6127 - val_accuracy: 0.6914\n",
      "Epoch 733/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.7652 - val_loss: 0.6156 - val_accuracy: 0.6963\n",
      "Epoch 734/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4679 - accuracy: 0.7635 - val_loss: 0.6149 - val_accuracy: 0.6928\n",
      "Epoch 735/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7636 - val_loss: 0.6194 - val_accuracy: 0.6924\n",
      "Epoch 736/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7634 - val_loss: 0.6184 - val_accuracy: 0.6950\n",
      "Epoch 737/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4612 - accuracy: 0.7671 - val_loss: 0.6196 - val_accuracy: 0.6919\n",
      "Epoch 738/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4686 - accuracy: 0.7647 - val_loss: 0.6189 - val_accuracy: 0.6951\n",
      "Epoch 739/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4731 - accuracy: 0.7612 - val_loss: 0.6255 - val_accuracy: 0.6950\n",
      "Epoch 740/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4746 - accuracy: 0.7615 - val_loss: 0.6249 - val_accuracy: 0.6882\n",
      "Epoch 741/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.7619 - val_loss: 0.6184 - val_accuracy: 0.6921\n",
      "Epoch 742/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7610 - val_loss: 0.6149 - val_accuracy: 0.6951\n",
      "Epoch 743/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.6218 - val_accuracy: 0.6945\n",
      "Epoch 744/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4682 - accuracy: 0.7644 - val_loss: 0.6303 - val_accuracy: 0.6928\n",
      "Epoch 745/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.7647 - val_loss: 0.6312 - val_accuracy: 0.6936\n",
      "Epoch 746/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4711 - accuracy: 0.7630 - val_loss: 0.6155 - val_accuracy: 0.6910\n",
      "Epoch 747/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4635 - accuracy: 0.7665 - val_loss: 0.6261 - val_accuracy: 0.6938\n",
      "Epoch 748/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4630 - accuracy: 0.7665 - val_loss: 0.6215 - val_accuracy: 0.6919\n",
      "Epoch 749/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4776 - accuracy: 0.7597 - val_loss: 0.6265 - val_accuracy: 0.6910\n",
      "Epoch 750/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7608 - val_loss: 0.6229 - val_accuracy: 0.6946\n",
      "Epoch 751/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4719 - accuracy: 0.7632 - val_loss: 0.6195 - val_accuracy: 0.6938\n",
      "Epoch 752/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4691 - accuracy: 0.7639 - val_loss: 0.6232 - val_accuracy: 0.6950\n",
      "Epoch 753/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.7642 - val_loss: 0.6114 - val_accuracy: 0.6961\n",
      "Epoch 754/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7673 - val_loss: 0.6318 - val_accuracy: 0.6876\n",
      "Epoch 755/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7636 - val_loss: 0.6205 - val_accuracy: 0.6943\n",
      "Epoch 756/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7606 - val_loss: 0.6276 - val_accuracy: 0.6881\n",
      "Epoch 757/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7636 - val_loss: 0.6178 - val_accuracy: 0.6964\n",
      "Epoch 758/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7671 - val_loss: 0.6212 - val_accuracy: 0.6887\n",
      "Epoch 759/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7648 - val_loss: 0.6212 - val_accuracy: 0.6908\n",
      "Epoch 760/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7644 - val_loss: 0.6335 - val_accuracy: 0.6909\n",
      "Epoch 761/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7621 - val_loss: 0.6146 - val_accuracy: 0.6919\n",
      "Epoch 762/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7624 - val_loss: 0.6268 - val_accuracy: 0.6893\n",
      "Epoch 763/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7623 - val_loss: 0.6210 - val_accuracy: 0.6956\n",
      "Epoch 764/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4812 - accuracy: 0.7587 - val_loss: 0.6205 - val_accuracy: 0.6949\n",
      "Epoch 765/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4617 - accuracy: 0.7673 - val_loss: 0.6120 - val_accuracy: 0.6958\n",
      "Epoch 766/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4701 - accuracy: 0.7624 - val_loss: 0.6247 - val_accuracy: 0.6936\n",
      "Epoch 767/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4641 - accuracy: 0.7648 - val_loss: 0.6295 - val_accuracy: 0.6915\n",
      "Epoch 768/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4652 - accuracy: 0.7659 - val_loss: 0.6303 - val_accuracy: 0.6904\n",
      "Epoch 769/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7623 - val_loss: 0.6328 - val_accuracy: 0.6886\n",
      "Epoch 770/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4613 - accuracy: 0.7674 - val_loss: 0.6299 - val_accuracy: 0.6880\n",
      "Epoch 771/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4686 - accuracy: 0.7653 - val_loss: 0.6194 - val_accuracy: 0.6957\n",
      "Epoch 772/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4640 - accuracy: 0.7664 - val_loss: 0.6239 - val_accuracy: 0.6931\n",
      "Epoch 773/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4627 - accuracy: 0.7668 - val_loss: 0.6166 - val_accuracy: 0.6952\n",
      "Epoch 774/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4636 - accuracy: 0.7663 - val_loss: 0.6206 - val_accuracy: 0.6926\n",
      "Epoch 775/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7653 - val_loss: 0.6186 - val_accuracy: 0.6940\n",
      "Epoch 776/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4668 - accuracy: 0.7662 - val_loss: 0.6241 - val_accuracy: 0.6967\n",
      "Epoch 777/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4665 - accuracy: 0.7649 - val_loss: 0.6174 - val_accuracy: 0.6931\n",
      "Epoch 778/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.6236 - val_accuracy: 0.6921\n",
      "Epoch 779/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4612 - accuracy: 0.7683 - val_loss: 0.6156 - val_accuracy: 0.6957\n",
      "Epoch 780/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4614 - accuracy: 0.7679 - val_loss: 0.6156 - val_accuracy: 0.6942\n",
      "Epoch 781/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4699 - accuracy: 0.7644 - val_loss: 0.6173 - val_accuracy: 0.6939\n",
      "Epoch 782/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4670 - accuracy: 0.7658 - val_loss: 0.6261 - val_accuracy: 0.6924\n",
      "Epoch 783/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4642 - accuracy: 0.7673 - val_loss: 0.6263 - val_accuracy: 0.6923\n",
      "Epoch 784/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4624 - accuracy: 0.7676 - val_loss: 0.6437 - val_accuracy: 0.6939\n",
      "Epoch 785/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4651 - accuracy: 0.7662 - val_loss: 0.6248 - val_accuracy: 0.6906\n",
      "Epoch 786/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4664 - accuracy: 0.7664 - val_loss: 0.6375 - val_accuracy: 0.6879\n",
      "Epoch 787/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7658 - val_loss: 0.6209 - val_accuracy: 0.6905\n",
      "Epoch 788/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7655 - val_loss: 0.6206 - val_accuracy: 0.6916\n",
      "Epoch 789/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.6457 - val_accuracy: 0.6843\n",
      "Epoch 790/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.7655 - val_loss: 0.6167 - val_accuracy: 0.6906\n",
      "Epoch 791/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4628 - accuracy: 0.7672 - val_loss: 0.6206 - val_accuracy: 0.6913\n",
      "Epoch 792/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4641 - accuracy: 0.7673 - val_loss: 0.6339 - val_accuracy: 0.6902\n",
      "Epoch 793/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4658 - accuracy: 0.7666 - val_loss: 0.6418 - val_accuracy: 0.6902\n",
      "Epoch 794/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.6261 - val_accuracy: 0.6966\n",
      "Epoch 795/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.7691 - val_loss: 0.6375 - val_accuracy: 0.6893\n",
      "Epoch 796/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7648 - val_loss: 0.6282 - val_accuracy: 0.6945\n",
      "Epoch 797/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7652 - val_loss: 0.6313 - val_accuracy: 0.6887\n",
      "Epoch 798/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7692 - val_loss: 0.6263 - val_accuracy: 0.6937\n",
      "Epoch 799/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7641 - val_loss: 0.6294 - val_accuracy: 0.6914\n",
      "Epoch 800/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7682 - val_loss: 0.6258 - val_accuracy: 0.6879\n",
      "Epoch 801/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.7675 - val_loss: 0.6263 - val_accuracy: 0.6927\n",
      "Epoch 802/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7670 - val_loss: 0.6251 - val_accuracy: 0.6917\n",
      "Epoch 803/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7703 - val_loss: 0.6311 - val_accuracy: 0.6951\n",
      "Epoch 804/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7668 - val_loss: 0.6270 - val_accuracy: 0.6895\n",
      "Epoch 805/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4635 - accuracy: 0.7672 - val_loss: 0.6263 - val_accuracy: 0.6908\n",
      "Epoch 806/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4621 - accuracy: 0.7695 - val_loss: 0.6276 - val_accuracy: 0.6951\n",
      "Epoch 807/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4667 - accuracy: 0.7672 - val_loss: 0.6318 - val_accuracy: 0.6897\n",
      "Epoch 808/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4561 - accuracy: 0.7704 - val_loss: 0.6227 - val_accuracy: 0.6940\n",
      "Epoch 809/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.7685 - val_loss: 0.6566 - val_accuracy: 0.6837\n",
      "Epoch 810/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4639 - accuracy: 0.7679 - val_loss: 0.6272 - val_accuracy: 0.6922\n",
      "Epoch 811/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4678 - accuracy: 0.7661 - val_loss: 0.6341 - val_accuracy: 0.6909\n",
      "Epoch 812/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4671 - accuracy: 0.7663 - val_loss: 0.6304 - val_accuracy: 0.6923\n",
      "Epoch 813/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4649 - accuracy: 0.7668 - val_loss: 0.6325 - val_accuracy: 0.6938\n",
      "Epoch 814/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7653 - val_loss: 0.6221 - val_accuracy: 0.6960\n",
      "Epoch 815/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4623 - accuracy: 0.7680 - val_loss: 0.6375 - val_accuracy: 0.6888\n",
      "Epoch 816/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.7670 - val_loss: 0.6252 - val_accuracy: 0.6911\n",
      "Epoch 817/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4532 - accuracy: 0.7721 - val_loss: 0.6337 - val_accuracy: 0.6936\n",
      "Epoch 818/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4583 - accuracy: 0.7697 - val_loss: 0.6296 - val_accuracy: 0.6936\n",
      "Epoch 819/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4612 - accuracy: 0.7685 - val_loss: 0.6279 - val_accuracy: 0.6937\n",
      "Epoch 820/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4599 - accuracy: 0.7691 - val_loss: 0.6524 - val_accuracy: 0.6895\n",
      "Epoch 821/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.6554 - val_accuracy: 0.6835\n",
      "Epoch 822/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4609 - accuracy: 0.7688 - val_loss: 0.6358 - val_accuracy: 0.6933\n",
      "Epoch 823/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.6323 - val_accuracy: 0.6942\n",
      "Epoch 824/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4568 - accuracy: 0.7712 - val_loss: 0.6437 - val_accuracy: 0.6901\n",
      "Epoch 825/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4671 - accuracy: 0.7658 - val_loss: 0.6529 - val_accuracy: 0.6809\n",
      "Epoch 826/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4671 - accuracy: 0.7669 - val_loss: 0.6339 - val_accuracy: 0.6932\n",
      "Epoch 827/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4582 - accuracy: 0.7716 - val_loss: 0.6351 - val_accuracy: 0.6884\n",
      "Epoch 828/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4587 - accuracy: 0.7702 - val_loss: 0.6309 - val_accuracy: 0.6908\n",
      "Epoch 829/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4524 - accuracy: 0.7730 - val_loss: 0.6311 - val_accuracy: 0.6911\n",
      "Epoch 830/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4702 - accuracy: 0.7649 - val_loss: 0.6456 - val_accuracy: 0.6884\n",
      "Epoch 831/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4565 - accuracy: 0.7711 - val_loss: 0.6317 - val_accuracy: 0.6920\n",
      "Epoch 832/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4573 - accuracy: 0.7705 - val_loss: 0.6234 - val_accuracy: 0.6927\n",
      "Epoch 833/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4575 - accuracy: 0.7715 - val_loss: 0.6287 - val_accuracy: 0.6929\n",
      "Epoch 834/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4661 - accuracy: 0.7654 - val_loss: 0.6304 - val_accuracy: 0.6925\n",
      "Epoch 835/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4576 - accuracy: 0.7706 - val_loss: 0.6471 - val_accuracy: 0.6848\n",
      "Epoch 836/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.6315 - val_accuracy: 0.6933\n",
      "Epoch 837/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.7714 - val_loss: 0.6326 - val_accuracy: 0.6920\n",
      "Epoch 838/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4548 - accuracy: 0.7733 - val_loss: 0.6361 - val_accuracy: 0.6890\n",
      "Epoch 839/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4574 - accuracy: 0.7711 - val_loss: 0.6349 - val_accuracy: 0.6940\n",
      "Epoch 840/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4609 - accuracy: 0.7705 - val_loss: 0.6340 - val_accuracy: 0.6920\n",
      "Epoch 841/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4544 - accuracy: 0.7732 - val_loss: 0.6383 - val_accuracy: 0.6915\n",
      "Epoch 842/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.7679 - val_loss: 0.6345 - val_accuracy: 0.6894\n",
      "Epoch 843/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4586 - accuracy: 0.7697 - val_loss: 0.6317 - val_accuracy: 0.6942\n",
      "Epoch 844/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7673 - val_loss: 0.6295 - val_accuracy: 0.6951\n",
      "Epoch 845/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.7727 - val_loss: 0.6503 - val_accuracy: 0.6910\n",
      "Epoch 846/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7696 - val_loss: 0.6361 - val_accuracy: 0.6916\n",
      "Epoch 847/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4613 - accuracy: 0.7683 - val_loss: 0.6351 - val_accuracy: 0.6908\n",
      "Epoch 848/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.7745 - val_loss: 0.6350 - val_accuracy: 0.6941\n",
      "Epoch 849/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4570 - accuracy: 0.7702 - val_loss: 0.6376 - val_accuracy: 0.6960\n",
      "Epoch 850/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4671 - accuracy: 0.7672 - val_loss: 0.6370 - val_accuracy: 0.6923\n",
      "Epoch 851/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4614 - accuracy: 0.7682 - val_loss: 0.6248 - val_accuracy: 0.6984\n",
      "Epoch 852/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4532 - accuracy: 0.7727 - val_loss: 0.6342 - val_accuracy: 0.6923\n",
      "Epoch 853/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.7721 - val_loss: 0.6481 - val_accuracy: 0.6878\n",
      "Epoch 854/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4578 - accuracy: 0.7698 - val_loss: 0.6406 - val_accuracy: 0.6954\n",
      "Epoch 855/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4555 - accuracy: 0.7722 - val_loss: 0.6418 - val_accuracy: 0.6917\n",
      "Epoch 856/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4685 - accuracy: 0.7658 - val_loss: 0.6383 - val_accuracy: 0.6907\n",
      "Epoch 857/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.7752 - val_loss: 0.6409 - val_accuracy: 0.6872\n",
      "Epoch 858/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4548 - accuracy: 0.7714 - val_loss: 0.6306 - val_accuracy: 0.6908\n",
      "Epoch 859/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.7736 - val_loss: 0.6739 - val_accuracy: 0.6810\n",
      "Epoch 860/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4619 - accuracy: 0.7690 - val_loss: 0.6417 - val_accuracy: 0.6897\n",
      "Epoch 861/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4561 - accuracy: 0.7720 - val_loss: 0.6409 - val_accuracy: 0.6911\n",
      "Epoch 862/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4623 - accuracy: 0.7705 - val_loss: 0.6415 - val_accuracy: 0.6860\n",
      "Epoch 863/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4578 - accuracy: 0.7699 - val_loss: 0.6301 - val_accuracy: 0.6901\n",
      "Epoch 864/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4520 - accuracy: 0.7748 - val_loss: 0.6373 - val_accuracy: 0.6906\n",
      "Epoch 865/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4602 - accuracy: 0.7688 - val_loss: 0.6372 - val_accuracy: 0.6911\n",
      "Epoch 866/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.7741 - val_loss: 0.6375 - val_accuracy: 0.6931\n",
      "Epoch 867/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4526 - accuracy: 0.7740 - val_loss: 0.6375 - val_accuracy: 0.6916\n",
      "Epoch 868/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4532 - accuracy: 0.7742 - val_loss: 0.6483 - val_accuracy: 0.6939\n",
      "Epoch 869/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.7658 - val_loss: 0.6579 - val_accuracy: 0.6843\n",
      "Epoch 870/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.7633 - val_loss: 0.6391 - val_accuracy: 0.6939\n",
      "Epoch 871/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4547 - accuracy: 0.7722 - val_loss: 0.6390 - val_accuracy: 0.6873\n",
      "Epoch 872/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4558 - accuracy: 0.7712 - val_loss: 0.6429 - val_accuracy: 0.6916\n",
      "Epoch 873/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4550 - accuracy: 0.7722 - val_loss: 0.6516 - val_accuracy: 0.6914\n",
      "Epoch 874/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.6488 - val_accuracy: 0.6902\n",
      "Epoch 875/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4511 - accuracy: 0.7727 - val_loss: 0.6342 - val_accuracy: 0.6924\n",
      "Epoch 876/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4536 - accuracy: 0.7728 - val_loss: 0.6457 - val_accuracy: 0.6882\n",
      "Epoch 877/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4570 - accuracy: 0.7714 - val_loss: 0.6446 - val_accuracy: 0.6930\n",
      "Epoch 878/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.7676 - val_loss: 0.6417 - val_accuracy: 0.6923\n",
      "Epoch 879/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.7734 - val_loss: 0.6397 - val_accuracy: 0.6911\n",
      "Epoch 880/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4574 - accuracy: 0.7694 - val_loss: 0.6364 - val_accuracy: 0.6931\n",
      "Epoch 881/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4566 - accuracy: 0.7711 - val_loss: 0.6407 - val_accuracy: 0.6908\n",
      "Epoch 882/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4523 - accuracy: 0.7737 - val_loss: 0.6453 - val_accuracy: 0.6915\n",
      "Epoch 883/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4527 - accuracy: 0.7726 - val_loss: 0.6520 - val_accuracy: 0.6853\n",
      "Epoch 884/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7739 - val_loss: 0.6400 - val_accuracy: 0.6918\n",
      "Epoch 885/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4510 - accuracy: 0.7752 - val_loss: 0.6504 - val_accuracy: 0.6898\n",
      "Epoch 886/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4595 - accuracy: 0.7693 - val_loss: 0.6422 - val_accuracy: 0.6885\n",
      "Epoch 887/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4590 - accuracy: 0.7716 - val_loss: 0.6437 - val_accuracy: 0.6888\n",
      "Epoch 888/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4585 - accuracy: 0.7722 - val_loss: 0.6361 - val_accuracy: 0.6930\n",
      "Epoch 889/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4478 - accuracy: 0.7765 - val_loss: 0.6480 - val_accuracy: 0.6956\n",
      "Epoch 890/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.7728 - val_loss: 0.6449 - val_accuracy: 0.6922\n",
      "Epoch 891/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4615 - accuracy: 0.7701 - val_loss: 0.6439 - val_accuracy: 0.6918\n",
      "Epoch 892/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4524 - accuracy: 0.7735 - val_loss: 0.6457 - val_accuracy: 0.6942\n",
      "Epoch 893/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4528 - accuracy: 0.7738 - val_loss: 0.6418 - val_accuracy: 0.6897\n",
      "Epoch 894/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4545 - accuracy: 0.7721 - val_loss: 0.6401 - val_accuracy: 0.6930\n",
      "Epoch 895/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4617 - accuracy: 0.7693 - val_loss: 0.6487 - val_accuracy: 0.6883\n",
      "Epoch 896/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4524 - accuracy: 0.7729 - val_loss: 0.6433 - val_accuracy: 0.6884\n",
      "Epoch 897/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4520 - accuracy: 0.7743 - val_loss: 0.6505 - val_accuracy: 0.6908\n",
      "Epoch 898/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4487 - accuracy: 0.7764 - val_loss: 0.6472 - val_accuracy: 0.6916\n",
      "Epoch 899/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.7745 - val_loss: 0.6425 - val_accuracy: 0.6950\n",
      "Epoch 900/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4573 - accuracy: 0.7718 - val_loss: 0.6407 - val_accuracy: 0.6888\n",
      "Epoch 901/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4513 - accuracy: 0.7746 - val_loss: 0.6392 - val_accuracy: 0.6913\n",
      "Epoch 902/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4523 - accuracy: 0.7741 - val_loss: 0.6491 - val_accuracy: 0.6928\n",
      "Epoch 903/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.7733 - val_loss: 0.6499 - val_accuracy: 0.6922\n",
      "Epoch 904/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4520 - accuracy: 0.7745 - val_loss: 0.6458 - val_accuracy: 0.6925\n",
      "Epoch 905/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4545 - accuracy: 0.7725 - val_loss: 0.6478 - val_accuracy: 0.6903\n",
      "Epoch 906/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4410 - accuracy: 0.7799 - val_loss: 0.6483 - val_accuracy: 0.6912\n",
      "Epoch 907/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4547 - accuracy: 0.7734 - val_loss: 0.6547 - val_accuracy: 0.6927\n",
      "Epoch 908/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4421 - accuracy: 0.7803 - val_loss: 0.6558 - val_accuracy: 0.6921\n",
      "Epoch 909/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4503 - accuracy: 0.7750 - val_loss: 0.6487 - val_accuracy: 0.6891\n",
      "Epoch 910/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4598 - accuracy: 0.7700 - val_loss: 0.6447 - val_accuracy: 0.6914\n",
      "Epoch 911/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.7755 - val_loss: 0.6541 - val_accuracy: 0.6908\n",
      "Epoch 912/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.6488 - val_accuracy: 0.6900\n",
      "Epoch 913/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4476 - accuracy: 0.7761 - val_loss: 0.6426 - val_accuracy: 0.6891\n",
      "Epoch 914/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4463 - accuracy: 0.7770 - val_loss: 0.6518 - val_accuracy: 0.6907\n",
      "Epoch 915/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4489 - accuracy: 0.7753 - val_loss: 0.6518 - val_accuracy: 0.6931\n",
      "Epoch 916/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4647 - accuracy: 0.7692 - val_loss: 0.6586 - val_accuracy: 0.6881\n",
      "Epoch 917/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.7752 - val_loss: 0.6524 - val_accuracy: 0.6864\n",
      "Epoch 918/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.7791 - val_loss: 0.6577 - val_accuracy: 0.6884\n",
      "Epoch 919/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7781 - val_loss: 0.6538 - val_accuracy: 0.6888\n",
      "Epoch 920/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4496 - accuracy: 0.7751 - val_loss: 0.6434 - val_accuracy: 0.6908\n",
      "Epoch 921/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4470 - accuracy: 0.7784 - val_loss: 0.6616 - val_accuracy: 0.6876\n",
      "Epoch 922/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4543 - accuracy: 0.7735 - val_loss: 0.6494 - val_accuracy: 0.6880\n",
      "Epoch 923/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4572 - accuracy: 0.7721 - val_loss: 0.6571 - val_accuracy: 0.6886\n",
      "Epoch 924/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4484 - accuracy: 0.7753 - val_loss: 0.6510 - val_accuracy: 0.6912\n",
      "Epoch 925/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4478 - accuracy: 0.7764 - val_loss: 0.6445 - val_accuracy: 0.6947\n",
      "Epoch 926/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4569 - accuracy: 0.7721 - val_loss: 0.6410 - val_accuracy: 0.6934\n",
      "Epoch 927/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7728 - val_loss: 0.6454 - val_accuracy: 0.6910\n",
      "Epoch 928/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4497 - accuracy: 0.7753 - val_loss: 0.6399 - val_accuracy: 0.6939\n",
      "Epoch 929/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4504 - accuracy: 0.7740 - val_loss: 0.6535 - val_accuracy: 0.6896\n",
      "Epoch 930/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7762 - val_loss: 0.6477 - val_accuracy: 0.6923\n",
      "Epoch 931/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4446 - accuracy: 0.7790 - val_loss: 0.6646 - val_accuracy: 0.6829\n",
      "Epoch 932/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4473 - accuracy: 0.7772 - val_loss: 0.6482 - val_accuracy: 0.6927\n",
      "Epoch 933/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.7752 - val_loss: 0.6468 - val_accuracy: 0.6916\n",
      "Epoch 934/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4481 - accuracy: 0.7765 - val_loss: 0.6469 - val_accuracy: 0.6942\n",
      "Epoch 935/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4472 - accuracy: 0.7772 - val_loss: 0.6612 - val_accuracy: 0.6865\n",
      "Epoch 936/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4491 - accuracy: 0.7772 - val_loss: 0.6561 - val_accuracy: 0.6915\n",
      "Epoch 937/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4454 - accuracy: 0.7776 - val_loss: 0.6524 - val_accuracy: 0.6907\n",
      "Epoch 938/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.7717 - val_loss: 0.6538 - val_accuracy: 0.6868\n",
      "Epoch 939/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4648 - accuracy: 0.7689 - val_loss: 0.6530 - val_accuracy: 0.6906\n",
      "Epoch 940/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4515 - accuracy: 0.7756 - val_loss: 0.6464 - val_accuracy: 0.6944\n",
      "Epoch 941/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4476 - accuracy: 0.7774 - val_loss: 0.6478 - val_accuracy: 0.6929\n",
      "Epoch 942/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.7736 - val_loss: 0.6521 - val_accuracy: 0.6917\n",
      "Epoch 943/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4405 - accuracy: 0.7803 - val_loss: 0.6594 - val_accuracy: 0.6888\n",
      "Epoch 944/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4479 - accuracy: 0.7780 - val_loss: 0.6565 - val_accuracy: 0.6886\n",
      "Epoch 945/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4450 - accuracy: 0.7766 - val_loss: 0.6560 - val_accuracy: 0.6868\n",
      "Epoch 946/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7779 - val_loss: 0.6519 - val_accuracy: 0.6933\n",
      "Epoch 947/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4555 - accuracy: 0.7741 - val_loss: 0.6706 - val_accuracy: 0.6903\n",
      "Epoch 948/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4416 - accuracy: 0.7794 - val_loss: 0.6528 - val_accuracy: 0.6919\n",
      "Epoch 949/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.7750 - val_loss: 0.6655 - val_accuracy: 0.6873\n",
      "Epoch 950/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.6617 - val_accuracy: 0.6903\n",
      "Epoch 951/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4504 - accuracy: 0.7759 - val_loss: 0.6572 - val_accuracy: 0.6903\n",
      "Epoch 952/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.7746 - val_loss: 0.6473 - val_accuracy: 0.6928\n",
      "Epoch 953/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.6477 - val_accuracy: 0.6927\n",
      "Epoch 954/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4450 - accuracy: 0.7783 - val_loss: 0.6684 - val_accuracy: 0.6877\n",
      "Epoch 955/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4521 - accuracy: 0.7748 - val_loss: 0.6495 - val_accuracy: 0.6893\n",
      "Epoch 956/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4464 - accuracy: 0.7769 - val_loss: 0.6573 - val_accuracy: 0.6865\n",
      "Epoch 957/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4372 - accuracy: 0.7819 - val_loss: 0.6566 - val_accuracy: 0.6866\n",
      "Epoch 958/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.7781 - val_loss: 0.6554 - val_accuracy: 0.6927\n",
      "Epoch 959/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4521 - accuracy: 0.7751 - val_loss: 0.6529 - val_accuracy: 0.6921\n",
      "Epoch 960/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.6504 - val_accuracy: 0.6908\n",
      "Epoch 961/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7790 - val_loss: 0.6596 - val_accuracy: 0.6865\n",
      "Epoch 962/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.7761 - val_loss: 0.6526 - val_accuracy: 0.6919\n",
      "Epoch 963/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.6525 - val_accuracy: 0.6916\n",
      "Epoch 964/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.7794 - val_loss: 0.6613 - val_accuracy: 0.6864\n",
      "Epoch 965/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4441 - accuracy: 0.7797 - val_loss: 0.6624 - val_accuracy: 0.6858\n",
      "Epoch 966/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.7741 - val_loss: 0.6549 - val_accuracy: 0.6906\n",
      "Epoch 967/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4571 - accuracy: 0.7732 - val_loss: 0.6517 - val_accuracy: 0.6921\n",
      "Epoch 968/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4500 - accuracy: 0.7759 - val_loss: 0.6517 - val_accuracy: 0.6911\n",
      "Epoch 969/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4391 - accuracy: 0.7807 - val_loss: 0.6610 - val_accuracy: 0.6899\n",
      "Epoch 970/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.7808 - val_loss: 0.6569 - val_accuracy: 0.6932\n",
      "Epoch 971/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4483 - accuracy: 0.7766 - val_loss: 0.6582 - val_accuracy: 0.6919\n",
      "Epoch 972/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4481 - accuracy: 0.7774 - val_loss: 0.6675 - val_accuracy: 0.6844\n",
      "Epoch 973/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.6617 - val_accuracy: 0.6863\n",
      "Epoch 974/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4515 - accuracy: 0.7755 - val_loss: 0.6553 - val_accuracy: 0.6917\n",
      "Epoch 975/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4512 - accuracy: 0.7755 - val_loss: 0.6522 - val_accuracy: 0.6890\n",
      "Epoch 976/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4410 - accuracy: 0.7801 - val_loss: 0.6605 - val_accuracy: 0.6863\n",
      "Epoch 977/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4382 - accuracy: 0.7820 - val_loss: 0.6641 - val_accuracy: 0.6881\n",
      "Epoch 978/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4488 - accuracy: 0.7772 - val_loss: 0.6593 - val_accuracy: 0.6891\n",
      "Epoch 979/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4457 - accuracy: 0.7786 - val_loss: 0.6657 - val_accuracy: 0.6852\n",
      "Epoch 980/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4581 - accuracy: 0.7730 - val_loss: 0.6537 - val_accuracy: 0.6918\n",
      "Epoch 981/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7724 - val_loss: 0.6580 - val_accuracy: 0.6870\n",
      "Epoch 982/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4559 - accuracy: 0.7727 - val_loss: 0.6597 - val_accuracy: 0.6824\n",
      "Epoch 983/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.6526 - val_accuracy: 0.6908\n",
      "Epoch 984/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4419 - accuracy: 0.7803 - val_loss: 0.6566 - val_accuracy: 0.6884\n",
      "Epoch 985/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7763 - val_loss: 0.6526 - val_accuracy: 0.6896\n",
      "Epoch 986/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.7753 - val_loss: 0.6544 - val_accuracy: 0.6888\n",
      "Epoch 987/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.6615 - val_accuracy: 0.6898\n",
      "Epoch 988/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4370 - accuracy: 0.7817 - val_loss: 0.6545 - val_accuracy: 0.6911\n",
      "Epoch 989/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.7807 - val_loss: 0.6592 - val_accuracy: 0.6869\n",
      "Epoch 990/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4437 - accuracy: 0.7794 - val_loss: 0.6638 - val_accuracy: 0.6917\n",
      "Epoch 991/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4445 - accuracy: 0.7793 - val_loss: 0.6635 - val_accuracy: 0.6916\n",
      "Epoch 992/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4475 - accuracy: 0.7781 - val_loss: 0.6610 - val_accuracy: 0.6870\n",
      "Epoch 993/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.7753 - val_loss: 0.6564 - val_accuracy: 0.6919\n",
      "Epoch 994/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4382 - accuracy: 0.7827 - val_loss: 0.6544 - val_accuracy: 0.6945\n",
      "Epoch 995/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4396 - accuracy: 0.7815 - val_loss: 0.6652 - val_accuracy: 0.6874\n",
      "Epoch 996/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4353 - accuracy: 0.7836 - val_loss: 0.6885 - val_accuracy: 0.6811\n",
      "Epoch 997/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4448 - accuracy: 0.7792 - val_loss: 0.6612 - val_accuracy: 0.6888\n",
      "Epoch 998/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4392 - accuracy: 0.7810 - val_loss: 0.6712 - val_accuracy: 0.6884\n",
      "Epoch 999/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4468 - accuracy: 0.7784 - val_loss: 0.6821 - val_accuracy: 0.6868\n",
      "Epoch 1000/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4469 - accuracy: 0.7776 - val_loss: 0.6613 - val_accuracy: 0.6891\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.6892\n",
      "Test Loss: 0.6503\n",
      "Test Accuracy: 0.6892\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 모델 정의\n",
    "\n",
    "ds_rho_input = Input(shape=(3,), name='density_matrix_input')\n",
    "\n",
    "# 시퀀스를 예측하기 위한 GRU 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(ds_rho_input)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = GRU(256, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[ds_rho_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "history = model.fit([rho_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([rho_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128)\n",
    "# callbacks=[early_stopping]\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([rho_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      " 16/185 [=>............................] - ETA: 0s - loss: 0.6197 - accuracy: 0.7046 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:04:28.291746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 17:04:28.292860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 17:04:28.293703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.6892\n",
      "Test Accuracy: 68.92\n",
      "Test Loss: 65.03\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, rho, sequence):\n",
    "    loss, acc = model.evaluate({'density_matrix_input': rho}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, rho_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_GRU_model_Rho.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step\n",
      "Results saved to GRU_cuda_results_Rho.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:04:29.193229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-17 17:04:29.194455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-17 17:04:29.195389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(rho_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "rho_samples = np.array(rho_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([rho_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_GRU'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'GRU_cuda_results_Rho.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to GRU_cuda_results_Rho.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Sample 1:\n",
      "Theta    : [0.51456531]\n",
      "Phi      : [1.51145762]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 1 1 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 1 1 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [2.31199557]\n",
      "Phi      : [2.26031985]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 1]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [1.29024766]\n",
      "Phi      : [0.96522899]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 0 1 2 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 1 1 3 3]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [2.07206636]\n",
      "Phi      : [3.68128822]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 3 3 2 4 4]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 4 2]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [2.76291863]\n",
      "Phi      : [1.14958058]\n",
      "Actual   : [0 0 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 0 0 4 0]\n",
      "Predicted: [0 0 1 0 0 0 2 4 0 1 1 3 3 2 4 4 1 1 3 3 3 2 2 4 4 1 3 3 2 2 4 4 4 1 3]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [2.34040383]\n",
      "Phi      : [2.26576055]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 1]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [1.8177799]\n",
      "Phi      : [3.18343174]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [0.07384158]\n",
      "Phi      : [3.90298364]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted: [0 0 0 2 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [2.11479362]\n",
      "Phi      : [4.11208312]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 1 2 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 3 2 2]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [2.38574539]\n",
      "Phi      : [3.26627023]\n",
      "Actual   : [0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 0 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 2 2 4 4 1 1 3 0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(rho_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "rho_samples = np.array(rho_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([rho_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
