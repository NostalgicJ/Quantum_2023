{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../../Data/using/dt_2.6/ByAstar_dt_2.6_modified.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "87/87 [==============================] - 7s 74ms/step - loss: 0.9854 - accuracy: 0.5613 - val_loss: 0.8715 - val_accuracy: 0.5934\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.7350 - accuracy: 0.6776 - val_loss: 0.4956 - val_accuracy: 0.8179\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.4535 - accuracy: 0.8286 - val_loss: 0.4579 - val_accuracy: 0.8247\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.4116 - accuracy: 0.8475 - val_loss: 0.4018 - val_accuracy: 0.8515\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3818 - accuracy: 0.8613 - val_loss: 0.3413 - val_accuracy: 0.8803\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.3642 - accuracy: 0.8701 - val_loss: 0.3988 - val_accuracy: 0.8495\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3605 - accuracy: 0.8708 - val_loss: 0.3300 - val_accuracy: 0.8837\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3580 - accuracy: 0.8685 - val_loss: 0.3340 - val_accuracy: 0.8772\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.3412 - accuracy: 0.8761 - val_loss: 0.3624 - val_accuracy: 0.8590\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.3300 - accuracy: 0.8785 - val_loss: 0.3461 - val_accuracy: 0.8639\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3400 - accuracy: 0.8738 - val_loss: 0.3216 - val_accuracy: 0.8792\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.3177 - accuracy: 0.8834 - val_loss: 0.3067 - val_accuracy: 0.8838\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3208 - accuracy: 0.8809 - val_loss: 0.3545 - val_accuracy: 0.8591\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.3085 - accuracy: 0.8837 - val_loss: 0.3195 - val_accuracy: 0.8757\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3115 - accuracy: 0.8819 - val_loss: 0.2960 - val_accuracy: 0.8829\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3140 - accuracy: 0.8789 - val_loss: 0.3236 - val_accuracy: 0.8728\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.3029 - accuracy: 0.8831 - val_loss: 0.2963 - val_accuracy: 0.8912\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2973 - accuracy: 0.8857 - val_loss: 0.2889 - val_accuracy: 0.8871\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2925 - accuracy: 0.8876 - val_loss: 0.3351 - val_accuracy: 0.8748\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2904 - accuracy: 0.8871 - val_loss: 0.3524 - val_accuracy: 0.8673\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2989 - accuracy: 0.8834 - val_loss: 0.2689 - val_accuracy: 0.8969\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2819 - accuracy: 0.8894 - val_loss: 0.2942 - val_accuracy: 0.8885\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2825 - accuracy: 0.8886 - val_loss: 0.3011 - val_accuracy: 0.8774\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2852 - accuracy: 0.8886 - val_loss: 0.2698 - val_accuracy: 0.8934\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2804 - accuracy: 0.8893 - val_loss: 0.2465 - val_accuracy: 0.9033\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2792 - accuracy: 0.8892 - val_loss: 0.2756 - val_accuracy: 0.8945\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2743 - accuracy: 0.8927 - val_loss: 0.2571 - val_accuracy: 0.8982\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2878 - accuracy: 0.8878 - val_loss: 0.2654 - val_accuracy: 0.8915\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2864 - accuracy: 0.8879 - val_loss: 0.2603 - val_accuracy: 0.8971\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2741 - accuracy: 0.8917 - val_loss: 0.2650 - val_accuracy: 0.8966\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2860 - accuracy: 0.8859 - val_loss: 0.3218 - val_accuracy: 0.8715\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2744 - accuracy: 0.8914 - val_loss: 0.2661 - val_accuracy: 0.8966\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2763 - accuracy: 0.8910 - val_loss: 0.2604 - val_accuracy: 0.8964\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2621 - accuracy: 0.8953 - val_loss: 0.2942 - val_accuracy: 0.8877\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2749 - accuracy: 0.8907 - val_loss: 0.2866 - val_accuracy: 0.8840\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2790 - accuracy: 0.8888 - val_loss: 0.2612 - val_accuracy: 0.8946\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2641 - accuracy: 0.8946 - val_loss: 0.2512 - val_accuracy: 0.8988\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2716 - accuracy: 0.8921 - val_loss: 0.2488 - val_accuracy: 0.8962\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2602 - accuracy: 0.8951 - val_loss: 0.2391 - val_accuracy: 0.9013\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2699 - accuracy: 0.8931 - val_loss: 0.2716 - val_accuracy: 0.8895\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2630 - accuracy: 0.8946 - val_loss: 0.2952 - val_accuracy: 0.8810\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2531 - accuracy: 0.8985 - val_loss: 0.2281 - val_accuracy: 0.9068\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2598 - accuracy: 0.8956 - val_loss: 0.2680 - val_accuracy: 0.8889\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2582 - accuracy: 0.8968 - val_loss: 0.2402 - val_accuracy: 0.9045\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2475 - accuracy: 0.9000 - val_loss: 0.2715 - val_accuracy: 0.8900\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2558 - accuracy: 0.8966 - val_loss: 0.2706 - val_accuracy: 0.8971\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2620 - accuracy: 0.8943 - val_loss: 0.2479 - val_accuracy: 0.9003\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2507 - accuracy: 0.8982 - val_loss: 0.2324 - val_accuracy: 0.9035\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2456 - accuracy: 0.8997 - val_loss: 0.2252 - val_accuracy: 0.9064\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2602 - accuracy: 0.8952 - val_loss: 0.2602 - val_accuracy: 0.8943\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2646 - accuracy: 0.8930 - val_loss: 0.2559 - val_accuracy: 0.8958\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2473 - accuracy: 0.9002 - val_loss: 0.3108 - val_accuracy: 0.8769\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2456 - accuracy: 0.9005 - val_loss: 0.2297 - val_accuracy: 0.9050\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2414 - accuracy: 0.9022 - val_loss: 0.2377 - val_accuracy: 0.9030\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2424 - accuracy: 0.9013 - val_loss: 0.2821 - val_accuracy: 0.8858\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2522 - accuracy: 0.8977 - val_loss: 0.2398 - val_accuracy: 0.9037\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2468 - accuracy: 0.8992 - val_loss: 0.2214 - val_accuracy: 0.9092\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2425 - accuracy: 0.9013 - val_loss: 0.2476 - val_accuracy: 0.8974\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2683 - accuracy: 0.8915 - val_loss: 0.2318 - val_accuracy: 0.9047\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2425 - accuracy: 0.9000 - val_loss: 0.2366 - val_accuracy: 0.9013\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2530 - accuracy: 0.8969 - val_loss: 0.2702 - val_accuracy: 0.8901\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2496 - accuracy: 0.8976 - val_loss: 0.2416 - val_accuracy: 0.9017\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2448 - accuracy: 0.8999 - val_loss: 0.2569 - val_accuracy: 0.8952\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2418 - accuracy: 0.9008 - val_loss: 0.2259 - val_accuracy: 0.9084\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2438 - accuracy: 0.8995 - val_loss: 0.3136 - val_accuracy: 0.8739\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2410 - accuracy: 0.9009 - val_loss: 0.2433 - val_accuracy: 0.8994\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2440 - accuracy: 0.8994 - val_loss: 0.2507 - val_accuracy: 0.8984\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2402 - accuracy: 0.9011 - val_loss: 0.2555 - val_accuracy: 0.8934\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2394 - accuracy: 0.9018 - val_loss: 0.2558 - val_accuracy: 0.8973\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2338 - accuracy: 0.9042 - val_loss: 0.2246 - val_accuracy: 0.9071\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2387 - accuracy: 0.9020 - val_loss: 0.2631 - val_accuracy: 0.8920\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2461 - accuracy: 0.8990 - val_loss: 0.2219 - val_accuracy: 0.9080\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2365 - accuracy: 0.9019 - val_loss: 0.2296 - val_accuracy: 0.9030\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2376 - accuracy: 0.9019 - val_loss: 0.2767 - val_accuracy: 0.8849\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2330 - accuracy: 0.9030 - val_loss: 0.2192 - val_accuracy: 0.9125\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2313 - accuracy: 0.9045 - val_loss: 0.2214 - val_accuracy: 0.9102\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2358 - accuracy: 0.9025 - val_loss: 0.2116 - val_accuracy: 0.9115\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2314 - accuracy: 0.9047 - val_loss: 0.2485 - val_accuracy: 0.9004\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2427 - accuracy: 0.9011 - val_loss: 0.2284 - val_accuracy: 0.9060\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2401 - accuracy: 0.9008 - val_loss: 0.2523 - val_accuracy: 0.8991\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2508 - accuracy: 0.8967 - val_loss: 0.3038 - val_accuracy: 0.8805\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2365 - accuracy: 0.9023 - val_loss: 0.2476 - val_accuracy: 0.8974\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2415 - accuracy: 0.8995 - val_loss: 0.2190 - val_accuracy: 0.9096\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2323 - accuracy: 0.9037 - val_loss: 0.2231 - val_accuracy: 0.9076\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2358 - accuracy: 0.9021 - val_loss: 0.2931 - val_accuracy: 0.8832\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2305 - accuracy: 0.9043 - val_loss: 0.2188 - val_accuracy: 0.9107\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2333 - accuracy: 0.9036 - val_loss: 0.2411 - val_accuracy: 0.8971\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2376 - accuracy: 0.9017 - val_loss: 0.2132 - val_accuracy: 0.9104\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2206 - accuracy: 0.9071 - val_loss: 0.2061 - val_accuracy: 0.9132\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2284 - accuracy: 0.9052 - val_loss: 0.2732 - val_accuracy: 0.8935\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2464 - accuracy: 0.8991 - val_loss: 0.3474 - val_accuracy: 0.8730\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2571 - accuracy: 0.8949 - val_loss: 0.2133 - val_accuracy: 0.9121\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2278 - accuracy: 0.9051 - val_loss: 0.2309 - val_accuracy: 0.9070\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2281 - accuracy: 0.9055 - val_loss: 0.2469 - val_accuracy: 0.8976\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2482 - accuracy: 0.8973 - val_loss: 0.2210 - val_accuracy: 0.9074\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2311 - accuracy: 0.9041 - val_loss: 0.2198 - val_accuracy: 0.9081\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2298 - accuracy: 0.9040 - val_loss: 0.2223 - val_accuracy: 0.9080\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2214 - accuracy: 0.9072 - val_loss: 0.2221 - val_accuracy: 0.9087\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2302 - accuracy: 0.9034 - val_loss: 0.2108 - val_accuracy: 0.9118\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2189 - accuracy: 0.9082 - val_loss: 0.2269 - val_accuracy: 0.9036\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2211 - accuracy: 0.9069 - val_loss: 0.2469 - val_accuracy: 0.8987\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2170 - accuracy: 0.9090 - val_loss: 0.2167 - val_accuracy: 0.9077\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2259 - accuracy: 0.9058 - val_loss: 0.2381 - val_accuracy: 0.9019\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2237 - accuracy: 0.9064 - val_loss: 0.2184 - val_accuracy: 0.9085\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2279 - accuracy: 0.9052 - val_loss: 0.2070 - val_accuracy: 0.9131\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2184 - accuracy: 0.9082 - val_loss: 0.1996 - val_accuracy: 0.9181\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2221 - accuracy: 0.9074 - val_loss: 0.2597 - val_accuracy: 0.8915\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2225 - accuracy: 0.9059 - val_loss: 0.1971 - val_accuracy: 0.9181\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2173 - accuracy: 0.9093 - val_loss: 0.2280 - val_accuracy: 0.9041\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2384 - accuracy: 0.9021 - val_loss: 0.2251 - val_accuracy: 0.9066\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2247 - accuracy: 0.9063 - val_loss: 0.2170 - val_accuracy: 0.9082\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2259 - accuracy: 0.9063 - val_loss: 0.2123 - val_accuracy: 0.9098\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2271 - accuracy: 0.9048 - val_loss: 0.2226 - val_accuracy: 0.9083\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2182 - accuracy: 0.9085 - val_loss: 0.2165 - val_accuracy: 0.9089\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2199 - accuracy: 0.9072 - val_loss: 0.2266 - val_accuracy: 0.9056\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2188 - accuracy: 0.9075 - val_loss: 0.2168 - val_accuracy: 0.9095\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2181 - accuracy: 0.9078 - val_loss: 0.2056 - val_accuracy: 0.9155\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2152 - accuracy: 0.9084 - val_loss: 0.2245 - val_accuracy: 0.9067\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2278 - accuracy: 0.9048 - val_loss: 0.2392 - val_accuracy: 0.9014\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2224 - accuracy: 0.9074 - val_loss: 0.2100 - val_accuracy: 0.9109\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2174 - accuracy: 0.9079 - val_loss: 0.2304 - val_accuracy: 0.9064\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2140 - accuracy: 0.9095 - val_loss: 0.2105 - val_accuracy: 0.9105\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2234 - accuracy: 0.9068 - val_loss: 0.2204 - val_accuracy: 0.9090\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2199 - accuracy: 0.9081 - val_loss: 0.2415 - val_accuracy: 0.9010\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2264 - accuracy: 0.9045 - val_loss: 0.2048 - val_accuracy: 0.9141\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2117 - accuracy: 0.9111 - val_loss: 0.2023 - val_accuracy: 0.9174\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2068 - accuracy: 0.9126 - val_loss: 0.1960 - val_accuracy: 0.9162\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2169 - accuracy: 0.9075 - val_loss: 0.2108 - val_accuracy: 0.9107\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2200 - accuracy: 0.9077 - val_loss: 0.2224 - val_accuracy: 0.9068\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2170 - accuracy: 0.9080 - val_loss: 0.2129 - val_accuracy: 0.9094\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2196 - accuracy: 0.9078 - val_loss: 0.1993 - val_accuracy: 0.9155\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2114 - accuracy: 0.9109 - val_loss: 0.2081 - val_accuracy: 0.9128\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2203 - accuracy: 0.9070 - val_loss: 0.2094 - val_accuracy: 0.9133\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2169 - accuracy: 0.9083 - val_loss: 0.2299 - val_accuracy: 0.9026\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2135 - accuracy: 0.9094 - val_loss: 0.2261 - val_accuracy: 0.9065\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2174 - accuracy: 0.9085 - val_loss: 0.2094 - val_accuracy: 0.9121\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2097 - accuracy: 0.9111 - val_loss: 0.2492 - val_accuracy: 0.8977\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2233 - accuracy: 0.9056 - val_loss: 0.2742 - val_accuracy: 0.8849\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2209 - accuracy: 0.9063 - val_loss: 0.2056 - val_accuracy: 0.9101\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2054 - accuracy: 0.9117 - val_loss: 0.1967 - val_accuracy: 0.9174\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2207 - accuracy: 0.9072 - val_loss: 0.2285 - val_accuracy: 0.9040\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2173 - accuracy: 0.9097 - val_loss: 0.2000 - val_accuracy: 0.9168\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2099 - accuracy: 0.9113 - val_loss: 0.2734 - val_accuracy: 0.8922\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2246 - accuracy: 0.9062 - val_loss: 0.2058 - val_accuracy: 0.9120\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2079 - accuracy: 0.9119 - val_loss: 0.2079 - val_accuracy: 0.9119\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2093 - accuracy: 0.9097 - val_loss: 0.1962 - val_accuracy: 0.9153\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2119 - accuracy: 0.9092 - val_loss: 0.1925 - val_accuracy: 0.9187\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2173 - accuracy: 0.9087 - val_loss: 0.2016 - val_accuracy: 0.9139\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2177 - accuracy: 0.9081 - val_loss: 0.1993 - val_accuracy: 0.9163\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2152 - accuracy: 0.9087 - val_loss: 0.2058 - val_accuracy: 0.9121\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2089 - accuracy: 0.9114 - val_loss: 0.2042 - val_accuracy: 0.9141\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2106 - accuracy: 0.9107 - val_loss: 0.2250 - val_accuracy: 0.9080\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2241 - accuracy: 0.9058 - val_loss: 0.2046 - val_accuracy: 0.9137\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2053 - accuracy: 0.9126 - val_loss: 0.2164 - val_accuracy: 0.9093\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2113 - accuracy: 0.9102 - val_loss: 0.2086 - val_accuracy: 0.9108\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2116 - accuracy: 0.9098 - val_loss: 0.1967 - val_accuracy: 0.9164\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2078 - accuracy: 0.9114 - val_loss: 0.3044 - val_accuracy: 0.8826\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2112 - accuracy: 0.9102 - val_loss: 0.2131 - val_accuracy: 0.9081\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2091 - accuracy: 0.9103 - val_loss: 0.1977 - val_accuracy: 0.9164\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2113 - accuracy: 0.9106 - val_loss: 0.2085 - val_accuracy: 0.9125\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2103 - accuracy: 0.9103 - val_loss: 0.2105 - val_accuracy: 0.9117\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2098 - accuracy: 0.9105 - val_loss: 0.2197 - val_accuracy: 0.9075\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2143 - accuracy: 0.9094 - val_loss: 0.2142 - val_accuracy: 0.9096\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2019 - accuracy: 0.9141 - val_loss: 0.1977 - val_accuracy: 0.9167\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2060 - accuracy: 0.9124 - val_loss: 0.2225 - val_accuracy: 0.9052\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2188 - accuracy: 0.9072 - val_loss: 0.2128 - val_accuracy: 0.9085\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2070 - accuracy: 0.9107 - val_loss: 0.2294 - val_accuracy: 0.9018\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2127 - accuracy: 0.9096 - val_loss: 0.2246 - val_accuracy: 0.9054\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2135 - accuracy: 0.9091 - val_loss: 0.2037 - val_accuracy: 0.9156\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2087 - accuracy: 0.9119 - val_loss: 0.2047 - val_accuracy: 0.9144\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2011 - accuracy: 0.9137 - val_loss: 0.2246 - val_accuracy: 0.9077\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2118 - accuracy: 0.9099 - val_loss: 0.2095 - val_accuracy: 0.9084\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2110 - accuracy: 0.9102 - val_loss: 0.2345 - val_accuracy: 0.9031\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2207 - accuracy: 0.9079 - val_loss: 0.2144 - val_accuracy: 0.9086\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2084 - accuracy: 0.9116 - val_loss: 0.1931 - val_accuracy: 0.9193\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2077 - accuracy: 0.9120 - val_loss: 0.2499 - val_accuracy: 0.8992\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2106 - accuracy: 0.9103 - val_loss: 0.2099 - val_accuracy: 0.9131\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1975 - accuracy: 0.9153 - val_loss: 0.1994 - val_accuracy: 0.9153\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2001 - accuracy: 0.9147 - val_loss: 0.2074 - val_accuracy: 0.9126\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2010 - accuracy: 0.9135 - val_loss: 0.2127 - val_accuracy: 0.9097\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2262 - accuracy: 0.9063 - val_loss: 0.2089 - val_accuracy: 0.9104\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2126 - accuracy: 0.9103 - val_loss: 0.2146 - val_accuracy: 0.9118\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2006 - accuracy: 0.9143 - val_loss: 0.1960 - val_accuracy: 0.9177\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2083 - accuracy: 0.9118 - val_loss: 0.2059 - val_accuracy: 0.9142\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2058 - accuracy: 0.9121 - val_loss: 0.1890 - val_accuracy: 0.9199\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2070 - accuracy: 0.9117 - val_loss: 0.2051 - val_accuracy: 0.9127\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2006 - accuracy: 0.9133 - val_loss: 0.2123 - val_accuracy: 0.9075\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2014 - accuracy: 0.9135 - val_loss: 0.2046 - val_accuracy: 0.9120\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2131 - accuracy: 0.9099 - val_loss: 0.2253 - val_accuracy: 0.9039\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2016 - accuracy: 0.9135 - val_loss: 0.1967 - val_accuracy: 0.9161\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2000 - accuracy: 0.9146 - val_loss: 0.2123 - val_accuracy: 0.9094\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2026 - accuracy: 0.9134 - val_loss: 0.2154 - val_accuracy: 0.9083\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1989 - accuracy: 0.9145 - val_loss: 0.2133 - val_accuracy: 0.9124\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1942 - accuracy: 0.9169 - val_loss: 0.2069 - val_accuracy: 0.9123\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2035 - accuracy: 0.9131 - val_loss: 0.2016 - val_accuracy: 0.9128\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2074 - accuracy: 0.9109 - val_loss: 0.1980 - val_accuracy: 0.9177\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1986 - accuracy: 0.9148 - val_loss: 0.2161 - val_accuracy: 0.9078\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2092 - accuracy: 0.9114 - val_loss: 0.1946 - val_accuracy: 0.9167\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1937 - accuracy: 0.9158 - val_loss: 0.2352 - val_accuracy: 0.9060\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2073 - accuracy: 0.9120 - val_loss: 0.2095 - val_accuracy: 0.9151\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.2161 - accuracy: 0.9095 - val_loss: 0.2171 - val_accuracy: 0.9078\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2019 - accuracy: 0.9135 - val_loss: 0.2049 - val_accuracy: 0.9116\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2007 - accuracy: 0.9144 - val_loss: 0.2104 - val_accuracy: 0.9105\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2010 - accuracy: 0.9142 - val_loss: 0.2157 - val_accuracy: 0.9092\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2022 - accuracy: 0.9140 - val_loss: 0.2053 - val_accuracy: 0.9123\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2032 - accuracy: 0.9129 - val_loss: 0.2033 - val_accuracy: 0.9137\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2078 - accuracy: 0.9119 - val_loss: 0.2313 - val_accuracy: 0.9017\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2007 - accuracy: 0.9133 - val_loss: 0.2001 - val_accuracy: 0.9145\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1995 - accuracy: 0.9151 - val_loss: 0.2002 - val_accuracy: 0.9151\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1969 - accuracy: 0.9156 - val_loss: 0.2116 - val_accuracy: 0.9151\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1987 - accuracy: 0.9140 - val_loss: 0.2061 - val_accuracy: 0.9131\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2028 - accuracy: 0.9139 - val_loss: 0.1985 - val_accuracy: 0.9161\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2056 - accuracy: 0.9115 - val_loss: 0.2099 - val_accuracy: 0.9110\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2042 - accuracy: 0.9109 - val_loss: 0.2147 - val_accuracy: 0.9100\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2003 - accuracy: 0.9134 - val_loss: 0.1941 - val_accuracy: 0.9179\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1967 - accuracy: 0.9155 - val_loss: 0.2315 - val_accuracy: 0.9008\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2091 - accuracy: 0.9112 - val_loss: 0.1940 - val_accuracy: 0.9181\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1966 - accuracy: 0.9159 - val_loss: 0.1907 - val_accuracy: 0.9198\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1985 - accuracy: 0.9148 - val_loss: 0.2248 - val_accuracy: 0.9058\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1996 - accuracy: 0.9139 - val_loss: 0.2051 - val_accuracy: 0.9085\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1970 - accuracy: 0.9144 - val_loss: 0.2159 - val_accuracy: 0.9096\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1989 - accuracy: 0.9137 - val_loss: 0.1877 - val_accuracy: 0.9184\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1974 - accuracy: 0.9152 - val_loss: 0.2263 - val_accuracy: 0.9086\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1973 - accuracy: 0.9159 - val_loss: 0.1973 - val_accuracy: 0.9172\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 0.1938 - accuracy: 0.9157 - val_loss: 0.1987 - val_accuracy: 0.9129\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1950 - accuracy: 0.9164 - val_loss: 0.1894 - val_accuracy: 0.9159\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2020 - accuracy: 0.9130 - val_loss: 0.2006 - val_accuracy: 0.9176\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2012 - accuracy: 0.9133 - val_loss: 0.1856 - val_accuracy: 0.9202\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1933 - accuracy: 0.9172 - val_loss: 0.1901 - val_accuracy: 0.9197\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1979 - accuracy: 0.9153 - val_loss: 0.2183 - val_accuracy: 0.9107\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.2125 - accuracy: 0.9095 - val_loss: 0.2000 - val_accuracy: 0.9144\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1972 - accuracy: 0.9145 - val_loss: 0.2246 - val_accuracy: 0.9084\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1958 - accuracy: 0.9162 - val_loss: 0.1888 - val_accuracy: 0.9191\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1933 - accuracy: 0.9162 - val_loss: 0.2098 - val_accuracy: 0.9122\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2062 - accuracy: 0.9128 - val_loss: 0.2298 - val_accuracy: 0.9048\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1984 - accuracy: 0.9152 - val_loss: 0.1897 - val_accuracy: 0.9203\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1976 - accuracy: 0.9150 - val_loss: 0.1945 - val_accuracy: 0.9179\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1950 - accuracy: 0.9156 - val_loss: 0.1912 - val_accuracy: 0.9193\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.2010 - accuracy: 0.9145 - val_loss: 0.2907 - val_accuracy: 0.8859\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1954 - accuracy: 0.9153 - val_loss: 0.1944 - val_accuracy: 0.9175\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.1948 - accuracy: 0.9154 - val_loss: 0.1860 - val_accuracy: 0.9212\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.2095 - accuracy: 0.9118 - val_loss: 0.1879 - val_accuracy: 0.9193\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 0.1955 - accuracy: 0.9165 - val_loss: 0.2090 - val_accuracy: 0.9119\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.2000 - accuracy: 0.9147 - val_loss: 0.1804 - val_accuracy: 0.9228\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1996 - accuracy: 0.9146 - val_loss: 0.2006 - val_accuracy: 0.9170\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.2082 - accuracy: 0.9118 - val_loss: 0.2350 - val_accuracy: 0.8998\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1981 - accuracy: 0.9151 - val_loss: 0.1946 - val_accuracy: 0.9190\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1946 - accuracy: 0.9162 - val_loss: 0.1973 - val_accuracy: 0.9180\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1928 - accuracy: 0.9168 - val_loss: 0.1905 - val_accuracy: 0.9189\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1896 - accuracy: 0.9181 - val_loss: 0.2065 - val_accuracy: 0.9091\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1986 - accuracy: 0.9150 - val_loss: 0.1982 - val_accuracy: 0.9150\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1914 - accuracy: 0.9174 - val_loss: 0.1897 - val_accuracy: 0.9172\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1908 - accuracy: 0.9173 - val_loss: 0.1875 - val_accuracy: 0.9201\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1930 - accuracy: 0.9167 - val_loss: 0.1815 - val_accuracy: 0.9225\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1994 - accuracy: 0.9143 - val_loss: 0.1865 - val_accuracy: 0.9191\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1895 - accuracy: 0.9183 - val_loss: 0.1896 - val_accuracy: 0.9172\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1915 - accuracy: 0.9182 - val_loss: 0.1869 - val_accuracy: 0.9183\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.2021 - accuracy: 0.9130 - val_loss: 0.1908 - val_accuracy: 0.9175\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1903 - accuracy: 0.9175 - val_loss: 0.2042 - val_accuracy: 0.9119\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.2000 - accuracy: 0.9145 - val_loss: 0.2112 - val_accuracy: 0.9145\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1940 - accuracy: 0.9165 - val_loss: 0.2048 - val_accuracy: 0.9128\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.2052 - accuracy: 0.9135 - val_loss: 0.2070 - val_accuracy: 0.9118\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1946 - accuracy: 0.9170 - val_loss: 0.1869 - val_accuracy: 0.9208\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1955 - accuracy: 0.9166 - val_loss: 0.2149 - val_accuracy: 0.9083\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2071 - accuracy: 0.9113 - val_loss: 0.1977 - val_accuracy: 0.9135\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1936 - accuracy: 0.9168 - val_loss: 0.1900 - val_accuracy: 0.9172\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1890 - accuracy: 0.9175 - val_loss: 0.1954 - val_accuracy: 0.9142\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1914 - accuracy: 0.9172 - val_loss: 0.1874 - val_accuracy: 0.9190\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 0.1857 - accuracy: 0.9194 - val_loss: 0.2211 - val_accuracy: 0.9103\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1984 - accuracy: 0.9155 - val_loss: 0.1997 - val_accuracy: 0.9151\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2059 - accuracy: 0.9119 - val_loss: 0.1848 - val_accuracy: 0.9206\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1887 - accuracy: 0.9178 - val_loss: 0.1900 - val_accuracy: 0.9169\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1871 - accuracy: 0.9182 - val_loss: 0.1902 - val_accuracy: 0.9178\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1821 - accuracy: 0.9204 - val_loss: 0.1881 - val_accuracy: 0.9197\n",
      "Epoch 275/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1871 - accuracy: 0.9193 - val_loss: 0.1933 - val_accuracy: 0.9179\n",
      "Epoch 276/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1916 - accuracy: 0.9169 - val_loss: 0.1943 - val_accuracy: 0.9180\n",
      "Epoch 277/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1965 - accuracy: 0.9156 - val_loss: 0.1923 - val_accuracy: 0.9177\n",
      "Epoch 278/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1942 - accuracy: 0.9159 - val_loss: 0.2114 - val_accuracy: 0.9106\n",
      "Epoch 279/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1979 - accuracy: 0.9146 - val_loss: 0.2301 - val_accuracy: 0.9022\n",
      "Epoch 280/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2056 - accuracy: 0.9125 - val_loss: 0.1817 - val_accuracy: 0.9231\n",
      "Epoch 281/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1940 - accuracy: 0.9161 - val_loss: 0.1938 - val_accuracy: 0.9166\n",
      "Epoch 282/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1967 - accuracy: 0.9145 - val_loss: 0.1922 - val_accuracy: 0.9171\n",
      "Epoch 283/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2002 - accuracy: 0.9143 - val_loss: 0.2153 - val_accuracy: 0.9076\n",
      "Epoch 284/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1949 - accuracy: 0.9162 - val_loss: 0.1894 - val_accuracy: 0.9190\n",
      "Epoch 285/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1990 - accuracy: 0.9158 - val_loss: 0.2135 - val_accuracy: 0.9099\n",
      "Epoch 286/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1944 - accuracy: 0.9164 - val_loss: 0.1924 - val_accuracy: 0.9177\n",
      "Epoch 287/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1863 - accuracy: 0.9194 - val_loss: 0.2069 - val_accuracy: 0.9126\n",
      "Epoch 288/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1870 - accuracy: 0.9193 - val_loss: 0.1949 - val_accuracy: 0.9169\n",
      "Epoch 289/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1895 - accuracy: 0.9178 - val_loss: 0.1874 - val_accuracy: 0.9208\n",
      "Epoch 290/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.2044 - accuracy: 0.9138 - val_loss: 0.2136 - val_accuracy: 0.9088\n",
      "Epoch 291/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.1895 - accuracy: 0.9180 - val_loss: 0.1896 - val_accuracy: 0.9172\n",
      "Epoch 292/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1924 - accuracy: 0.9173 - val_loss: 0.1828 - val_accuracy: 0.9209\n",
      "Epoch 293/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1880 - accuracy: 0.9180 - val_loss: 0.1904 - val_accuracy: 0.9174\n",
      "Epoch 294/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1938 - accuracy: 0.9160 - val_loss: 0.1980 - val_accuracy: 0.9134\n",
      "Epoch 295/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1826 - accuracy: 0.9206 - val_loss: 0.1990 - val_accuracy: 0.9171\n",
      "Epoch 296/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1955 - accuracy: 0.9155 - val_loss: 0.1972 - val_accuracy: 0.9157\n",
      "Epoch 297/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1860 - accuracy: 0.9189 - val_loss: 0.1963 - val_accuracy: 0.9163\n",
      "Epoch 298/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1905 - accuracy: 0.9181 - val_loss: 0.2045 - val_accuracy: 0.9129\n",
      "Epoch 299/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1981 - accuracy: 0.9144 - val_loss: 0.2050 - val_accuracy: 0.9137\n",
      "Epoch 300/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1974 - accuracy: 0.9156 - val_loss: 0.2035 - val_accuracy: 0.9137\n",
      "Epoch 301/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1988 - accuracy: 0.9150 - val_loss: 0.1914 - val_accuracy: 0.9193\n",
      "Epoch 302/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1966 - accuracy: 0.9148 - val_loss: 0.1997 - val_accuracy: 0.9147\n",
      "Epoch 303/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1893 - accuracy: 0.9168 - val_loss: 0.1862 - val_accuracy: 0.9210\n",
      "Epoch 304/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1828 - accuracy: 0.9209 - val_loss: 0.1898 - val_accuracy: 0.9196\n",
      "Epoch 305/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1909 - accuracy: 0.9175 - val_loss: 0.1944 - val_accuracy: 0.9173\n",
      "Epoch 306/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1832 - accuracy: 0.9200 - val_loss: 0.2216 - val_accuracy: 0.9102\n",
      "Epoch 307/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1915 - accuracy: 0.9170 - val_loss: 0.2477 - val_accuracy: 0.8990\n",
      "Epoch 308/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1983 - accuracy: 0.9135 - val_loss: 0.1981 - val_accuracy: 0.9173\n",
      "Epoch 309/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1995 - accuracy: 0.9150 - val_loss: 0.2148 - val_accuracy: 0.9107\n",
      "Epoch 310/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1908 - accuracy: 0.9176 - val_loss: 0.2087 - val_accuracy: 0.9140\n",
      "Epoch 311/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1909 - accuracy: 0.9176 - val_loss: 0.1880 - val_accuracy: 0.9216\n",
      "Epoch 312/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1939 - accuracy: 0.9164 - val_loss: 0.1896 - val_accuracy: 0.9193\n",
      "Epoch 313/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1913 - accuracy: 0.9168 - val_loss: 0.2118 - val_accuracy: 0.9106\n",
      "Epoch 314/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1984 - accuracy: 0.9153 - val_loss: 0.1959 - val_accuracy: 0.9158\n",
      "Epoch 315/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1894 - accuracy: 0.9180 - val_loss: 0.1875 - val_accuracy: 0.9193\n",
      "Epoch 316/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1887 - accuracy: 0.9181 - val_loss: 0.1848 - val_accuracy: 0.9216\n",
      "Epoch 317/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1842 - accuracy: 0.9192 - val_loss: 0.2663 - val_accuracy: 0.8985\n",
      "Epoch 318/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1949 - accuracy: 0.9162 - val_loss: 0.1862 - val_accuracy: 0.9193\n",
      "Epoch 319/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1887 - accuracy: 0.9188 - val_loss: 0.1859 - val_accuracy: 0.9205\n",
      "Epoch 320/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1880 - accuracy: 0.9185 - val_loss: 0.2033 - val_accuracy: 0.9158\n",
      "Epoch 321/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1840 - accuracy: 0.9199 - val_loss: 0.2089 - val_accuracy: 0.9147\n",
      "Epoch 322/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1952 - accuracy: 0.9165 - val_loss: 0.2072 - val_accuracy: 0.9114\n",
      "Epoch 323/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1884 - accuracy: 0.9187 - val_loss: 0.2028 - val_accuracy: 0.9169\n",
      "Epoch 324/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1819 - accuracy: 0.9216 - val_loss: 0.1881 - val_accuracy: 0.9188\n",
      "Epoch 325/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1891 - accuracy: 0.9188 - val_loss: 0.1879 - val_accuracy: 0.9199\n",
      "Epoch 326/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1906 - accuracy: 0.9184 - val_loss: 0.1903 - val_accuracy: 0.9189\n",
      "Epoch 327/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1978 - accuracy: 0.9154 - val_loss: 0.2019 - val_accuracy: 0.9139\n",
      "Epoch 328/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1874 - accuracy: 0.9194 - val_loss: 0.2187 - val_accuracy: 0.9089\n",
      "Epoch 329/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1828 - accuracy: 0.9204 - val_loss: 0.1985 - val_accuracy: 0.9158\n",
      "Epoch 330/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1871 - accuracy: 0.9188 - val_loss: 0.1845 - val_accuracy: 0.9193\n",
      "Epoch 331/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1889 - accuracy: 0.9176 - val_loss: 0.1908 - val_accuracy: 0.9177\n",
      "Epoch 332/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1811 - accuracy: 0.9206 - val_loss: 0.2247 - val_accuracy: 0.9047\n",
      "Epoch 333/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1891 - accuracy: 0.9185 - val_loss: 0.1985 - val_accuracy: 0.9154\n",
      "Epoch 334/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1838 - accuracy: 0.9202 - val_loss: 0.1973 - val_accuracy: 0.9163\n",
      "Epoch 335/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1915 - accuracy: 0.9167 - val_loss: 0.2563 - val_accuracy: 0.8980\n",
      "Epoch 336/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1901 - accuracy: 0.9176 - val_loss: 0.1932 - val_accuracy: 0.9186\n",
      "Epoch 337/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1904 - accuracy: 0.9183 - val_loss: 0.2066 - val_accuracy: 0.9127\n",
      "Epoch 338/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1923 - accuracy: 0.9163 - val_loss: 0.1826 - val_accuracy: 0.9202\n",
      "Epoch 339/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1842 - accuracy: 0.9192 - val_loss: 0.2100 - val_accuracy: 0.9122\n",
      "Epoch 340/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1845 - accuracy: 0.9202 - val_loss: 0.1867 - val_accuracy: 0.9184\n",
      "Epoch 341/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1894 - accuracy: 0.9178 - val_loss: 0.2132 - val_accuracy: 0.9120\n",
      "Epoch 342/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1882 - accuracy: 0.9185 - val_loss: 0.1764 - val_accuracy: 0.9238\n",
      "Epoch 343/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1821 - accuracy: 0.9204 - val_loss: 0.1805 - val_accuracy: 0.9223\n",
      "Epoch 344/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1857 - accuracy: 0.9195 - val_loss: 0.2067 - val_accuracy: 0.9125\n",
      "Epoch 345/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2013 - accuracy: 0.9126 - val_loss: 0.1874 - val_accuracy: 0.9207\n",
      "Epoch 346/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1849 - accuracy: 0.9198 - val_loss: 0.1910 - val_accuracy: 0.9183\n",
      "Epoch 347/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1865 - accuracy: 0.9184 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1947 - accuracy: 0.9160 - val_loss: 0.2322 - val_accuracy: 0.9062\n",
      "Epoch 349/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1887 - accuracy: 0.9179 - val_loss: 0.1849 - val_accuracy: 0.9223\n",
      "Epoch 350/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1839 - accuracy: 0.9204 - val_loss: 0.1770 - val_accuracy: 0.9239\n",
      "Epoch 351/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1801 - accuracy: 0.9220 - val_loss: 0.1863 - val_accuracy: 0.9208\n",
      "Epoch 352/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1799 - accuracy: 0.9215 - val_loss: 0.2327 - val_accuracy: 0.9076\n",
      "Epoch 353/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1919 - accuracy: 0.9173 - val_loss: 0.1823 - val_accuracy: 0.9194\n",
      "Epoch 354/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1788 - accuracy: 0.9212 - val_loss: 0.1865 - val_accuracy: 0.9199\n",
      "Epoch 355/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1875 - accuracy: 0.9188 - val_loss: 0.2018 - val_accuracy: 0.9159\n",
      "Epoch 356/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1827 - accuracy: 0.9209 - val_loss: 0.1957 - val_accuracy: 0.9150\n",
      "Epoch 357/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1847 - accuracy: 0.9201 - val_loss: 0.1819 - val_accuracy: 0.9225\n",
      "Epoch 358/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1903 - accuracy: 0.9177 - val_loss: 0.1937 - val_accuracy: 0.9182\n",
      "Epoch 359/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1955 - accuracy: 0.9157 - val_loss: 0.2048 - val_accuracy: 0.9140\n",
      "Epoch 360/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1858 - accuracy: 0.9193 - val_loss: 0.2246 - val_accuracy: 0.9104\n",
      "Epoch 361/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1977 - accuracy: 0.9151 - val_loss: 0.1907 - val_accuracy: 0.9186\n",
      "Epoch 362/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1807 - accuracy: 0.9213 - val_loss: 0.1842 - val_accuracy: 0.9217\n",
      "Epoch 363/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1961 - accuracy: 0.9165 - val_loss: 0.1903 - val_accuracy: 0.9196\n",
      "Epoch 364/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1886 - accuracy: 0.9180 - val_loss: 0.2119 - val_accuracy: 0.9087\n",
      "Epoch 365/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1866 - accuracy: 0.9199 - val_loss: 0.1903 - val_accuracy: 0.9216\n",
      "Epoch 366/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1792 - accuracy: 0.9218 - val_loss: 0.1953 - val_accuracy: 0.9168\n",
      "Epoch 367/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1828 - accuracy: 0.9206 - val_loss: 0.1917 - val_accuracy: 0.9183\n",
      "Epoch 368/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1848 - accuracy: 0.9195 - val_loss: 0.1832 - val_accuracy: 0.9225\n",
      "Epoch 369/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1816 - accuracy: 0.9198 - val_loss: 0.1824 - val_accuracy: 0.9234\n",
      "Epoch 370/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1862 - accuracy: 0.9193 - val_loss: 0.1787 - val_accuracy: 0.9224\n",
      "Epoch 371/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1884 - accuracy: 0.9183 - val_loss: 0.1823 - val_accuracy: 0.9230\n",
      "Epoch 372/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1905 - accuracy: 0.9180 - val_loss: 0.1815 - val_accuracy: 0.9219\n",
      "Epoch 373/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1766 - accuracy: 0.9226 - val_loss: 0.1877 - val_accuracy: 0.9198\n",
      "Epoch 374/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1908 - accuracy: 0.9174 - val_loss: 0.1985 - val_accuracy: 0.9132\n",
      "Epoch 375/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1881 - accuracy: 0.9178 - val_loss: 0.1833 - val_accuracy: 0.9204\n",
      "Epoch 376/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1788 - accuracy: 0.9219 - val_loss: 0.1909 - val_accuracy: 0.9182\n",
      "Epoch 377/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1907 - accuracy: 0.9173 - val_loss: 0.1809 - val_accuracy: 0.9225\n",
      "Epoch 378/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1833 - accuracy: 0.9210 - val_loss: 0.1858 - val_accuracy: 0.9206\n",
      "Epoch 379/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1988 - accuracy: 0.9151 - val_loss: 0.1986 - val_accuracy: 0.9168\n",
      "Epoch 380/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1833 - accuracy: 0.9208 - val_loss: 0.1969 - val_accuracy: 0.9140\n",
      "Epoch 381/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2162 - accuracy: 0.9096 - val_loss: 0.1928 - val_accuracy: 0.9176\n",
      "Epoch 382/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1865 - accuracy: 0.9186 - val_loss: 0.1881 - val_accuracy: 0.9199\n",
      "Epoch 383/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1844 - accuracy: 0.9200 - val_loss: 0.2108 - val_accuracy: 0.9128\n",
      "Epoch 384/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1976 - accuracy: 0.9150 - val_loss: 0.1938 - val_accuracy: 0.9165\n",
      "Epoch 385/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1768 - accuracy: 0.9225 - val_loss: 0.1913 - val_accuracy: 0.9184\n",
      "Epoch 386/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1837 - accuracy: 0.9187 - val_loss: 0.2157 - val_accuracy: 0.9115\n",
      "Epoch 387/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1882 - accuracy: 0.9192 - val_loss: 0.2061 - val_accuracy: 0.9139\n",
      "Epoch 388/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1901 - accuracy: 0.9180 - val_loss: 0.1833 - val_accuracy: 0.9202\n",
      "Epoch 389/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1764 - accuracy: 0.9217 - val_loss: 0.2006 - val_accuracy: 0.9119\n",
      "Epoch 390/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.1868 - accuracy: 0.9195 - val_loss: 0.1823 - val_accuracy: 0.9206\n",
      "Epoch 391/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1893 - accuracy: 0.9187 - val_loss: 0.1878 - val_accuracy: 0.9190\n",
      "Epoch 392/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1832 - accuracy: 0.9202 - val_loss: 0.1902 - val_accuracy: 0.9198\n",
      "Epoch 393/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1820 - accuracy: 0.9213 - val_loss: 0.1803 - val_accuracy: 0.9238\n",
      "Epoch 394/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1822 - accuracy: 0.9208 - val_loss: 0.1911 - val_accuracy: 0.9170\n",
      "Epoch 395/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1845 - accuracy: 0.9194 - val_loss: 0.1877 - val_accuracy: 0.9212\n",
      "Epoch 396/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1845 - accuracy: 0.9198 - val_loss: 0.1984 - val_accuracy: 0.9174\n",
      "Epoch 397/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1909 - accuracy: 0.9170 - val_loss: 0.1985 - val_accuracy: 0.9150\n",
      "Epoch 398/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1801 - accuracy: 0.9210 - val_loss: 0.2182 - val_accuracy: 0.9134\n",
      "Epoch 399/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1922 - accuracy: 0.9174 - val_loss: 0.2253 - val_accuracy: 0.9053\n",
      "Epoch 400/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1817 - accuracy: 0.9204 - val_loss: 0.2002 - val_accuracy: 0.9145\n",
      "Epoch 401/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1907 - accuracy: 0.9175 - val_loss: 0.1930 - val_accuracy: 0.9170\n",
      "Epoch 402/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1845 - accuracy: 0.9193 - val_loss: 0.1835 - val_accuracy: 0.9196\n",
      "Epoch 403/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1881 - accuracy: 0.9190 - val_loss: 0.2037 - val_accuracy: 0.9143\n",
      "Epoch 404/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1856 - accuracy: 0.9195 - val_loss: 0.2032 - val_accuracy: 0.9107\n",
      "Epoch 405/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1820 - accuracy: 0.9198 - val_loss: 0.1783 - val_accuracy: 0.9226\n",
      "Epoch 406/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1781 - accuracy: 0.9219 - val_loss: 0.2135 - val_accuracy: 0.9134\n",
      "Epoch 407/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1851 - accuracy: 0.9190 - val_loss: 0.1866 - val_accuracy: 0.9192\n",
      "Epoch 408/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1841 - accuracy: 0.9201 - val_loss: 0.1865 - val_accuracy: 0.9205\n",
      "Epoch 409/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1838 - accuracy: 0.9198 - val_loss: 0.1902 - val_accuracy: 0.9187\n",
      "Epoch 410/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1883 - accuracy: 0.9183 - val_loss: 0.1880 - val_accuracy: 0.9180\n",
      "Epoch 411/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1867 - accuracy: 0.9186 - val_loss: 0.2178 - val_accuracy: 0.9079\n",
      "Epoch 412/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1885 - accuracy: 0.9180 - val_loss: 0.2282 - val_accuracy: 0.9055\n",
      "Epoch 413/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1852 - accuracy: 0.9198 - val_loss: 0.1955 - val_accuracy: 0.9151\n",
      "Epoch 414/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1817 - accuracy: 0.9210 - val_loss: 0.2257 - val_accuracy: 0.9065\n",
      "Epoch 415/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1801 - accuracy: 0.9217 - val_loss: 0.1877 - val_accuracy: 0.9191\n",
      "Epoch 416/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1972 - accuracy: 0.9142 - val_loss: 0.1859 - val_accuracy: 0.9202\n",
      "Epoch 417/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1902 - accuracy: 0.9185 - val_loss: 0.1909 - val_accuracy: 0.9179\n",
      "Epoch 418/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1851 - accuracy: 0.9201 - val_loss: 0.1850 - val_accuracy: 0.9204\n",
      "Epoch 419/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1912 - accuracy: 0.9161 - val_loss: 0.1944 - val_accuracy: 0.9171\n",
      "Epoch 420/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1878 - accuracy: 0.9188 - val_loss: 0.1926 - val_accuracy: 0.9168\n",
      "Epoch 421/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1896 - accuracy: 0.9182 - val_loss: 0.2191 - val_accuracy: 0.9063\n",
      "Epoch 422/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1868 - accuracy: 0.9183 - val_loss: 0.2166 - val_accuracy: 0.9111\n",
      "Epoch 423/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1849 - accuracy: 0.9197 - val_loss: 0.1857 - val_accuracy: 0.9219\n",
      "Epoch 424/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1808 - accuracy: 0.9201 - val_loss: 0.1812 - val_accuracy: 0.9232\n",
      "Epoch 425/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1869 - accuracy: 0.9190 - val_loss: 0.2216 - val_accuracy: 0.9060\n",
      "Epoch 426/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1822 - accuracy: 0.9200 - val_loss: 0.1782 - val_accuracy: 0.9240\n",
      "Epoch 427/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1756 - accuracy: 0.9230 - val_loss: 0.1913 - val_accuracy: 0.9200\n",
      "Epoch 428/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1790 - accuracy: 0.9221 - val_loss: 0.1794 - val_accuracy: 0.9232\n",
      "Epoch 429/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1881 - accuracy: 0.9193 - val_loss: 0.1977 - val_accuracy: 0.9163\n",
      "Epoch 430/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1954 - accuracy: 0.9175 - val_loss: 0.1834 - val_accuracy: 0.9206\n",
      "Epoch 431/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1914 - accuracy: 0.9179 - val_loss: 0.1852 - val_accuracy: 0.9206\n",
      "Epoch 432/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1833 - accuracy: 0.9196 - val_loss: 0.2131 - val_accuracy: 0.9097\n",
      "Epoch 433/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1754 - accuracy: 0.9234 - val_loss: 0.2022 - val_accuracy: 0.9161\n",
      "Epoch 434/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1847 - accuracy: 0.9193 - val_loss: 0.2192 - val_accuracy: 0.9096\n",
      "Epoch 435/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1858 - accuracy: 0.9200 - val_loss: 0.1961 - val_accuracy: 0.9167\n",
      "Epoch 436/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1969 - accuracy: 0.9154 - val_loss: 0.1851 - val_accuracy: 0.9206\n",
      "Epoch 437/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1838 - accuracy: 0.9198 - val_loss: 0.1816 - val_accuracy: 0.9219\n",
      "Epoch 438/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1839 - accuracy: 0.9208 - val_loss: 0.2033 - val_accuracy: 0.9143\n",
      "Epoch 439/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1819 - accuracy: 0.9197 - val_loss: 0.1938 - val_accuracy: 0.9168\n",
      "Epoch 440/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1854 - accuracy: 0.9188 - val_loss: 0.1827 - val_accuracy: 0.9198\n",
      "Epoch 441/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1840 - accuracy: 0.9200 - val_loss: 0.1858 - val_accuracy: 0.9211\n",
      "Epoch 442/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1782 - accuracy: 0.9219 - val_loss: 0.1787 - val_accuracy: 0.9235\n",
      "Epoch 443/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1795 - accuracy: 0.9225 - val_loss: 0.1873 - val_accuracy: 0.9183\n",
      "Epoch 444/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1784 - accuracy: 0.9226 - val_loss: 0.1835 - val_accuracy: 0.9209\n",
      "Epoch 445/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1889 - accuracy: 0.9178 - val_loss: 0.2142 - val_accuracy: 0.9133\n",
      "Epoch 446/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1885 - accuracy: 0.9190 - val_loss: 0.2065 - val_accuracy: 0.9118\n",
      "Epoch 447/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1808 - accuracy: 0.9220 - val_loss: 0.1791 - val_accuracy: 0.9225\n",
      "Epoch 448/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1789 - accuracy: 0.9217 - val_loss: 0.1847 - val_accuracy: 0.9190\n",
      "Epoch 449/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1799 - accuracy: 0.9212 - val_loss: 0.1845 - val_accuracy: 0.9211\n",
      "Epoch 450/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1893 - accuracy: 0.9190 - val_loss: 0.1864 - val_accuracy: 0.9191\n",
      "Epoch 451/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1754 - accuracy: 0.9238 - val_loss: 0.1952 - val_accuracy: 0.9165\n",
      "Epoch 452/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1789 - accuracy: 0.9214 - val_loss: 0.1822 - val_accuracy: 0.9215\n",
      "Epoch 453/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1844 - accuracy: 0.9201 - val_loss: 0.1876 - val_accuracy: 0.9182\n",
      "Epoch 454/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1814 - accuracy: 0.9207 - val_loss: 0.1905 - val_accuracy: 0.9177\n",
      "Epoch 455/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1769 - accuracy: 0.9228 - val_loss: 0.1851 - val_accuracy: 0.9202\n",
      "Epoch 456/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1844 - accuracy: 0.9197 - val_loss: 0.1816 - val_accuracy: 0.9206\n",
      "Epoch 457/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1780 - accuracy: 0.9223 - val_loss: 0.1786 - val_accuracy: 0.9240\n",
      "Epoch 458/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1792 - accuracy: 0.9221 - val_loss: 0.1949 - val_accuracy: 0.9185\n",
      "Epoch 459/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1843 - accuracy: 0.9199 - val_loss: 0.1837 - val_accuracy: 0.9215\n",
      "Epoch 460/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1792 - accuracy: 0.9217 - val_loss: 0.1788 - val_accuracy: 0.9232\n",
      "Epoch 461/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1812 - accuracy: 0.9203 - val_loss: 0.1846 - val_accuracy: 0.9201\n",
      "Epoch 462/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1839 - accuracy: 0.9199 - val_loss: 0.1867 - val_accuracy: 0.9182\n",
      "Epoch 463/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1811 - accuracy: 0.9206 - val_loss: 0.1972 - val_accuracy: 0.9184\n",
      "Epoch 464/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1946 - accuracy: 0.9168 - val_loss: 0.2008 - val_accuracy: 0.9168\n",
      "Epoch 465/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1911 - accuracy: 0.9186 - val_loss: 0.1928 - val_accuracy: 0.9162\n",
      "Epoch 466/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1764 - accuracy: 0.9223 - val_loss: 0.1766 - val_accuracy: 0.9254\n",
      "Epoch 467/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1863 - accuracy: 0.9185 - val_loss: 0.1834 - val_accuracy: 0.9212\n",
      "Epoch 468/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1728 - accuracy: 0.9235 - val_loss: 0.1952 - val_accuracy: 0.9160\n",
      "Epoch 469/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1768 - accuracy: 0.9220 - val_loss: 0.2011 - val_accuracy: 0.9139\n",
      "Epoch 470/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1868 - accuracy: 0.9202 - val_loss: 0.2087 - val_accuracy: 0.9142\n",
      "Epoch 471/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1767 - accuracy: 0.9224 - val_loss: 0.1845 - val_accuracy: 0.9214\n",
      "Epoch 472/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1881 - accuracy: 0.9191 - val_loss: 0.2018 - val_accuracy: 0.9156\n",
      "Epoch 473/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1972 - accuracy: 0.9157 - val_loss: 0.1815 - val_accuracy: 0.9220\n",
      "Epoch 474/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1764 - accuracy: 0.9240 - val_loss: 0.1777 - val_accuracy: 0.9213\n",
      "Epoch 475/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1719 - accuracy: 0.9245 - val_loss: 0.1835 - val_accuracy: 0.9206\n",
      "Epoch 476/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1837 - accuracy: 0.9206 - val_loss: 0.2071 - val_accuracy: 0.9128\n",
      "Epoch 477/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1835 - accuracy: 0.9196 - val_loss: 0.1894 - val_accuracy: 0.9174\n",
      "Epoch 478/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1868 - accuracy: 0.9193 - val_loss: 0.1992 - val_accuracy: 0.9125\n",
      "Epoch 479/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.1815 - val_accuracy: 0.9207\n",
      "Epoch 480/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1791 - accuracy: 0.9228 - val_loss: 0.2005 - val_accuracy: 0.9157\n",
      "Epoch 481/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1927 - accuracy: 0.9172 - val_loss: 0.1973 - val_accuracy: 0.9159\n",
      "Epoch 482/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1698 - accuracy: 0.9255 - val_loss: 0.1832 - val_accuracy: 0.9210\n",
      "Epoch 483/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1849 - accuracy: 0.9200 - val_loss: 0.1899 - val_accuracy: 0.9183\n",
      "Epoch 484/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1840 - accuracy: 0.9206 - val_loss: 0.1978 - val_accuracy: 0.9176\n",
      "Epoch 485/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1802 - accuracy: 0.9213 - val_loss: 0.2018 - val_accuracy: 0.9118\n",
      "Epoch 486/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1785 - accuracy: 0.9223 - val_loss: 0.1892 - val_accuracy: 0.9191\n",
      "Epoch 487/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1762 - accuracy: 0.9235 - val_loss: 0.1890 - val_accuracy: 0.9195\n",
      "Epoch 488/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1830 - accuracy: 0.9208 - val_loss: 0.1945 - val_accuracy: 0.9168\n",
      "Epoch 489/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1854 - accuracy: 0.9201 - val_loss: 0.1823 - val_accuracy: 0.9229\n",
      "Epoch 490/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1841 - accuracy: 0.9194 - val_loss: 0.1970 - val_accuracy: 0.9182\n",
      "Epoch 491/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1836 - accuracy: 0.9201 - val_loss: 0.1867 - val_accuracy: 0.9202\n",
      "Epoch 492/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1745 - accuracy: 0.9239 - val_loss: 0.1751 - val_accuracy: 0.9235\n",
      "Epoch 493/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1755 - accuracy: 0.9228 - val_loss: 0.2414 - val_accuracy: 0.9062\n",
      "Epoch 494/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1931 - accuracy: 0.9171 - val_loss: 0.1932 - val_accuracy: 0.9183\n",
      "Epoch 495/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1754 - accuracy: 0.9234 - val_loss: 0.1887 - val_accuracy: 0.9193\n",
      "Epoch 496/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1763 - accuracy: 0.9229 - val_loss: 0.1873 - val_accuracy: 0.9179\n",
      "Epoch 497/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1810 - accuracy: 0.9218 - val_loss: 0.1916 - val_accuracy: 0.9183\n",
      "Epoch 498/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1836 - accuracy: 0.9202 - val_loss: 0.1895 - val_accuracy: 0.9178\n",
      "Epoch 499/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1810 - accuracy: 0.9203 - val_loss: 0.1763 - val_accuracy: 0.9220\n",
      "Epoch 500/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1757 - accuracy: 0.9234 - val_loss: 0.1961 - val_accuracy: 0.9162\n",
      "Epoch 501/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1860 - accuracy: 0.9192 - val_loss: 0.1855 - val_accuracy: 0.9175\n",
      "Epoch 502/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1821 - accuracy: 0.9208 - val_loss: 0.1804 - val_accuracy: 0.9225\n",
      "Epoch 503/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1753 - accuracy: 0.9237 - val_loss: 0.1778 - val_accuracy: 0.9229\n",
      "Epoch 504/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1819 - accuracy: 0.9215 - val_loss: 0.1851 - val_accuracy: 0.9206\n",
      "Epoch 505/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1785 - accuracy: 0.9225 - val_loss: 0.2037 - val_accuracy: 0.9108\n",
      "Epoch 506/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1739 - accuracy: 0.9236 - val_loss: 0.1808 - val_accuracy: 0.9219\n",
      "Epoch 507/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1719 - accuracy: 0.9248 - val_loss: 0.1835 - val_accuracy: 0.9208\n",
      "Epoch 508/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1887 - accuracy: 0.9187 - val_loss: 0.1860 - val_accuracy: 0.9208\n",
      "Epoch 509/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1776 - accuracy: 0.9223 - val_loss: 0.1912 - val_accuracy: 0.9189\n",
      "Epoch 510/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1837 - accuracy: 0.9205 - val_loss: 0.1978 - val_accuracy: 0.9148\n",
      "Epoch 511/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1888 - accuracy: 0.9187 - val_loss: 0.1969 - val_accuracy: 0.9153\n",
      "Epoch 512/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1717 - accuracy: 0.9242 - val_loss: 0.1785 - val_accuracy: 0.9221\n",
      "Epoch 513/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1761 - accuracy: 0.9230 - val_loss: 0.1808 - val_accuracy: 0.9231\n",
      "Epoch 514/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1739 - accuracy: 0.9242 - val_loss: 0.2074 - val_accuracy: 0.9127\n",
      "Epoch 515/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1759 - accuracy: 0.9231 - val_loss: 0.1802 - val_accuracy: 0.9204\n",
      "Epoch 516/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1772 - accuracy: 0.9219 - val_loss: 0.2027 - val_accuracy: 0.9151\n",
      "Epoch 517/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1865 - accuracy: 0.9190 - val_loss: 0.1895 - val_accuracy: 0.9181\n",
      "Epoch 518/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1819 - accuracy: 0.9209 - val_loss: 0.1875 - val_accuracy: 0.9195\n",
      "Epoch 519/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1794 - accuracy: 0.9222 - val_loss: 0.1905 - val_accuracy: 0.9190\n",
      "Epoch 520/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1882 - accuracy: 0.9183 - val_loss: 0.1951 - val_accuracy: 0.9189\n",
      "Epoch 521/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1856 - accuracy: 0.9189 - val_loss: 0.2239 - val_accuracy: 0.9045\n",
      "Epoch 522/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1799 - accuracy: 0.9211 - val_loss: 0.1806 - val_accuracy: 0.9221\n",
      "Epoch 523/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1763 - accuracy: 0.9229 - val_loss: 0.2061 - val_accuracy: 0.9136\n",
      "Epoch 524/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1864 - accuracy: 0.9195 - val_loss: 0.1796 - val_accuracy: 0.9242\n",
      "Epoch 525/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1757 - accuracy: 0.9234 - val_loss: 0.1777 - val_accuracy: 0.9244\n",
      "Epoch 526/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1839 - accuracy: 0.9200 - val_loss: 0.1991 - val_accuracy: 0.9180\n",
      "Epoch 527/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1848 - accuracy: 0.9209 - val_loss: 0.1808 - val_accuracy: 0.9224\n",
      "Epoch 528/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1828 - accuracy: 0.9188 - val_loss: 0.1985 - val_accuracy: 0.9169\n",
      "Epoch 529/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1839 - accuracy: 0.9203 - val_loss: 0.1826 - val_accuracy: 0.9228\n",
      "Epoch 530/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1874 - accuracy: 0.9197 - val_loss: 0.1985 - val_accuracy: 0.9174\n",
      "Epoch 531/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1764 - accuracy: 0.9221 - val_loss: 0.1808 - val_accuracy: 0.9224\n",
      "Epoch 532/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1770 - accuracy: 0.9218 - val_loss: 0.1880 - val_accuracy: 0.9193\n",
      "Epoch 533/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1749 - accuracy: 0.9242 - val_loss: 0.2009 - val_accuracy: 0.9125\n",
      "Epoch 534/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1828 - accuracy: 0.9201 - val_loss: 0.1790 - val_accuracy: 0.9221\n",
      "Epoch 535/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1759 - accuracy: 0.9230 - val_loss: 0.1801 - val_accuracy: 0.9235\n",
      "Epoch 536/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1810 - accuracy: 0.9214 - val_loss: 0.1923 - val_accuracy: 0.9167\n",
      "Epoch 537/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1907 - accuracy: 0.9166 - val_loss: 0.1945 - val_accuracy: 0.9188\n",
      "Epoch 538/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1866 - accuracy: 0.9202 - val_loss: 0.1880 - val_accuracy: 0.9196\n",
      "Epoch 539/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1749 - accuracy: 0.9230 - val_loss: 0.1783 - val_accuracy: 0.9223\n",
      "Epoch 540/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1679 - accuracy: 0.9264 - val_loss: 0.1987 - val_accuracy: 0.9167\n",
      "Epoch 541/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1777 - accuracy: 0.9220 - val_loss: 0.1917 - val_accuracy: 0.9142\n",
      "Epoch 542/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1923 - accuracy: 0.9161 - val_loss: 0.1919 - val_accuracy: 0.9181\n",
      "Epoch 543/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1751 - accuracy: 0.9240 - val_loss: 0.1854 - val_accuracy: 0.9194\n",
      "Epoch 544/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1700 - accuracy: 0.9256 - val_loss: 0.1805 - val_accuracy: 0.9206\n",
      "Epoch 545/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 0.1851 - accuracy: 0.9192 - val_loss: 0.1844 - val_accuracy: 0.9199\n",
      "Epoch 546/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1734 - accuracy: 0.9238 - val_loss: 0.1759 - val_accuracy: 0.9227\n",
      "Epoch 547/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1813 - accuracy: 0.9211 - val_loss: 0.2164 - val_accuracy: 0.9106\n",
      "Epoch 548/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1753 - accuracy: 0.9241 - val_loss: 0.2064 - val_accuracy: 0.9106\n",
      "Epoch 549/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2012 - accuracy: 0.9158 - val_loss: 0.1754 - val_accuracy: 0.9243\n",
      "Epoch 550/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1813 - accuracy: 0.9212 - val_loss: 0.1810 - val_accuracy: 0.9204\n",
      "Epoch 551/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1789 - accuracy: 0.9214 - val_loss: 0.1932 - val_accuracy: 0.9168\n",
      "Epoch 552/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1813 - accuracy: 0.9209 - val_loss: 0.1883 - val_accuracy: 0.9169\n",
      "Epoch 553/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1864 - accuracy: 0.9202 - val_loss: 0.2273 - val_accuracy: 0.9050\n",
      "Epoch 554/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1831 - accuracy: 0.9208 - val_loss: 0.1792 - val_accuracy: 0.9225\n",
      "Epoch 555/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1750 - accuracy: 0.9237 - val_loss: 0.1764 - val_accuracy: 0.9239\n",
      "Epoch 556/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1739 - accuracy: 0.9240 - val_loss: 0.1908 - val_accuracy: 0.9189\n",
      "Epoch 557/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1757 - accuracy: 0.9233 - val_loss: 0.1829 - val_accuracy: 0.9224\n",
      "Epoch 558/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.2019 - accuracy: 0.9166 - val_loss: 0.1852 - val_accuracy: 0.9215\n",
      "Epoch 559/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1827 - accuracy: 0.9212 - val_loss: 0.1813 - val_accuracy: 0.9215\n",
      "Epoch 560/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1773 - accuracy: 0.9221 - val_loss: 0.1864 - val_accuracy: 0.9203\n",
      "Epoch 561/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1831 - accuracy: 0.9199 - val_loss: 0.1788 - val_accuracy: 0.9230\n",
      "Epoch 562/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1697 - accuracy: 0.9256 - val_loss: 0.2022 - val_accuracy: 0.9153\n",
      "Epoch 563/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1817 - accuracy: 0.9215 - val_loss: 0.1940 - val_accuracy: 0.9159\n",
      "Epoch 564/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1759 - accuracy: 0.9227 - val_loss: 0.1759 - val_accuracy: 0.9244\n",
      "Epoch 565/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1721 - accuracy: 0.9244 - val_loss: 0.1853 - val_accuracy: 0.9201\n",
      "Epoch 566/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1805 - accuracy: 0.9221 - val_loss: 0.2041 - val_accuracy: 0.9148\n",
      "Epoch 567/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1772 - accuracy: 0.9226 - val_loss: 0.2231 - val_accuracy: 0.9073\n",
      "Epoch 568/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1780 - accuracy: 0.9218 - val_loss: 0.1780 - val_accuracy: 0.9208\n",
      "Epoch 569/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1936 - accuracy: 0.9169 - val_loss: 0.1896 - val_accuracy: 0.9179\n",
      "Epoch 570/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1780 - accuracy: 0.9220 - val_loss: 0.1781 - val_accuracy: 0.9231\n",
      "Epoch 571/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1859 - accuracy: 0.9206 - val_loss: 0.1950 - val_accuracy: 0.9177\n",
      "Epoch 572/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.2079 - accuracy: 0.9132 - val_loss: 0.1925 - val_accuracy: 0.9175\n",
      "Epoch 573/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1866 - accuracy: 0.9183 - val_loss: 0.1938 - val_accuracy: 0.9176\n",
      "Epoch 574/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1843 - accuracy: 0.9203 - val_loss: 0.1859 - val_accuracy: 0.9210\n",
      "Epoch 575/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1782 - accuracy: 0.9230 - val_loss: 0.1793 - val_accuracy: 0.9219\n",
      "Epoch 576/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1805 - accuracy: 0.9208 - val_loss: 0.1944 - val_accuracy: 0.9147\n",
      "Epoch 577/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1908 - accuracy: 0.9173 - val_loss: 0.2141 - val_accuracy: 0.9097\n",
      "Epoch 578/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1855 - accuracy: 0.9191 - val_loss: 0.1800 - val_accuracy: 0.9229\n",
      "Epoch 579/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1756 - accuracy: 0.9230 - val_loss: 0.1895 - val_accuracy: 0.9192\n",
      "Epoch 580/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1843 - accuracy: 0.9199 - val_loss: 0.1792 - val_accuracy: 0.9219\n",
      "Epoch 581/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1700 - accuracy: 0.9255 - val_loss: 0.2137 - val_accuracy: 0.9111\n",
      "Epoch 582/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1898 - accuracy: 0.9171 - val_loss: 0.1830 - val_accuracy: 0.9203\n",
      "Epoch 583/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.1690 - accuracy: 0.9258 - val_loss: 0.1821 - val_accuracy: 0.9210\n",
      "Epoch 584/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 0.1753 - accuracy: 0.9230 - val_loss: 0.1935 - val_accuracy: 0.9186\n",
      "Epoch 585/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1814 - accuracy: 0.9207 - val_loss: 0.1972 - val_accuracy: 0.9166\n",
      "Epoch 586/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 0.1862 - accuracy: 0.9200 - val_loss: 0.1976 - val_accuracy: 0.9178\n",
      "Epoch 587/1000\n",
      "87/87 [==============================] - 6s 72ms/step - loss: 0.1862 - accuracy: 0.9194 - val_loss: 0.1808 - val_accuracy: 0.9232\n",
      "Epoch 588/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1710 - accuracy: 0.9252 - val_loss: 0.1882 - val_accuracy: 0.9197\n",
      "Epoch 589/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1795 - accuracy: 0.9224 - val_loss: 0.1948 - val_accuracy: 0.9193\n",
      "Epoch 590/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1810 - accuracy: 0.9217 - val_loss: 0.1775 - val_accuracy: 0.9224\n",
      "Epoch 591/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1756 - accuracy: 0.9237 - val_loss: 0.1802 - val_accuracy: 0.9234\n",
      "Epoch 592/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1816 - accuracy: 0.9218 - val_loss: 0.1998 - val_accuracy: 0.9167\n",
      "Epoch 593/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1869 - accuracy: 0.9190 - val_loss: 0.1978 - val_accuracy: 0.9161\n",
      "Epoch 594/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1897 - accuracy: 0.9179 - val_loss: 0.1854 - val_accuracy: 0.9208\n",
      "Epoch 595/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1795 - accuracy: 0.9219 - val_loss: 0.1739 - val_accuracy: 0.9245\n",
      "Epoch 596/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2000 - accuracy: 0.9139 - val_loss: 0.1906 - val_accuracy: 0.9187\n",
      "Epoch 597/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1804 - accuracy: 0.9216 - val_loss: 0.1857 - val_accuracy: 0.9217\n",
      "Epoch 598/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1773 - accuracy: 0.9224 - val_loss: 0.1869 - val_accuracy: 0.9200\n",
      "Epoch 599/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1820 - accuracy: 0.9214 - val_loss: 0.2033 - val_accuracy: 0.9152\n",
      "Epoch 600/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1766 - accuracy: 0.9232 - val_loss: 0.1971 - val_accuracy: 0.9181\n",
      "Epoch 601/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1792 - accuracy: 0.9211 - val_loss: 0.1856 - val_accuracy: 0.9196\n",
      "Epoch 602/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1758 - accuracy: 0.9238 - val_loss: 0.1977 - val_accuracy: 0.9170\n",
      "Epoch 603/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1729 - accuracy: 0.9237 - val_loss: 0.1986 - val_accuracy: 0.9153\n",
      "Epoch 604/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1832 - accuracy: 0.9210 - val_loss: 0.2007 - val_accuracy: 0.9150\n",
      "Epoch 605/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1823 - accuracy: 0.9208 - val_loss: 0.1893 - val_accuracy: 0.9169\n",
      "Epoch 606/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1775 - accuracy: 0.9229 - val_loss: 0.1793 - val_accuracy: 0.9228\n",
      "Epoch 607/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1861 - accuracy: 0.9195 - val_loss: 0.1758 - val_accuracy: 0.9237\n",
      "Epoch 608/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1845 - accuracy: 0.9206 - val_loss: 0.2433 - val_accuracy: 0.9010\n",
      "Epoch 609/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2017 - accuracy: 0.9141 - val_loss: 0.1793 - val_accuracy: 0.9235\n",
      "Epoch 610/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1781 - accuracy: 0.9221 - val_loss: 0.1747 - val_accuracy: 0.9238\n",
      "Epoch 611/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1716 - accuracy: 0.9240 - val_loss: 0.1898 - val_accuracy: 0.9191\n",
      "Epoch 612/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1697 - accuracy: 0.9256 - val_loss: 0.2013 - val_accuracy: 0.9159\n",
      "Epoch 613/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1810 - accuracy: 0.9214 - val_loss: 0.1847 - val_accuracy: 0.9198\n",
      "Epoch 614/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1798 - accuracy: 0.9217 - val_loss: 0.2106 - val_accuracy: 0.9119\n",
      "Epoch 615/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1781 - accuracy: 0.9219 - val_loss: 0.2033 - val_accuracy: 0.9130\n",
      "Epoch 616/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1949 - accuracy: 0.9162 - val_loss: 0.1790 - val_accuracy: 0.9228\n",
      "Epoch 617/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1772 - accuracy: 0.9220 - val_loss: 0.1912 - val_accuracy: 0.9186\n",
      "Epoch 618/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1857 - accuracy: 0.9192 - val_loss: 0.1876 - val_accuracy: 0.9197\n",
      "Epoch 619/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1728 - accuracy: 0.9249 - val_loss: 0.1819 - val_accuracy: 0.9227\n",
      "Epoch 620/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1770 - accuracy: 0.9223 - val_loss: 0.1925 - val_accuracy: 0.9183\n",
      "Epoch 621/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1745 - accuracy: 0.9234 - val_loss: 0.1786 - val_accuracy: 0.9228\n",
      "Epoch 622/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1763 - accuracy: 0.9226 - val_loss: 0.1846 - val_accuracy: 0.9204\n",
      "Epoch 623/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1756 - accuracy: 0.9231 - val_loss: 0.1811 - val_accuracy: 0.9211\n",
      "Epoch 624/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1793 - accuracy: 0.9212 - val_loss: 0.1805 - val_accuracy: 0.9217\n",
      "Epoch 625/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1689 - accuracy: 0.9257 - val_loss: 0.1953 - val_accuracy: 0.9139\n",
      "Epoch 626/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1780 - accuracy: 0.9213 - val_loss: 0.1816 - val_accuracy: 0.9192\n",
      "Epoch 627/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1733 - accuracy: 0.9246 - val_loss: 0.1804 - val_accuracy: 0.9225\n",
      "Epoch 628/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1991 - accuracy: 0.9147 - val_loss: 0.2014 - val_accuracy: 0.9163\n",
      "Epoch 629/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1891 - accuracy: 0.9185 - val_loss: 0.2039 - val_accuracy: 0.9158\n",
      "Epoch 630/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1911 - accuracy: 0.9177 - val_loss: 0.2095 - val_accuracy: 0.9103\n",
      "Epoch 631/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1799 - accuracy: 0.9224 - val_loss: 0.1907 - val_accuracy: 0.9188\n",
      "Epoch 632/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1809 - accuracy: 0.9214 - val_loss: 0.1906 - val_accuracy: 0.9179\n",
      "Epoch 633/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1868 - accuracy: 0.9192 - val_loss: 0.2097 - val_accuracy: 0.9142\n",
      "Epoch 634/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1988 - accuracy: 0.9163 - val_loss: 0.1869 - val_accuracy: 0.9196\n",
      "Epoch 635/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1740 - accuracy: 0.9239 - val_loss: 0.1778 - val_accuracy: 0.9239\n",
      "Epoch 636/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1796 - accuracy: 0.9215 - val_loss: 0.1907 - val_accuracy: 0.9170\n",
      "Epoch 637/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1824 - accuracy: 0.9209 - val_loss: 0.1786 - val_accuracy: 0.9238\n",
      "Epoch 638/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1710 - accuracy: 0.9258 - val_loss: 0.1888 - val_accuracy: 0.9210\n",
      "Epoch 639/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1920 - accuracy: 0.9178 - val_loss: 0.2058 - val_accuracy: 0.9116\n",
      "Epoch 640/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1836 - accuracy: 0.9203 - val_loss: 0.1824 - val_accuracy: 0.9205\n",
      "Epoch 641/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1724 - accuracy: 0.9242 - val_loss: 0.1830 - val_accuracy: 0.9209\n",
      "Epoch 642/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1731 - accuracy: 0.9238 - val_loss: 0.1904 - val_accuracy: 0.9183\n",
      "Epoch 643/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1813 - accuracy: 0.9214 - val_loss: 0.1810 - val_accuracy: 0.9210\n",
      "Epoch 644/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1773 - accuracy: 0.9233 - val_loss: 0.1848 - val_accuracy: 0.9218\n",
      "Epoch 645/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1770 - accuracy: 0.9234 - val_loss: 0.1793 - val_accuracy: 0.9223\n",
      "Epoch 646/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1897 - accuracy: 0.9189 - val_loss: 0.1925 - val_accuracy: 0.9175\n",
      "Epoch 647/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1925 - accuracy: 0.9171 - val_loss: 0.1874 - val_accuracy: 0.9185\n",
      "Epoch 648/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1942 - accuracy: 0.9168 - val_loss: 0.2197 - val_accuracy: 0.9070\n",
      "Epoch 649/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1874 - accuracy: 0.9188 - val_loss: 0.1879 - val_accuracy: 0.9196\n",
      "Epoch 650/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1742 - accuracy: 0.9238 - val_loss: 0.1978 - val_accuracy: 0.9140\n",
      "Epoch 651/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1801 - accuracy: 0.9221 - val_loss: 0.1935 - val_accuracy: 0.9145\n",
      "Epoch 652/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1796 - accuracy: 0.9209 - val_loss: 0.1783 - val_accuracy: 0.9244\n",
      "Epoch 653/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1717 - accuracy: 0.9245 - val_loss: 0.1795 - val_accuracy: 0.9235\n",
      "Epoch 654/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1774 - accuracy: 0.9224 - val_loss: 0.1870 - val_accuracy: 0.9211\n",
      "Epoch 655/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1857 - accuracy: 0.9190 - val_loss: 0.1786 - val_accuracy: 0.9218\n",
      "Epoch 656/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1742 - accuracy: 0.9235 - val_loss: 0.2032 - val_accuracy: 0.9137\n",
      "Epoch 657/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1868 - accuracy: 0.9188 - val_loss: 0.1968 - val_accuracy: 0.9179\n",
      "Epoch 658/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1725 - accuracy: 0.9246 - val_loss: 0.1866 - val_accuracy: 0.9183\n",
      "Epoch 659/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1781 - accuracy: 0.9214 - val_loss: 0.2081 - val_accuracy: 0.9140\n",
      "Epoch 660/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1817 - accuracy: 0.9218 - val_loss: 0.1895 - val_accuracy: 0.9185\n",
      "Epoch 661/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1786 - accuracy: 0.9226 - val_loss: 0.1890 - val_accuracy: 0.9188\n",
      "Epoch 662/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1924 - accuracy: 0.9174 - val_loss: 0.2039 - val_accuracy: 0.9158\n",
      "Epoch 663/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1826 - accuracy: 0.9218 - val_loss: 0.1910 - val_accuracy: 0.9185\n",
      "Epoch 664/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1886 - accuracy: 0.9202 - val_loss: 0.1829 - val_accuracy: 0.9222\n",
      "Epoch 665/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1884 - accuracy: 0.9190 - val_loss: 0.1885 - val_accuracy: 0.9176\n",
      "Epoch 666/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1817 - accuracy: 0.9212 - val_loss: 0.2040 - val_accuracy: 0.9176\n",
      "Epoch 667/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1883 - accuracy: 0.9189 - val_loss: 0.1899 - val_accuracy: 0.9197\n",
      "Epoch 668/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2000 - accuracy: 0.9154 - val_loss: 0.1989 - val_accuracy: 0.9166\n",
      "Epoch 669/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1834 - accuracy: 0.9201 - val_loss: 0.1851 - val_accuracy: 0.9210\n",
      "Epoch 670/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1775 - accuracy: 0.9229 - val_loss: 0.1988 - val_accuracy: 0.9178\n",
      "Epoch 671/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2089 - accuracy: 0.9122 - val_loss: 0.1889 - val_accuracy: 0.9180\n",
      "Epoch 672/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1800 - accuracy: 0.9214 - val_loss: 0.1873 - val_accuracy: 0.9187\n",
      "Epoch 673/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1741 - accuracy: 0.9240 - val_loss: 0.1825 - val_accuracy: 0.9202\n",
      "Epoch 674/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1866 - accuracy: 0.9196 - val_loss: 0.1960 - val_accuracy: 0.9170\n",
      "Epoch 675/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1790 - accuracy: 0.9219 - val_loss: 0.1850 - val_accuracy: 0.9185\n",
      "Epoch 676/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1779 - accuracy: 0.9224 - val_loss: 0.1964 - val_accuracy: 0.9179\n",
      "Epoch 677/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1806 - accuracy: 0.9212 - val_loss: 0.1835 - val_accuracy: 0.9209\n",
      "Epoch 678/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1822 - accuracy: 0.9216 - val_loss: 0.1861 - val_accuracy: 0.9209\n",
      "Epoch 679/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1800 - accuracy: 0.9219 - val_loss: 0.1995 - val_accuracy: 0.9155\n",
      "Epoch 680/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1831 - accuracy: 0.9205 - val_loss: 0.1873 - val_accuracy: 0.9202\n",
      "Epoch 681/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1785 - accuracy: 0.9230 - val_loss: 0.1935 - val_accuracy: 0.9174\n",
      "Epoch 682/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1813 - accuracy: 0.9210 - val_loss: 0.1918 - val_accuracy: 0.9175\n",
      "Epoch 683/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1794 - accuracy: 0.9218 - val_loss: 0.1869 - val_accuracy: 0.9198\n",
      "Epoch 684/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1741 - accuracy: 0.9235 - val_loss: 0.1895 - val_accuracy: 0.9185\n",
      "Epoch 685/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1709 - accuracy: 0.9248 - val_loss: 0.1959 - val_accuracy: 0.9174\n",
      "Epoch 686/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2084 - accuracy: 0.9135 - val_loss: 0.1996 - val_accuracy: 0.9156\n",
      "Epoch 687/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1876 - accuracy: 0.9191 - val_loss: 0.2170 - val_accuracy: 0.9081\n",
      "Epoch 688/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1909 - accuracy: 0.9176 - val_loss: 0.1837 - val_accuracy: 0.9193\n",
      "Epoch 689/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1802 - accuracy: 0.9215 - val_loss: 0.1794 - val_accuracy: 0.9228\n",
      "Epoch 690/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1741 - accuracy: 0.9237 - val_loss: 0.1771 - val_accuracy: 0.9217\n",
      "Epoch 691/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1824 - accuracy: 0.9202 - val_loss: 0.1814 - val_accuracy: 0.9223\n",
      "Epoch 692/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1827 - accuracy: 0.9207 - val_loss: 0.1941 - val_accuracy: 0.9162\n",
      "Epoch 693/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1736 - accuracy: 0.9245 - val_loss: 0.1981 - val_accuracy: 0.9157\n",
      "Epoch 694/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1843 - accuracy: 0.9199 - val_loss: 0.1752 - val_accuracy: 0.9261\n",
      "Epoch 695/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1750 - accuracy: 0.9241 - val_loss: 0.1961 - val_accuracy: 0.9157\n",
      "Epoch 696/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1716 - accuracy: 0.9245 - val_loss: 0.1841 - val_accuracy: 0.9217\n",
      "Epoch 697/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1790 - accuracy: 0.9228 - val_loss: 0.1752 - val_accuracy: 0.9247\n",
      "Epoch 698/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1862 - accuracy: 0.9192 - val_loss: 0.1808 - val_accuracy: 0.9239\n",
      "Epoch 699/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1716 - accuracy: 0.9240 - val_loss: 0.1795 - val_accuracy: 0.9225\n",
      "Epoch 700/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1719 - accuracy: 0.9245 - val_loss: 0.1859 - val_accuracy: 0.9184\n",
      "Epoch 701/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1771 - accuracy: 0.9225 - val_loss: 0.1836 - val_accuracy: 0.9227\n",
      "Epoch 702/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1862 - accuracy: 0.9198 - val_loss: 0.1928 - val_accuracy: 0.9179\n",
      "Epoch 703/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1745 - accuracy: 0.9241 - val_loss: 0.1865 - val_accuracy: 0.9191\n",
      "Epoch 704/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1856 - accuracy: 0.9199 - val_loss: 0.1869 - val_accuracy: 0.9188\n",
      "Epoch 705/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1827 - accuracy: 0.9210 - val_loss: 0.1837 - val_accuracy: 0.9212\n",
      "Epoch 706/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1799 - accuracy: 0.9221 - val_loss: 0.1883 - val_accuracy: 0.9202\n",
      "Epoch 707/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1703 - accuracy: 0.9255 - val_loss: 0.1757 - val_accuracy: 0.9242\n",
      "Epoch 708/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1718 - accuracy: 0.9246 - val_loss: 0.1858 - val_accuracy: 0.9178\n",
      "Epoch 709/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1863 - accuracy: 0.9200 - val_loss: 0.1965 - val_accuracy: 0.9151\n",
      "Epoch 710/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1820 - accuracy: 0.9207 - val_loss: 0.2054 - val_accuracy: 0.9127\n",
      "Epoch 711/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1786 - accuracy: 0.9219 - val_loss: 0.1866 - val_accuracy: 0.9177\n",
      "Epoch 712/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1721 - accuracy: 0.9250 - val_loss: 0.1881 - val_accuracy: 0.9203\n",
      "Epoch 713/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1831 - accuracy: 0.9205 - val_loss: 0.1815 - val_accuracy: 0.9205\n",
      "Epoch 714/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1811 - accuracy: 0.9204 - val_loss: 0.1837 - val_accuracy: 0.9216\n",
      "Epoch 715/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1753 - accuracy: 0.9226 - val_loss: 0.1849 - val_accuracy: 0.9208\n",
      "Epoch 716/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1732 - accuracy: 0.9237 - val_loss: 0.1833 - val_accuracy: 0.9203\n",
      "Epoch 717/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1855 - accuracy: 0.9197 - val_loss: 0.1855 - val_accuracy: 0.9185\n",
      "Epoch 718/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1831 - accuracy: 0.9210 - val_loss: 0.1784 - val_accuracy: 0.9236\n",
      "Epoch 719/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1730 - accuracy: 0.9243 - val_loss: 0.1812 - val_accuracy: 0.9228\n",
      "Epoch 720/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1799 - accuracy: 0.9222 - val_loss: 0.1932 - val_accuracy: 0.9178\n",
      "Epoch 721/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1816 - accuracy: 0.9205 - val_loss: 0.1982 - val_accuracy: 0.9140\n",
      "Epoch 722/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1793 - accuracy: 0.9216 - val_loss: 0.1936 - val_accuracy: 0.9160\n",
      "Epoch 723/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1786 - accuracy: 0.9229 - val_loss: 0.1930 - val_accuracy: 0.9183\n",
      "Epoch 724/1000\n",
      "87/87 [==============================] - 4s 48ms/step - loss: 0.1793 - accuracy: 0.9224 - val_loss: 0.1921 - val_accuracy: 0.9175\n",
      "Epoch 725/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1747 - accuracy: 0.9239 - val_loss: 0.1947 - val_accuracy: 0.9168\n",
      "Epoch 726/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1767 - accuracy: 0.9230 - val_loss: 0.1795 - val_accuracy: 0.9223\n",
      "Epoch 727/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1849 - accuracy: 0.9202 - val_loss: 0.2278 - val_accuracy: 0.9113\n",
      "Epoch 728/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1850 - accuracy: 0.9206 - val_loss: 0.1896 - val_accuracy: 0.9189\n",
      "Epoch 729/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1813 - accuracy: 0.9213 - val_loss: 0.1961 - val_accuracy: 0.9181\n",
      "Epoch 730/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1833 - accuracy: 0.9197 - val_loss: 0.2109 - val_accuracy: 0.9141\n",
      "Epoch 731/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1840 - accuracy: 0.9206 - val_loss: 0.1884 - val_accuracy: 0.9199\n",
      "Epoch 732/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1910 - accuracy: 0.9181 - val_loss: 0.1854 - val_accuracy: 0.9200\n",
      "Epoch 733/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1793 - accuracy: 0.9221 - val_loss: 0.1873 - val_accuracy: 0.9205\n",
      "Epoch 734/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1780 - accuracy: 0.9225 - val_loss: 0.1866 - val_accuracy: 0.9209\n",
      "Epoch 735/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1826 - accuracy: 0.9204 - val_loss: 0.1835 - val_accuracy: 0.9210\n",
      "Epoch 736/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1821 - accuracy: 0.9207 - val_loss: 0.1843 - val_accuracy: 0.9218\n",
      "Epoch 737/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1809 - accuracy: 0.9226 - val_loss: 0.2212 - val_accuracy: 0.9086\n",
      "Epoch 738/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1829 - accuracy: 0.9200 - val_loss: 0.1863 - val_accuracy: 0.9193\n",
      "Epoch 739/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1977 - accuracy: 0.9153 - val_loss: 0.1906 - val_accuracy: 0.9189\n",
      "Epoch 740/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1721 - accuracy: 0.9246 - val_loss: 0.1732 - val_accuracy: 0.9255\n",
      "Epoch 741/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1746 - accuracy: 0.9240 - val_loss: 0.1771 - val_accuracy: 0.9260\n",
      "Epoch 742/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1982 - accuracy: 0.9157 - val_loss: 0.1937 - val_accuracy: 0.9176\n",
      "Epoch 743/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1736 - accuracy: 0.9238 - val_loss: 0.2281 - val_accuracy: 0.9077\n",
      "Epoch 744/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1883 - accuracy: 0.9193 - val_loss: 0.2072 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1967 - accuracy: 0.9166 - val_loss: 0.1925 - val_accuracy: 0.9195\n",
      "Epoch 746/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1960 - accuracy: 0.9161 - val_loss: 0.1976 - val_accuracy: 0.9173\n",
      "Epoch 747/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1763 - accuracy: 0.9224 - val_loss: 0.1905 - val_accuracy: 0.9190\n",
      "Epoch 748/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1931 - accuracy: 0.9176 - val_loss: 0.1914 - val_accuracy: 0.9206\n",
      "Epoch 749/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1829 - accuracy: 0.9211 - val_loss: 0.1882 - val_accuracy: 0.9175\n",
      "Epoch 750/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1807 - accuracy: 0.9221 - val_loss: 0.1812 - val_accuracy: 0.9214\n",
      "Epoch 751/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1816 - accuracy: 0.9212 - val_loss: 0.2016 - val_accuracy: 0.9128\n",
      "Epoch 752/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1797 - accuracy: 0.9220 - val_loss: 0.1773 - val_accuracy: 0.9237\n",
      "Epoch 753/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1902 - accuracy: 0.9166 - val_loss: 0.1871 - val_accuracy: 0.9206\n",
      "Epoch 754/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1739 - accuracy: 0.9239 - val_loss: 0.1806 - val_accuracy: 0.9226\n",
      "Epoch 755/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1874 - accuracy: 0.9181 - val_loss: 0.1849 - val_accuracy: 0.9206\n",
      "Epoch 756/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1918 - accuracy: 0.9176 - val_loss: 0.2272 - val_accuracy: 0.9032\n",
      "Epoch 757/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1846 - accuracy: 0.9185 - val_loss: 0.1816 - val_accuracy: 0.9212\n",
      "Epoch 758/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1883 - accuracy: 0.9190 - val_loss: 0.1847 - val_accuracy: 0.9218\n",
      "Epoch 759/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1726 - accuracy: 0.9252 - val_loss: 0.1845 - val_accuracy: 0.9203\n",
      "Epoch 760/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1859 - accuracy: 0.9203 - val_loss: 0.1827 - val_accuracy: 0.9220\n",
      "Epoch 761/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1776 - accuracy: 0.9232 - val_loss: 0.2005 - val_accuracy: 0.9164\n",
      "Epoch 762/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1924 - accuracy: 0.9180 - val_loss: 0.1944 - val_accuracy: 0.9157\n",
      "Epoch 763/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1843 - accuracy: 0.9201 - val_loss: 0.1829 - val_accuracy: 0.9213\n",
      "Epoch 764/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1736 - accuracy: 0.9244 - val_loss: 0.1903 - val_accuracy: 0.9196\n",
      "Epoch 765/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1763 - accuracy: 0.9232 - val_loss: 0.1753 - val_accuracy: 0.9232\n",
      "Epoch 766/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1759 - accuracy: 0.9235 - val_loss: 0.1923 - val_accuracy: 0.9196\n",
      "Epoch 767/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1818 - accuracy: 0.9222 - val_loss: 0.1834 - val_accuracy: 0.9193\n",
      "Epoch 768/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1758 - accuracy: 0.9232 - val_loss: 0.2023 - val_accuracy: 0.9158\n",
      "Epoch 769/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1818 - accuracy: 0.9209 - val_loss: 0.1850 - val_accuracy: 0.9217\n",
      "Epoch 770/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1792 - accuracy: 0.9222 - val_loss: 0.2190 - val_accuracy: 0.9083\n",
      "Epoch 771/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1818 - accuracy: 0.9217 - val_loss: 0.1973 - val_accuracy: 0.9165\n",
      "Epoch 772/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2007 - accuracy: 0.9137 - val_loss: 0.2200 - val_accuracy: 0.9071\n",
      "Epoch 773/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1990 - accuracy: 0.9156 - val_loss: 0.1838 - val_accuracy: 0.9208\n",
      "Epoch 774/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1769 - accuracy: 0.9245 - val_loss: 0.1841 - val_accuracy: 0.9204\n",
      "Epoch 775/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1835 - accuracy: 0.9203 - val_loss: 0.1805 - val_accuracy: 0.9223\n",
      "Epoch 776/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1720 - accuracy: 0.9251 - val_loss: 0.1784 - val_accuracy: 0.9232\n",
      "Epoch 777/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1834 - accuracy: 0.9204 - val_loss: 0.1974 - val_accuracy: 0.9142\n",
      "Epoch 778/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1791 - accuracy: 0.9223 - val_loss: 0.1815 - val_accuracy: 0.9220\n",
      "Epoch 779/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1793 - accuracy: 0.9210 - val_loss: 0.2046 - val_accuracy: 0.9172\n",
      "Epoch 780/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1852 - accuracy: 0.9198 - val_loss: 0.1934 - val_accuracy: 0.9192\n",
      "Epoch 781/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1786 - accuracy: 0.9229 - val_loss: 0.1783 - val_accuracy: 0.9237\n",
      "Epoch 782/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1844 - accuracy: 0.9207 - val_loss: 0.1854 - val_accuracy: 0.9192\n",
      "Epoch 783/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1721 - accuracy: 0.9247 - val_loss: 0.1823 - val_accuracy: 0.9213\n",
      "Epoch 784/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1783 - accuracy: 0.9223 - val_loss: 0.1881 - val_accuracy: 0.9163\n",
      "Epoch 785/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1860 - accuracy: 0.9198 - val_loss: 0.2297 - val_accuracy: 0.9051\n",
      "Epoch 786/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1978 - accuracy: 0.9152 - val_loss: 0.1900 - val_accuracy: 0.9206\n",
      "Epoch 787/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1864 - accuracy: 0.9204 - val_loss: 0.2050 - val_accuracy: 0.9155\n",
      "Epoch 788/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1944 - accuracy: 0.9165 - val_loss: 0.1955 - val_accuracy: 0.9183\n",
      "Epoch 789/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1859 - accuracy: 0.9188 - val_loss: 0.1942 - val_accuracy: 0.9185\n",
      "Epoch 790/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1846 - accuracy: 0.9200 - val_loss: 0.1818 - val_accuracy: 0.9220\n",
      "Epoch 791/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.1872 - val_accuracy: 0.9219\n",
      "Epoch 792/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1864 - accuracy: 0.9195 - val_loss: 0.1786 - val_accuracy: 0.9234\n",
      "Epoch 793/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1810 - accuracy: 0.9217 - val_loss: 0.1815 - val_accuracy: 0.9221\n",
      "Epoch 794/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1882 - accuracy: 0.9185 - val_loss: 0.1902 - val_accuracy: 0.9197\n",
      "Epoch 795/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1863 - accuracy: 0.9193 - val_loss: 0.2136 - val_accuracy: 0.9111\n",
      "Epoch 796/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2036 - accuracy: 0.9131 - val_loss: 0.1910 - val_accuracy: 0.9184\n",
      "Epoch 797/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1816 - accuracy: 0.9220 - val_loss: 0.1856 - val_accuracy: 0.9206\n",
      "Epoch 798/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1820 - accuracy: 0.9210 - val_loss: 0.1859 - val_accuracy: 0.9201\n",
      "Epoch 799/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1857 - accuracy: 0.9196 - val_loss: 0.1878 - val_accuracy: 0.9203\n",
      "Epoch 800/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1793 - accuracy: 0.9219 - val_loss: 0.1841 - val_accuracy: 0.9209\n",
      "Epoch 801/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1761 - accuracy: 0.9226 - val_loss: 0.1890 - val_accuracy: 0.9210\n",
      "Epoch 802/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2009 - accuracy: 0.9157 - val_loss: 0.2072 - val_accuracy: 0.9131\n",
      "Epoch 803/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2055 - accuracy: 0.9139 - val_loss: 0.1978 - val_accuracy: 0.9179\n",
      "Epoch 804/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1847 - accuracy: 0.9203 - val_loss: 0.1850 - val_accuracy: 0.9209\n",
      "Epoch 805/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1827 - accuracy: 0.9209 - val_loss: 0.2084 - val_accuracy: 0.9130\n",
      "Epoch 806/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1805 - accuracy: 0.9214 - val_loss: 0.1910 - val_accuracy: 0.9183\n",
      "Epoch 807/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1879 - accuracy: 0.9192 - val_loss: 0.2110 - val_accuracy: 0.9072\n",
      "Epoch 808/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1755 - accuracy: 0.9222 - val_loss: 0.1884 - val_accuracy: 0.9177\n",
      "Epoch 809/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1825 - accuracy: 0.9206 - val_loss: 0.1843 - val_accuracy: 0.9187\n",
      "Epoch 810/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1795 - accuracy: 0.9221 - val_loss: 0.1866 - val_accuracy: 0.9198\n",
      "Epoch 811/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1755 - accuracy: 0.9226 - val_loss: 0.1922 - val_accuracy: 0.9190\n",
      "Epoch 812/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1856 - accuracy: 0.9201 - val_loss: 0.1980 - val_accuracy: 0.9157\n",
      "Epoch 813/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1950 - accuracy: 0.9172 - val_loss: 0.1953 - val_accuracy: 0.9178\n",
      "Epoch 814/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1887 - accuracy: 0.9194 - val_loss: 0.1996 - val_accuracy: 0.9132\n",
      "Epoch 815/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1890 - accuracy: 0.9185 - val_loss: 0.1930 - val_accuracy: 0.9176\n",
      "Epoch 816/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1907 - accuracy: 0.9186 - val_loss: 0.2066 - val_accuracy: 0.9131\n",
      "Epoch 817/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1817 - accuracy: 0.9214 - val_loss: 0.1858 - val_accuracy: 0.9196\n",
      "Epoch 818/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1747 - accuracy: 0.9237 - val_loss: 0.1849 - val_accuracy: 0.9199\n",
      "Epoch 819/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1719 - accuracy: 0.9260 - val_loss: 0.1840 - val_accuracy: 0.9195\n",
      "Epoch 820/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1875 - accuracy: 0.9184 - val_loss: 0.1839 - val_accuracy: 0.9204\n",
      "Epoch 821/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1734 - accuracy: 0.9240 - val_loss: 0.1861 - val_accuracy: 0.9187\n",
      "Epoch 822/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1777 - accuracy: 0.9225 - val_loss: 0.2055 - val_accuracy: 0.9122\n",
      "Epoch 823/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2075 - accuracy: 0.9151 - val_loss: 0.1975 - val_accuracy: 0.9173\n",
      "Epoch 824/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1796 - accuracy: 0.9224 - val_loss: 0.1834 - val_accuracy: 0.9208\n",
      "Epoch 825/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1788 - accuracy: 0.9228 - val_loss: 0.2006 - val_accuracy: 0.9150\n",
      "Epoch 826/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2005 - accuracy: 0.9150 - val_loss: 0.2009 - val_accuracy: 0.9116\n",
      "Epoch 827/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1989 - accuracy: 0.9160 - val_loss: 0.1972 - val_accuracy: 0.9161\n",
      "Epoch 828/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2006 - accuracy: 0.9152 - val_loss: 0.2375 - val_accuracy: 0.9034\n",
      "Epoch 829/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2005 - accuracy: 0.9154 - val_loss: 0.2199 - val_accuracy: 0.9066\n",
      "Epoch 830/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1855 - accuracy: 0.9197 - val_loss: 0.1929 - val_accuracy: 0.9174\n",
      "Epoch 831/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1772 - accuracy: 0.9231 - val_loss: 0.1814 - val_accuracy: 0.9221\n",
      "Epoch 832/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1786 - accuracy: 0.9223 - val_loss: 0.1963 - val_accuracy: 0.9160\n",
      "Epoch 833/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1718 - accuracy: 0.9237 - val_loss: 0.1781 - val_accuracy: 0.9232\n",
      "Epoch 834/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1716 - accuracy: 0.9244 - val_loss: 0.1851 - val_accuracy: 0.9206\n",
      "Epoch 835/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1916 - accuracy: 0.9183 - val_loss: 0.2018 - val_accuracy: 0.9147\n",
      "Epoch 836/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1862 - accuracy: 0.9189 - val_loss: 0.1802 - val_accuracy: 0.9225\n",
      "Epoch 837/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1800 - accuracy: 0.9223 - val_loss: 0.2071 - val_accuracy: 0.9133\n",
      "Epoch 838/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1880 - accuracy: 0.9188 - val_loss: 0.1945 - val_accuracy: 0.9183\n",
      "Epoch 839/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1786 - accuracy: 0.9222 - val_loss: 0.1913 - val_accuracy: 0.9185\n",
      "Epoch 840/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1723 - accuracy: 0.9250 - val_loss: 0.1836 - val_accuracy: 0.9202\n",
      "Epoch 841/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1962 - accuracy: 0.9177 - val_loss: 0.2646 - val_accuracy: 0.8969\n",
      "Epoch 842/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2261 - accuracy: 0.9069 - val_loss: 0.2195 - val_accuracy: 0.9073\n",
      "Epoch 843/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2337 - accuracy: 0.9024 - val_loss: 0.2753 - val_accuracy: 0.8896\n",
      "Epoch 844/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2232 - accuracy: 0.9062 - val_loss: 0.2224 - val_accuracy: 0.9064\n",
      "Epoch 845/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2116 - accuracy: 0.9109 - val_loss: 0.2125 - val_accuracy: 0.9119\n",
      "Epoch 846/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2005 - accuracy: 0.9152 - val_loss: 0.1962 - val_accuracy: 0.9165\n",
      "Epoch 847/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2052 - accuracy: 0.9135 - val_loss: 0.2117 - val_accuracy: 0.9101\n",
      "Epoch 848/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1900 - accuracy: 0.9184 - val_loss: 0.1882 - val_accuracy: 0.9192\n",
      "Epoch 849/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1831 - accuracy: 0.9214 - val_loss: 0.1936 - val_accuracy: 0.9172\n",
      "Epoch 850/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1918 - accuracy: 0.9184 - val_loss: 0.2144 - val_accuracy: 0.9095\n",
      "Epoch 851/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2042 - accuracy: 0.9142 - val_loss: 0.2040 - val_accuracy: 0.9152\n",
      "Epoch 852/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1964 - accuracy: 0.9168 - val_loss: 0.1874 - val_accuracy: 0.9203\n",
      "Epoch 853/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1920 - accuracy: 0.9170 - val_loss: 0.2304 - val_accuracy: 0.9035\n",
      "Epoch 854/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2028 - accuracy: 0.9129 - val_loss: 0.1915 - val_accuracy: 0.9180\n",
      "Epoch 855/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1837 - accuracy: 0.9197 - val_loss: 0.1928 - val_accuracy: 0.9166\n",
      "Epoch 856/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1795 - accuracy: 0.9219 - val_loss: 0.2027 - val_accuracy: 0.9134\n",
      "Epoch 857/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1861 - accuracy: 0.9196 - val_loss: 0.1963 - val_accuracy: 0.9160\n",
      "Epoch 858/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2144 - accuracy: 0.9109 - val_loss: 0.2298 - val_accuracy: 0.9063\n",
      "Epoch 859/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1981 - accuracy: 0.9162 - val_loss: 0.2015 - val_accuracy: 0.9143\n",
      "Epoch 860/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1985 - accuracy: 0.9159 - val_loss: 0.1877 - val_accuracy: 0.9207\n",
      "Epoch 861/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1820 - accuracy: 0.9210 - val_loss: 0.1848 - val_accuracy: 0.9208\n",
      "Epoch 862/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1840 - accuracy: 0.9219 - val_loss: 0.1836 - val_accuracy: 0.9218\n",
      "Epoch 863/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1819 - accuracy: 0.9229 - val_loss: 0.2093 - val_accuracy: 0.9133\n",
      "Epoch 864/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2052 - accuracy: 0.9150 - val_loss: 0.2165 - val_accuracy: 0.9096\n",
      "Epoch 865/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.3117 - accuracy: 0.8808 - val_loss: 0.2269 - val_accuracy: 0.9068\n",
      "Epoch 866/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2164 - accuracy: 0.9098 - val_loss: 0.2048 - val_accuracy: 0.9159\n",
      "Epoch 867/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2146 - accuracy: 0.9101 - val_loss: 0.2146 - val_accuracy: 0.9127\n",
      "Epoch 868/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2080 - accuracy: 0.9125 - val_loss: 0.2073 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2003 - accuracy: 0.9156 - val_loss: 0.1951 - val_accuracy: 0.9172\n",
      "Epoch 870/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2066 - accuracy: 0.9140 - val_loss: 0.2338 - val_accuracy: 0.9070\n",
      "Epoch 871/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2038 - accuracy: 0.9147 - val_loss: 0.1969 - val_accuracy: 0.9185\n",
      "Epoch 872/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2163 - accuracy: 0.9094 - val_loss: 0.2077 - val_accuracy: 0.9126\n",
      "Epoch 873/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1930 - accuracy: 0.9178 - val_loss: 0.2178 - val_accuracy: 0.9079\n",
      "Epoch 874/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1956 - accuracy: 0.9168 - val_loss: 0.1947 - val_accuracy: 0.9164\n",
      "Epoch 875/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2005 - accuracy: 0.9158 - val_loss: 0.2019 - val_accuracy: 0.9166\n",
      "Epoch 876/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.1979 - val_accuracy: 0.9171\n",
      "Epoch 877/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1902 - accuracy: 0.9193 - val_loss: 0.1932 - val_accuracy: 0.9201\n",
      "Epoch 878/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2014 - accuracy: 0.9145 - val_loss: 0.2150 - val_accuracy: 0.9111\n",
      "Epoch 879/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1924 - accuracy: 0.9179 - val_loss: 0.1885 - val_accuracy: 0.9191\n",
      "Epoch 880/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1785 - accuracy: 0.9230 - val_loss: 0.2039 - val_accuracy: 0.9144\n",
      "Epoch 881/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1887 - accuracy: 0.9199 - val_loss: 0.2276 - val_accuracy: 0.9068\n",
      "Epoch 882/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2182 - accuracy: 0.9107 - val_loss: 0.1845 - val_accuracy: 0.9208\n",
      "Epoch 883/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1806 - accuracy: 0.9212 - val_loss: 0.1862 - val_accuracy: 0.9211\n",
      "Epoch 884/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1769 - accuracy: 0.9235 - val_loss: 0.1890 - val_accuracy: 0.9204\n",
      "Epoch 885/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1847 - accuracy: 0.9209 - val_loss: 0.1924 - val_accuracy: 0.9173\n",
      "Epoch 886/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1770 - accuracy: 0.9236 - val_loss: 0.1887 - val_accuracy: 0.9189\n",
      "Epoch 887/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1915 - accuracy: 0.9181 - val_loss: 0.1934 - val_accuracy: 0.9178\n",
      "Epoch 888/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1997 - accuracy: 0.9156 - val_loss: 0.1883 - val_accuracy: 0.9196\n",
      "Epoch 889/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1837 - accuracy: 0.9210 - val_loss: 0.1930 - val_accuracy: 0.9172\n",
      "Epoch 890/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2025 - accuracy: 0.9140 - val_loss: 0.2099 - val_accuracy: 0.9125\n",
      "Epoch 891/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1941 - accuracy: 0.9175 - val_loss: 0.1990 - val_accuracy: 0.9155\n",
      "Epoch 892/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2058 - accuracy: 0.9139 - val_loss: 0.1975 - val_accuracy: 0.9160\n",
      "Epoch 893/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1964 - accuracy: 0.9168 - val_loss: 0.2042 - val_accuracy: 0.9158\n",
      "Epoch 894/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2029 - accuracy: 0.9149 - val_loss: 0.1990 - val_accuracy: 0.9143\n",
      "Epoch 895/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1935 - accuracy: 0.9176 - val_loss: 0.2034 - val_accuracy: 0.9166\n",
      "Epoch 896/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2062 - accuracy: 0.9129 - val_loss: 0.1897 - val_accuracy: 0.9194\n",
      "Epoch 897/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1963 - accuracy: 0.9165 - val_loss: 0.1959 - val_accuracy: 0.9176\n",
      "Epoch 898/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.1930 - val_accuracy: 0.9189\n",
      "Epoch 899/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1849 - accuracy: 0.9214 - val_loss: 0.1824 - val_accuracy: 0.9229\n",
      "Epoch 900/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1832 - accuracy: 0.9209 - val_loss: 0.2068 - val_accuracy: 0.9118\n",
      "Epoch 901/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1834 - accuracy: 0.9215 - val_loss: 0.1978 - val_accuracy: 0.9166\n",
      "Epoch 902/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1937 - accuracy: 0.9170 - val_loss: 0.2075 - val_accuracy: 0.9135\n",
      "Epoch 903/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1922 - accuracy: 0.9178 - val_loss: 0.1855 - val_accuracy: 0.9189\n",
      "Epoch 904/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1801 - accuracy: 0.9223 - val_loss: 0.1927 - val_accuracy: 0.9196\n",
      "Epoch 905/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1814 - accuracy: 0.9220 - val_loss: 0.2068 - val_accuracy: 0.9114\n",
      "Epoch 906/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1948 - accuracy: 0.9166 - val_loss: 0.1954 - val_accuracy: 0.9164\n",
      "Epoch 907/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1819 - accuracy: 0.9220 - val_loss: 0.1872 - val_accuracy: 0.9211\n",
      "Epoch 908/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2257 - accuracy: 0.9100 - val_loss: 0.3399 - val_accuracy: 0.8663\n",
      "Epoch 909/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.3031 - accuracy: 0.8822 - val_loss: 0.2439 - val_accuracy: 0.9035\n",
      "Epoch 910/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2553 - accuracy: 0.8972 - val_loss: 0.2278 - val_accuracy: 0.9075\n",
      "Epoch 911/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2216 - accuracy: 0.9094 - val_loss: 0.2137 - val_accuracy: 0.9121\n",
      "Epoch 912/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2139 - accuracy: 0.9117 - val_loss: 0.2253 - val_accuracy: 0.9061\n",
      "Epoch 913/1000\n",
      "87/87 [==============================] - 4s 48ms/step - loss: 0.2137 - accuracy: 0.9109 - val_loss: 0.2479 - val_accuracy: 0.9020\n",
      "Epoch 914/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2170 - accuracy: 0.9104 - val_loss: 0.2048 - val_accuracy: 0.9158\n",
      "Epoch 915/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2084 - accuracy: 0.9125 - val_loss: 0.2021 - val_accuracy: 0.9135\n",
      "Epoch 916/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2064 - accuracy: 0.9129 - val_loss: 0.2050 - val_accuracy: 0.9127\n",
      "Epoch 917/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1953 - accuracy: 0.9174 - val_loss: 0.2078 - val_accuracy: 0.9125\n",
      "Epoch 918/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1943 - accuracy: 0.9172 - val_loss: 0.2145 - val_accuracy: 0.9138\n",
      "Epoch 919/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1934 - accuracy: 0.9185 - val_loss: 0.2009 - val_accuracy: 0.9150\n",
      "Epoch 920/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1894 - accuracy: 0.9188 - val_loss: 0.2022 - val_accuracy: 0.9159\n",
      "Epoch 921/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2071 - accuracy: 0.9124 - val_loss: 0.1879 - val_accuracy: 0.9196\n",
      "Epoch 922/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1880 - accuracy: 0.9199 - val_loss: 0.1955 - val_accuracy: 0.9158\n",
      "Epoch 923/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2009 - accuracy: 0.9155 - val_loss: 0.2234 - val_accuracy: 0.9048\n",
      "Epoch 924/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1940 - accuracy: 0.9169 - val_loss: 0.1896 - val_accuracy: 0.9194\n",
      "Epoch 925/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1942 - accuracy: 0.9166 - val_loss: 0.1968 - val_accuracy: 0.9147\n",
      "Epoch 926/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1861 - accuracy: 0.9193 - val_loss: 0.1891 - val_accuracy: 0.9203\n",
      "Epoch 927/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1806 - accuracy: 0.9220 - val_loss: 0.1790 - val_accuracy: 0.9225\n",
      "Epoch 928/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1842 - accuracy: 0.9212 - val_loss: 0.2038 - val_accuracy: 0.9135\n",
      "Epoch 929/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1929 - accuracy: 0.9182 - val_loss: 0.1849 - val_accuracy: 0.9194\n",
      "Epoch 930/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1847 - accuracy: 0.9207 - val_loss: 0.1903 - val_accuracy: 0.9190\n",
      "Epoch 931/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2139 - accuracy: 0.9096 - val_loss: 0.2122 - val_accuracy: 0.9138\n",
      "Epoch 932/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1962 - accuracy: 0.9169 - val_loss: 0.1849 - val_accuracy: 0.9218\n",
      "Epoch 933/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1785 - accuracy: 0.9227 - val_loss: 0.1875 - val_accuracy: 0.9186\n",
      "Epoch 934/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1934 - accuracy: 0.9171 - val_loss: 0.1922 - val_accuracy: 0.9197\n",
      "Epoch 935/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1818 - accuracy: 0.9209 - val_loss: 0.1872 - val_accuracy: 0.9192\n",
      "Epoch 936/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1805 - accuracy: 0.9218 - val_loss: 0.1899 - val_accuracy: 0.9214\n",
      "Epoch 937/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1912 - accuracy: 0.9184 - val_loss: 0.1977 - val_accuracy: 0.9177\n",
      "Epoch 938/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1878 - accuracy: 0.9205 - val_loss: 0.1889 - val_accuracy: 0.9207\n",
      "Epoch 939/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1845 - accuracy: 0.9197 - val_loss: 0.1975 - val_accuracy: 0.9179\n",
      "Epoch 940/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1871 - accuracy: 0.9195 - val_loss: 0.2056 - val_accuracy: 0.9173\n",
      "Epoch 941/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2007 - accuracy: 0.9146 - val_loss: 0.2201 - val_accuracy: 0.9083\n",
      "Epoch 942/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1955 - accuracy: 0.9167 - val_loss: 0.2106 - val_accuracy: 0.9120\n",
      "Epoch 943/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2022 - accuracy: 0.9146 - val_loss: 0.2370 - val_accuracy: 0.9053\n",
      "Epoch 944/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.2044 - accuracy: 0.9146 - val_loss: 0.2145 - val_accuracy: 0.9128\n",
      "Epoch 945/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2076 - accuracy: 0.9111 - val_loss: 0.2190 - val_accuracy: 0.9131\n",
      "Epoch 946/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1991 - accuracy: 0.9154 - val_loss: 0.2175 - val_accuracy: 0.9112\n",
      "Epoch 947/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1912 - accuracy: 0.9194 - val_loss: 0.2008 - val_accuracy: 0.9158\n",
      "Epoch 948/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1982 - accuracy: 0.9157 - val_loss: 0.1913 - val_accuracy: 0.9179\n",
      "Epoch 949/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1934 - accuracy: 0.9169 - val_loss: 0.2153 - val_accuracy: 0.9110\n",
      "Epoch 950/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1897 - accuracy: 0.9184 - val_loss: 0.2044 - val_accuracy: 0.9154\n",
      "Epoch 951/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1848 - accuracy: 0.9201 - val_loss: 0.1862 - val_accuracy: 0.9218\n",
      "Epoch 952/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1902 - accuracy: 0.9185 - val_loss: 0.1984 - val_accuracy: 0.9150\n",
      "Epoch 953/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1851 - accuracy: 0.9204 - val_loss: 0.1886 - val_accuracy: 0.9202\n",
      "Epoch 954/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1894 - accuracy: 0.9185 - val_loss: 0.1960 - val_accuracy: 0.9178\n",
      "Epoch 955/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1811 - accuracy: 0.9216 - val_loss: 0.1890 - val_accuracy: 0.9195\n",
      "Epoch 956/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2108 - accuracy: 0.9136 - val_loss: 0.2954 - val_accuracy: 0.8891\n",
      "Epoch 957/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2496 - accuracy: 0.8981 - val_loss: 0.2155 - val_accuracy: 0.9106\n",
      "Epoch 958/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2149 - accuracy: 0.9098 - val_loss: 0.2209 - val_accuracy: 0.9111\n",
      "Epoch 959/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2214 - accuracy: 0.9082 - val_loss: 0.2147 - val_accuracy: 0.9117\n",
      "Epoch 960/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2164 - accuracy: 0.9089 - val_loss: 0.2094 - val_accuracy: 0.9137\n",
      "Epoch 961/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2159 - accuracy: 0.9110 - val_loss: 0.2126 - val_accuracy: 0.9138\n",
      "Epoch 962/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2024 - accuracy: 0.9146 - val_loss: 0.1988 - val_accuracy: 0.9164\n",
      "Epoch 963/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1996 - accuracy: 0.9157 - val_loss: 0.1882 - val_accuracy: 0.9208\n",
      "Epoch 964/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2038 - accuracy: 0.9137 - val_loss: 0.1934 - val_accuracy: 0.9186\n",
      "Epoch 965/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1996 - accuracy: 0.9163 - val_loss: 0.1983 - val_accuracy: 0.9169\n",
      "Epoch 966/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1920 - accuracy: 0.9183 - val_loss: 0.2066 - val_accuracy: 0.9134\n",
      "Epoch 967/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2029 - accuracy: 0.9129 - val_loss: 0.1950 - val_accuracy: 0.9180\n",
      "Epoch 968/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1851 - accuracy: 0.9202 - val_loss: 0.1986 - val_accuracy: 0.9165\n",
      "Epoch 969/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2053 - accuracy: 0.9130 - val_loss: 0.2090 - val_accuracy: 0.9090\n",
      "Epoch 970/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1921 - accuracy: 0.9176 - val_loss: 0.1935 - val_accuracy: 0.9175\n",
      "Epoch 971/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1809 - accuracy: 0.9224 - val_loss: 0.1840 - val_accuracy: 0.9204\n",
      "Epoch 972/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1835 - accuracy: 0.9199 - val_loss: 0.1865 - val_accuracy: 0.9193\n",
      "Epoch 973/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1924 - accuracy: 0.9179 - val_loss: 0.2199 - val_accuracy: 0.9080\n",
      "Epoch 974/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1986 - accuracy: 0.9153 - val_loss: 0.1971 - val_accuracy: 0.9168\n",
      "Epoch 975/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1935 - accuracy: 0.9174 - val_loss: 0.2193 - val_accuracy: 0.9088\n",
      "Epoch 976/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2050 - accuracy: 0.9124 - val_loss: 0.2076 - val_accuracy: 0.9136\n",
      "Epoch 977/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1921 - accuracy: 0.9171 - val_loss: 0.1978 - val_accuracy: 0.9145\n",
      "Epoch 978/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1892 - accuracy: 0.9183 - val_loss: 0.2060 - val_accuracy: 0.9134\n",
      "Epoch 979/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1923 - accuracy: 0.9176 - val_loss: 0.1920 - val_accuracy: 0.9178\n",
      "Epoch 980/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2021 - accuracy: 0.9148 - val_loss: 0.1959 - val_accuracy: 0.9179\n",
      "Epoch 981/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1947 - accuracy: 0.9169 - val_loss: 0.1847 - val_accuracy: 0.9200\n",
      "Epoch 982/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1906 - accuracy: 0.9188 - val_loss: 0.1928 - val_accuracy: 0.9181\n",
      "Epoch 983/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1887 - accuracy: 0.9190 - val_loss: 0.1978 - val_accuracy: 0.9150\n",
      "Epoch 984/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2077 - accuracy: 0.9128 - val_loss: 0.2085 - val_accuracy: 0.9130\n",
      "Epoch 985/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1934 - accuracy: 0.9177 - val_loss: 0.1971 - val_accuracy: 0.9157\n",
      "Epoch 986/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1835 - accuracy: 0.9193 - val_loss: 0.1958 - val_accuracy: 0.9170\n",
      "Epoch 987/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1895 - accuracy: 0.9183 - val_loss: 0.1929 - val_accuracy: 0.9177\n",
      "Epoch 988/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1893 - accuracy: 0.9185 - val_loss: 0.1851 - val_accuracy: 0.9214\n",
      "Epoch 989/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1909 - accuracy: 0.9177 - val_loss: 0.1899 - val_accuracy: 0.9191\n",
      "Epoch 990/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1959 - accuracy: 0.9169 - val_loss: 0.2112 - val_accuracy: 0.9138\n",
      "Epoch 991/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1932 - accuracy: 0.9172 - val_loss: 0.2021 - val_accuracy: 0.9143\n",
      "Epoch 992/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1978 - accuracy: 0.9161 - val_loss: 0.2064 - val_accuracy: 0.9130\n",
      "Epoch 993/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2034 - accuracy: 0.9135 - val_loss: 0.2186 - val_accuracy: 0.9092\n",
      "Epoch 994/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2004 - accuracy: 0.9160 - val_loss: 0.2232 - val_accuracy: 0.9080\n",
      "Epoch 995/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2006 - accuracy: 0.9144 - val_loss: 0.1927 - val_accuracy: 0.9173\n",
      "Epoch 996/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1856 - accuracy: 0.9210 - val_loss: 0.1957 - val_accuracy: 0.9180\n",
      "Epoch 997/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1983 - accuracy: 0.9170 - val_loss: 0.1907 - val_accuracy: 0.9203\n",
      "Epoch 998/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1815 - accuracy: 0.9222 - val_loss: 0.1907 - val_accuracy: 0.9195\n",
      "Epoch 999/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1961 - accuracy: 0.9154 - val_loss: 0.1951 - val_accuracy: 0.9167\n",
      "Epoch 1000/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1863 - accuracy: 0.9206 - val_loss: 0.1955 - val_accuracy: 0.9181\n",
      "108/108 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9170\n",
      "Test Loss: 0.1989\n",
      "Test Accuracy: 0.9170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 SimpleRNN 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = SimpleRNN(256, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/108 [>.............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9292 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeojung/.local/lib/python3.10/site-packages/keras/src/engine/functional.py:639: UserWarning: Input dict contained keys ['sequence_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9170\n",
      "Test Accuracy: 91.70\n",
      "Test Loss: 19.89\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, theta, phi, sequence):\n",
    "    loss, acc = model.evaluate({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, theta_test, phi_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeojung/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_SimpleRNN_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "Results saved to simpleRNN_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_simpleRNN'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'simpleRNN_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to simpleRNN_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sample 1:\n",
      "Theta    : [1.32549228]\n",
      "Phi      : [0.8657268]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 1 4 3 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 1 3 3]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [1.20255823]\n",
      "Phi      : [2.08703407]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 1 1 3 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 1 1 3 3]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [2.74902066]\n",
      "Phi      : [4.73903203]\n",
      "Actual   : [0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4]\n",
      "Predicted: [0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [2.721728]\n",
      "Phi      : [1.02688224]\n",
      "Actual   : [0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 3 2 3 4 4]\n",
      "Predicted: [0 0 0 1 0 0 4 4 1 1 3 3 3 2 2 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [0.29038208]\n",
      "Phi      : [2.89353153]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [0.3944755]\n",
      "Phi      : [3.62477968]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 2]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [1.67823594]\n",
      "Phi      : [6.11785498]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [2.74672106]\n",
      "Phi      : [4.15091791]\n",
      "Actual   : [0 0 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 1 1 0 3]\n",
      "Predicted: [0 0 2 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 4 3 1 2 3]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [0.68681928]\n",
      "Phi      : [0.35208133]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 1 1 3 3 2 4 1 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 1 1 3 3 2 4 4 1 3]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [2.41822435]\n",
      "Phi      : [1.74695627]\n",
      "Actual   : [0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 3 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
