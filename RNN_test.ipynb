{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, SimpleRNN, Dense, Flatten, RepeatVector, Concatenate, TimeDistributed\n",
    "\n",
    "# 가상의 데이터 생성\n",
    "# 데이터의 형태는 실제 데이터셋에 따라 조정되어야 합니다.\n",
    "num_samples = 1000\n",
    "max_seq_length = 10\n",
    "theta = np.random.rand(num_samples, 1) * 2 * np.pi\n",
    "phi = np.random.rand(num_samples, 1) * 2 * np.pi\n",
    "sequence = np.random.randint(5, size=(num_samples, max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각을 독립적인 입력으로 처리\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "sequence_input = Input(shape=(max_seq_length,), name='sequence_input')\n",
    "\n",
    "# theta와 phi를 시퀀스의 각 타임스텝에 반복\n",
    "theta_repeated = RepeatVector(max_seq_length)(theta_input)\n",
    "phi_repeated = RepeatVector(max_seq_length)(phi_input)\n",
    "\n",
    "# 시퀀스 임베딩\n",
    "sequence_embedding = Embedding(5, 32, input_length=max_seq_length)(sequence_input)\n",
    "\n",
    "# 입력들을 합침\n",
    "concat_layer = Concatenate()([theta_repeated, phi_repeated, sequence_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 레이어\n",
    "rnn_layer = SimpleRNN(32, return_sequences=True)(concat_layer)\n",
    "\n",
    "# 출력 레이어\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(rnn_layer)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=[theta_input, phi_input, sequence_input], outputs=output)\n",
    "\n",
    "# 모델 학습\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1), epochs=10, validation_split=0.2)\n",
    "\n",
    "# 새로운 theta와 phi 값에 대한 리스트 예측\n",
    "new_theta = np.array([[0.5]])\n",
    "new_phi = np.array([[0.5]])\n",
    "new_sequence = np.zeros((1, max_seq_length))  # 초기 시퀀스는 0으로 설정\n",
    "predicted_sequence = model.predict({'theta_input': new_theta, 'phi_input': new_phi, 'sequence_input': new_sequence})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9740461  0.00150249 0.00283895 0.01172099 0.00989156]\n",
      "  [0.97008383 0.00176454 0.00280468 0.01278157 0.01256536]\n",
      "  [0.97046465 0.00215553 0.00204273 0.01330278 0.01203432]\n",
      "  [0.97573686 0.00154915 0.00209132 0.01182453 0.00879812]\n",
      "  [0.97263134 0.00177073 0.00224956 0.01358771 0.00976066]\n",
      "  [0.9699743  0.00179466 0.00233559 0.01333149 0.01256401]\n",
      "  [0.96921283 0.00174713 0.00245519 0.01340958 0.01317524]\n",
      "  [0.96838456 0.00177329 0.00252713 0.01274544 0.01456957]\n",
      "  [0.9679192  0.00183257 0.00249692 0.01215918 0.01559203]\n",
      "  [0.9679409  0.00191405 0.00246025 0.01212933 0.01555538]]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 16ms/step - loss: 1.7247 - accuracy: 0.2138 - val_loss: 1.4150 - val_accuracy: 0.3699\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2979 - accuracy: 0.4916 - val_loss: 1.1453 - val_accuracy: 0.5563\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0139 - accuracy: 0.6434 - val_loss: 0.8280 - val_accuracy: 0.7586\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6950 - accuracy: 0.8454 - val_loss: 0.5239 - val_accuracy: 0.9176\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9256 - val_loss: 0.3131 - val_accuracy: 0.9464\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.9510 - val_loss: 0.2104 - val_accuracy: 0.9589\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1869 - accuracy: 0.9646 - val_loss: 0.1540 - val_accuracy: 0.9721\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9759 - val_loss: 0.1171 - val_accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9848 - val_loss: 0.0915 - val_accuracy: 0.9886\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9912 - val_loss: 0.0719 - val_accuracy: 0.9914\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 2 2 4 4 1 1 3 2 2 0 0 4 3]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 2 2 4 4 1 1 3 2 2 4 0 4 3]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 3 2 2 4 1 1 1 2]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 3 2 2 4 1 1 1 2]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 0 4]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 0 2]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 3 2 2 4 1 1 3 3]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1 3 3 2 2 4 1 1 3 3]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 1 3 3 2 4 1 1 3 3 2 2 4 4 1 3 3 2 2 2 4 4 1]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 1 3 3 2 4 1 1 3 3 2 2 4 4 1 3 3 2 2 4 4 4 1]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 2 1 0]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 3 2 2 4 1 1]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "True sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1]\n",
      "Predicted sequence: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Embedding, RepeatVector, Concatenate, TimeDistributed\n",
    "\n",
    "# CSV 파일에서 데이터 읽기\n",
    "df = pd.read_csv('ByAstar_20230627_093742.csv')\n",
    "\n",
    "# theta, phi 값 불러오기\n",
    "theta = df['Theta'].values.reshape(-1, 1)\n",
    "phi = df['Phi'].values.reshape(-1, 1)\n",
    "\n",
    "# sequence를 리스트로 변환\n",
    "sequence = df['combination'].apply(eval).to_list()\n",
    "\n",
    "# 시퀀스의 최대 길이 계산\n",
    "max_seq_length = max(len(seq) for seq in sequence)\n",
    "\n",
    "# 시퀀스를 동일한 길이로 패딩\n",
    "sequence_padded = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_seq_length)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "theta_train, theta_test, phi_train, phi_test, sequence_train, sequence_test = train_test_split(theta, phi, sequence_padded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 입력 레이어 생성\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "sequence_input = Input(shape=(max_seq_length,), name='sequence_input')\n",
    "\n",
    "# theta와 phi를 시퀀스의 각 타임스텝에 반복\n",
    "theta_repeated = RepeatVector(max_seq_length)(theta_input)\n",
    "phi_repeated = RepeatVector(max_seq_length)(phi_input)\n",
    "\n",
    "# 시퀀스 임베딩\n",
    "sequence_embedding = Embedding(5, 32, input_length=max_seq_length)(sequence_input)\n",
    "\n",
    "# 입력들을 합침\n",
    "concat_layer = Concatenate()([theta_repeated, phi_repeated, sequence_embedding])\n",
    "\n",
    "# RNN 레이어\n",
    "rnn_layer = SimpleRNN(32, return_sequences=True)(concat_layer)\n",
    "\n",
    "# 출력 레이어\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(rnn_layer)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=[theta_input, phi_input, sequence_input], outputs=output)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit({'theta_input': theta_train, 'phi_input': phi_train, 'sequence_input': sequence_train}, np.expand_dims(sequence_train, -1), epochs=10, validation_data=({'theta_input': theta_test, 'phi_input': phi_test, 'sequence_input': sequence_test}, np.expand_dims(sequence_test, -1)))\n",
    "\n",
    "# 테스트 세트에 대한 리스트 예측\n",
    "predicted_sequence = model.predict({'theta_input': theta_test, 'phi_input': phi_test, 'sequence_input': sequence_test})\n",
    "\n",
    "# 첫 5개의 예측된 시퀀스 출력\n",
    "for i in range(10):\n",
    "    print(f\"True sequence: {sequence_test[i]}\")\n",
    "    print(f\"Predicted sequence: {np.argmax(predicted_sequence[i], axis=1)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
