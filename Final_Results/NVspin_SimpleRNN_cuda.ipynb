{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Concatenate, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../Data/using/dt_2.6/ByAstar_dt_2.6_modified.csv')\n",
    "\n",
    "df = df.dropna(subset=['combination'])\n",
    "\n",
    "# 데이터셋 분리: train_set 8 : test_set 2\n",
    "train_df, test_df = train_test_split(df, shuffle=True, test_size=0.2)\n",
    "# train_set을 다시 8:2로 나눠서 train_set과 validation_set을 만듦\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=0.2)\n",
    "# random_state=42\n",
    "\n",
    "# 모든 시퀀스의 길이 중에서 최대 길이를 구하기\n",
    "all_sequences = [eval(str(seq)) for seq in df['combination'].values]\n",
    "max_seq_length = max([len(seq) for seq in all_sequences])\n",
    "\n",
    "# 각 데이터셋에서 theta, phi, sequence 추출하고 reshape 적용\n",
    "theta_train = train_df['Theta'].values.reshape(-1, 1)\n",
    "phi_train = train_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_train = pad_sequences(train_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_val = val_df['Theta'].values.reshape(-1, 1)\n",
    "phi_val = val_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_val = pad_sequences(val_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "theta_test = test_df['Theta'].values.reshape(-1, 1)\n",
    "phi_test = test_df['Phi'].values.reshape(-1, 1)\n",
    "sequence_test = pad_sequences(test_df['combination'].apply(eval).tolist(), maxlen=max_seq_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "87/87 [==============================] - 7s 68ms/step - loss: 0.9950 - accuracy: 0.5593 - val_loss: 0.8661 - val_accuracy: 0.5947\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 6s 66ms/step - loss: 0.7282 - accuracy: 0.6823 - val_loss: 0.4821 - val_accuracy: 0.8211\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 6s 65ms/step - loss: 0.4484 - accuracy: 0.8348 - val_loss: 0.4254 - val_accuracy: 0.8406\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 6s 67ms/step - loss: 0.4095 - accuracy: 0.8490 - val_loss: 0.4025 - val_accuracy: 0.8464\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 6s 68ms/step - loss: 0.4301 - accuracy: 0.8410 - val_loss: 0.3732 - val_accuracy: 0.8661\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3864 - accuracy: 0.8624 - val_loss: 0.3643 - val_accuracy: 0.8721\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 6s 66ms/step - loss: 0.3622 - accuracy: 0.8741 - val_loss: 0.4268 - val_accuracy: 0.8483\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3837 - accuracy: 0.8618 - val_loss: 0.3363 - val_accuracy: 0.8840\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3497 - accuracy: 0.8737 - val_loss: 0.3799 - val_accuracy: 0.8660\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.3395 - accuracy: 0.8773 - val_loss: 0.3043 - val_accuracy: 0.8882\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 6s 68ms/step - loss: 0.3534 - accuracy: 0.8743 - val_loss: 0.3714 - val_accuracy: 0.8644\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 6s 67ms/step - loss: 0.3397 - accuracy: 0.8765 - val_loss: 0.3161 - val_accuracy: 0.8834\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 6s 66ms/step - loss: 0.3154 - accuracy: 0.8852 - val_loss: 0.3399 - val_accuracy: 0.8719\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 6s 68ms/step - loss: 0.3313 - accuracy: 0.8777 - val_loss: 0.3125 - val_accuracy: 0.8844\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3100 - accuracy: 0.8857 - val_loss: 0.3269 - val_accuracy: 0.8786\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 6s 65ms/step - loss: 0.3091 - accuracy: 0.8837 - val_loss: 0.4505 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.3161 - accuracy: 0.8815 - val_loss: 0.2650 - val_accuracy: 0.9033\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.3070 - accuracy: 0.8851 - val_loss: 0.2662 - val_accuracy: 0.9001\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3002 - accuracy: 0.8856 - val_loss: 0.2862 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 6s 67ms/step - loss: 0.2913 - accuracy: 0.8893 - val_loss: 0.3172 - val_accuracy: 0.8853\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.3051 - accuracy: 0.8840 - val_loss: 0.2784 - val_accuracy: 0.8951\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 5s 62ms/step - loss: 0.2956 - accuracy: 0.8874 - val_loss: 0.3266 - val_accuracy: 0.8686\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.2891 - accuracy: 0.8897 - val_loss: 0.3094 - val_accuracy: 0.8781\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 5s 62ms/step - loss: 0.2920 - accuracy: 0.8880 - val_loss: 0.2689 - val_accuracy: 0.8982\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 5s 60ms/step - loss: 0.2869 - accuracy: 0.8892 - val_loss: 0.3627 - val_accuracy: 0.8588\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.3041 - accuracy: 0.8836 - val_loss: 0.2651 - val_accuracy: 0.8994\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 5s 60ms/step - loss: 0.2918 - accuracy: 0.8871 - val_loss: 0.2774 - val_accuracy: 0.8945\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 5s 62ms/step - loss: 0.2801 - accuracy: 0.8906 - val_loss: 0.2622 - val_accuracy: 0.8973\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 5s 63ms/step - loss: 0.2692 - accuracy: 0.8953 - val_loss: 0.3020 - val_accuracy: 0.8830\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 6s 67ms/step - loss: 0.2723 - accuracy: 0.8934 - val_loss: 0.3410 - val_accuracy: 0.8644\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 6s 65ms/step - loss: 0.2846 - accuracy: 0.8899 - val_loss: 0.3061 - val_accuracy: 0.8773\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 5s 52ms/step - loss: 0.2675 - accuracy: 0.8947 - val_loss: 0.2442 - val_accuracy: 0.9056\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.2646 - accuracy: 0.8955 - val_loss: 0.3044 - val_accuracy: 0.8809\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.2694 - accuracy: 0.8930 - val_loss: 0.2420 - val_accuracy: 0.9047\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2664 - accuracy: 0.8942 - val_loss: 0.3086 - val_accuracy: 0.8741\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2782 - accuracy: 0.8906 - val_loss: 0.2603 - val_accuracy: 0.8998\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2727 - accuracy: 0.8923 - val_loss: 0.2671 - val_accuracy: 0.8922\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2897 - accuracy: 0.8855 - val_loss: 0.2490 - val_accuracy: 0.9062\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2733 - accuracy: 0.8921 - val_loss: 0.2720 - val_accuracy: 0.8955\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2621 - accuracy: 0.8946 - val_loss: 0.2548 - val_accuracy: 0.8998\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2712 - accuracy: 0.8925 - val_loss: 0.3066 - val_accuracy: 0.8770\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2645 - accuracy: 0.8943 - val_loss: 0.2787 - val_accuracy: 0.8931\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2821 - accuracy: 0.8884 - val_loss: 0.2324 - val_accuracy: 0.9088\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2539 - accuracy: 0.8989 - val_loss: 0.2793 - val_accuracy: 0.8887\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2598 - accuracy: 0.8960 - val_loss: 0.2267 - val_accuracy: 0.9080\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2473 - accuracy: 0.9010 - val_loss: 0.2687 - val_accuracy: 0.9018\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2688 - accuracy: 0.8928 - val_loss: 0.2653 - val_accuracy: 0.8952\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2581 - accuracy: 0.8967 - val_loss: 0.2830 - val_accuracy: 0.8902\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2635 - accuracy: 0.8945 - val_loss: 0.2638 - val_accuracy: 0.9002\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2553 - accuracy: 0.8973 - val_loss: 0.2557 - val_accuracy: 0.9001\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2522 - accuracy: 0.8972 - val_loss: 0.2413 - val_accuracy: 0.9035\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2536 - accuracy: 0.8981 - val_loss: 0.2826 - val_accuracy: 0.8852\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2528 - accuracy: 0.8978 - val_loss: 0.2591 - val_accuracy: 0.8984\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2492 - accuracy: 0.8995 - val_loss: 0.2832 - val_accuracy: 0.8909\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2577 - accuracy: 0.8952 - val_loss: 0.2319 - val_accuracy: 0.9063\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2578 - accuracy: 0.8963 - val_loss: 0.2203 - val_accuracy: 0.9127\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2400 - accuracy: 0.9021 - val_loss: 0.2341 - val_accuracy: 0.9082\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2492 - accuracy: 0.8989 - val_loss: 0.2665 - val_accuracy: 0.8964\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2519 - accuracy: 0.8980 - val_loss: 0.2621 - val_accuracy: 0.8925\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2561 - accuracy: 0.8957 - val_loss: 0.2322 - val_accuracy: 0.9053\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2467 - accuracy: 0.8999 - val_loss: 0.2287 - val_accuracy: 0.9081\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2493 - accuracy: 0.8986 - val_loss: 0.2436 - val_accuracy: 0.9018\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2482 - accuracy: 0.8995 - val_loss: 0.2387 - val_accuracy: 0.9042\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2493 - accuracy: 0.8986 - val_loss: 0.2600 - val_accuracy: 0.8972\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2677 - accuracy: 0.8921 - val_loss: 0.2486 - val_accuracy: 0.9028\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2464 - accuracy: 0.8995 - val_loss: 0.2541 - val_accuracy: 0.8983\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2402 - accuracy: 0.9015 - val_loss: 0.2464 - val_accuracy: 0.9017\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2521 - accuracy: 0.8969 - val_loss: 0.2587 - val_accuracy: 0.8960\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2497 - accuracy: 0.8977 - val_loss: 0.2155 - val_accuracy: 0.9145\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2339 - accuracy: 0.9037 - val_loss: 0.2250 - val_accuracy: 0.9090\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2377 - accuracy: 0.9027 - val_loss: 0.2396 - val_accuracy: 0.9040\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2615 - accuracy: 0.8950 - val_loss: 0.3026 - val_accuracy: 0.8804\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2443 - accuracy: 0.9007 - val_loss: 0.2659 - val_accuracy: 0.8975\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2410 - accuracy: 0.9007 - val_loss: 0.2232 - val_accuracy: 0.9079\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2352 - accuracy: 0.9035 - val_loss: 0.2414 - val_accuracy: 0.9034\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2318 - accuracy: 0.9036 - val_loss: 0.2197 - val_accuracy: 0.9105\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2372 - accuracy: 0.9018 - val_loss: 0.2215 - val_accuracy: 0.9095\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2437 - accuracy: 0.8997 - val_loss: 0.3011 - val_accuracy: 0.8818\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2479 - accuracy: 0.8988 - val_loss: 0.2426 - val_accuracy: 0.9048\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2359 - accuracy: 0.9024 - val_loss: 0.2269 - val_accuracy: 0.9078\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2351 - accuracy: 0.9032 - val_loss: 0.2194 - val_accuracy: 0.9077\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2383 - accuracy: 0.9016 - val_loss: 0.2099 - val_accuracy: 0.9137\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2385 - accuracy: 0.9015 - val_loss: 0.2283 - val_accuracy: 0.9071\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2311 - accuracy: 0.9044 - val_loss: 0.2287 - val_accuracy: 0.9070\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2411 - accuracy: 0.9007 - val_loss: 0.2579 - val_accuracy: 0.8976\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2374 - accuracy: 0.9014 - val_loss: 0.2171 - val_accuracy: 0.9129\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2268 - accuracy: 0.9059 - val_loss: 0.2318 - val_accuracy: 0.9064\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2409 - accuracy: 0.9011 - val_loss: 0.2518 - val_accuracy: 0.8974\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2316 - accuracy: 0.9041 - val_loss: 0.2191 - val_accuracy: 0.9093\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2349 - accuracy: 0.9026 - val_loss: 0.2420 - val_accuracy: 0.9016\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2439 - accuracy: 0.8994 - val_loss: 0.2425 - val_accuracy: 0.9020\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2365 - accuracy: 0.9022 - val_loss: 0.2318 - val_accuracy: 0.9064\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2370 - accuracy: 0.9025 - val_loss: 0.2301 - val_accuracy: 0.9059\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2297 - accuracy: 0.9038 - val_loss: 0.2180 - val_accuracy: 0.9118\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2337 - accuracy: 0.9022 - val_loss: 0.2140 - val_accuracy: 0.9139\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2399 - accuracy: 0.9012 - val_loss: 0.2543 - val_accuracy: 0.8971\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2415 - accuracy: 0.9013 - val_loss: 0.2076 - val_accuracy: 0.9161\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2273 - accuracy: 0.9050 - val_loss: 0.2245 - val_accuracy: 0.9087\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2344 - accuracy: 0.9025 - val_loss: 0.2278 - val_accuracy: 0.9071\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2324 - accuracy: 0.9034 - val_loss: 0.2497 - val_accuracy: 0.8970\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2258 - accuracy: 0.9046 - val_loss: 0.2237 - val_accuracy: 0.9076\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2248 - accuracy: 0.9065 - val_loss: 0.2213 - val_accuracy: 0.9083\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2266 - accuracy: 0.9048 - val_loss: 0.2285 - val_accuracy: 0.9125\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2347 - accuracy: 0.9021 - val_loss: 0.2334 - val_accuracy: 0.9049\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2227 - accuracy: 0.9060 - val_loss: 0.2637 - val_accuracy: 0.8921\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2416 - accuracy: 0.9005 - val_loss: 0.2105 - val_accuracy: 0.9150\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2213 - accuracy: 0.9067 - val_loss: 0.2126 - val_accuracy: 0.9120\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2330 - accuracy: 0.9036 - val_loss: 0.2568 - val_accuracy: 0.8928\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2447 - accuracy: 0.8980 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2264 - accuracy: 0.9053 - val_loss: 0.2242 - val_accuracy: 0.9108\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2312 - accuracy: 0.9034 - val_loss: 0.2258 - val_accuracy: 0.9114\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2252 - accuracy: 0.9061 - val_loss: 0.2077 - val_accuracy: 0.9141\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2239 - accuracy: 0.9058 - val_loss: 0.2218 - val_accuracy: 0.9100\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2241 - accuracy: 0.9062 - val_loss: 0.2275 - val_accuracy: 0.9083\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2336 - accuracy: 0.9027 - val_loss: 0.2396 - val_accuracy: 0.9011\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2230 - accuracy: 0.9070 - val_loss: 0.2168 - val_accuracy: 0.9072\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2240 - accuracy: 0.9055 - val_loss: 0.2293 - val_accuracy: 0.9078\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2179 - accuracy: 0.9081 - val_loss: 0.2804 - val_accuracy: 0.8865\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2259 - accuracy: 0.9053 - val_loss: 0.2090 - val_accuracy: 0.9152\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2254 - accuracy: 0.9064 - val_loss: 0.1999 - val_accuracy: 0.9155\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2187 - accuracy: 0.9078 - val_loss: 0.2320 - val_accuracy: 0.9099\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2303 - accuracy: 0.9045 - val_loss: 0.2496 - val_accuracy: 0.8967\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2376 - accuracy: 0.9023 - val_loss: 0.2515 - val_accuracy: 0.9018\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2169 - accuracy: 0.9089 - val_loss: 0.1998 - val_accuracy: 0.9168\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2248 - accuracy: 0.9055 - val_loss: 0.1965 - val_accuracy: 0.9183\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2181 - accuracy: 0.9076 - val_loss: 0.2053 - val_accuracy: 0.9142\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2220 - accuracy: 0.9069 - val_loss: 0.2141 - val_accuracy: 0.9142\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2145 - accuracy: 0.9099 - val_loss: 0.2538 - val_accuracy: 0.8935\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2259 - accuracy: 0.9054 - val_loss: 0.2074 - val_accuracy: 0.9145\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2273 - accuracy: 0.9053 - val_loss: 0.2432 - val_accuracy: 0.9043\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2195 - accuracy: 0.9075 - val_loss: 0.2075 - val_accuracy: 0.9145\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2250 - accuracy: 0.9053 - val_loss: 0.2022 - val_accuracy: 0.9184\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2222 - accuracy: 0.9063 - val_loss: 0.2369 - val_accuracy: 0.9062\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2178 - accuracy: 0.9079 - val_loss: 0.2243 - val_accuracy: 0.9107\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2212 - accuracy: 0.9066 - val_loss: 0.2142 - val_accuracy: 0.9107\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2238 - accuracy: 0.9067 - val_loss: 0.2000 - val_accuracy: 0.9157\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2186 - accuracy: 0.9082 - val_loss: 0.2291 - val_accuracy: 0.9073\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2224 - accuracy: 0.9068 - val_loss: 0.2113 - val_accuracy: 0.9124\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2249 - accuracy: 0.9049 - val_loss: 0.2314 - val_accuracy: 0.9043\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2329 - accuracy: 0.9031 - val_loss: 0.2188 - val_accuracy: 0.9115\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2177 - accuracy: 0.9078 - val_loss: 0.2394 - val_accuracy: 0.9060\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2111 - accuracy: 0.9101 - val_loss: 0.2129 - val_accuracy: 0.9128\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2181 - accuracy: 0.9081 - val_loss: 0.2359 - val_accuracy: 0.9030\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2235 - accuracy: 0.9056 - val_loss: 0.2244 - val_accuracy: 0.9098\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2179 - accuracy: 0.9075 - val_loss: 0.2342 - val_accuracy: 0.9082\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2136 - accuracy: 0.9088 - val_loss: 0.2154 - val_accuracy: 0.9128\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2112 - accuracy: 0.9098 - val_loss: 0.2309 - val_accuracy: 0.9059\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2142 - accuracy: 0.9090 - val_loss: 0.2094 - val_accuracy: 0.9129\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2283 - accuracy: 0.9038 - val_loss: 0.2350 - val_accuracy: 0.9005\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2219 - accuracy: 0.9064 - val_loss: 0.2078 - val_accuracy: 0.9136\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2101 - accuracy: 0.9104 - val_loss: 0.2207 - val_accuracy: 0.9117\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2080 - accuracy: 0.9104 - val_loss: 0.1999 - val_accuracy: 0.9189\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2061 - accuracy: 0.9123 - val_loss: 0.2083 - val_accuracy: 0.9157\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2186 - accuracy: 0.9078 - val_loss: 0.2188 - val_accuracy: 0.9103\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.2090 - val_accuracy: 0.9126\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2071 - accuracy: 0.9105 - val_loss: 0.1959 - val_accuracy: 0.9182\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2117 - accuracy: 0.9100 - val_loss: 0.2126 - val_accuracy: 0.9119\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2219 - accuracy: 0.9065 - val_loss: 0.2231 - val_accuracy: 0.9091\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2123 - accuracy: 0.9090 - val_loss: 0.2022 - val_accuracy: 0.9151\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2031 - accuracy: 0.9135 - val_loss: 0.2154 - val_accuracy: 0.9107\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2107 - accuracy: 0.9103 - val_loss: 0.2168 - val_accuracy: 0.9098\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2178 - accuracy: 0.9073 - val_loss: 0.2194 - val_accuracy: 0.9088\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2055 - accuracy: 0.9118 - val_loss: 0.1989 - val_accuracy: 0.9169\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2106 - accuracy: 0.9099 - val_loss: 0.2045 - val_accuracy: 0.9153\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2216 - accuracy: 0.9071 - val_loss: 0.2391 - val_accuracy: 0.9004\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2152 - accuracy: 0.9085 - val_loss: 0.2223 - val_accuracy: 0.9091\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2204 - accuracy: 0.9067 - val_loss: 0.2098 - val_accuracy: 0.9134\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2043 - accuracy: 0.9125 - val_loss: 0.2078 - val_accuracy: 0.9161\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2151 - accuracy: 0.9081 - val_loss: 0.1921 - val_accuracy: 0.9190\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2149 - accuracy: 0.9087 - val_loss: 0.1965 - val_accuracy: 0.9181\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2150 - accuracy: 0.9082 - val_loss: 0.2038 - val_accuracy: 0.9154\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2136 - accuracy: 0.9091 - val_loss: 0.2355 - val_accuracy: 0.9046\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2069 - accuracy: 0.9123 - val_loss: 0.2139 - val_accuracy: 0.9128\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 4s 41ms/step - loss: 0.2097 - accuracy: 0.9110 - val_loss: 0.2427 - val_accuracy: 0.9029\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2066 - accuracy: 0.9113 - val_loss: 0.2282 - val_accuracy: 0.9070\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2084 - accuracy: 0.9111 - val_loss: 0.2243 - val_accuracy: 0.9072\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2134 - accuracy: 0.9083 - val_loss: 0.1947 - val_accuracy: 0.9190\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2013 - accuracy: 0.9131 - val_loss: 0.2031 - val_accuracy: 0.9151\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2086 - accuracy: 0.9118 - val_loss: 0.2393 - val_accuracy: 0.9041\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2164 - accuracy: 0.9092 - val_loss: 0.1942 - val_accuracy: 0.9196\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2057 - accuracy: 0.9117 - val_loss: 0.2072 - val_accuracy: 0.9151\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2040 - accuracy: 0.9124 - val_loss: 0.2000 - val_accuracy: 0.9164\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2075 - accuracy: 0.9109 - val_loss: 0.2136 - val_accuracy: 0.9131\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2165 - accuracy: 0.9086 - val_loss: 0.1946 - val_accuracy: 0.9193\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2051 - accuracy: 0.9123 - val_loss: 0.1999 - val_accuracy: 0.9180\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2205 - accuracy: 0.9070 - val_loss: 0.2093 - val_accuracy: 0.9136\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2087 - accuracy: 0.9106 - val_loss: 0.2015 - val_accuracy: 0.9155\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2050 - accuracy: 0.9123 - val_loss: 0.2081 - val_accuracy: 0.9132\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2078 - accuracy: 0.9113 - val_loss: 0.2232 - val_accuracy: 0.9081\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2138 - accuracy: 0.9090 - val_loss: 0.2068 - val_accuracy: 0.9137\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2150 - accuracy: 0.9090 - val_loss: 0.2300 - val_accuracy: 0.9066\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2112 - accuracy: 0.9105 - val_loss: 0.1973 - val_accuracy: 0.9178\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2040 - accuracy: 0.9123 - val_loss: 0.2056 - val_accuracy: 0.9131\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1997 - accuracy: 0.9138 - val_loss: 0.1877 - val_accuracy: 0.9211\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1975 - accuracy: 0.9156 - val_loss: 0.2012 - val_accuracy: 0.9170\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 4s 51ms/step - loss: 0.2010 - accuracy: 0.9135 - val_loss: 0.2325 - val_accuracy: 0.9057\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2010 - accuracy: 0.9126 - val_loss: 0.2049 - val_accuracy: 0.9150\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.2156 - accuracy: 0.9082 - val_loss: 0.2082 - val_accuracy: 0.9152\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1949 - accuracy: 0.9162 - val_loss: 0.1922 - val_accuracy: 0.9206\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1981 - accuracy: 0.9145 - val_loss: 0.1968 - val_accuracy: 0.9169\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2087 - accuracy: 0.9116 - val_loss: 0.2004 - val_accuracy: 0.9164\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2070 - accuracy: 0.9118 - val_loss: 0.1987 - val_accuracy: 0.9167\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2018 - accuracy: 0.9143 - val_loss: 0.2035 - val_accuracy: 0.9160\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2108 - accuracy: 0.9106 - val_loss: 0.1904 - val_accuracy: 0.9199\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2279 - accuracy: 0.9050 - val_loss: 0.2034 - val_accuracy: 0.9139\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2023 - accuracy: 0.9132 - val_loss: 0.2043 - val_accuracy: 0.9169\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2001 - accuracy: 0.9149 - val_loss: 0.2140 - val_accuracy: 0.9098\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2101 - accuracy: 0.9103 - val_loss: 0.1874 - val_accuracy: 0.9216\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1952 - accuracy: 0.9145 - val_loss: 0.1930 - val_accuracy: 0.9172\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2020 - accuracy: 0.9135 - val_loss: 0.2103 - val_accuracy: 0.9105\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2061 - accuracy: 0.9112 - val_loss: 0.2277 - val_accuracy: 0.9075\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1996 - accuracy: 0.9136 - val_loss: 0.2275 - val_accuracy: 0.9075\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2222 - accuracy: 0.9067 - val_loss: 0.1922 - val_accuracy: 0.9195\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2017 - accuracy: 0.9130 - val_loss: 0.1973 - val_accuracy: 0.9174\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2036 - accuracy: 0.9121 - val_loss: 0.2066 - val_accuracy: 0.9130\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2017 - accuracy: 0.9144 - val_loss: 0.1922 - val_accuracy: 0.9178\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1966 - accuracy: 0.9147 - val_loss: 0.1949 - val_accuracy: 0.9205\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2140 - accuracy: 0.9091 - val_loss: 0.2251 - val_accuracy: 0.9081\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2136 - accuracy: 0.9079 - val_loss: 0.2154 - val_accuracy: 0.9107\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2097 - accuracy: 0.9102 - val_loss: 0.2010 - val_accuracy: 0.9150\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2005 - accuracy: 0.9141 - val_loss: 0.2002 - val_accuracy: 0.9180\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1982 - accuracy: 0.9151 - val_loss: 0.2058 - val_accuracy: 0.9158\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2043 - accuracy: 0.9129 - val_loss: 0.2628 - val_accuracy: 0.8987\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1989 - accuracy: 0.9144 - val_loss: 0.2036 - val_accuracy: 0.9156\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2022 - accuracy: 0.9142 - val_loss: 0.2034 - val_accuracy: 0.9161\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2149 - accuracy: 0.9084 - val_loss: 0.2069 - val_accuracy: 0.9120\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2051 - accuracy: 0.9130 - val_loss: 0.2332 - val_accuracy: 0.9069\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2010 - accuracy: 0.9134 - val_loss: 0.2304 - val_accuracy: 0.9107\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1996 - accuracy: 0.9144 - val_loss: 0.1943 - val_accuracy: 0.9197\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2101 - accuracy: 0.9102 - val_loss: 0.2014 - val_accuracy: 0.9180\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2046 - accuracy: 0.9125 - val_loss: 0.2121 - val_accuracy: 0.9130\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2042 - accuracy: 0.9123 - val_loss: 0.2265 - val_accuracy: 0.9040\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2286 - accuracy: 0.9042 - val_loss: 0.2286 - val_accuracy: 0.9096\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2022 - accuracy: 0.9135 - val_loss: 0.2146 - val_accuracy: 0.9115\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2010 - accuracy: 0.9139 - val_loss: 0.1996 - val_accuracy: 0.9164\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1942 - accuracy: 0.9171 - val_loss: 0.1950 - val_accuracy: 0.9192\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1963 - accuracy: 0.9156 - val_loss: 0.1860 - val_accuracy: 0.9224\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1997 - accuracy: 0.9141 - val_loss: 0.2023 - val_accuracy: 0.9162\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1906 - accuracy: 0.9176 - val_loss: 0.2204 - val_accuracy: 0.9115\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2072 - accuracy: 0.9111 - val_loss: 0.2034 - val_accuracy: 0.9166\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1969 - accuracy: 0.9151 - val_loss: 0.2065 - val_accuracy: 0.9133\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2007 - accuracy: 0.9131 - val_loss: 0.2029 - val_accuracy: 0.9155\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1948 - accuracy: 0.9157 - val_loss: 0.1946 - val_accuracy: 0.9161\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1969 - accuracy: 0.9148 - val_loss: 0.2009 - val_accuracy: 0.9160\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1943 - accuracy: 0.9160 - val_loss: 0.1938 - val_accuracy: 0.9187\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1977 - accuracy: 0.9150 - val_loss: 0.2163 - val_accuracy: 0.9136\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2077 - accuracy: 0.9116 - val_loss: 0.2059 - val_accuracy: 0.9133\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1938 - accuracy: 0.9169 - val_loss: 0.1989 - val_accuracy: 0.9163\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1981 - accuracy: 0.9140 - val_loss: 0.1952 - val_accuracy: 0.9195\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1932 - accuracy: 0.9165 - val_loss: 0.2190 - val_accuracy: 0.9117\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2016 - accuracy: 0.9139 - val_loss: 0.2087 - val_accuracy: 0.9168\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1980 - accuracy: 0.9150 - val_loss: 0.1989 - val_accuracy: 0.9171\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2011 - accuracy: 0.9130 - val_loss: 0.1873 - val_accuracy: 0.9212\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1901 - accuracy: 0.9175 - val_loss: 0.2322 - val_accuracy: 0.9123\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1998 - accuracy: 0.9145 - val_loss: 0.1978 - val_accuracy: 0.9165\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2162 - accuracy: 0.9082 - val_loss: 0.2225 - val_accuracy: 0.9127\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1938 - accuracy: 0.9165 - val_loss: 0.1968 - val_accuracy: 0.9193\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1943 - accuracy: 0.9163 - val_loss: 0.2241 - val_accuracy: 0.9078\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2044 - accuracy: 0.9136 - val_loss: 0.1990 - val_accuracy: 0.9166\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1974 - accuracy: 0.9157 - val_loss: 0.1913 - val_accuracy: 0.9202\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1971 - accuracy: 0.9149 - val_loss: 0.2082 - val_accuracy: 0.9129\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1984 - accuracy: 0.9153 - val_loss: 0.1868 - val_accuracy: 0.9198\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2061 - accuracy: 0.9118 - val_loss: 0.1936 - val_accuracy: 0.9205\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2215 - accuracy: 0.9065 - val_loss: 0.2782 - val_accuracy: 0.8830\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1963 - accuracy: 0.9164 - val_loss: 0.1930 - val_accuracy: 0.9206\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1913 - accuracy: 0.9176 - val_loss: 0.1962 - val_accuracy: 0.9181\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1979 - accuracy: 0.9153 - val_loss: 0.1910 - val_accuracy: 0.9205\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1975 - accuracy: 0.9147 - val_loss: 0.2404 - val_accuracy: 0.9069\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1960 - accuracy: 0.9159 - val_loss: 0.1910 - val_accuracy: 0.9208\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1908 - accuracy: 0.9178 - val_loss: 0.2409 - val_accuracy: 0.9050\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1943 - accuracy: 0.9164 - val_loss: 0.2055 - val_accuracy: 0.9133\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2015 - accuracy: 0.9127 - val_loss: 0.1930 - val_accuracy: 0.9188\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 4s 41ms/step - loss: 0.2014 - accuracy: 0.9136 - val_loss: 0.1993 - val_accuracy: 0.9192\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1989 - accuracy: 0.9149 - val_loss: 0.1963 - val_accuracy: 0.9191\n",
      "Epoch 275/1000\n",
      "87/87 [==============================] - 4s 47ms/step - loss: 0.1903 - accuracy: 0.9173 - val_loss: 0.2003 - val_accuracy: 0.9147\n",
      "Epoch 276/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1894 - accuracy: 0.9181 - val_loss: 0.1963 - val_accuracy: 0.9185\n",
      "Epoch 277/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1946 - accuracy: 0.9170 - val_loss: 0.2045 - val_accuracy: 0.9126\n",
      "Epoch 278/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2020 - accuracy: 0.9124 - val_loss: 0.1866 - val_accuracy: 0.9204\n",
      "Epoch 279/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1942 - accuracy: 0.9157 - val_loss: 0.2128 - val_accuracy: 0.9144\n",
      "Epoch 280/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2011 - accuracy: 0.9134 - val_loss: 0.1898 - val_accuracy: 0.9209\n",
      "Epoch 281/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1978 - accuracy: 0.9151 - val_loss: 0.2035 - val_accuracy: 0.9135\n",
      "Epoch 282/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1923 - accuracy: 0.9174 - val_loss: 0.2031 - val_accuracy: 0.9154\n",
      "Epoch 283/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1935 - accuracy: 0.9165 - val_loss: 0.1982 - val_accuracy: 0.9185\n",
      "Epoch 284/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1964 - accuracy: 0.9146 - val_loss: 0.1844 - val_accuracy: 0.9218\n",
      "Epoch 285/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1863 - accuracy: 0.9189 - val_loss: 0.1933 - val_accuracy: 0.9189\n",
      "Epoch 286/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2031 - accuracy: 0.9132 - val_loss: 0.1948 - val_accuracy: 0.9203\n",
      "Epoch 287/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2001 - accuracy: 0.9146 - val_loss: 0.1882 - val_accuracy: 0.9206\n",
      "Epoch 288/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1848 - accuracy: 0.9192 - val_loss: 0.2112 - val_accuracy: 0.9138\n",
      "Epoch 289/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1909 - accuracy: 0.9177 - val_loss: 0.1887 - val_accuracy: 0.9202\n",
      "Epoch 290/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1913 - accuracy: 0.9167 - val_loss: 0.2058 - val_accuracy: 0.9155\n",
      "Epoch 291/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1844 - accuracy: 0.9196 - val_loss: 0.2322 - val_accuracy: 0.9091\n",
      "Epoch 292/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1974 - accuracy: 0.9144 - val_loss: 0.1979 - val_accuracy: 0.9184\n",
      "Epoch 293/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1990 - accuracy: 0.9152 - val_loss: 0.2122 - val_accuracy: 0.9125\n",
      "Epoch 294/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1853 - accuracy: 0.9190 - val_loss: 0.1923 - val_accuracy: 0.9209\n",
      "Epoch 295/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1942 - accuracy: 0.9166 - val_loss: 0.2102 - val_accuracy: 0.9113\n",
      "Epoch 296/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1912 - accuracy: 0.9169 - val_loss: 0.2206 - val_accuracy: 0.9124\n",
      "Epoch 297/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1933 - accuracy: 0.9165 - val_loss: 0.1838 - val_accuracy: 0.9229\n",
      "Epoch 298/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1930 - accuracy: 0.9171 - val_loss: 0.1976 - val_accuracy: 0.9179\n",
      "Epoch 299/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1975 - accuracy: 0.9150 - val_loss: 0.1890 - val_accuracy: 0.9207\n",
      "Epoch 300/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1938 - accuracy: 0.9171 - val_loss: 0.2082 - val_accuracy: 0.9167\n",
      "Epoch 301/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1955 - accuracy: 0.9149 - val_loss: 0.2137 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1907 - accuracy: 0.9163 - val_loss: 0.1890 - val_accuracy: 0.9215\n",
      "Epoch 303/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1956 - accuracy: 0.9152 - val_loss: 0.1890 - val_accuracy: 0.9198\n",
      "Epoch 304/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1907 - accuracy: 0.9173 - val_loss: 0.1834 - val_accuracy: 0.9224\n",
      "Epoch 305/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1896 - accuracy: 0.9181 - val_loss: 0.2761 - val_accuracy: 0.8945\n",
      "Epoch 306/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1985 - accuracy: 0.9149 - val_loss: 0.1896 - val_accuracy: 0.9209\n",
      "Epoch 307/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1928 - accuracy: 0.9174 - val_loss: 0.2026 - val_accuracy: 0.9174\n",
      "Epoch 308/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1941 - accuracy: 0.9171 - val_loss: 0.1840 - val_accuracy: 0.9226\n",
      "Epoch 309/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1852 - accuracy: 0.9193 - val_loss: 0.2032 - val_accuracy: 0.9180\n",
      "Epoch 310/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1966 - accuracy: 0.9165 - val_loss: 0.2442 - val_accuracy: 0.9038\n",
      "Epoch 311/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.3121 - accuracy: 0.8837 - val_loss: 0.2366 - val_accuracy: 0.9084\n",
      "Epoch 312/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2439 - accuracy: 0.9022 - val_loss: 0.2276 - val_accuracy: 0.9100\n",
      "Epoch 313/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2325 - accuracy: 0.9043 - val_loss: 0.2102 - val_accuracy: 0.9134\n",
      "Epoch 314/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2373 - accuracy: 0.9039 - val_loss: 0.2295 - val_accuracy: 0.9072\n",
      "Epoch 315/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2256 - accuracy: 0.9074 - val_loss: 0.2589 - val_accuracy: 0.8947\n",
      "Epoch 316/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2329 - accuracy: 0.9050 - val_loss: 0.2015 - val_accuracy: 0.9184\n",
      "Epoch 317/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2160 - accuracy: 0.9091 - val_loss: 0.2135 - val_accuracy: 0.9137\n",
      "Epoch 318/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2081 - accuracy: 0.9124 - val_loss: 0.2049 - val_accuracy: 0.9137\n",
      "Epoch 319/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2024 - accuracy: 0.9143 - val_loss: 0.1988 - val_accuracy: 0.9175\n",
      "Epoch 320/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2477 - accuracy: 0.8977 - val_loss: 0.2194 - val_accuracy: 0.9107\n",
      "Epoch 321/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2119 - accuracy: 0.9112 - val_loss: 0.2032 - val_accuracy: 0.9170\n",
      "Epoch 322/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2132 - accuracy: 0.9105 - val_loss: 0.2009 - val_accuracy: 0.9170\n",
      "Epoch 323/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2065 - accuracy: 0.9126 - val_loss: 0.2123 - val_accuracy: 0.9142\n",
      "Epoch 324/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2070 - accuracy: 0.9125 - val_loss: 0.2007 - val_accuracy: 0.9150\n",
      "Epoch 325/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2040 - accuracy: 0.9140 - val_loss: 0.2095 - val_accuracy: 0.9140\n",
      "Epoch 326/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2539 - accuracy: 0.9000 - val_loss: 0.2271 - val_accuracy: 0.9109\n",
      "Epoch 327/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2268 - accuracy: 0.9087 - val_loss: 0.2196 - val_accuracy: 0.9139\n",
      "Epoch 328/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2141 - accuracy: 0.9119 - val_loss: 0.2047 - val_accuracy: 0.9179\n",
      "Epoch 329/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2076 - accuracy: 0.9131 - val_loss: 0.2079 - val_accuracy: 0.9158\n",
      "Epoch 330/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2098 - accuracy: 0.9129 - val_loss: 0.2172 - val_accuracy: 0.9134\n",
      "Epoch 331/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2155 - accuracy: 0.9106 - val_loss: 0.2003 - val_accuracy: 0.9184\n",
      "Epoch 332/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2276 - accuracy: 0.9068 - val_loss: 0.2077 - val_accuracy: 0.9156\n",
      "Epoch 333/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2531 - accuracy: 0.8981 - val_loss: 0.2247 - val_accuracy: 0.9114\n",
      "Epoch 334/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2106 - accuracy: 0.9122 - val_loss: 0.2359 - val_accuracy: 0.9049\n",
      "Epoch 335/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2144 - accuracy: 0.9107 - val_loss: 0.2057 - val_accuracy: 0.9158\n",
      "Epoch 336/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2709 - accuracy: 0.8937 - val_loss: 0.2656 - val_accuracy: 0.8955\n",
      "Epoch 337/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2438 - accuracy: 0.9009 - val_loss: 0.2055 - val_accuracy: 0.9184\n",
      "Epoch 338/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2117 - accuracy: 0.9118 - val_loss: 0.2069 - val_accuracy: 0.9163\n",
      "Epoch 339/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2217 - accuracy: 0.9084 - val_loss: 0.2151 - val_accuracy: 0.9112\n",
      "Epoch 340/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2112 - accuracy: 0.9117 - val_loss: 0.2025 - val_accuracy: 0.9170\n",
      "Epoch 341/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2062 - accuracy: 0.9136 - val_loss: 0.2009 - val_accuracy: 0.9159\n",
      "Epoch 342/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2065 - accuracy: 0.9136 - val_loss: 0.1952 - val_accuracy: 0.9197\n",
      "Epoch 343/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2166 - accuracy: 0.9096 - val_loss: 0.2221 - val_accuracy: 0.9125\n",
      "Epoch 344/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2083 - accuracy: 0.9134 - val_loss: 0.2193 - val_accuracy: 0.9141\n",
      "Epoch 345/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2090 - accuracy: 0.9130 - val_loss: 0.2605 - val_accuracy: 0.8949\n",
      "Epoch 346/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2085 - accuracy: 0.9126 - val_loss: 0.2101 - val_accuracy: 0.9141\n",
      "Epoch 347/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2026 - accuracy: 0.9142 - val_loss: 0.1938 - val_accuracy: 0.9221\n",
      "Epoch 348/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2060 - accuracy: 0.9140 - val_loss: 0.2551 - val_accuracy: 0.9011\n",
      "Epoch 349/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2775 - accuracy: 0.8904 - val_loss: 0.4274 - val_accuracy: 0.8425\n",
      "Epoch 350/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2714 - accuracy: 0.8946 - val_loss: 0.2469 - val_accuracy: 0.9068\n",
      "Epoch 351/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2649 - accuracy: 0.8943 - val_loss: 0.2366 - val_accuracy: 0.9042\n",
      "Epoch 352/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2288 - accuracy: 0.9039 - val_loss: 0.2168 - val_accuracy: 0.9094\n",
      "Epoch 353/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2101 - accuracy: 0.9122 - val_loss: 0.1997 - val_accuracy: 0.9187\n",
      "Epoch 354/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1950 - accuracy: 0.9169 - val_loss: 0.1932 - val_accuracy: 0.9200\n",
      "Epoch 355/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2013 - accuracy: 0.9136 - val_loss: 0.2010 - val_accuracy: 0.9168\n",
      "Epoch 356/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1935 - accuracy: 0.9163 - val_loss: 0.1979 - val_accuracy: 0.9174\n",
      "Epoch 357/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2048 - accuracy: 0.9126 - val_loss: 0.1915 - val_accuracy: 0.9197\n",
      "Epoch 358/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1922 - accuracy: 0.9182 - val_loss: 0.2058 - val_accuracy: 0.9155\n",
      "Epoch 359/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1972 - accuracy: 0.9154 - val_loss: 0.2077 - val_accuracy: 0.9136\n",
      "Epoch 360/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2014 - accuracy: 0.9138 - val_loss: 0.1952 - val_accuracy: 0.9184\n",
      "Epoch 361/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1961 - accuracy: 0.9148 - val_loss: 0.2116 - val_accuracy: 0.9145\n",
      "Epoch 362/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1929 - accuracy: 0.9168 - val_loss: 0.1941 - val_accuracy: 0.9182\n",
      "Epoch 363/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1863 - accuracy: 0.9183 - val_loss: 0.1847 - val_accuracy: 0.9235\n",
      "Epoch 364/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1828 - accuracy: 0.9194 - val_loss: 0.2076 - val_accuracy: 0.9160\n",
      "Epoch 365/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1917 - accuracy: 0.9173 - val_loss: 0.2038 - val_accuracy: 0.9170\n",
      "Epoch 366/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2059 - accuracy: 0.9126 - val_loss: 0.1952 - val_accuracy: 0.9176\n",
      "Epoch 367/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1899 - accuracy: 0.9175 - val_loss: 0.1932 - val_accuracy: 0.9183\n",
      "Epoch 368/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1946 - accuracy: 0.9149 - val_loss: 0.2092 - val_accuracy: 0.9118\n",
      "Epoch 369/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1879 - accuracy: 0.9183 - val_loss: 0.1842 - val_accuracy: 0.9217\n",
      "Epoch 370/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1877 - accuracy: 0.9178 - val_loss: 0.1906 - val_accuracy: 0.9207\n",
      "Epoch 371/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1809 - accuracy: 0.9204 - val_loss: 0.1854 - val_accuracy: 0.9208\n",
      "Epoch 372/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1875 - accuracy: 0.9181 - val_loss: 0.1997 - val_accuracy: 0.9185\n",
      "Epoch 373/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1875 - accuracy: 0.9182 - val_loss: 0.1901 - val_accuracy: 0.9189\n",
      "Epoch 374/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1914 - accuracy: 0.9164 - val_loss: 0.1929 - val_accuracy: 0.9202\n",
      "Epoch 375/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1890 - accuracy: 0.9189 - val_loss: 0.2008 - val_accuracy: 0.9157\n",
      "Epoch 376/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1972 - accuracy: 0.9151 - val_loss: 0.1874 - val_accuracy: 0.9210\n",
      "Epoch 377/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1888 - accuracy: 0.9179 - val_loss: 0.1925 - val_accuracy: 0.9211\n",
      "Epoch 378/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1900 - accuracy: 0.9189 - val_loss: 0.1954 - val_accuracy: 0.9199\n",
      "Epoch 379/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2075 - accuracy: 0.9116 - val_loss: 0.1939 - val_accuracy: 0.9191\n",
      "Epoch 380/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1906 - accuracy: 0.9176 - val_loss: 0.2162 - val_accuracy: 0.9107\n",
      "Epoch 381/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1928 - accuracy: 0.9160 - val_loss: 0.1846 - val_accuracy: 0.9207\n",
      "Epoch 382/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1901 - accuracy: 0.9171 - val_loss: 0.2016 - val_accuracy: 0.9189\n",
      "Epoch 383/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1833 - accuracy: 0.9198 - val_loss: 0.1956 - val_accuracy: 0.9162\n",
      "Epoch 384/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1870 - accuracy: 0.9186 - val_loss: 0.1855 - val_accuracy: 0.9216\n",
      "Epoch 385/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1901 - accuracy: 0.9173 - val_loss: 0.2131 - val_accuracy: 0.9111\n",
      "Epoch 386/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1895 - accuracy: 0.9176 - val_loss: 0.1838 - val_accuracy: 0.9218\n",
      "Epoch 387/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1885 - accuracy: 0.9183 - val_loss: 0.2020 - val_accuracy: 0.9171\n",
      "Epoch 388/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1870 - accuracy: 0.9184 - val_loss: 0.2194 - val_accuracy: 0.9094\n",
      "Epoch 389/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2032 - accuracy: 0.9126 - val_loss: 0.1905 - val_accuracy: 0.9195\n",
      "Epoch 390/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1792 - accuracy: 0.9220 - val_loss: 0.1815 - val_accuracy: 0.9234\n",
      "Epoch 391/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1856 - accuracy: 0.9190 - val_loss: 0.1860 - val_accuracy: 0.9201\n",
      "Epoch 392/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1832 - accuracy: 0.9204 - val_loss: 0.1883 - val_accuracy: 0.9212\n",
      "Epoch 393/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1856 - accuracy: 0.9192 - val_loss: 0.1864 - val_accuracy: 0.9243\n",
      "Epoch 394/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1907 - accuracy: 0.9184 - val_loss: 0.2029 - val_accuracy: 0.9143\n",
      "Epoch 395/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1838 - accuracy: 0.9196 - val_loss: 0.1886 - val_accuracy: 0.9202\n",
      "Epoch 396/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1922 - accuracy: 0.9167 - val_loss: 0.2357 - val_accuracy: 0.9110\n",
      "Epoch 397/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1891 - accuracy: 0.9183 - val_loss: 0.1882 - val_accuracy: 0.9181\n",
      "Epoch 398/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1909 - accuracy: 0.9180 - val_loss: 0.1781 - val_accuracy: 0.9247\n",
      "Epoch 399/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2014 - accuracy: 0.9140 - val_loss: 0.2256 - val_accuracy: 0.9102\n",
      "Epoch 400/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2076 - accuracy: 0.9107 - val_loss: 0.1882 - val_accuracy: 0.9210\n",
      "Epoch 401/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1862 - accuracy: 0.9192 - val_loss: 0.2359 - val_accuracy: 0.9082\n",
      "Epoch 402/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1938 - accuracy: 0.9165 - val_loss: 0.1971 - val_accuracy: 0.9183\n",
      "Epoch 403/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1899 - accuracy: 0.9184 - val_loss: 0.1796 - val_accuracy: 0.9234\n",
      "Epoch 404/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1857 - accuracy: 0.9192 - val_loss: 0.1927 - val_accuracy: 0.9195\n",
      "Epoch 405/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1924 - accuracy: 0.9182 - val_loss: 0.1818 - val_accuracy: 0.9209\n",
      "Epoch 406/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1854 - accuracy: 0.9202 - val_loss: 0.2010 - val_accuracy: 0.9178\n",
      "Epoch 407/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1853 - accuracy: 0.9200 - val_loss: 0.1993 - val_accuracy: 0.9180\n",
      "Epoch 408/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1852 - accuracy: 0.9199 - val_loss: 0.1966 - val_accuracy: 0.9189\n",
      "Epoch 409/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1924 - accuracy: 0.9171 - val_loss: 0.1875 - val_accuracy: 0.9204\n",
      "Epoch 410/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1943 - accuracy: 0.9160 - val_loss: 0.1905 - val_accuracy: 0.9217\n",
      "Epoch 411/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2028 - accuracy: 0.9133 - val_loss: 0.3075 - val_accuracy: 0.8878\n",
      "Epoch 412/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2048 - accuracy: 0.9142 - val_loss: 0.2125 - val_accuracy: 0.9152\n",
      "Epoch 413/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1832 - accuracy: 0.9201 - val_loss: 0.1892 - val_accuracy: 0.9190\n",
      "Epoch 414/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1952 - accuracy: 0.9162 - val_loss: 0.2263 - val_accuracy: 0.9109\n",
      "Epoch 415/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1953 - accuracy: 0.9152 - val_loss: 0.1864 - val_accuracy: 0.9199\n",
      "Epoch 416/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1867 - accuracy: 0.9185 - val_loss: 0.2006 - val_accuracy: 0.9115\n",
      "Epoch 417/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1883 - accuracy: 0.9180 - val_loss: 0.1885 - val_accuracy: 0.9214\n",
      "Epoch 418/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1861 - accuracy: 0.9185 - val_loss: 0.1929 - val_accuracy: 0.9192\n",
      "Epoch 419/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1848 - accuracy: 0.9189 - val_loss: 0.2094 - val_accuracy: 0.9154\n",
      "Epoch 420/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1910 - accuracy: 0.9168 - val_loss: 0.2074 - val_accuracy: 0.9157\n",
      "Epoch 421/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1787 - accuracy: 0.9222 - val_loss: 0.1831 - val_accuracy: 0.9220\n",
      "Epoch 422/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1923 - accuracy: 0.9176 - val_loss: 0.2001 - val_accuracy: 0.9162\n",
      "Epoch 423/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1784 - accuracy: 0.9219 - val_loss: 0.1877 - val_accuracy: 0.9179\n",
      "Epoch 424/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2063 - accuracy: 0.9130 - val_loss: 0.1880 - val_accuracy: 0.9225\n",
      "Epoch 425/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1893 - accuracy: 0.9182 - val_loss: 0.2037 - val_accuracy: 0.9138\n",
      "Epoch 426/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2115 - accuracy: 0.9126 - val_loss: 0.1906 - val_accuracy: 0.9198\n",
      "Epoch 427/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1880 - accuracy: 0.9187 - val_loss: 0.1859 - val_accuracy: 0.9218\n",
      "Epoch 428/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1887 - accuracy: 0.9179 - val_loss: 0.1858 - val_accuracy: 0.9243\n",
      "Epoch 429/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1899 - accuracy: 0.9183 - val_loss: 0.1930 - val_accuracy: 0.9166\n",
      "Epoch 430/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1851 - accuracy: 0.9192 - val_loss: 0.1877 - val_accuracy: 0.9228\n",
      "Epoch 431/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1824 - accuracy: 0.9207 - val_loss: 0.1934 - val_accuracy: 0.9181\n",
      "Epoch 432/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1883 - accuracy: 0.9181 - val_loss: 0.2116 - val_accuracy: 0.9127\n",
      "Epoch 433/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1916 - accuracy: 0.9167 - val_loss: 0.1878 - val_accuracy: 0.9195\n",
      "Epoch 434/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1872 - accuracy: 0.9192 - val_loss: 0.1924 - val_accuracy: 0.9203\n",
      "Epoch 435/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1854 - accuracy: 0.9193 - val_loss: 0.1943 - val_accuracy: 0.9180\n",
      "Epoch 436/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1857 - accuracy: 0.9188 - val_loss: 0.1870 - val_accuracy: 0.9199\n",
      "Epoch 437/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1818 - accuracy: 0.9206 - val_loss: 0.2341 - val_accuracy: 0.9052\n",
      "Epoch 438/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1861 - accuracy: 0.9198 - val_loss: 0.2204 - val_accuracy: 0.9115\n",
      "Epoch 439/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1921 - accuracy: 0.9172 - val_loss: 0.1845 - val_accuracy: 0.9217\n",
      "Epoch 440/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1771 - accuracy: 0.9215 - val_loss: 0.1894 - val_accuracy: 0.9175\n",
      "Epoch 441/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1844 - accuracy: 0.9196 - val_loss: 0.1969 - val_accuracy: 0.9178\n",
      "Epoch 442/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1912 - accuracy: 0.9168 - val_loss: 0.1883 - val_accuracy: 0.9212\n",
      "Epoch 443/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1868 - accuracy: 0.9192 - val_loss: 0.1911 - val_accuracy: 0.9186\n",
      "Epoch 444/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1844 - accuracy: 0.9196 - val_loss: 0.1919 - val_accuracy: 0.9208\n",
      "Epoch 445/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1826 - accuracy: 0.9203 - val_loss: 0.1875 - val_accuracy: 0.9213\n",
      "Epoch 446/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1829 - accuracy: 0.9203 - val_loss: 0.1774 - val_accuracy: 0.9257\n",
      "Epoch 447/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1806 - accuracy: 0.9212 - val_loss: 0.1794 - val_accuracy: 0.9249\n",
      "Epoch 448/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1876 - accuracy: 0.9187 - val_loss: 0.1833 - val_accuracy: 0.9225\n",
      "Epoch 449/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1776 - accuracy: 0.9222 - val_loss: 0.1875 - val_accuracy: 0.9225\n",
      "Epoch 450/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1799 - accuracy: 0.9217 - val_loss: 0.1889 - val_accuracy: 0.9196\n",
      "Epoch 451/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1765 - accuracy: 0.9217 - val_loss: 0.1947 - val_accuracy: 0.9203\n",
      "Epoch 452/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1800 - accuracy: 0.9217 - val_loss: 0.1978 - val_accuracy: 0.9188\n",
      "Epoch 453/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1922 - accuracy: 0.9173 - val_loss: 0.1947 - val_accuracy: 0.9178\n",
      "Epoch 454/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1882 - accuracy: 0.9179 - val_loss: 0.1957 - val_accuracy: 0.9183\n",
      "Epoch 455/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1835 - accuracy: 0.9203 - val_loss: 0.1835 - val_accuracy: 0.9211\n",
      "Epoch 456/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2019 - accuracy: 0.9144 - val_loss: 0.2056 - val_accuracy: 0.9154\n",
      "Epoch 457/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1870 - accuracy: 0.9190 - val_loss: 0.1802 - val_accuracy: 0.9228\n",
      "Epoch 458/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1916 - accuracy: 0.9182 - val_loss: 0.2114 - val_accuracy: 0.9163\n",
      "Epoch 459/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1838 - accuracy: 0.9199 - val_loss: 0.2046 - val_accuracy: 0.9172\n",
      "Epoch 460/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1827 - accuracy: 0.9192 - val_loss: 0.1846 - val_accuracy: 0.9244\n",
      "Epoch 461/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1777 - accuracy: 0.9216 - val_loss: 0.1825 - val_accuracy: 0.9225\n",
      "Epoch 462/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1802 - accuracy: 0.9211 - val_loss: 0.1862 - val_accuracy: 0.9209\n",
      "Epoch 463/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2005 - accuracy: 0.9148 - val_loss: 0.2134 - val_accuracy: 0.9138\n",
      "Epoch 464/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1806 - accuracy: 0.9211 - val_loss: 0.1997 - val_accuracy: 0.9163\n",
      "Epoch 465/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1829 - accuracy: 0.9204 - val_loss: 0.2090 - val_accuracy: 0.9133\n",
      "Epoch 466/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1863 - accuracy: 0.9193 - val_loss: 0.1849 - val_accuracy: 0.9217\n",
      "Epoch 467/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1734 - accuracy: 0.9233 - val_loss: 0.1922 - val_accuracy: 0.9196\n",
      "Epoch 468/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1824 - accuracy: 0.9203 - val_loss: 0.1905 - val_accuracy: 0.9205\n",
      "Epoch 469/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1889 - accuracy: 0.9184 - val_loss: 0.1936 - val_accuracy: 0.9191\n",
      "Epoch 470/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1825 - accuracy: 0.9198 - val_loss: 0.1915 - val_accuracy: 0.9181\n",
      "Epoch 471/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1864 - accuracy: 0.9187 - val_loss: 0.2143 - val_accuracy: 0.9144\n",
      "Epoch 472/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1812 - accuracy: 0.9212 - val_loss: 0.1885 - val_accuracy: 0.9214\n",
      "Epoch 473/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1861 - accuracy: 0.9196 - val_loss: 0.1794 - val_accuracy: 0.9233\n",
      "Epoch 474/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1821 - accuracy: 0.9209 - val_loss: 0.1963 - val_accuracy: 0.9191\n",
      "Epoch 475/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1765 - accuracy: 0.9229 - val_loss: 0.1855 - val_accuracy: 0.9213\n",
      "Epoch 476/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1761 - accuracy: 0.9233 - val_loss: 0.1927 - val_accuracy: 0.9207\n",
      "Epoch 477/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1852 - accuracy: 0.9194 - val_loss: 0.1876 - val_accuracy: 0.9224\n",
      "Epoch 478/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1765 - accuracy: 0.9224 - val_loss: 0.1820 - val_accuracy: 0.9234\n",
      "Epoch 479/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1755 - accuracy: 0.9226 - val_loss: 0.1977 - val_accuracy: 0.9198\n",
      "Epoch 480/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1742 - accuracy: 0.9226 - val_loss: 0.1979 - val_accuracy: 0.9168\n",
      "Epoch 481/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1880 - accuracy: 0.9184 - val_loss: 0.2056 - val_accuracy: 0.9132\n",
      "Epoch 482/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1884 - accuracy: 0.9184 - val_loss: 0.2029 - val_accuracy: 0.9176\n",
      "Epoch 483/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1869 - accuracy: 0.9189 - val_loss: 0.1813 - val_accuracy: 0.9243\n",
      "Epoch 484/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1891 - accuracy: 0.9180 - val_loss: 0.2137 - val_accuracy: 0.9137\n",
      "Epoch 485/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1759 - accuracy: 0.9222 - val_loss: 0.2123 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1817 - accuracy: 0.9215 - val_loss: 0.1888 - val_accuracy: 0.9214\n",
      "Epoch 487/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1821 - accuracy: 0.9202 - val_loss: 0.1811 - val_accuracy: 0.9236\n",
      "Epoch 488/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1769 - accuracy: 0.9229 - val_loss: 0.1952 - val_accuracy: 0.9198\n",
      "Epoch 489/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1911 - accuracy: 0.9176 - val_loss: 0.1946 - val_accuracy: 0.9187\n",
      "Epoch 490/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1799 - accuracy: 0.9209 - val_loss: 0.1795 - val_accuracy: 0.9232\n",
      "Epoch 491/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1829 - accuracy: 0.9203 - val_loss: 0.1825 - val_accuracy: 0.9204\n",
      "Epoch 492/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1749 - accuracy: 0.9230 - val_loss: 0.1897 - val_accuracy: 0.9218\n",
      "Epoch 493/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1768 - accuracy: 0.9231 - val_loss: 0.1964 - val_accuracy: 0.9193\n",
      "Epoch 494/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1828 - accuracy: 0.9193 - val_loss: 0.1923 - val_accuracy: 0.9168\n",
      "Epoch 495/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1828 - accuracy: 0.9205 - val_loss: 0.2048 - val_accuracy: 0.9163\n",
      "Epoch 496/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1832 - accuracy: 0.9201 - val_loss: 0.1946 - val_accuracy: 0.9192\n",
      "Epoch 497/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1803 - accuracy: 0.9220 - val_loss: 0.1943 - val_accuracy: 0.9173\n",
      "Epoch 498/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1865 - accuracy: 0.9193 - val_loss: 0.1959 - val_accuracy: 0.9179\n",
      "Epoch 499/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1911 - accuracy: 0.9172 - val_loss: 0.2089 - val_accuracy: 0.9127\n",
      "Epoch 500/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1832 - accuracy: 0.9200 - val_loss: 0.1960 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1756 - accuracy: 0.9225 - val_loss: 0.1859 - val_accuracy: 0.9217\n",
      "Epoch 502/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1793 - accuracy: 0.9216 - val_loss: 0.1838 - val_accuracy: 0.9220\n",
      "Epoch 503/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1806 - accuracy: 0.9211 - val_loss: 0.1864 - val_accuracy: 0.9222\n",
      "Epoch 504/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1788 - accuracy: 0.9222 - val_loss: 0.1887 - val_accuracy: 0.9227\n",
      "Epoch 505/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1939 - accuracy: 0.9160 - val_loss: 0.1854 - val_accuracy: 0.9219\n",
      "Epoch 506/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1797 - accuracy: 0.9224 - val_loss: 0.2236 - val_accuracy: 0.9048\n",
      "Epoch 507/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1900 - accuracy: 0.9178 - val_loss: 0.2222 - val_accuracy: 0.9103\n",
      "Epoch 508/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1820 - accuracy: 0.9203 - val_loss: 0.1889 - val_accuracy: 0.9193\n",
      "Epoch 509/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1788 - accuracy: 0.9220 - val_loss: 0.2003 - val_accuracy: 0.9176\n",
      "Epoch 510/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1915 - accuracy: 0.9179 - val_loss: 0.1827 - val_accuracy: 0.9231\n",
      "Epoch 511/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1810 - accuracy: 0.9204 - val_loss: 0.1826 - val_accuracy: 0.9251\n",
      "Epoch 512/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1865 - accuracy: 0.9173 - val_loss: 0.1818 - val_accuracy: 0.9229\n",
      "Epoch 513/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1771 - accuracy: 0.9224 - val_loss: 0.1870 - val_accuracy: 0.9194\n",
      "Epoch 514/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1841 - accuracy: 0.9202 - val_loss: 0.2000 - val_accuracy: 0.9144\n",
      "Epoch 515/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1783 - accuracy: 0.9218 - val_loss: 0.1816 - val_accuracy: 0.9228\n",
      "Epoch 516/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1763 - accuracy: 0.9224 - val_loss: 0.2093 - val_accuracy: 0.9155\n",
      "Epoch 517/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1821 - accuracy: 0.9202 - val_loss: 0.1766 - val_accuracy: 0.9246\n",
      "Epoch 518/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1729 - accuracy: 0.9233 - val_loss: 0.1831 - val_accuracy: 0.9239\n",
      "Epoch 519/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1784 - accuracy: 0.9220 - val_loss: 0.1938 - val_accuracy: 0.9171\n",
      "Epoch 520/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1911 - accuracy: 0.9175 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1801 - accuracy: 0.9207 - val_loss: 0.1851 - val_accuracy: 0.9217\n",
      "Epoch 522/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1887 - accuracy: 0.9181 - val_loss: 0.1780 - val_accuracy: 0.9243\n",
      "Epoch 523/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1725 - accuracy: 0.9244 - val_loss: 0.1909 - val_accuracy: 0.9210\n",
      "Epoch 524/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1801 - accuracy: 0.9213 - val_loss: 0.1831 - val_accuracy: 0.9220\n",
      "Epoch 525/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1785 - accuracy: 0.9214 - val_loss: 0.1788 - val_accuracy: 0.9235\n",
      "Epoch 526/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1935 - accuracy: 0.9167 - val_loss: 0.1867 - val_accuracy: 0.9204\n",
      "Epoch 527/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1785 - accuracy: 0.9225 - val_loss: 0.1937 - val_accuracy: 0.9193\n",
      "Epoch 528/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1938 - accuracy: 0.9172 - val_loss: 0.1934 - val_accuracy: 0.9175\n",
      "Epoch 529/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1746 - accuracy: 0.9236 - val_loss: 0.1987 - val_accuracy: 0.9166\n",
      "Epoch 530/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1790 - accuracy: 0.9211 - val_loss: 0.1954 - val_accuracy: 0.9195\n",
      "Epoch 531/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1866 - accuracy: 0.9198 - val_loss: 0.2018 - val_accuracy: 0.9166\n",
      "Epoch 532/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1973 - accuracy: 0.9169 - val_loss: 0.2884 - val_accuracy: 0.8811\n",
      "Epoch 533/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1871 - accuracy: 0.9191 - val_loss: 0.1809 - val_accuracy: 0.9260\n",
      "Epoch 534/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1880 - accuracy: 0.9180 - val_loss: 0.2090 - val_accuracy: 0.9129\n",
      "Epoch 535/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1846 - accuracy: 0.9189 - val_loss: 0.2022 - val_accuracy: 0.9192\n",
      "Epoch 536/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1846 - accuracy: 0.9201 - val_loss: 0.1852 - val_accuracy: 0.9214\n",
      "Epoch 537/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1797 - accuracy: 0.9222 - val_loss: 0.1833 - val_accuracy: 0.9232\n",
      "Epoch 538/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1748 - accuracy: 0.9229 - val_loss: 0.1850 - val_accuracy: 0.9180\n",
      "Epoch 539/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1733 - accuracy: 0.9236 - val_loss: 0.1810 - val_accuracy: 0.9214\n",
      "Epoch 540/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1782 - accuracy: 0.9225 - val_loss: 0.1865 - val_accuracy: 0.9190\n",
      "Epoch 541/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1772 - accuracy: 0.9231 - val_loss: 0.1904 - val_accuracy: 0.9205\n",
      "Epoch 542/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1923 - accuracy: 0.9185 - val_loss: 0.2055 - val_accuracy: 0.9161\n",
      "Epoch 543/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1792 - accuracy: 0.9224 - val_loss: 0.1874 - val_accuracy: 0.9224\n",
      "Epoch 544/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1763 - accuracy: 0.9236 - val_loss: 0.1893 - val_accuracy: 0.9222\n",
      "Epoch 545/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1898 - accuracy: 0.9185 - val_loss: 0.1885 - val_accuracy: 0.9188\n",
      "Epoch 546/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1754 - accuracy: 0.9235 - val_loss: 0.1773 - val_accuracy: 0.9238\n",
      "Epoch 547/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1716 - accuracy: 0.9243 - val_loss: 0.1824 - val_accuracy: 0.9206\n",
      "Epoch 548/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1838 - accuracy: 0.9196 - val_loss: 0.2353 - val_accuracy: 0.9060\n",
      "Epoch 549/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1869 - accuracy: 0.9188 - val_loss: 0.1898 - val_accuracy: 0.9197\n",
      "Epoch 550/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1751 - accuracy: 0.9240 - val_loss: 0.1923 - val_accuracy: 0.9187\n",
      "Epoch 551/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1738 - accuracy: 0.9239 - val_loss: 0.1810 - val_accuracy: 0.9224\n",
      "Epoch 552/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1893 - accuracy: 0.9179 - val_loss: 0.1898 - val_accuracy: 0.9220\n",
      "Epoch 553/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1965 - accuracy: 0.9152 - val_loss: 0.2073 - val_accuracy: 0.9121\n",
      "Epoch 554/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1895 - accuracy: 0.9173 - val_loss: 0.1937 - val_accuracy: 0.9181\n",
      "Epoch 555/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1811 - accuracy: 0.9204 - val_loss: 0.1795 - val_accuracy: 0.9222\n",
      "Epoch 556/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1743 - accuracy: 0.9232 - val_loss: 0.2030 - val_accuracy: 0.9155\n",
      "Epoch 557/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1842 - accuracy: 0.9197 - val_loss: 0.1897 - val_accuracy: 0.9196\n",
      "Epoch 558/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1744 - accuracy: 0.9236 - val_loss: 0.1826 - val_accuracy: 0.9220\n",
      "Epoch 559/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1733 - accuracy: 0.9244 - val_loss: 0.1849 - val_accuracy: 0.9191\n",
      "Epoch 560/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1701 - accuracy: 0.9247 - val_loss: 0.1774 - val_accuracy: 0.9235\n",
      "Epoch 561/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1773 - accuracy: 0.9222 - val_loss: 0.1780 - val_accuracy: 0.9240\n",
      "Epoch 562/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1884 - accuracy: 0.9182 - val_loss: 0.2013 - val_accuracy: 0.9177\n",
      "Epoch 563/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1781 - accuracy: 0.9222 - val_loss: 0.1971 - val_accuracy: 0.9196\n",
      "Epoch 564/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1794 - accuracy: 0.9211 - val_loss: 0.1817 - val_accuracy: 0.9219\n",
      "Epoch 565/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1827 - accuracy: 0.9203 - val_loss: 0.1987 - val_accuracy: 0.9172\n",
      "Epoch 566/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1785 - accuracy: 0.9221 - val_loss: 0.1802 - val_accuracy: 0.9238\n",
      "Epoch 567/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1795 - accuracy: 0.9221 - val_loss: 0.1898 - val_accuracy: 0.9211\n",
      "Epoch 568/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1880 - accuracy: 0.9175 - val_loss: 0.1818 - val_accuracy: 0.9204\n",
      "Epoch 569/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1896 - accuracy: 0.9184 - val_loss: 0.1975 - val_accuracy: 0.9170\n",
      "Epoch 570/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1784 - accuracy: 0.9220 - val_loss: 0.2388 - val_accuracy: 0.9078\n",
      "Epoch 571/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1840 - accuracy: 0.9197 - val_loss: 0.1909 - val_accuracy: 0.9206\n",
      "Epoch 572/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1771 - accuracy: 0.9221 - val_loss: 0.1766 - val_accuracy: 0.9263\n",
      "Epoch 573/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1808 - accuracy: 0.9205 - val_loss: 0.1910 - val_accuracy: 0.9196\n",
      "Epoch 574/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1727 - accuracy: 0.9241 - val_loss: 0.1838 - val_accuracy: 0.9226\n",
      "Epoch 575/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1786 - accuracy: 0.9215 - val_loss: 0.2227 - val_accuracy: 0.9102\n",
      "Epoch 576/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1837 - accuracy: 0.9193 - val_loss: 0.1868 - val_accuracy: 0.9225\n",
      "Epoch 577/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1936 - accuracy: 0.9173 - val_loss: 0.2347 - val_accuracy: 0.9054\n",
      "Epoch 578/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1955 - accuracy: 0.9163 - val_loss: 0.1770 - val_accuracy: 0.9246\n",
      "Epoch 579/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1732 - accuracy: 0.9242 - val_loss: 0.1764 - val_accuracy: 0.9250\n",
      "Epoch 580/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1799 - accuracy: 0.9214 - val_loss: 0.1932 - val_accuracy: 0.9156\n",
      "Epoch 581/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2018 - accuracy: 0.9134 - val_loss: 0.1992 - val_accuracy: 0.9164\n",
      "Epoch 582/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1903 - accuracy: 0.9182 - val_loss: 0.2047 - val_accuracy: 0.9159\n",
      "Epoch 583/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1736 - accuracy: 0.9239 - val_loss: 0.1774 - val_accuracy: 0.9238\n",
      "Epoch 584/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1901 - accuracy: 0.9184 - val_loss: 0.1789 - val_accuracy: 0.9262\n",
      "Epoch 585/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1954 - accuracy: 0.9162 - val_loss: 0.2113 - val_accuracy: 0.9081\n",
      "Epoch 586/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1834 - accuracy: 0.9211 - val_loss: 0.2122 - val_accuracy: 0.9130\n",
      "Epoch 587/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1799 - accuracy: 0.9218 - val_loss: 0.1887 - val_accuracy: 0.9192\n",
      "Epoch 588/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1822 - accuracy: 0.9209 - val_loss: 0.1791 - val_accuracy: 0.9241\n",
      "Epoch 589/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1736 - accuracy: 0.9235 - val_loss: 0.1941 - val_accuracy: 0.9178\n",
      "Epoch 590/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1745 - accuracy: 0.9233 - val_loss: 0.1945 - val_accuracy: 0.9196\n",
      "Epoch 591/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1913 - accuracy: 0.9177 - val_loss: 0.2250 - val_accuracy: 0.9111\n",
      "Epoch 592/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1726 - accuracy: 0.9245 - val_loss: 0.1773 - val_accuracy: 0.9262\n",
      "Epoch 593/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1812 - accuracy: 0.9202 - val_loss: 0.2291 - val_accuracy: 0.9108\n",
      "Epoch 594/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1724 - accuracy: 0.9236 - val_loss: 0.1906 - val_accuracy: 0.9194\n",
      "Epoch 595/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1724 - accuracy: 0.9243 - val_loss: 0.2078 - val_accuracy: 0.9173\n",
      "Epoch 596/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1844 - accuracy: 0.9203 - val_loss: 0.2105 - val_accuracy: 0.9113\n",
      "Epoch 597/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2031 - accuracy: 0.9141 - val_loss: 0.2037 - val_accuracy: 0.9126\n",
      "Epoch 598/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1905 - accuracy: 0.9173 - val_loss: 0.1901 - val_accuracy: 0.9196\n",
      "Epoch 599/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1857 - accuracy: 0.9203 - val_loss: 0.2549 - val_accuracy: 0.9042\n",
      "Epoch 600/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1922 - accuracy: 0.9180 - val_loss: 0.1936 - val_accuracy: 0.9173\n",
      "Epoch 601/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1744 - accuracy: 0.9238 - val_loss: 0.1863 - val_accuracy: 0.9228\n",
      "Epoch 602/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1859 - accuracy: 0.9200 - val_loss: 0.1967 - val_accuracy: 0.9174\n",
      "Epoch 603/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1762 - accuracy: 0.9225 - val_loss: 0.1817 - val_accuracy: 0.9211\n",
      "Epoch 604/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1763 - accuracy: 0.9231 - val_loss: 0.2058 - val_accuracy: 0.9185\n",
      "Epoch 605/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1822 - accuracy: 0.9199 - val_loss: 0.1896 - val_accuracy: 0.9187\n",
      "Epoch 606/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1689 - accuracy: 0.9260 - val_loss: 0.1889 - val_accuracy: 0.9185\n",
      "Epoch 607/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1902 - accuracy: 0.9168 - val_loss: 0.1895 - val_accuracy: 0.9211\n",
      "Epoch 608/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1791 - accuracy: 0.9216 - val_loss: 0.2088 - val_accuracy: 0.9138\n",
      "Epoch 609/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1801 - accuracy: 0.9214 - val_loss: 0.1784 - val_accuracy: 0.9240\n",
      "Epoch 610/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1791 - accuracy: 0.9212 - val_loss: 0.1878 - val_accuracy: 0.9220\n",
      "Epoch 611/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1841 - accuracy: 0.9189 - val_loss: 0.2049 - val_accuracy: 0.9153\n",
      "Epoch 612/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1901 - accuracy: 0.9177 - val_loss: 0.1867 - val_accuracy: 0.9218\n",
      "Epoch 613/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1788 - accuracy: 0.9226 - val_loss: 0.2199 - val_accuracy: 0.9094\n",
      "Epoch 614/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1802 - accuracy: 0.9208 - val_loss: 0.1854 - val_accuracy: 0.9230\n",
      "Epoch 615/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1779 - accuracy: 0.9222 - val_loss: 0.1782 - val_accuracy: 0.9239\n",
      "Epoch 616/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1913 - accuracy: 0.9167 - val_loss: 0.1900 - val_accuracy: 0.9220\n",
      "Epoch 617/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1746 - accuracy: 0.9239 - val_loss: 0.1859 - val_accuracy: 0.9214\n",
      "Epoch 618/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1752 - accuracy: 0.9232 - val_loss: 0.1827 - val_accuracy: 0.9221\n",
      "Epoch 619/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1771 - accuracy: 0.9231 - val_loss: 0.1933 - val_accuracy: 0.9193\n",
      "Epoch 620/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1849 - accuracy: 0.9197 - val_loss: 0.1885 - val_accuracy: 0.9204\n",
      "Epoch 621/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1726 - accuracy: 0.9246 - val_loss: 0.1740 - val_accuracy: 0.9264\n",
      "Epoch 622/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1772 - accuracy: 0.9221 - val_loss: 0.1910 - val_accuracy: 0.9175\n",
      "Epoch 623/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1749 - accuracy: 0.9234 - val_loss: 0.1845 - val_accuracy: 0.9206\n",
      "Epoch 624/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1747 - accuracy: 0.9235 - val_loss: 0.1898 - val_accuracy: 0.9212\n",
      "Epoch 625/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1671 - accuracy: 0.9261 - val_loss: 0.1801 - val_accuracy: 0.9256\n",
      "Epoch 626/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1874 - accuracy: 0.9189 - val_loss: 0.1923 - val_accuracy: 0.9186\n",
      "Epoch 627/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1788 - accuracy: 0.9219 - val_loss: 0.1811 - val_accuracy: 0.9223\n",
      "Epoch 628/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1727 - accuracy: 0.9240 - val_loss: 0.1947 - val_accuracy: 0.9187\n",
      "Epoch 629/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1761 - accuracy: 0.9228 - val_loss: 0.1885 - val_accuracy: 0.9218\n",
      "Epoch 630/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1881 - accuracy: 0.9186 - val_loss: 0.1869 - val_accuracy: 0.9235\n",
      "Epoch 631/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1863 - accuracy: 0.9192 - val_loss: 0.2028 - val_accuracy: 0.9164\n",
      "Epoch 632/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1789 - accuracy: 0.9222 - val_loss: 0.2095 - val_accuracy: 0.9150\n",
      "Epoch 633/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1716 - accuracy: 0.9248 - val_loss: 0.2022 - val_accuracy: 0.9174\n",
      "Epoch 634/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1908 - accuracy: 0.9173 - val_loss: 0.1871 - val_accuracy: 0.9204\n",
      "Epoch 635/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1851 - accuracy: 0.9202 - val_loss: 0.1875 - val_accuracy: 0.9219\n",
      "Epoch 636/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1838 - accuracy: 0.9205 - val_loss: 0.1882 - val_accuracy: 0.9219\n",
      "Epoch 637/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2071 - accuracy: 0.9135 - val_loss: 0.2557 - val_accuracy: 0.8951\n",
      "Epoch 638/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1960 - accuracy: 0.9157 - val_loss: 0.2020 - val_accuracy: 0.9148\n",
      "Epoch 639/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1811 - accuracy: 0.9209 - val_loss: 0.2045 - val_accuracy: 0.9172\n",
      "Epoch 640/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1776 - accuracy: 0.9231 - val_loss: 0.2348 - val_accuracy: 0.8995\n",
      "Epoch 641/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1884 - accuracy: 0.9187 - val_loss: 0.1869 - val_accuracy: 0.9202\n",
      "Epoch 642/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1816 - accuracy: 0.9208 - val_loss: 0.1815 - val_accuracy: 0.9251\n",
      "Epoch 643/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1733 - accuracy: 0.9240 - val_loss: 0.1937 - val_accuracy: 0.9178\n",
      "Epoch 644/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1747 - accuracy: 0.9227 - val_loss: 0.2120 - val_accuracy: 0.9147\n",
      "Epoch 645/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1820 - accuracy: 0.9201 - val_loss: 0.1905 - val_accuracy: 0.9195\n",
      "Epoch 646/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1766 - accuracy: 0.9223 - val_loss: 0.1899 - val_accuracy: 0.9196\n",
      "Epoch 647/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2024 - accuracy: 0.9145 - val_loss: 0.2090 - val_accuracy: 0.9124\n",
      "Epoch 648/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1726 - accuracy: 0.9240 - val_loss: 0.1865 - val_accuracy: 0.9211\n",
      "Epoch 649/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1868 - accuracy: 0.9191 - val_loss: 0.1786 - val_accuracy: 0.9219\n",
      "Epoch 650/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1736 - accuracy: 0.9238 - val_loss: 0.2074 - val_accuracy: 0.9154\n",
      "Epoch 651/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1829 - accuracy: 0.9204 - val_loss: 0.1982 - val_accuracy: 0.9182\n",
      "Epoch 652/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1829 - accuracy: 0.9201 - val_loss: 0.1899 - val_accuracy: 0.9183\n",
      "Epoch 653/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1811 - accuracy: 0.9212 - val_loss: 0.2049 - val_accuracy: 0.9155\n",
      "Epoch 654/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1890 - accuracy: 0.9176 - val_loss: 0.1903 - val_accuracy: 0.9186\n",
      "Epoch 655/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1762 - accuracy: 0.9231 - val_loss: 0.1811 - val_accuracy: 0.9240\n",
      "Epoch 656/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1731 - accuracy: 0.9243 - val_loss: 0.1897 - val_accuracy: 0.9216\n",
      "Epoch 657/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1741 - accuracy: 0.9235 - val_loss: 0.1910 - val_accuracy: 0.9203\n",
      "Epoch 658/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1799 - accuracy: 0.9222 - val_loss: 0.1848 - val_accuracy: 0.9214\n",
      "Epoch 659/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1775 - accuracy: 0.9219 - val_loss: 0.1984 - val_accuracy: 0.9159\n",
      "Epoch 660/1000\n",
      "87/87 [==============================] - 4s 41ms/step - loss: 0.1976 - accuracy: 0.9151 - val_loss: 0.1780 - val_accuracy: 0.9245\n",
      "Epoch 661/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1735 - accuracy: 0.9243 - val_loss: 0.1950 - val_accuracy: 0.9152\n",
      "Epoch 662/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1774 - accuracy: 0.9228 - val_loss: 0.1802 - val_accuracy: 0.9204\n",
      "Epoch 663/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1706 - accuracy: 0.9248 - val_loss: 0.1886 - val_accuracy: 0.9217\n",
      "Epoch 664/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1774 - accuracy: 0.9227 - val_loss: 0.2000 - val_accuracy: 0.9181\n",
      "Epoch 665/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1793 - accuracy: 0.9219 - val_loss: 0.1820 - val_accuracy: 0.9232\n",
      "Epoch 666/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1834 - accuracy: 0.9203 - val_loss: 0.1886 - val_accuracy: 0.9202\n",
      "Epoch 667/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1943 - accuracy: 0.9157 - val_loss: 0.2050 - val_accuracy: 0.9153\n",
      "Epoch 668/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2299 - accuracy: 0.9048 - val_loss: 0.1981 - val_accuracy: 0.9165\n",
      "Epoch 669/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1915 - accuracy: 0.9177 - val_loss: 0.1853 - val_accuracy: 0.9205\n",
      "Epoch 670/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1801 - accuracy: 0.9216 - val_loss: 0.1965 - val_accuracy: 0.9197\n",
      "Epoch 671/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1800 - accuracy: 0.9215 - val_loss: 0.1810 - val_accuracy: 0.9250\n",
      "Epoch 672/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1868 - accuracy: 0.9200 - val_loss: 0.2210 - val_accuracy: 0.9092\n",
      "Epoch 673/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1899 - accuracy: 0.9185 - val_loss: 0.2062 - val_accuracy: 0.9111\n",
      "Epoch 674/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1843 - accuracy: 0.9199 - val_loss: 0.1887 - val_accuracy: 0.9207\n",
      "Epoch 675/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1864 - accuracy: 0.9187 - val_loss: 0.1895 - val_accuracy: 0.9210\n",
      "Epoch 676/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1824 - accuracy: 0.9206 - val_loss: 0.1771 - val_accuracy: 0.9257\n",
      "Epoch 677/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1760 - accuracy: 0.9232 - val_loss: 0.1909 - val_accuracy: 0.9187\n",
      "Epoch 678/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1731 - accuracy: 0.9245 - val_loss: 0.1821 - val_accuracy: 0.9242\n",
      "Epoch 679/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1781 - accuracy: 0.9225 - val_loss: 0.1795 - val_accuracy: 0.9239\n",
      "Epoch 680/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1703 - accuracy: 0.9243 - val_loss: 0.1819 - val_accuracy: 0.9220\n",
      "Epoch 681/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1846 - accuracy: 0.9196 - val_loss: 0.1966 - val_accuracy: 0.9181\n",
      "Epoch 682/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1762 - accuracy: 0.9229 - val_loss: 0.1840 - val_accuracy: 0.9234\n",
      "Epoch 683/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.1771 - val_accuracy: 0.9248\n",
      "Epoch 684/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1766 - accuracy: 0.9232 - val_loss: 0.1893 - val_accuracy: 0.9188\n",
      "Epoch 685/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1913 - accuracy: 0.9172 - val_loss: 0.1995 - val_accuracy: 0.9175\n",
      "Epoch 686/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1804 - accuracy: 0.9211 - val_loss: 0.1827 - val_accuracy: 0.9218\n",
      "Epoch 687/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1735 - accuracy: 0.9244 - val_loss: 0.2335 - val_accuracy: 0.9014\n",
      "Epoch 688/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1778 - accuracy: 0.9220 - val_loss: 0.1855 - val_accuracy: 0.9224\n",
      "Epoch 689/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1781 - accuracy: 0.9230 - val_loss: 0.1915 - val_accuracy: 0.9204\n",
      "Epoch 690/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1765 - accuracy: 0.9234 - val_loss: 0.2049 - val_accuracy: 0.9152\n",
      "Epoch 691/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2252 - accuracy: 0.9061 - val_loss: 0.2075 - val_accuracy: 0.9124\n",
      "Epoch 692/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1896 - accuracy: 0.9184 - val_loss: 0.1959 - val_accuracy: 0.9186\n",
      "Epoch 693/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1893 - accuracy: 0.9214 - val_loss: 0.1873 - val_accuracy: 0.9219\n",
      "Epoch 694/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1962 - accuracy: 0.9160 - val_loss: 0.2003 - val_accuracy: 0.9188\n",
      "Epoch 695/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1961 - accuracy: 0.9154 - val_loss: 0.1827 - val_accuracy: 0.9227\n",
      "Epoch 696/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1831 - accuracy: 0.9207 - val_loss: 0.1821 - val_accuracy: 0.9234\n",
      "Epoch 697/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1761 - accuracy: 0.9233 - val_loss: 0.1810 - val_accuracy: 0.9237\n",
      "Epoch 698/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1724 - accuracy: 0.9241 - val_loss: 0.2021 - val_accuracy: 0.9155\n",
      "Epoch 699/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1788 - accuracy: 0.9224 - val_loss: 0.2240 - val_accuracy: 0.9133\n",
      "Epoch 700/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1848 - accuracy: 0.9203 - val_loss: 0.1751 - val_accuracy: 0.9258\n",
      "Epoch 701/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1731 - accuracy: 0.9246 - val_loss: 0.1802 - val_accuracy: 0.9257\n",
      "Epoch 702/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1717 - accuracy: 0.9247 - val_loss: 0.1944 - val_accuracy: 0.9152\n",
      "Epoch 703/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1935 - accuracy: 0.9173 - val_loss: 0.2610 - val_accuracy: 0.9008\n",
      "Epoch 704/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1906 - accuracy: 0.9175 - val_loss: 0.1791 - val_accuracy: 0.9257\n",
      "Epoch 705/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1776 - accuracy: 0.9228 - val_loss: 0.2169 - val_accuracy: 0.9045\n",
      "Epoch 706/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1812 - accuracy: 0.9207 - val_loss: 0.1923 - val_accuracy: 0.9191\n",
      "Epoch 707/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1774 - accuracy: 0.9224 - val_loss: 0.1841 - val_accuracy: 0.9222\n",
      "Epoch 708/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1769 - accuracy: 0.9230 - val_loss: 0.2008 - val_accuracy: 0.9188\n",
      "Epoch 709/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1852 - accuracy: 0.9195 - val_loss: 0.1932 - val_accuracy: 0.9191\n",
      "Epoch 710/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1753 - accuracy: 0.9236 - val_loss: 0.2142 - val_accuracy: 0.9089\n",
      "Epoch 711/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1880 - accuracy: 0.9182 - val_loss: 0.2032 - val_accuracy: 0.9167\n",
      "Epoch 712/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1783 - accuracy: 0.9226 - val_loss: 0.2399 - val_accuracy: 0.9097\n",
      "Epoch 713/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1898 - accuracy: 0.9179 - val_loss: 0.1887 - val_accuracy: 0.9209\n",
      "Epoch 714/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1813 - accuracy: 0.9209 - val_loss: 0.1993 - val_accuracy: 0.9168\n",
      "Epoch 715/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1739 - accuracy: 0.9241 - val_loss: 0.1878 - val_accuracy: 0.9199\n",
      "Epoch 716/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1868 - accuracy: 0.9205 - val_loss: 0.1767 - val_accuracy: 0.9266\n",
      "Epoch 717/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1705 - accuracy: 0.9243 - val_loss: 0.1797 - val_accuracy: 0.9232\n",
      "Epoch 718/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1791 - accuracy: 0.9219 - val_loss: 0.1853 - val_accuracy: 0.9198\n",
      "Epoch 719/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1699 - accuracy: 0.9256 - val_loss: 0.1917 - val_accuracy: 0.9214\n",
      "Epoch 720/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1802 - accuracy: 0.9215 - val_loss: 0.2065 - val_accuracy: 0.9130\n",
      "Epoch 721/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1837 - accuracy: 0.9204 - val_loss: 0.2194 - val_accuracy: 0.9105\n",
      "Epoch 722/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1815 - accuracy: 0.9223 - val_loss: 0.1851 - val_accuracy: 0.9199\n",
      "Epoch 723/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1778 - accuracy: 0.9226 - val_loss: 0.1824 - val_accuracy: 0.9245\n",
      "Epoch 724/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1812 - accuracy: 0.9209 - val_loss: 0.1827 - val_accuracy: 0.9243\n",
      "Epoch 725/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1747 - accuracy: 0.9237 - val_loss: 0.2006 - val_accuracy: 0.9147\n",
      "Epoch 726/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1776 - accuracy: 0.9224 - val_loss: 0.1912 - val_accuracy: 0.9174\n",
      "Epoch 727/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1729 - accuracy: 0.9244 - val_loss: 0.1779 - val_accuracy: 0.9243\n",
      "Epoch 728/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1698 - accuracy: 0.9249 - val_loss: 0.1719 - val_accuracy: 0.9271\n",
      "Epoch 729/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1741 - accuracy: 0.9236 - val_loss: 0.1855 - val_accuracy: 0.9216\n",
      "Epoch 730/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1722 - accuracy: 0.9241 - val_loss: 0.2026 - val_accuracy: 0.9135\n",
      "Epoch 731/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1781 - accuracy: 0.9221 - val_loss: 0.1887 - val_accuracy: 0.9202\n",
      "Epoch 732/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1913 - accuracy: 0.9178 - val_loss: 0.1934 - val_accuracy: 0.9214\n",
      "Epoch 733/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1780 - accuracy: 0.9222 - val_loss: 0.1929 - val_accuracy: 0.9161\n",
      "Epoch 734/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1798 - accuracy: 0.9204 - val_loss: 0.2000 - val_accuracy: 0.9184\n",
      "Epoch 735/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1897 - accuracy: 0.9185 - val_loss: 0.1946 - val_accuracy: 0.9173\n",
      "Epoch 736/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1929 - accuracy: 0.9172 - val_loss: 0.1963 - val_accuracy: 0.9168\n",
      "Epoch 737/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1809 - accuracy: 0.9221 - val_loss: 0.1767 - val_accuracy: 0.9238\n",
      "Epoch 738/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1688 - accuracy: 0.9257 - val_loss: 0.1920 - val_accuracy: 0.9170\n",
      "Epoch 739/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1751 - accuracy: 0.9234 - val_loss: 0.1875 - val_accuracy: 0.9200\n",
      "Epoch 740/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1775 - accuracy: 0.9221 - val_loss: 0.2023 - val_accuracy: 0.9162\n",
      "Epoch 741/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1794 - accuracy: 0.9211 - val_loss: 0.2095 - val_accuracy: 0.9114\n",
      "Epoch 742/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1808 - accuracy: 0.9206 - val_loss: 0.1741 - val_accuracy: 0.9263\n",
      "Epoch 743/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1718 - accuracy: 0.9246 - val_loss: 0.1995 - val_accuracy: 0.9197\n",
      "Epoch 744/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1751 - accuracy: 0.9242 - val_loss: 0.2061 - val_accuracy: 0.9159\n",
      "Epoch 745/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1814 - accuracy: 0.9204 - val_loss: 0.2115 - val_accuracy: 0.9100\n",
      "Epoch 746/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1884 - accuracy: 0.9183 - val_loss: 0.2291 - val_accuracy: 0.9090\n",
      "Epoch 747/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1858 - accuracy: 0.9194 - val_loss: 0.1926 - val_accuracy: 0.9199\n",
      "Epoch 748/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1857 - accuracy: 0.9191 - val_loss: 0.2123 - val_accuracy: 0.9143\n",
      "Epoch 749/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1865 - accuracy: 0.9180 - val_loss: 0.1944 - val_accuracy: 0.9185\n",
      "Epoch 750/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1839 - accuracy: 0.9202 - val_loss: 0.1860 - val_accuracy: 0.9210\n",
      "Epoch 751/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1824 - accuracy: 0.9203 - val_loss: 0.2047 - val_accuracy: 0.9165\n",
      "Epoch 752/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1866 - accuracy: 0.9197 - val_loss: 0.1934 - val_accuracy: 0.9176\n",
      "Epoch 753/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1891 - accuracy: 0.9185 - val_loss: 0.2008 - val_accuracy: 0.9162\n",
      "Epoch 754/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1836 - accuracy: 0.9198 - val_loss: 0.1823 - val_accuracy: 0.9231\n",
      "Epoch 755/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1722 - accuracy: 0.9241 - val_loss: 0.1939 - val_accuracy: 0.9201\n",
      "Epoch 756/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2106 - accuracy: 0.9114 - val_loss: 0.1951 - val_accuracy: 0.9167\n",
      "Epoch 757/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1819 - accuracy: 0.9208 - val_loss: 0.1920 - val_accuracy: 0.9211\n",
      "Epoch 758/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1863 - accuracy: 0.9189 - val_loss: 0.1928 - val_accuracy: 0.9190\n",
      "Epoch 759/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1690 - accuracy: 0.9255 - val_loss: 0.1758 - val_accuracy: 0.9268\n",
      "Epoch 760/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1755 - accuracy: 0.9221 - val_loss: 0.1854 - val_accuracy: 0.9222\n",
      "Epoch 761/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1701 - accuracy: 0.9253 - val_loss: 0.1797 - val_accuracy: 0.9236\n",
      "Epoch 762/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1718 - accuracy: 0.9240 - val_loss: 0.1888 - val_accuracy: 0.9205\n",
      "Epoch 763/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1897 - accuracy: 0.9175 - val_loss: 0.1942 - val_accuracy: 0.9206\n",
      "Epoch 764/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1717 - accuracy: 0.9256 - val_loss: 0.1986 - val_accuracy: 0.9185\n",
      "Epoch 765/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2009 - accuracy: 0.9145 - val_loss: 0.1996 - val_accuracy: 0.9192\n",
      "Epoch 766/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1707 - accuracy: 0.9247 - val_loss: 0.1790 - val_accuracy: 0.9239\n",
      "Epoch 767/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1985 - accuracy: 0.9141 - val_loss: 0.1975 - val_accuracy: 0.9178\n",
      "Epoch 768/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1770 - accuracy: 0.9218 - val_loss: 0.2231 - val_accuracy: 0.9035\n",
      "Epoch 769/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1927 - accuracy: 0.9174 - val_loss: 0.1949 - val_accuracy: 0.9162\n",
      "Epoch 770/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1759 - accuracy: 0.9226 - val_loss: 0.2079 - val_accuracy: 0.9181\n",
      "Epoch 771/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1857 - accuracy: 0.9200 - val_loss: 0.1979 - val_accuracy: 0.9216\n",
      "Epoch 772/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1916 - accuracy: 0.9176 - val_loss: 0.1947 - val_accuracy: 0.9172\n",
      "Epoch 773/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1757 - accuracy: 0.9239 - val_loss: 0.2191 - val_accuracy: 0.9106\n",
      "Epoch 774/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1740 - accuracy: 0.9241 - val_loss: 0.1889 - val_accuracy: 0.9207\n",
      "Epoch 775/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1868 - accuracy: 0.9190 - val_loss: 0.1862 - val_accuracy: 0.9220\n",
      "Epoch 776/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1680 - accuracy: 0.9256 - val_loss: 0.1781 - val_accuracy: 0.9230\n",
      "Epoch 777/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1655 - accuracy: 0.9275 - val_loss: 0.1762 - val_accuracy: 0.9265\n",
      "Epoch 778/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1750 - accuracy: 0.9231 - val_loss: 0.1907 - val_accuracy: 0.9182\n",
      "Epoch 779/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1726 - accuracy: 0.9243 - val_loss: 0.1818 - val_accuracy: 0.9218\n",
      "Epoch 780/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1802 - accuracy: 0.9221 - val_loss: 0.1897 - val_accuracy: 0.9164\n",
      "Epoch 781/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2081 - accuracy: 0.9121 - val_loss: 0.2165 - val_accuracy: 0.9132\n",
      "Epoch 782/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1883 - accuracy: 0.9190 - val_loss: 0.1945 - val_accuracy: 0.9199\n",
      "Epoch 783/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1903 - accuracy: 0.9179 - val_loss: 0.1864 - val_accuracy: 0.9231\n",
      "Epoch 784/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1775 - accuracy: 0.9232 - val_loss: 0.1922 - val_accuracy: 0.9211\n",
      "Epoch 785/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1770 - accuracy: 0.9225 - val_loss: 0.1933 - val_accuracy: 0.9187\n",
      "Epoch 786/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2089 - accuracy: 0.9136 - val_loss: 0.2187 - val_accuracy: 0.9129\n",
      "Epoch 787/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1884 - accuracy: 0.9189 - val_loss: 0.2030 - val_accuracy: 0.9163\n",
      "Epoch 788/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1925 - accuracy: 0.9172 - val_loss: 0.1930 - val_accuracy: 0.9204\n",
      "Epoch 789/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1846 - accuracy: 0.9202 - val_loss: 0.1976 - val_accuracy: 0.9194\n",
      "Epoch 790/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1896 - accuracy: 0.9182 - val_loss: 0.1867 - val_accuracy: 0.9218\n",
      "Epoch 791/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1779 - accuracy: 0.9227 - val_loss: 0.1853 - val_accuracy: 0.9208\n",
      "Epoch 792/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1846 - accuracy: 0.9204 - val_loss: 0.1983 - val_accuracy: 0.9170\n",
      "Epoch 793/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1834 - accuracy: 0.9204 - val_loss: 0.1966 - val_accuracy: 0.9196\n",
      "Epoch 794/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1844 - accuracy: 0.9195 - val_loss: 0.2010 - val_accuracy: 0.9178\n",
      "Epoch 795/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1978 - accuracy: 0.9149 - val_loss: 0.1867 - val_accuracy: 0.9213\n",
      "Epoch 796/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1834 - accuracy: 0.9211 - val_loss: 0.1833 - val_accuracy: 0.9243\n",
      "Epoch 797/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1914 - accuracy: 0.9174 - val_loss: 0.2077 - val_accuracy: 0.9128\n",
      "Epoch 798/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1861 - accuracy: 0.9188 - val_loss: 0.1945 - val_accuracy: 0.9183\n",
      "Epoch 799/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1739 - accuracy: 0.9234 - val_loss: 0.2014 - val_accuracy: 0.9180\n",
      "Epoch 800/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1834 - accuracy: 0.9212 - val_loss: 0.1919 - val_accuracy: 0.9179\n",
      "Epoch 801/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1968 - accuracy: 0.9155 - val_loss: 0.1949 - val_accuracy: 0.9183\n",
      "Epoch 802/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1875 - accuracy: 0.9185 - val_loss: 0.2117 - val_accuracy: 0.9111\n",
      "Epoch 803/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1855 - accuracy: 0.9193 - val_loss: 0.2000 - val_accuracy: 0.9153\n",
      "Epoch 804/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1934 - accuracy: 0.9166 - val_loss: 0.2186 - val_accuracy: 0.9127\n",
      "Epoch 805/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1766 - accuracy: 0.9227 - val_loss: 0.1888 - val_accuracy: 0.9209\n",
      "Epoch 806/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1775 - accuracy: 0.9227 - val_loss: 0.2006 - val_accuracy: 0.9170\n",
      "Epoch 807/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1766 - accuracy: 0.9218 - val_loss: 0.1957 - val_accuracy: 0.9156\n",
      "Epoch 808/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1770 - accuracy: 0.9227 - val_loss: 0.1957 - val_accuracy: 0.9190\n",
      "Epoch 809/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1780 - accuracy: 0.9229 - val_loss: 0.1845 - val_accuracy: 0.9235\n",
      "Epoch 810/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1795 - accuracy: 0.9223 - val_loss: 0.1785 - val_accuracy: 0.9248\n",
      "Epoch 811/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1802 - accuracy: 0.9215 - val_loss: 0.1766 - val_accuracy: 0.9246\n",
      "Epoch 812/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1700 - accuracy: 0.9253 - val_loss: 0.1810 - val_accuracy: 0.9248\n",
      "Epoch 813/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1775 - accuracy: 0.9234 - val_loss: 0.1904 - val_accuracy: 0.9191\n",
      "Epoch 814/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1726 - accuracy: 0.9245 - val_loss: 0.2123 - val_accuracy: 0.9135\n",
      "Epoch 815/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1837 - accuracy: 0.9197 - val_loss: 0.2071 - val_accuracy: 0.9147\n",
      "Epoch 816/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1765 - accuracy: 0.9223 - val_loss: 0.1906 - val_accuracy: 0.9213\n",
      "Epoch 817/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1864 - accuracy: 0.9195 - val_loss: 0.1852 - val_accuracy: 0.9214\n",
      "Epoch 818/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1876 - accuracy: 0.9188 - val_loss: 0.2226 - val_accuracy: 0.9118\n",
      "Epoch 819/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2042 - accuracy: 0.9134 - val_loss: 0.1884 - val_accuracy: 0.9195\n",
      "Epoch 820/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1883 - accuracy: 0.9184 - val_loss: 0.1833 - val_accuracy: 0.9216\n",
      "Epoch 821/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1846 - accuracy: 0.9198 - val_loss: 0.1855 - val_accuracy: 0.9225\n",
      "Epoch 822/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2261 - accuracy: 0.9067 - val_loss: 0.2937 - val_accuracy: 0.8890\n",
      "Epoch 823/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2372 - accuracy: 0.9012 - val_loss: 0.2235 - val_accuracy: 0.9099\n",
      "Epoch 824/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2055 - accuracy: 0.9122 - val_loss: 0.1926 - val_accuracy: 0.9192\n",
      "Epoch 825/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1903 - accuracy: 0.9185 - val_loss: 0.1986 - val_accuracy: 0.9209\n",
      "Epoch 826/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1935 - accuracy: 0.9172 - val_loss: 0.2229 - val_accuracy: 0.9120\n",
      "Epoch 827/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1955 - accuracy: 0.9171 - val_loss: 0.1890 - val_accuracy: 0.9232\n",
      "Epoch 828/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1976 - accuracy: 0.9173 - val_loss: 0.2439 - val_accuracy: 0.9041\n",
      "Epoch 829/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2066 - accuracy: 0.9130 - val_loss: 0.2003 - val_accuracy: 0.9174\n",
      "Epoch 830/1000\n",
      "87/87 [==============================] - 4s 46ms/step - loss: 0.1873 - accuracy: 0.9192 - val_loss: 0.1901 - val_accuracy: 0.9216\n",
      "Epoch 831/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.2507 - accuracy: 0.9024 - val_loss: 0.2200 - val_accuracy: 0.9165\n",
      "Epoch 832/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2025 - accuracy: 0.9160 - val_loss: 0.1930 - val_accuracy: 0.9239\n",
      "Epoch 833/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1939 - accuracy: 0.9186 - val_loss: 0.2175 - val_accuracy: 0.9143\n",
      "Epoch 834/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1874 - accuracy: 0.9191 - val_loss: 0.1817 - val_accuracy: 0.9244\n",
      "Epoch 835/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1768 - accuracy: 0.9229 - val_loss: 0.1894 - val_accuracy: 0.9181\n",
      "Epoch 836/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1782 - accuracy: 0.9221 - val_loss: 0.2118 - val_accuracy: 0.9135\n",
      "Epoch 837/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1816 - accuracy: 0.9216 - val_loss: 0.2126 - val_accuracy: 0.9175\n",
      "Epoch 838/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1836 - accuracy: 0.9207 - val_loss: 0.2131 - val_accuracy: 0.9115\n",
      "Epoch 839/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1959 - accuracy: 0.9165 - val_loss: 0.2012 - val_accuracy: 0.9146\n",
      "Epoch 840/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1798 - accuracy: 0.9220 - val_loss: 0.2052 - val_accuracy: 0.9170\n",
      "Epoch 841/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1807 - accuracy: 0.9218 - val_loss: 0.1992 - val_accuracy: 0.9160\n",
      "Epoch 842/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1807 - accuracy: 0.9214 - val_loss: 0.1896 - val_accuracy: 0.9200\n",
      "Epoch 843/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1857 - accuracy: 0.9201 - val_loss: 0.1890 - val_accuracy: 0.9169\n",
      "Epoch 844/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1839 - accuracy: 0.9194 - val_loss: 0.1868 - val_accuracy: 0.9231\n",
      "Epoch 845/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1751 - accuracy: 0.9239 - val_loss: 0.1896 - val_accuracy: 0.9209\n",
      "Epoch 846/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1878 - accuracy: 0.9195 - val_loss: 0.1895 - val_accuracy: 0.9191\n",
      "Epoch 847/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1824 - accuracy: 0.9205 - val_loss: 0.1887 - val_accuracy: 0.9217\n",
      "Epoch 848/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1751 - accuracy: 0.9234 - val_loss: 0.2041 - val_accuracy: 0.9130\n",
      "Epoch 849/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1973 - accuracy: 0.9167 - val_loss: 0.2251 - val_accuracy: 0.9091\n",
      "Epoch 850/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1917 - accuracy: 0.9185 - val_loss: 0.1857 - val_accuracy: 0.9227\n",
      "Epoch 851/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1862 - accuracy: 0.9192 - val_loss: 0.1894 - val_accuracy: 0.9176\n",
      "Epoch 852/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1786 - accuracy: 0.9219 - val_loss: 0.1848 - val_accuracy: 0.9229\n",
      "Epoch 853/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1784 - accuracy: 0.9229 - val_loss: 0.1897 - val_accuracy: 0.9215\n",
      "Epoch 854/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1810 - accuracy: 0.9224 - val_loss: 0.1866 - val_accuracy: 0.9235\n",
      "Epoch 855/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1732 - accuracy: 0.9241 - val_loss: 0.1852 - val_accuracy: 0.9215\n",
      "Epoch 856/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1840 - accuracy: 0.9203 - val_loss: 0.1860 - val_accuracy: 0.9236\n",
      "Epoch 857/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1819 - accuracy: 0.9224 - val_loss: 0.1890 - val_accuracy: 0.9201\n",
      "Epoch 858/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1828 - accuracy: 0.9205 - val_loss: 0.1926 - val_accuracy: 0.9194\n",
      "Epoch 859/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1935 - accuracy: 0.9171 - val_loss: 0.1972 - val_accuracy: 0.9184\n",
      "Epoch 860/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1826 - accuracy: 0.9206 - val_loss: 0.1849 - val_accuracy: 0.9224\n",
      "Epoch 861/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1765 - accuracy: 0.9228 - val_loss: 0.2045 - val_accuracy: 0.9171\n",
      "Epoch 862/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1830 - accuracy: 0.9213 - val_loss: 0.1905 - val_accuracy: 0.9188\n",
      "Epoch 863/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1886 - accuracy: 0.9185 - val_loss: 0.1948 - val_accuracy: 0.9194\n",
      "Epoch 864/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1745 - accuracy: 0.9234 - val_loss: 0.2172 - val_accuracy: 0.9140\n",
      "Epoch 865/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2058 - accuracy: 0.9117 - val_loss: 0.1967 - val_accuracy: 0.9196\n",
      "Epoch 866/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1817 - accuracy: 0.9200 - val_loss: 0.2122 - val_accuracy: 0.9140\n",
      "Epoch 867/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1747 - accuracy: 0.9231 - val_loss: 0.1824 - val_accuracy: 0.9260\n",
      "Epoch 868/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1815 - accuracy: 0.9209 - val_loss: 0.1853 - val_accuracy: 0.9232\n",
      "Epoch 869/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2073 - accuracy: 0.9128 - val_loss: 0.1895 - val_accuracy: 0.9202\n",
      "Epoch 870/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1918 - accuracy: 0.9164 - val_loss: 0.1824 - val_accuracy: 0.9227\n",
      "Epoch 871/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1965 - accuracy: 0.9174 - val_loss: 0.2523 - val_accuracy: 0.8997\n",
      "Epoch 872/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2378 - accuracy: 0.9064 - val_loss: 0.2665 - val_accuracy: 0.8919\n",
      "Epoch 873/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2171 - accuracy: 0.9098 - val_loss: 0.1962 - val_accuracy: 0.9193\n",
      "Epoch 874/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1813 - accuracy: 0.9223 - val_loss: 0.1835 - val_accuracy: 0.9223\n",
      "Epoch 875/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1743 - accuracy: 0.9247 - val_loss: 0.1979 - val_accuracy: 0.9190\n",
      "Epoch 876/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1753 - accuracy: 0.9236 - val_loss: 0.1908 - val_accuracy: 0.9207\n",
      "Epoch 877/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1899 - accuracy: 0.9187 - val_loss: 0.1907 - val_accuracy: 0.9198\n",
      "Epoch 878/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1798 - accuracy: 0.9216 - val_loss: 0.2107 - val_accuracy: 0.9103\n",
      "Epoch 879/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1840 - accuracy: 0.9197 - val_loss: 0.1858 - val_accuracy: 0.9212\n",
      "Epoch 880/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1753 - accuracy: 0.9249 - val_loss: 0.1949 - val_accuracy: 0.9184\n",
      "Epoch 881/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2260 - accuracy: 0.9085 - val_loss: 0.2822 - val_accuracy: 0.8841\n",
      "Epoch 882/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2335 - accuracy: 0.9031 - val_loss: 0.2363 - val_accuracy: 0.9038\n",
      "Epoch 883/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2157 - accuracy: 0.9092 - val_loss: 0.2038 - val_accuracy: 0.9157\n",
      "Epoch 884/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2013 - accuracy: 0.9140 - val_loss: 0.2331 - val_accuracy: 0.9041\n",
      "Epoch 885/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2073 - accuracy: 0.9129 - val_loss: 0.2034 - val_accuracy: 0.9156\n",
      "Epoch 886/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1877 - accuracy: 0.9194 - val_loss: 0.1930 - val_accuracy: 0.9201\n",
      "Epoch 887/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1983 - accuracy: 0.9150 - val_loss: 0.2286 - val_accuracy: 0.9096\n",
      "Epoch 888/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1900 - accuracy: 0.9178 - val_loss: 0.1953 - val_accuracy: 0.9185\n",
      "Epoch 889/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1973 - accuracy: 0.9146 - val_loss: 0.2161 - val_accuracy: 0.9063\n",
      "Epoch 890/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1854 - accuracy: 0.9196 - val_loss: 0.2002 - val_accuracy: 0.9159\n",
      "Epoch 891/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2041 - accuracy: 0.9141 - val_loss: 0.2415 - val_accuracy: 0.9050\n",
      "Epoch 892/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2005 - accuracy: 0.9145 - val_loss: 0.1885 - val_accuracy: 0.9216\n",
      "Epoch 893/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1813 - accuracy: 0.9223 - val_loss: 0.2093 - val_accuracy: 0.9112\n",
      "Epoch 894/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1805 - accuracy: 0.9215 - val_loss: 0.2143 - val_accuracy: 0.9110\n",
      "Epoch 895/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1988 - accuracy: 0.9149 - val_loss: 0.1890 - val_accuracy: 0.9208\n",
      "Epoch 896/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1913 - accuracy: 0.9184 - val_loss: 0.1947 - val_accuracy: 0.9188\n",
      "Epoch 897/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1795 - accuracy: 0.9209 - val_loss: 0.1873 - val_accuracy: 0.9199\n",
      "Epoch 898/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1812 - accuracy: 0.9217 - val_loss: 0.1824 - val_accuracy: 0.9230\n",
      "Epoch 899/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1948 - accuracy: 0.9198 - val_loss: 0.2491 - val_accuracy: 0.9015\n",
      "Epoch 900/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1878 - accuracy: 0.9185 - val_loss: 0.1931 - val_accuracy: 0.9184\n",
      "Epoch 901/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1865 - accuracy: 0.9196 - val_loss: 0.1944 - val_accuracy: 0.9167\n",
      "Epoch 902/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1953 - accuracy: 0.9167 - val_loss: 0.2205 - val_accuracy: 0.9110\n",
      "Epoch 903/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1788 - accuracy: 0.9229 - val_loss: 0.1774 - val_accuracy: 0.9252\n",
      "Epoch 904/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1753 - accuracy: 0.9233 - val_loss: 0.2052 - val_accuracy: 0.9130\n",
      "Epoch 905/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2054 - accuracy: 0.9126 - val_loss: 0.2002 - val_accuracy: 0.9179\n",
      "Epoch 906/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2332 - accuracy: 0.9035 - val_loss: 0.1991 - val_accuracy: 0.9171\n",
      "Epoch 907/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1950 - accuracy: 0.9167 - val_loss: 0.2161 - val_accuracy: 0.9111\n",
      "Epoch 908/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1815 - accuracy: 0.9212 - val_loss: 0.1906 - val_accuracy: 0.9223\n",
      "Epoch 909/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1836 - accuracy: 0.9213 - val_loss: 0.2011 - val_accuracy: 0.9161\n",
      "Epoch 910/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1815 - accuracy: 0.9211 - val_loss: 0.1844 - val_accuracy: 0.9209\n",
      "Epoch 911/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1767 - accuracy: 0.9223 - val_loss: 0.1970 - val_accuracy: 0.9162\n",
      "Epoch 912/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1886 - accuracy: 0.9180 - val_loss: 0.1888 - val_accuracy: 0.9197\n",
      "Epoch 913/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1875 - accuracy: 0.9179 - val_loss: 0.2094 - val_accuracy: 0.9132\n",
      "Epoch 914/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1780 - accuracy: 0.9226 - val_loss: 0.1897 - val_accuracy: 0.9206\n",
      "Epoch 915/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1767 - accuracy: 0.9227 - val_loss: 0.1877 - val_accuracy: 0.9205\n",
      "Epoch 916/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1797 - accuracy: 0.9215 - val_loss: 0.2000 - val_accuracy: 0.9178\n",
      "Epoch 917/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2087 - accuracy: 0.9123 - val_loss: 0.2129 - val_accuracy: 0.9120\n",
      "Epoch 918/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1944 - accuracy: 0.9164 - val_loss: 0.1857 - val_accuracy: 0.9214\n",
      "Epoch 919/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1871 - accuracy: 0.9191 - val_loss: 0.2065 - val_accuracy: 0.9158\n",
      "Epoch 920/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1839 - accuracy: 0.9207 - val_loss: 0.1919 - val_accuracy: 0.9183\n",
      "Epoch 921/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1872 - accuracy: 0.9189 - val_loss: 0.2010 - val_accuracy: 0.9153\n",
      "Epoch 922/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1804 - accuracy: 0.9221 - val_loss: 0.1964 - val_accuracy: 0.9175\n",
      "Epoch 923/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1727 - accuracy: 0.9246 - val_loss: 0.1802 - val_accuracy: 0.9225\n",
      "Epoch 924/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1845 - accuracy: 0.9200 - val_loss: 0.1871 - val_accuracy: 0.9206\n",
      "Epoch 925/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1878 - accuracy: 0.9194 - val_loss: 0.2010 - val_accuracy: 0.9172\n",
      "Epoch 926/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1859 - accuracy: 0.9187 - val_loss: 0.1910 - val_accuracy: 0.9188\n",
      "Epoch 927/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1763 - accuracy: 0.9230 - val_loss: 0.1929 - val_accuracy: 0.9197\n",
      "Epoch 928/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1934 - accuracy: 0.9184 - val_loss: 0.1846 - val_accuracy: 0.9240\n",
      "Epoch 929/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1768 - accuracy: 0.9224 - val_loss: 0.1809 - val_accuracy: 0.9212\n",
      "Epoch 930/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1876 - accuracy: 0.9194 - val_loss: 0.1969 - val_accuracy: 0.9151\n",
      "Epoch 931/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1773 - accuracy: 0.9226 - val_loss: 0.1762 - val_accuracy: 0.9215\n",
      "Epoch 932/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1771 - accuracy: 0.9224 - val_loss: 0.2031 - val_accuracy: 0.9171\n",
      "Epoch 933/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1836 - accuracy: 0.9210 - val_loss: 0.2093 - val_accuracy: 0.9138\n",
      "Epoch 934/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1851 - accuracy: 0.9202 - val_loss: 0.2052 - val_accuracy: 0.9132\n",
      "Epoch 935/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1807 - accuracy: 0.9214 - val_loss: 0.1894 - val_accuracy: 0.9199\n",
      "Epoch 936/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1828 - accuracy: 0.9200 - val_loss: 0.1818 - val_accuracy: 0.9241\n",
      "Epoch 937/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1801 - accuracy: 0.9205 - val_loss: 0.1816 - val_accuracy: 0.9262\n",
      "Epoch 938/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1763 - accuracy: 0.9229 - val_loss: 0.1824 - val_accuracy: 0.9232\n",
      "Epoch 939/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1710 - accuracy: 0.9243 - val_loss: 0.1822 - val_accuracy: 0.9209\n",
      "Epoch 940/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1847 - accuracy: 0.9189 - val_loss: 0.1839 - val_accuracy: 0.9223\n",
      "Epoch 941/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1941 - accuracy: 0.9160 - val_loss: 0.1926 - val_accuracy: 0.9167\n",
      "Epoch 942/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1932 - accuracy: 0.9168 - val_loss: 0.1914 - val_accuracy: 0.9188\n",
      "Epoch 943/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1982 - accuracy: 0.9149 - val_loss: 0.1856 - val_accuracy: 0.9223\n",
      "Epoch 944/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2700 - accuracy: 0.8929 - val_loss: 0.2096 - val_accuracy: 0.9144\n",
      "Epoch 945/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2013 - accuracy: 0.9150 - val_loss: 0.2315 - val_accuracy: 0.9105\n",
      "Epoch 946/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1990 - accuracy: 0.9156 - val_loss: 0.1936 - val_accuracy: 0.9194\n",
      "Epoch 947/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1881 - accuracy: 0.9188 - val_loss: 0.1919 - val_accuracy: 0.9178\n",
      "Epoch 948/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1906 - accuracy: 0.9177 - val_loss: 0.1905 - val_accuracy: 0.9203\n",
      "Epoch 949/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.2160 - val_accuracy: 0.9112\n",
      "Epoch 950/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1934 - accuracy: 0.9172 - val_loss: 0.1840 - val_accuracy: 0.9239\n",
      "Epoch 951/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1738 - accuracy: 0.9251 - val_loss: 0.1873 - val_accuracy: 0.9214\n",
      "Epoch 952/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1759 - accuracy: 0.9237 - val_loss: 0.2037 - val_accuracy: 0.9167\n",
      "Epoch 953/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1780 - accuracy: 0.9222 - val_loss: 0.1826 - val_accuracy: 0.9221\n",
      "Epoch 954/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1767 - accuracy: 0.9232 - val_loss: 0.1951 - val_accuracy: 0.9182\n",
      "Epoch 955/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2036 - accuracy: 0.9140 - val_loss: 0.2100 - val_accuracy: 0.9130\n",
      "Epoch 956/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1906 - accuracy: 0.9183 - val_loss: 0.1926 - val_accuracy: 0.9179\n",
      "Epoch 957/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1779 - accuracy: 0.9222 - val_loss: 0.1845 - val_accuracy: 0.9225\n",
      "Epoch 958/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1748 - accuracy: 0.9236 - val_loss: 0.1836 - val_accuracy: 0.9231\n",
      "Epoch 959/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1816 - accuracy: 0.9212 - val_loss: 0.1926 - val_accuracy: 0.9216\n",
      "Epoch 960/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1980 - accuracy: 0.9180 - val_loss: 0.3722 - val_accuracy: 0.8619\n",
      "Epoch 961/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2582 - accuracy: 0.8957 - val_loss: 0.2505 - val_accuracy: 0.9028\n",
      "Epoch 962/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2300 - accuracy: 0.9053 - val_loss: 0.2153 - val_accuracy: 0.9126\n",
      "Epoch 963/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2086 - accuracy: 0.9124 - val_loss: 0.2019 - val_accuracy: 0.9190\n",
      "Epoch 964/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1981 - accuracy: 0.9167 - val_loss: 0.2157 - val_accuracy: 0.9112\n",
      "Epoch 965/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2089 - accuracy: 0.9125 - val_loss: 0.1914 - val_accuracy: 0.9205\n",
      "Epoch 966/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1902 - accuracy: 0.9184 - val_loss: 0.1849 - val_accuracy: 0.9223\n",
      "Epoch 967/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1987 - accuracy: 0.9154 - val_loss: 0.2032 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2048 - accuracy: 0.9142 - val_loss: 0.2016 - val_accuracy: 0.9148\n",
      "Epoch 969/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1851 - accuracy: 0.9202 - val_loss: 0.2289 - val_accuracy: 0.9098\n",
      "Epoch 970/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2023 - accuracy: 0.9136 - val_loss: 0.1956 - val_accuracy: 0.9182\n",
      "Epoch 971/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1863 - accuracy: 0.9200 - val_loss: 0.2052 - val_accuracy: 0.9118\n",
      "Epoch 972/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2087 - accuracy: 0.9130 - val_loss: 0.2186 - val_accuracy: 0.9107\n",
      "Epoch 973/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1998 - accuracy: 0.9152 - val_loss: 0.2165 - val_accuracy: 0.9105\n",
      "Epoch 974/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1976 - accuracy: 0.9160 - val_loss: 0.1840 - val_accuracy: 0.9236\n",
      "Epoch 975/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.2011 - accuracy: 0.9168 - val_loss: 0.2017 - val_accuracy: 0.9187\n",
      "Epoch 976/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1950 - accuracy: 0.9181 - val_loss: 0.1972 - val_accuracy: 0.9196\n",
      "Epoch 977/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1824 - accuracy: 0.9220 - val_loss: 0.1885 - val_accuracy: 0.9214\n",
      "Epoch 978/1000\n",
      "87/87 [==============================] - 4s 41ms/step - loss: 0.1770 - accuracy: 0.9221 - val_loss: 0.1842 - val_accuracy: 0.9250\n",
      "Epoch 979/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1738 - accuracy: 0.9236 - val_loss: 0.1845 - val_accuracy: 0.9227\n",
      "Epoch 980/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1999 - accuracy: 0.9152 - val_loss: 0.2257 - val_accuracy: 0.9096\n",
      "Epoch 981/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1953 - accuracy: 0.9169 - val_loss: 0.2244 - val_accuracy: 0.9113\n",
      "Epoch 982/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1878 - accuracy: 0.9192 - val_loss: 0.2089 - val_accuracy: 0.9145\n",
      "Epoch 983/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1968 - accuracy: 0.9166 - val_loss: 0.1946 - val_accuracy: 0.9186\n",
      "Epoch 984/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1805 - accuracy: 0.9222 - val_loss: 0.1864 - val_accuracy: 0.9242\n",
      "Epoch 985/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1919 - accuracy: 0.9168 - val_loss: 0.1959 - val_accuracy: 0.9174\n",
      "Epoch 986/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1872 - accuracy: 0.9188 - val_loss: 0.2079 - val_accuracy: 0.9116\n",
      "Epoch 987/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2051 - accuracy: 0.9135 - val_loss: 0.2041 - val_accuracy: 0.9148\n",
      "Epoch 988/1000\n",
      "87/87 [==============================] - 4s 45ms/step - loss: 0.1858 - accuracy: 0.9191 - val_loss: 0.2000 - val_accuracy: 0.9187\n",
      "Epoch 989/1000\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 0.1859 - accuracy: 0.9197 - val_loss: 0.1992 - val_accuracy: 0.9162\n",
      "Epoch 990/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1831 - accuracy: 0.9209 - val_loss: 0.2064 - val_accuracy: 0.9166\n",
      "Epoch 991/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1963 - accuracy: 0.9159 - val_loss: 0.1888 - val_accuracy: 0.9220\n",
      "Epoch 992/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2146 - accuracy: 0.9097 - val_loss: 0.1949 - val_accuracy: 0.9212\n",
      "Epoch 993/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2187 - accuracy: 0.9086 - val_loss: 0.1997 - val_accuracy: 0.9167\n",
      "Epoch 994/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2311 - accuracy: 0.9042 - val_loss: 0.2175 - val_accuracy: 0.9130\n",
      "Epoch 995/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.2101 - accuracy: 0.9123 - val_loss: 0.2206 - val_accuracy: 0.9088\n",
      "Epoch 996/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.2153 - accuracy: 0.9101 - val_loss: 0.1980 - val_accuracy: 0.9182\n",
      "Epoch 997/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1886 - accuracy: 0.9185 - val_loss: 0.1982 - val_accuracy: 0.9190\n",
      "Epoch 998/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1938 - accuracy: 0.9169 - val_loss: 0.1989 - val_accuracy: 0.9161\n",
      "Epoch 999/1000\n",
      "87/87 [==============================] - 4s 44ms/step - loss: 0.1985 - accuracy: 0.9145 - val_loss: 0.2042 - val_accuracy: 0.9148\n",
      "Epoch 1000/1000\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 0.1849 - accuracy: 0.9195 - val_loss: 0.1872 - val_accuracy: 0.9234\n",
      "108/108 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.9222\n",
      "Test Loss: 0.1861\n",
      "Test Accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 모델 정의\n",
    "theta_input = Input(shape=(1,), name='theta_input')\n",
    "phi_input = Input(shape=(1,), name='phi_input')\n",
    "\n",
    "# theta와 phi를 Concatenate\n",
    "merged = Concatenate()([theta_input, phi_input])\n",
    "\n",
    "# 시퀀스를 예측하기 위한 SimpleRNN 레이어\n",
    "repeated_vector = RepeatVector(max_seq_length)(merged)  # max_sequence_length는 시퀀스의 최대 길이\n",
    "\n",
    "rnn_layer = SimpleRNN(256, return_sequences=True, name='rnn_layer')(repeated_vector)\n",
    "\n",
    "output = TimeDistributed(Dense(5, activation='softmax'), name='output_layer')(rnn_layer)\n",
    "\n",
    "model = Model(inputs=[theta_input, phi_input], outputs=output)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit([theta_train, phi_train], np.expand_dims(sequence_train, -1), \n",
    "                    validation_data=([theta_val, phi_val], np.expand_dims(sequence_val, -1)), epochs=1000, batch_size=128)\n",
    "\n",
    "# 검증\n",
    "loss, accuracy = model.evaluate([theta_test, phi_test], np.expand_dims(sequence_test, -1))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/108 [>.............................] - ETA: 1s - loss: 0.1825 - accuracy: 0.9180 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeojung/.conda/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['sequence_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.9222\n",
      "Test Accuracy: 92.22\n",
      "Test Loss: 18.61\n"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "         # Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 70, 0, 0.01])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        # plt.axis([45, 60, 0.999, 1.0])\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(model, theta, phi, sequence):\n",
    "    loss, acc = model.evaluate({'theta_input': theta, 'phi_input': phi, 'sequence_input': sequence}, np.expand_dims(sequence, -1))\n",
    "    print(\"Test Accuracy: {:.2f}\".format(acc*100))\n",
    "    print(\"Test Loss: {:.2f}\".format(loss*100))\n",
    "\n",
    "# 결과 그래프 그리기\n",
    "plot_history(history)\n",
    "\n",
    "# 모델 성능 평가\n",
    "evaluate(model, theta_test, phi_test, sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 디렉토리 생성\n",
    "models_dir = 'saved_models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "# 모델 저장\n",
    "model.save(os.path.join(models_dir, \"NVspin_SimpleRNN_model.h5\"))\n",
    "\n",
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"SimpleRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "Results saved to simpleRNN_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "df_results = pd.DataFrame({\n",
    "    'Theta': theta_samples.ravel(),\n",
    "    'Phi': phi_samples.ravel(),\n",
    "    'Actual Sequence': [list(seq) for seq in sequence_samples],\n",
    "    'Predicted Sequence': [list(seq) for seq in predicted_sequences]\n",
    "})\n",
    "\n",
    "# 결과를 저장할 디렉토리 생성\n",
    "results_dir = 'sample_simpleRNN'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results.to_csv(os.path.join(results_dir, 'simpleRNN_results.csv'), index=False)\n",
    "\n",
    "print(\"Results saved to simpleRNN_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Sample 1:\n",
      "Theta    : [0.25019659]\n",
      "Phi      : [4.22272085]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      "----------\n",
      "Sample 2:\n",
      "Theta    : [0.14008434]\n",
      "Phi      : [1.00165046]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n",
      "Sample 3:\n",
      "Theta    : [2.91582152]\n",
      "Phi      : [1.7600918]\n",
      "Actual   : [0 0 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 4]\n",
      "Predicted: [0 0 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 1]\n",
      "----------\n",
      "Sample 4:\n",
      "Theta    : [0.08155872]\n",
      "Phi      : [3.73591258]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "----------\n",
      "Sample 5:\n",
      "Theta    : [3.12046623]\n",
      "Phi      : [2.98315861]\n",
      "Actual   : [0 0 0 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1]\n",
      "Predicted: [0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1]\n",
      "----------\n",
      "Sample 6:\n",
      "Theta    : [1.41057273]\n",
      "Phi      : [2.11074559]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 4 4 3 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 1 2]\n",
      "----------\n",
      "Sample 7:\n",
      "Theta    : [1.28855062]\n",
      "Phi      : [4.08101479]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3 2 2 4 4 1 1 3 3 2 2]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2]\n",
      "----------\n",
      "Sample 8:\n",
      "Theta    : [2.39451833]\n",
      "Phi      : [5.00231203]\n",
      "Actual   : [0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 0 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 4 1 1 3 3 2 2 4 1]\n",
      "----------\n",
      "Sample 9:\n",
      "Theta    : [0.40436158]\n",
      "Phi      : [0.93015823]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1 1]\n",
      "----------\n",
      "Sample 10:\n",
      "Theta    : [1.05773823]\n",
      "Phi      : [4.56989323]\n",
      "Actual   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 4 1 1 3 3 2 2 4]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 10개의 샘플을 무작위로 선택\n",
    "indices = np.random.choice(len(theta_test), 10)\n",
    "\n",
    "theta_samples = np.array(theta_test)[indices]\n",
    "phi_samples = np.array(phi_test)[indices]\n",
    "sequence_samples = np.array(sequence_test)[indices]\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "predicted_sequences = model.predict([theta_samples, phi_samples])\n",
    "\n",
    "# 가장 확률이 높은 클래스의 인덱스를 선택\n",
    "predicted_sequences = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(\"Theta    :\", theta_samples[i])\n",
    "    print(\"Phi      :\", phi_samples[i])\n",
    "    print(\"Actual   :\", sequence_samples[i])\n",
    "    print(\"Predicted:\", predicted_sequences[i])\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
